/* Generated by Cython 0.29.37 */

/* BEGIN: Cython Metadata
{
    "distutils": {
        "depends": [
            "C:\\Users\\runneradmin\\AppData\\Local\\Temp\\pip-build-env-b2egv6w5\\overlay\\Lib\\site-packages\\numpy\\core\\include\\numpy\\arrayobject.h",
            "C:\\Users\\runneradmin\\AppData\\Local\\Temp\\pip-build-env-b2egv6w5\\overlay\\Lib\\site-packages\\numpy\\core\\include\\numpy\\arrayscalars.h",
            "C:\\Users\\runneradmin\\AppData\\Local\\Temp\\pip-build-env-b2egv6w5\\overlay\\Lib\\site-packages\\numpy\\core\\include\\numpy\\ndarrayobject.h",
            "C:\\Users\\runneradmin\\AppData\\Local\\Temp\\pip-build-env-b2egv6w5\\overlay\\Lib\\site-packages\\numpy\\core\\include\\numpy\\ndarraytypes.h",
            "C:\\Users\\runneradmin\\AppData\\Local\\Temp\\pip-build-env-b2egv6w5\\overlay\\Lib\\site-packages\\numpy\\core\\include\\numpy\\ufuncobject.h",
            "C:\\Users\\runneradmin\\AppData\\Local\\pypa\\cibuildwheel\\Cache\\nuget-cpython\\python.3.12.4\\tools\\Include\\Python.h"
        ],
        "extra_compile_args": [
            "-std=c++11"
        ],
        "include_dirs": [
            "C:\\Users\\runneradmin\\AppData\\Local\\Temp\\pip-build-env-b2egv6w5\\overlay\\Lib\\site-packages\\numpy\\core\\include",
            "C:\\Users\\runneradmin\\AppData\\Local\\pypa\\cibuildwheel\\Cache\\nuget-cpython\\python.3.12.4\\tools\\Include"
        ],
        "language": "c++",
        "name": "spacy.tokenizer",
        "sources": [
            "spacy/tokenizer.pyx"
        ]
    },
    "module_name": "spacy.tokenizer"
}
END: Cython Metadata */

#ifndef PY_SSIZE_T_CLEAN
#define PY_SSIZE_T_CLEAN
#endif /* PY_SSIZE_T_CLEAN */
#include "Python.h"
#ifndef Py_PYTHON_H
    #error Python headers needed to compile C extensions, please install development version of Python.
#elif PY_VERSION_HEX < 0x02060000 || (0x03000000 <= PY_VERSION_HEX && PY_VERSION_HEX < 0x03030000)
    #error Cython requires Python 2.6+ or Python 3.3+.
#else
#define CYTHON_ABI "0_29_37"
#define CYTHON_HEX_VERSION 0x001D25F0
#define CYTHON_FUTURE_DIVISION 0
#include <stddef.h>
#ifndef offsetof
  #define offsetof(type, member) ( (size_t) & ((type*)0) -> member )
#endif
#if !defined(WIN32) && !defined(MS_WINDOWS)
  #ifndef __stdcall
    #define __stdcall
  #endif
  #ifndef __cdecl
    #define __cdecl
  #endif
  #ifndef __fastcall
    #define __fastcall
  #endif
#endif
#ifndef DL_IMPORT
  #define DL_IMPORT(t) t
#endif
#ifndef DL_EXPORT
  #define DL_EXPORT(t) t
#endif
#define __PYX_COMMA ,
#ifndef HAVE_LONG_LONG
  #if PY_VERSION_HEX >= 0x02070000
    #define HAVE_LONG_LONG
  #endif
#endif
#ifndef PY_LONG_LONG
  #define PY_LONG_LONG LONG_LONG
#endif
#ifndef Py_HUGE_VAL
  #define Py_HUGE_VAL HUGE_VAL
#endif
#ifdef PYPY_VERSION
  #define CYTHON_COMPILING_IN_PYPY 1
  #define CYTHON_COMPILING_IN_PYSTON 0
  #define CYTHON_COMPILING_IN_CPYTHON 0
  #define CYTHON_COMPILING_IN_NOGIL 0
  #undef CYTHON_USE_TYPE_SLOTS
  #define CYTHON_USE_TYPE_SLOTS 0
  #undef CYTHON_USE_PYTYPE_LOOKUP
  #define CYTHON_USE_PYTYPE_LOOKUP 0
  #if PY_VERSION_HEX < 0x03050000
    #undef CYTHON_USE_ASYNC_SLOTS
    #define CYTHON_USE_ASYNC_SLOTS 0
  #elif !defined(CYTHON_USE_ASYNC_SLOTS)
    #define CYTHON_USE_ASYNC_SLOTS 1
  #endif
  #undef CYTHON_USE_PYLIST_INTERNALS
  #define CYTHON_USE_PYLIST_INTERNALS 0
  #undef CYTHON_USE_UNICODE_INTERNALS
  #define CYTHON_USE_UNICODE_INTERNALS 0
  #undef CYTHON_USE_UNICODE_WRITER
  #define CYTHON_USE_UNICODE_WRITER 0
  #undef CYTHON_USE_PYLONG_INTERNALS
  #define CYTHON_USE_PYLONG_INTERNALS 0
  #undef CYTHON_AVOID_BORROWED_REFS
  #define CYTHON_AVOID_BORROWED_REFS 1
  #undef CYTHON_ASSUME_SAFE_MACROS
  #define CYTHON_ASSUME_SAFE_MACROS 0
  #undef CYTHON_UNPACK_METHODS
  #define CYTHON_UNPACK_METHODS 0
  #undef CYTHON_FAST_THREAD_STATE
  #define CYTHON_FAST_THREAD_STATE 0
  #undef CYTHON_FAST_PYCALL
  #define CYTHON_FAST_PYCALL 0
  #if PY_VERSION_HEX < 0x03090000
    #undef CYTHON_PEP489_MULTI_PHASE_INIT
    #define CYTHON_PEP489_MULTI_PHASE_INIT 0
  #elif !defined(CYTHON_PEP489_MULTI_PHASE_INIT)
    #define CYTHON_PEP489_MULTI_PHASE_INIT 1
  #endif
  #undef CYTHON_USE_TP_FINALIZE
  #define CYTHON_USE_TP_FINALIZE (PY_VERSION_HEX >= 0x030400a1 && PYPY_VERSION_NUM >= 0x07030C00)
  #undef CYTHON_USE_DICT_VERSIONS
  #define CYTHON_USE_DICT_VERSIONS 0
  #undef CYTHON_USE_EXC_INFO_STACK
  #define CYTHON_USE_EXC_INFO_STACK 0
  #ifndef CYTHON_UPDATE_DESCRIPTOR_DOC
    #define CYTHON_UPDATE_DESCRIPTOR_DOC 0
  #endif
#elif defined(PYSTON_VERSION)
  #define CYTHON_COMPILING_IN_PYPY 0
  #define CYTHON_COMPILING_IN_PYSTON 1
  #define CYTHON_COMPILING_IN_CPYTHON 0
  #define CYTHON_COMPILING_IN_NOGIL 0
  #ifndef CYTHON_USE_TYPE_SLOTS
    #define CYTHON_USE_TYPE_SLOTS 1
  #endif
  #undef CYTHON_USE_PYTYPE_LOOKUP
  #define CYTHON_USE_PYTYPE_LOOKUP 0
  #undef CYTHON_USE_ASYNC_SLOTS
  #define CYTHON_USE_ASYNC_SLOTS 0
  #undef CYTHON_USE_PYLIST_INTERNALS
  #define CYTHON_USE_PYLIST_INTERNALS 0
  #ifndef CYTHON_USE_UNICODE_INTERNALS
    #define CYTHON_USE_UNICODE_INTERNALS 1
  #endif
  #undef CYTHON_USE_UNICODE_WRITER
  #define CYTHON_USE_UNICODE_WRITER 0
  #undef CYTHON_USE_PYLONG_INTERNALS
  #define CYTHON_USE_PYLONG_INTERNALS 0
  #ifndef CYTHON_AVOID_BORROWED_REFS
    #define CYTHON_AVOID_BORROWED_REFS 0
  #endif
  #ifndef CYTHON_ASSUME_SAFE_MACROS
    #define CYTHON_ASSUME_SAFE_MACROS 1
  #endif
  #ifndef CYTHON_UNPACK_METHODS
    #define CYTHON_UNPACK_METHODS 1
  #endif
  #undef CYTHON_FAST_THREAD_STATE
  #define CYTHON_FAST_THREAD_STATE 0
  #undef CYTHON_FAST_PYCALL
  #define CYTHON_FAST_PYCALL 0
  #undef CYTHON_PEP489_MULTI_PHASE_INIT
  #define CYTHON_PEP489_MULTI_PHASE_INIT 0
  #undef CYTHON_USE_TP_FINALIZE
  #define CYTHON_USE_TP_FINALIZE 0
  #undef CYTHON_USE_DICT_VERSIONS
  #define CYTHON_USE_DICT_VERSIONS 0
  #undef CYTHON_USE_EXC_INFO_STACK
  #define CYTHON_USE_EXC_INFO_STACK 0
  #ifndef CYTHON_UPDATE_DESCRIPTOR_DOC
    #define CYTHON_UPDATE_DESCRIPTOR_DOC 0
  #endif
#elif defined(PY_NOGIL)
  #define CYTHON_COMPILING_IN_PYPY 0
  #define CYTHON_COMPILING_IN_PYSTON 0
  #define CYTHON_COMPILING_IN_CPYTHON 0
  #define CYTHON_COMPILING_IN_NOGIL 1
  #ifndef CYTHON_USE_TYPE_SLOTS
    #define CYTHON_USE_TYPE_SLOTS 1
  #endif
  #undef CYTHON_USE_PYTYPE_LOOKUP
  #define CYTHON_USE_PYTYPE_LOOKUP 0
  #ifndef CYTHON_USE_ASYNC_SLOTS
    #define CYTHON_USE_ASYNC_SLOTS 1
  #endif
  #undef CYTHON_USE_PYLIST_INTERNALS
  #define CYTHON_USE_PYLIST_INTERNALS 0
  #ifndef CYTHON_USE_UNICODE_INTERNALS
    #define CYTHON_USE_UNICODE_INTERNALS 1
  #endif
  #undef CYTHON_USE_UNICODE_WRITER
  #define CYTHON_USE_UNICODE_WRITER 0
  #undef CYTHON_USE_PYLONG_INTERNALS
  #define CYTHON_USE_PYLONG_INTERNALS 0
  #ifndef CYTHON_AVOID_BORROWED_REFS
    #define CYTHON_AVOID_BORROWED_REFS 0
  #endif
  #ifndef CYTHON_ASSUME_SAFE_MACROS
    #define CYTHON_ASSUME_SAFE_MACROS 1
  #endif
  #ifndef CYTHON_UNPACK_METHODS
    #define CYTHON_UNPACK_METHODS 1
  #endif
  #undef CYTHON_FAST_THREAD_STATE
  #define CYTHON_FAST_THREAD_STATE 0
  #undef CYTHON_FAST_PYCALL
  #define CYTHON_FAST_PYCALL 0
  #ifndef CYTHON_PEP489_MULTI_PHASE_INIT
    #define CYTHON_PEP489_MULTI_PHASE_INIT 1
  #endif
  #ifndef CYTHON_USE_TP_FINALIZE
    #define CYTHON_USE_TP_FINALIZE 1
  #endif
  #undef CYTHON_USE_DICT_VERSIONS
  #define CYTHON_USE_DICT_VERSIONS 0
  #undef CYTHON_USE_EXC_INFO_STACK
  #define CYTHON_USE_EXC_INFO_STACK 0
#else
  #define CYTHON_COMPILING_IN_PYPY 0
  #define CYTHON_COMPILING_IN_PYSTON 0
  #define CYTHON_COMPILING_IN_CPYTHON 1
  #define CYTHON_COMPILING_IN_NOGIL 0
  #ifndef CYTHON_USE_TYPE_SLOTS
    #define CYTHON_USE_TYPE_SLOTS 1
  #endif
  #if PY_VERSION_HEX < 0x02070000
    #undef CYTHON_USE_PYTYPE_LOOKUP
    #define CYTHON_USE_PYTYPE_LOOKUP 0
  #elif !defined(CYTHON_USE_PYTYPE_LOOKUP)
    #define CYTHON_USE_PYTYPE_LOOKUP 1
  #endif
  #if PY_MAJOR_VERSION < 3
    #undef CYTHON_USE_ASYNC_SLOTS
    #define CYTHON_USE_ASYNC_SLOTS 0
  #elif !defined(CYTHON_USE_ASYNC_SLOTS)
    #define CYTHON_USE_ASYNC_SLOTS 1
  #endif
  #if PY_VERSION_HEX < 0x02070000
    #undef CYTHON_USE_PYLONG_INTERNALS
    #define CYTHON_USE_PYLONG_INTERNALS 0
  #elif !defined(CYTHON_USE_PYLONG_INTERNALS)
    #define CYTHON_USE_PYLONG_INTERNALS (PY_VERSION_HEX < 0x030C00A5)
  #endif
  #ifndef CYTHON_USE_PYLIST_INTERNALS
    #define CYTHON_USE_PYLIST_INTERNALS 1
  #endif
  #ifndef CYTHON_USE_UNICODE_INTERNALS
    #define CYTHON_USE_UNICODE_INTERNALS 1
  #endif
  #if PY_VERSION_HEX < 0x030300F0 || PY_VERSION_HEX >= 0x030B00A2
    #undef CYTHON_USE_UNICODE_WRITER
    #define CYTHON_USE_UNICODE_WRITER 0
  #elif !defined(CYTHON_USE_UNICODE_WRITER)
    #define CYTHON_USE_UNICODE_WRITER 1
  #endif
  #ifndef CYTHON_AVOID_BORROWED_REFS
    #define CYTHON_AVOID_BORROWED_REFS 0
  #endif
  #ifndef CYTHON_ASSUME_SAFE_MACROS
    #define CYTHON_ASSUME_SAFE_MACROS 1
  #endif
  #ifndef CYTHON_UNPACK_METHODS
    #define CYTHON_UNPACK_METHODS 1
  #endif
  #if PY_VERSION_HEX >= 0x030B00A4
    #undef CYTHON_FAST_THREAD_STATE
    #define CYTHON_FAST_THREAD_STATE 0
  #elif !defined(CYTHON_FAST_THREAD_STATE)
    #define CYTHON_FAST_THREAD_STATE 1
  #endif
  #ifndef CYTHON_FAST_PYCALL
    #define CYTHON_FAST_PYCALL (PY_VERSION_HEX < 0x030A0000)
  #endif
  #ifndef CYTHON_PEP489_MULTI_PHASE_INIT
    #define CYTHON_PEP489_MULTI_PHASE_INIT (PY_VERSION_HEX >= 0x03050000)
  #endif
  #ifndef CYTHON_USE_TP_FINALIZE
    #define CYTHON_USE_TP_FINALIZE (PY_VERSION_HEX >= 0x030400a1)
  #endif
  #ifndef CYTHON_USE_DICT_VERSIONS
    #define CYTHON_USE_DICT_VERSIONS ((PY_VERSION_HEX >= 0x030600B1) && (PY_VERSION_HEX < 0x030C00A5))
  #endif
  #if PY_VERSION_HEX >= 0x030B00A4
    #undef CYTHON_USE_EXC_INFO_STACK
    #define CYTHON_USE_EXC_INFO_STACK 0
  #elif !defined(CYTHON_USE_EXC_INFO_STACK)
    #define CYTHON_USE_EXC_INFO_STACK (PY_VERSION_HEX >= 0x030700A3)
  #endif
  #ifndef CYTHON_UPDATE_DESCRIPTOR_DOC
    #define CYTHON_UPDATE_DESCRIPTOR_DOC 1
  #endif
#endif
#if !defined(CYTHON_FAST_PYCCALL)
#define CYTHON_FAST_PYCCALL  (CYTHON_FAST_PYCALL && PY_VERSION_HEX >= 0x030600B1)
#endif
#if CYTHON_USE_PYLONG_INTERNALS
  #if PY_MAJOR_VERSION < 3
    #include "longintrepr.h"
  #endif
  #undef SHIFT
  #undef BASE
  #undef MASK
  #ifdef SIZEOF_VOID_P
    enum { __pyx_check_sizeof_voidp = 1 / (int)(SIZEOF_VOID_P == sizeof(void*)) };
  #endif
#endif
#ifndef __has_attribute
  #define __has_attribute(x) 0
#endif
#ifndef __has_cpp_attribute
  #define __has_cpp_attribute(x) 0
#endif
#ifndef CYTHON_RESTRICT
  #if defined(__GNUC__)
    #define CYTHON_RESTRICT __restrict__
  #elif defined(_MSC_VER) && _MSC_VER >= 1400
    #define CYTHON_RESTRICT __restrict
  #elif defined (__STDC_VERSION__) && __STDC_VERSION__ >= 199901L
    #define CYTHON_RESTRICT restrict
  #else
    #define CYTHON_RESTRICT
  #endif
#endif
#ifndef CYTHON_UNUSED
# if defined(__GNUC__)
#   if !(defined(__cplusplus)) || (__GNUC__ > 3 || (__GNUC__ == 3 && __GNUC_MINOR__ >= 4))
#     define CYTHON_UNUSED __attribute__ ((__unused__))
#   else
#     define CYTHON_UNUSED
#   endif
# elif defined(__ICC) || (defined(__INTEL_COMPILER) && !defined(_MSC_VER))
#   define CYTHON_UNUSED __attribute__ ((__unused__))
# else
#   define CYTHON_UNUSED
# endif
#endif
#ifndef CYTHON_MAYBE_UNUSED_VAR
#  if defined(__cplusplus)
     template<class T> void CYTHON_MAYBE_UNUSED_VAR( const T& ) { }
#  else
#    define CYTHON_MAYBE_UNUSED_VAR(x) (void)(x)
#  endif
#endif
#ifndef CYTHON_NCP_UNUSED
# if CYTHON_COMPILING_IN_CPYTHON
#  define CYTHON_NCP_UNUSED
# else
#  define CYTHON_NCP_UNUSED CYTHON_UNUSED
# endif
#endif
#define __Pyx_void_to_None(void_result) ((void)(void_result), Py_INCREF(Py_None), Py_None)
#ifdef _MSC_VER
    #ifndef _MSC_STDINT_H_
        #if _MSC_VER < 1300
           typedef unsigned char     uint8_t;
           typedef unsigned int      uint32_t;
        #else
           typedef unsigned __int8   uint8_t;
           typedef unsigned __int32  uint32_t;
        #endif
    #endif
#else
   #include <stdint.h>
#endif
#ifndef CYTHON_FALLTHROUGH
  #if defined(__cplusplus) && __cplusplus >= 201103L
    #if __has_cpp_attribute(fallthrough)
      #define CYTHON_FALLTHROUGH [[fallthrough]]
    #elif __has_cpp_attribute(clang::fallthrough)
      #define CYTHON_FALLTHROUGH [[clang::fallthrough]]
    #elif __has_cpp_attribute(gnu::fallthrough)
      #define CYTHON_FALLTHROUGH [[gnu::fallthrough]]
    #endif
  #endif
  #ifndef CYTHON_FALLTHROUGH
    #if __has_attribute(fallthrough)
      #define CYTHON_FALLTHROUGH __attribute__((fallthrough))
    #else
      #define CYTHON_FALLTHROUGH
    #endif
  #endif
  #if defined(__clang__ ) && defined(__apple_build_version__)
    #if __apple_build_version__ < 7000000
      #undef  CYTHON_FALLTHROUGH
      #define CYTHON_FALLTHROUGH
    #endif
  #endif
#endif

#ifndef __cplusplus
  #error "Cython files generated with the C++ option must be compiled with a C++ compiler."
#endif
#ifndef CYTHON_INLINE
  #if defined(__clang__)
    #define CYTHON_INLINE __inline__ __attribute__ ((__unused__))
  #else
    #define CYTHON_INLINE inline
  #endif
#endif
template<typename T>
void __Pyx_call_destructor(T& x) {
    x.~T();
}
template<typename T>
class __Pyx_FakeReference {
  public:
    __Pyx_FakeReference() : ptr(NULL) { }
    __Pyx_FakeReference(const T& ref) : ptr(const_cast<T*>(&ref)) { }
    T *operator->() { return ptr; }
    T *operator&() { return ptr; }
    operator T&() { return *ptr; }
    template<typename U> bool operator ==(U other) { return *ptr == other; }
    template<typename U> bool operator !=(U other) { return *ptr != other; }
  private:
    T *ptr;
};

#define __PYX_BUILD_PY_SSIZE_T "n"
#define CYTHON_FORMAT_SSIZE_T "z"
#if PY_MAJOR_VERSION < 3
  #define __Pyx_BUILTIN_MODULE_NAME "__builtin__"
  #define __Pyx_PyCode_New(a, k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos)\
          PyCode_New(a+k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos)
  #define __Pyx_DefaultClassType PyClass_Type
#else
  #define __Pyx_BUILTIN_MODULE_NAME "builtins"
  #define __Pyx_DefaultClassType PyType_Type
#if PY_VERSION_HEX >= 0x030B00A1
    static CYTHON_INLINE PyCodeObject* __Pyx_PyCode_New(int a, int k, int l, int s, int f,
                                                    PyObject *code, PyObject *c, PyObject* n, PyObject *v,
                                                    PyObject *fv, PyObject *cell, PyObject* fn,
                                                    PyObject *name, int fline, PyObject *lnos) {
        PyObject *kwds=NULL, *argcount=NULL, *posonlyargcount=NULL, *kwonlyargcount=NULL;
        PyObject *nlocals=NULL, *stacksize=NULL, *flags=NULL, *replace=NULL, *call_result=NULL, *empty=NULL;
        const char *fn_cstr=NULL;
        const char *name_cstr=NULL;
        PyCodeObject* co=NULL;
        PyObject *type, *value, *traceback;
        PyErr_Fetch(&type, &value, &traceback);
        if (!(kwds=PyDict_New())) goto end;
        if (!(argcount=PyLong_FromLong(a))) goto end;
        if (PyDict_SetItemString(kwds, "co_argcount", argcount) != 0) goto end;
        if (!(posonlyargcount=PyLong_FromLong(0))) goto end;
        if (PyDict_SetItemString(kwds, "co_posonlyargcount", posonlyargcount) != 0) goto end;
        if (!(kwonlyargcount=PyLong_FromLong(k))) goto end;
        if (PyDict_SetItemString(kwds, "co_kwonlyargcount", kwonlyargcount) != 0) goto end;
        if (!(nlocals=PyLong_FromLong(l))) goto end;
        if (PyDict_SetItemString(kwds, "co_nlocals", nlocals) != 0) goto end;
        if (!(stacksize=PyLong_FromLong(s))) goto end;
        if (PyDict_SetItemString(kwds, "co_stacksize", stacksize) != 0) goto end;
        if (!(flags=PyLong_FromLong(f))) goto end;
        if (PyDict_SetItemString(kwds, "co_flags", flags) != 0) goto end;
        if (PyDict_SetItemString(kwds, "co_code", code) != 0) goto end;
        if (PyDict_SetItemString(kwds, "co_consts", c) != 0) goto end;
        if (PyDict_SetItemString(kwds, "co_names", n) != 0) goto end;
        if (PyDict_SetItemString(kwds, "co_varnames", v) != 0) goto end;
        if (PyDict_SetItemString(kwds, "co_freevars", fv) != 0) goto end;
        if (PyDict_SetItemString(kwds, "co_cellvars", cell) != 0) goto end;
        if (PyDict_SetItemString(kwds, "co_linetable", lnos) != 0) goto end;
        if (!(fn_cstr=PyUnicode_AsUTF8AndSize(fn, NULL))) goto end;
        if (!(name_cstr=PyUnicode_AsUTF8AndSize(name, NULL))) goto end;
        if (!(co = PyCode_NewEmpty(fn_cstr, name_cstr, fline))) goto end;
        if (!(replace = PyObject_GetAttrString((PyObject*)co, "replace"))) goto cleanup_code_too;
        if (!(empty = PyTuple_New(0))) goto cleanup_code_too; // unfortunately __pyx_empty_tuple isn't available here
        if (!(call_result = PyObject_Call(replace, empty, kwds))) goto cleanup_code_too;
        Py_XDECREF((PyObject*)co);
        co = (PyCodeObject*)call_result;
        call_result = NULL;
        if (0) {
            cleanup_code_too:
            Py_XDECREF((PyObject*)co);
            co = NULL;
        }
        end:
        Py_XDECREF(kwds);
        Py_XDECREF(argcount);
        Py_XDECREF(posonlyargcount);
        Py_XDECREF(kwonlyargcount);
        Py_XDECREF(nlocals);
        Py_XDECREF(stacksize);
        Py_XDECREF(replace);
        Py_XDECREF(call_result);
        Py_XDECREF(empty);
        if (type) {
            PyErr_Restore(type, value, traceback);
        }
        return co;
    }
#else
  #define __Pyx_PyCode_New(a, k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos)\
          PyCode_New(a, k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos)
#endif
  #define __Pyx_DefaultClassType PyType_Type
#endif
#if PY_VERSION_HEX >= 0x030900F0 && !CYTHON_COMPILING_IN_PYPY
  #define __Pyx_PyObject_GC_IsFinalized(o) PyObject_GC_IsFinalized(o)
#else
  #define __Pyx_PyObject_GC_IsFinalized(o) _PyGC_FINALIZED(o)
#endif
#ifndef Py_TPFLAGS_CHECKTYPES
  #define Py_TPFLAGS_CHECKTYPES 0
#endif
#ifndef Py_TPFLAGS_HAVE_INDEX
  #define Py_TPFLAGS_HAVE_INDEX 0
#endif
#ifndef Py_TPFLAGS_HAVE_NEWBUFFER
  #define Py_TPFLAGS_HAVE_NEWBUFFER 0
#endif
#ifndef Py_TPFLAGS_HAVE_FINALIZE
  #define Py_TPFLAGS_HAVE_FINALIZE 0
#endif
#ifndef METH_STACKLESS
  #define METH_STACKLESS 0
#endif
#if PY_VERSION_HEX <= 0x030700A3 || !defined(METH_FASTCALL)
  #ifndef METH_FASTCALL
     #define METH_FASTCALL 0x80
  #endif
  typedef PyObject *(*__Pyx_PyCFunctionFast) (PyObject *self, PyObject *const *args, Py_ssize_t nargs);
  typedef PyObject *(*__Pyx_PyCFunctionFastWithKeywords) (PyObject *self, PyObject *const *args,
                                                          Py_ssize_t nargs, PyObject *kwnames);
#else
  #define __Pyx_PyCFunctionFast _PyCFunctionFast
  #define __Pyx_PyCFunctionFastWithKeywords _PyCFunctionFastWithKeywords
#endif
#if CYTHON_FAST_PYCCALL
#define __Pyx_PyFastCFunction_Check(func)\
    ((PyCFunction_Check(func) && (METH_FASTCALL == (PyCFunction_GET_FLAGS(func) & ~(METH_CLASS | METH_STATIC | METH_COEXIST | METH_KEYWORDS | METH_STACKLESS)))))
#else
#define __Pyx_PyFastCFunction_Check(func) 0
#endif
#if CYTHON_COMPILING_IN_PYPY && !defined(PyObject_Malloc)
  #define PyObject_Malloc(s)   PyMem_Malloc(s)
  #define PyObject_Free(p)     PyMem_Free(p)
  #define PyObject_Realloc(p)  PyMem_Realloc(p)
#endif
#if CYTHON_COMPILING_IN_CPYTHON && PY_VERSION_HEX < 0x030400A1
  #define PyMem_RawMalloc(n)           PyMem_Malloc(n)
  #define PyMem_RawRealloc(p, n)       PyMem_Realloc(p, n)
  #define PyMem_RawFree(p)             PyMem_Free(p)
#endif
#if CYTHON_COMPILING_IN_PYSTON
  #define __Pyx_PyCode_HasFreeVars(co)  PyCode_HasFreeVars(co)
  #define __Pyx_PyFrame_SetLineNumber(frame, lineno) PyFrame_SetLineNumber(frame, lineno)
#else
  #define __Pyx_PyCode_HasFreeVars(co)  (PyCode_GetNumFree(co) > 0)
  #define __Pyx_PyFrame_SetLineNumber(frame, lineno)  (frame)->f_lineno = (lineno)
#endif
#if !CYTHON_FAST_THREAD_STATE || PY_VERSION_HEX < 0x02070000
  #define __Pyx_PyThreadState_Current PyThreadState_GET()
#elif PY_VERSION_HEX >= 0x03060000
  #define __Pyx_PyThreadState_Current _PyThreadState_UncheckedGet()
#elif PY_VERSION_HEX >= 0x03000000
  #define __Pyx_PyThreadState_Current PyThreadState_GET()
#else
  #define __Pyx_PyThreadState_Current _PyThreadState_Current
#endif
#if PY_VERSION_HEX < 0x030700A2 && !defined(PyThread_tss_create) && !defined(Py_tss_NEEDS_INIT)
#include "pythread.h"
#define Py_tss_NEEDS_INIT 0
typedef int Py_tss_t;
static CYTHON_INLINE int PyThread_tss_create(Py_tss_t *key) {
  *key = PyThread_create_key();
  return 0;
}
static CYTHON_INLINE Py_tss_t * PyThread_tss_alloc(void) {
  Py_tss_t *key = (Py_tss_t *)PyObject_Malloc(sizeof(Py_tss_t));
  *key = Py_tss_NEEDS_INIT;
  return key;
}
static CYTHON_INLINE void PyThread_tss_free(Py_tss_t *key) {
  PyObject_Free(key);
}
static CYTHON_INLINE int PyThread_tss_is_created(Py_tss_t *key) {
  return *key != Py_tss_NEEDS_INIT;
}
static CYTHON_INLINE void PyThread_tss_delete(Py_tss_t *key) {
  PyThread_delete_key(*key);
  *key = Py_tss_NEEDS_INIT;
}
static CYTHON_INLINE int PyThread_tss_set(Py_tss_t *key, void *value) {
  return PyThread_set_key_value(*key, value);
}
static CYTHON_INLINE void * PyThread_tss_get(Py_tss_t *key) {
  return PyThread_get_key_value(*key);
}
#endif
#if CYTHON_COMPILING_IN_CPYTHON || defined(_PyDict_NewPresized)
#define __Pyx_PyDict_NewPresized(n)  ((n <= 8) ? PyDict_New() : _PyDict_NewPresized(n))
#else
#define __Pyx_PyDict_NewPresized(n)  PyDict_New()
#endif
#if PY_MAJOR_VERSION >= 3 || CYTHON_FUTURE_DIVISION
  #define __Pyx_PyNumber_Divide(x,y)         PyNumber_TrueDivide(x,y)
  #define __Pyx_PyNumber_InPlaceDivide(x,y)  PyNumber_InPlaceTrueDivide(x,y)
#else
  #define __Pyx_PyNumber_Divide(x,y)         PyNumber_Divide(x,y)
  #define __Pyx_PyNumber_InPlaceDivide(x,y)  PyNumber_InPlaceDivide(x,y)
#endif
#if CYTHON_COMPILING_IN_CPYTHON && PY_VERSION_HEX >= 0x030500A1 && CYTHON_USE_UNICODE_INTERNALS
#define __Pyx_PyDict_GetItemStr(dict, name)  _PyDict_GetItem_KnownHash(dict, name, ((PyASCIIObject *) name)->hash)
#else
#define __Pyx_PyDict_GetItemStr(dict, name)  PyDict_GetItem(dict, name)
#endif
#if PY_VERSION_HEX > 0x03030000 && defined(PyUnicode_KIND)
  #define CYTHON_PEP393_ENABLED 1
  #if PY_VERSION_HEX >= 0x030C0000
    #define __Pyx_PyUnicode_READY(op)       (0)
  #else
    #define __Pyx_PyUnicode_READY(op)       (likely(PyUnicode_IS_READY(op)) ?\
                                                0 : _PyUnicode_Ready((PyObject *)(op)))
  #endif
  #define __Pyx_PyUnicode_GET_LENGTH(u)   PyUnicode_GET_LENGTH(u)
  #define __Pyx_PyUnicode_READ_CHAR(u, i) PyUnicode_READ_CHAR(u, i)
  #define __Pyx_PyUnicode_MAX_CHAR_VALUE(u)   PyUnicode_MAX_CHAR_VALUE(u)
  #define __Pyx_PyUnicode_KIND(u)         PyUnicode_KIND(u)
  #define __Pyx_PyUnicode_DATA(u)         PyUnicode_DATA(u)
  #define __Pyx_PyUnicode_READ(k, d, i)   PyUnicode_READ(k, d, i)
  #define __Pyx_PyUnicode_WRITE(k, d, i, ch)  PyUnicode_WRITE(k, d, i, ch)
  #if PY_VERSION_HEX >= 0x030C0000
    #define __Pyx_PyUnicode_IS_TRUE(u)      (0 != PyUnicode_GET_LENGTH(u))
  #else
    #if CYTHON_COMPILING_IN_CPYTHON && PY_VERSION_HEX >= 0x03090000
    #define __Pyx_PyUnicode_IS_TRUE(u)      (0 != (likely(PyUnicode_IS_READY(u)) ? PyUnicode_GET_LENGTH(u) : ((PyCompactUnicodeObject *)(u))->wstr_length))
    #else
    #define __Pyx_PyUnicode_IS_TRUE(u)      (0 != (likely(PyUnicode_IS_READY(u)) ? PyUnicode_GET_LENGTH(u) : PyUnicode_GET_SIZE(u)))
    #endif
  #endif
#else
  #define CYTHON_PEP393_ENABLED 0
  #define PyUnicode_1BYTE_KIND  1
  #define PyUnicode_2BYTE_KIND  2
  #define PyUnicode_4BYTE_KIND  4
  #define __Pyx_PyUnicode_READY(op)       (0)
  #define __Pyx_PyUnicode_GET_LENGTH(u)   PyUnicode_GET_SIZE(u)
  #define __Pyx_PyUnicode_READ_CHAR(u, i) ((Py_UCS4)(PyUnicode_AS_UNICODE(u)[i]))
  #define __Pyx_PyUnicode_MAX_CHAR_VALUE(u)   ((sizeof(Py_UNICODE) == 2) ? 65535 : 1114111)
  #define __Pyx_PyUnicode_KIND(u)         (sizeof(Py_UNICODE))
  #define __Pyx_PyUnicode_DATA(u)         ((void*)PyUnicode_AS_UNICODE(u))
  #define __Pyx_PyUnicode_READ(k, d, i)   ((void)(k), (Py_UCS4)(((Py_UNICODE*)d)[i]))
  #define __Pyx_PyUnicode_WRITE(k, d, i, ch)  (((void)(k)), ((Py_UNICODE*)d)[i] = ch)
  #define __Pyx_PyUnicode_IS_TRUE(u)      (0 != PyUnicode_GET_SIZE(u))
#endif
#if CYTHON_COMPILING_IN_PYPY
  #define __Pyx_PyUnicode_Concat(a, b)      PyNumber_Add(a, b)
  #define __Pyx_PyUnicode_ConcatSafe(a, b)  PyNumber_Add(a, b)
#else
  #define __Pyx_PyUnicode_Concat(a, b)      PyUnicode_Concat(a, b)
  #define __Pyx_PyUnicode_ConcatSafe(a, b)  ((unlikely((a) == Py_None) || unlikely((b) == Py_None)) ?\
      PyNumber_Add(a, b) : __Pyx_PyUnicode_Concat(a, b))
#endif
#if CYTHON_COMPILING_IN_PYPY && !defined(PyUnicode_Contains)
  #define PyUnicode_Contains(u, s)  PySequence_Contains(u, s)
#endif
#if CYTHON_COMPILING_IN_PYPY && !defined(PyByteArray_Check)
  #define PyByteArray_Check(obj)  PyObject_TypeCheck(obj, &PyByteArray_Type)
#endif
#if CYTHON_COMPILING_IN_PYPY && !defined(PyObject_Format)
  #define PyObject_Format(obj, fmt)  PyObject_CallMethod(obj, "__format__", "O", fmt)
#endif
#define __Pyx_PyString_FormatSafe(a, b)   ((unlikely((a) == Py_None || (PyString_Check(b) && !PyString_CheckExact(b)))) ? PyNumber_Remainder(a, b) : __Pyx_PyString_Format(a, b))
#define __Pyx_PyUnicode_FormatSafe(a, b)  ((unlikely((a) == Py_None || (PyUnicode_Check(b) && !PyUnicode_CheckExact(b)))) ? PyNumber_Remainder(a, b) : PyUnicode_Format(a, b))
#if PY_MAJOR_VERSION >= 3
  #define __Pyx_PyString_Format(a, b)  PyUnicode_Format(a, b)
#else
  #define __Pyx_PyString_Format(a, b)  PyString_Format(a, b)
#endif
#if PY_MAJOR_VERSION < 3 && !defined(PyObject_ASCII)
  #define PyObject_ASCII(o)            PyObject_Repr(o)
#endif
#if PY_MAJOR_VERSION >= 3
  #define PyBaseString_Type            PyUnicode_Type
  #define PyStringObject               PyUnicodeObject
  #define PyString_Type                PyUnicode_Type
  #define PyString_Check               PyUnicode_Check
  #define PyString_CheckExact          PyUnicode_CheckExact
#ifndef PyObject_Unicode
  #define PyObject_Unicode             PyObject_Str
#endif
#endif
#if PY_MAJOR_VERSION >= 3
  #define __Pyx_PyBaseString_Check(obj) PyUnicode_Check(obj)
  #define __Pyx_PyBaseString_CheckExact(obj) PyUnicode_CheckExact(obj)
#else
  #define __Pyx_PyBaseString_Check(obj) (PyString_Check(obj) || PyUnicode_Check(obj))
  #define __Pyx_PyBaseString_CheckExact(obj) (PyString_CheckExact(obj) || PyUnicode_CheckExact(obj))
#endif
#ifndef PySet_CheckExact
  #define PySet_CheckExact(obj)        (Py_TYPE(obj) == &PySet_Type)
#endif
#if PY_VERSION_HEX >= 0x030900A4
  #define __Pyx_SET_REFCNT(obj, refcnt) Py_SET_REFCNT(obj, refcnt)
  #define __Pyx_SET_SIZE(obj, size) Py_SET_SIZE(obj, size)
#else
  #define __Pyx_SET_REFCNT(obj, refcnt) Py_REFCNT(obj) = (refcnt)
  #define __Pyx_SET_SIZE(obj, size) Py_SIZE(obj) = (size)
#endif
#if CYTHON_ASSUME_SAFE_MACROS
  #define __Pyx_PySequence_SIZE(seq)  Py_SIZE(seq)
#else
  #define __Pyx_PySequence_SIZE(seq)  PySequence_Size(seq)
#endif
#if PY_MAJOR_VERSION >= 3
  #define PyIntObject                  PyLongObject
  #define PyInt_Type                   PyLong_Type
  #define PyInt_Check(op)              PyLong_Check(op)
  #define PyInt_CheckExact(op)         PyLong_CheckExact(op)
  #define PyInt_FromString             PyLong_FromString
  #define PyInt_FromUnicode            PyLong_FromUnicode
  #define PyInt_FromLong               PyLong_FromLong
  #define PyInt_FromSize_t             PyLong_FromSize_t
  #define PyInt_FromSsize_t            PyLong_FromSsize_t
  #define PyInt_AsLong                 PyLong_AsLong
  #define PyInt_AS_LONG                PyLong_AS_LONG
  #define PyInt_AsSsize_t              PyLong_AsSsize_t
  #define PyInt_AsUnsignedLongMask     PyLong_AsUnsignedLongMask
  #define PyInt_AsUnsignedLongLongMask PyLong_AsUnsignedLongLongMask
  #define PyNumber_Int                 PyNumber_Long
#endif
#if PY_MAJOR_VERSION >= 3
  #define PyBoolObject                 PyLongObject
#endif
#if PY_MAJOR_VERSION >= 3 && CYTHON_COMPILING_IN_PYPY
  #ifndef PyUnicode_InternFromString
    #define PyUnicode_InternFromString(s) PyUnicode_FromString(s)
  #endif
#endif
#if PY_VERSION_HEX < 0x030200A4
  typedef long Py_hash_t;
  #define __Pyx_PyInt_FromHash_t PyInt_FromLong
  #define __Pyx_PyInt_AsHash_t   __Pyx_PyIndex_AsHash_t
#else
  #define __Pyx_PyInt_FromHash_t PyInt_FromSsize_t
  #define __Pyx_PyInt_AsHash_t   __Pyx_PyIndex_AsSsize_t
#endif
#if PY_MAJOR_VERSION >= 3
  #define __Pyx_PyMethod_New(func, self, klass) ((self) ? ((void)(klass), PyMethod_New(func, self)) : __Pyx_NewRef(func))
#else
  #define __Pyx_PyMethod_New(func, self, klass) PyMethod_New(func, self, klass)
#endif
#if CYTHON_USE_ASYNC_SLOTS
  #if PY_VERSION_HEX >= 0x030500B1
    #define __Pyx_PyAsyncMethodsStruct PyAsyncMethods
    #define __Pyx_PyType_AsAsync(obj) (Py_TYPE(obj)->tp_as_async)
  #else
    #define __Pyx_PyType_AsAsync(obj) ((__Pyx_PyAsyncMethodsStruct*) (Py_TYPE(obj)->tp_reserved))
  #endif
#else
  #define __Pyx_PyType_AsAsync(obj) NULL
#endif
#ifndef __Pyx_PyAsyncMethodsStruct
    typedef struct {
        unaryfunc am_await;
        unaryfunc am_aiter;
        unaryfunc am_anext;
    } __Pyx_PyAsyncMethodsStruct;
#endif

#if defined(_WIN32) || defined(WIN32) || defined(MS_WINDOWS)
  #if !defined(_USE_MATH_DEFINES)
    #define _USE_MATH_DEFINES
  #endif
#endif
#include <math.h>
#ifdef NAN
#define __PYX_NAN() ((float) NAN)
#else
static CYTHON_INLINE float __PYX_NAN() {
  float value;
  memset(&value, 0xFF, sizeof(value));
  return value;
}
#endif
#if defined(__CYGWIN__) && defined(_LDBL_EQ_DBL)
#define __Pyx_truncl trunc
#else
#define __Pyx_truncl truncl
#endif

#define __PYX_MARK_ERR_POS(f_index, lineno) \
    { __pyx_filename = __pyx_f[f_index]; (void)__pyx_filename; __pyx_lineno = lineno; (void)__pyx_lineno; __pyx_clineno = __LINE__; (void)__pyx_clineno; }
#define __PYX_ERR(f_index, lineno, Ln_error) \
    { __PYX_MARK_ERR_POS(f_index, lineno) goto Ln_error; }

#ifndef __PYX_EXTERN_C
  #ifdef __cplusplus
    #define __PYX_EXTERN_C extern "C"
  #else
    #define __PYX_EXTERN_C extern
  #endif
#endif

#define __PYX_HAVE__spacy__tokenizer
#define __PYX_HAVE_API__spacy__tokenizer
/* Early includes */
#include "ios"
#include "new"
#include "stdexcept"
#include "typeinfo"
#include <vector>
#include <stdint.h>
#include <utility>

    #if __cplusplus >= 201103L || (defined(_MSC_VER) && _MSC_VER >= 1600)
    // move should be defined for these versions of MSVC, but __cplusplus isn't set usefully
    #include <type_traits>

    namespace cython_std {
    template <typename T> typename std::remove_reference<T>::type&& move(T& t) noexcept { return std::move(t); }
    template <typename T> typename std::remove_reference<T>::type&& move(T&& t) noexcept { return std::move(t); }
    }

    #endif
    
#include <unordered_map>
#include <unordered_set>
#include <string.h>
#include <stdio.h>
#include "numpy/arrayobject.h"
#include "numpy/ndarrayobject.h"
#include "numpy/ndarraytypes.h"
#include "numpy/arrayscalars.h"
#include "numpy/ufuncobject.h"

    /* NumPy API declarations from "numpy/__init__.pxd" */
    
#include <set>
#include <algorithm>
#include "pythread.h"
#include <stdlib.h>
#include "pystate.h"
#ifdef _OPENMP
#include <omp.h>
#endif /* _OPENMP */

#if defined(PYREX_WITHOUT_ASSERTIONS) && !defined(CYTHON_WITHOUT_ASSERTIONS)
#define CYTHON_WITHOUT_ASSERTIONS
#endif

typedef struct {PyObject **p; const char *s; const Py_ssize_t n; const char* encoding;
                const char is_unicode; const char is_str; const char intern; } __Pyx_StringTabEntry;

#define __PYX_DEFAULT_STRING_ENCODING_IS_ASCII 0
#define __PYX_DEFAULT_STRING_ENCODING_IS_UTF8 0
#define __PYX_DEFAULT_STRING_ENCODING_IS_DEFAULT (PY_MAJOR_VERSION >= 3 && __PYX_DEFAULT_STRING_ENCODING_IS_UTF8)
#define __PYX_DEFAULT_STRING_ENCODING ""
#define __Pyx_PyObject_FromString __Pyx_PyBytes_FromString
#define __Pyx_PyObject_FromStringAndSize __Pyx_PyBytes_FromStringAndSize
#define __Pyx_uchar_cast(c) ((unsigned char)c)
#define __Pyx_long_cast(x) ((long)x)
#define __Pyx_fits_Py_ssize_t(v, type, is_signed)  (\
    (sizeof(type) < sizeof(Py_ssize_t))  ||\
    (sizeof(type) > sizeof(Py_ssize_t) &&\
          likely(v < (type)PY_SSIZE_T_MAX ||\
                 v == (type)PY_SSIZE_T_MAX)  &&\
          (!is_signed || likely(v > (type)PY_SSIZE_T_MIN ||\
                                v == (type)PY_SSIZE_T_MIN)))  ||\
    (sizeof(type) == sizeof(Py_ssize_t) &&\
          (is_signed || likely(v < (type)PY_SSIZE_T_MAX ||\
                               v == (type)PY_SSIZE_T_MAX)))  )
static CYTHON_INLINE int __Pyx_is_valid_index(Py_ssize_t i, Py_ssize_t limit) {
    return (size_t) i < (size_t) limit;
}
#if defined (__cplusplus) && __cplusplus >= 201103L
    #include <cstdlib>
    #define __Pyx_sst_abs(value) std::abs(value)
#elif SIZEOF_INT >= SIZEOF_SIZE_T
    #define __Pyx_sst_abs(value) abs(value)
#elif SIZEOF_LONG >= SIZEOF_SIZE_T
    #define __Pyx_sst_abs(value) labs(value)
#elif defined (_MSC_VER)
    #define __Pyx_sst_abs(value) ((Py_ssize_t)_abs64(value))
#elif defined (__STDC_VERSION__) && __STDC_VERSION__ >= 199901L
    #define __Pyx_sst_abs(value) llabs(value)
#elif defined (__GNUC__)
    #define __Pyx_sst_abs(value) __builtin_llabs(value)
#else
    #define __Pyx_sst_abs(value) ((value<0) ? -value : value)
#endif
static CYTHON_INLINE const char* __Pyx_PyObject_AsString(PyObject*);
static CYTHON_INLINE const char* __Pyx_PyObject_AsStringAndSize(PyObject*, Py_ssize_t* length);
#define __Pyx_PyByteArray_FromString(s) PyByteArray_FromStringAndSize((const char*)s, strlen((const char*)s))
#define __Pyx_PyByteArray_FromStringAndSize(s, l) PyByteArray_FromStringAndSize((const char*)s, l)
#define __Pyx_PyBytes_FromString        PyBytes_FromString
#define __Pyx_PyBytes_FromStringAndSize PyBytes_FromStringAndSize
static CYTHON_INLINE PyObject* __Pyx_PyUnicode_FromString(const char*);
#if PY_MAJOR_VERSION < 3
    #define __Pyx_PyStr_FromString        __Pyx_PyBytes_FromString
    #define __Pyx_PyStr_FromStringAndSize __Pyx_PyBytes_FromStringAndSize
#else
    #define __Pyx_PyStr_FromString        __Pyx_PyUnicode_FromString
    #define __Pyx_PyStr_FromStringAndSize __Pyx_PyUnicode_FromStringAndSize
#endif
#define __Pyx_PyBytes_AsWritableString(s)     ((char*) PyBytes_AS_STRING(s))
#define __Pyx_PyBytes_AsWritableSString(s)    ((signed char*) PyBytes_AS_STRING(s))
#define __Pyx_PyBytes_AsWritableUString(s)    ((unsigned char*) PyBytes_AS_STRING(s))
#define __Pyx_PyBytes_AsString(s)     ((const char*) PyBytes_AS_STRING(s))
#define __Pyx_PyBytes_AsSString(s)    ((const signed char*) PyBytes_AS_STRING(s))
#define __Pyx_PyBytes_AsUString(s)    ((const unsigned char*) PyBytes_AS_STRING(s))
#define __Pyx_PyObject_AsWritableString(s)    ((char*) __Pyx_PyObject_AsString(s))
#define __Pyx_PyObject_AsWritableSString(s)    ((signed char*) __Pyx_PyObject_AsString(s))
#define __Pyx_PyObject_AsWritableUString(s)    ((unsigned char*) __Pyx_PyObject_AsString(s))
#define __Pyx_PyObject_AsSString(s)    ((const signed char*) __Pyx_PyObject_AsString(s))
#define __Pyx_PyObject_AsUString(s)    ((const unsigned char*) __Pyx_PyObject_AsString(s))
#define __Pyx_PyObject_FromCString(s)  __Pyx_PyObject_FromString((const char*)s)
#define __Pyx_PyBytes_FromCString(s)   __Pyx_PyBytes_FromString((const char*)s)
#define __Pyx_PyByteArray_FromCString(s)   __Pyx_PyByteArray_FromString((const char*)s)
#define __Pyx_PyStr_FromCString(s)     __Pyx_PyStr_FromString((const char*)s)
#define __Pyx_PyUnicode_FromCString(s) __Pyx_PyUnicode_FromString((const char*)s)
static CYTHON_INLINE size_t __Pyx_Py_UNICODE_strlen(const Py_UNICODE *u) {
    const Py_UNICODE *u_end = u;
    while (*u_end++) ;
    return (size_t)(u_end - u - 1);
}
#define __Pyx_PyUnicode_FromUnicode(u)       PyUnicode_FromUnicode(u, __Pyx_Py_UNICODE_strlen(u))
#define __Pyx_PyUnicode_FromUnicodeAndLength PyUnicode_FromUnicode
#define __Pyx_PyUnicode_AsUnicode            PyUnicode_AsUnicode
#define __Pyx_NewRef(obj) (Py_INCREF(obj), obj)
#define __Pyx_Owned_Py_None(b) __Pyx_NewRef(Py_None)
static CYTHON_INLINE PyObject * __Pyx_PyBool_FromLong(long b);
static CYTHON_INLINE int __Pyx_PyObject_IsTrue(PyObject*);
static CYTHON_INLINE int __Pyx_PyObject_IsTrueAndDecref(PyObject*);
static CYTHON_INLINE PyObject* __Pyx_PyNumber_IntOrLong(PyObject* x);
#define __Pyx_PySequence_Tuple(obj)\
    (likely(PyTuple_CheckExact(obj)) ? __Pyx_NewRef(obj) : PySequence_Tuple(obj))
static CYTHON_INLINE Py_ssize_t __Pyx_PyIndex_AsSsize_t(PyObject*);
static CYTHON_INLINE PyObject * __Pyx_PyInt_FromSize_t(size_t);
static CYTHON_INLINE Py_hash_t __Pyx_PyIndex_AsHash_t(PyObject*);
#if CYTHON_ASSUME_SAFE_MACROS
#define __pyx_PyFloat_AsDouble(x) (PyFloat_CheckExact(x) ? PyFloat_AS_DOUBLE(x) : PyFloat_AsDouble(x))
#else
#define __pyx_PyFloat_AsDouble(x) PyFloat_AsDouble(x)
#endif
#define __pyx_PyFloat_AsFloat(x) ((float) __pyx_PyFloat_AsDouble(x))
#if PY_MAJOR_VERSION >= 3
#define __Pyx_PyNumber_Int(x) (PyLong_CheckExact(x) ? __Pyx_NewRef(x) : PyNumber_Long(x))
#else
#define __Pyx_PyNumber_Int(x) (PyInt_CheckExact(x) ? __Pyx_NewRef(x) : PyNumber_Int(x))
#endif
#define __Pyx_PyNumber_Float(x) (PyFloat_CheckExact(x) ? __Pyx_NewRef(x) : PyNumber_Float(x))
#if PY_MAJOR_VERSION < 3 && __PYX_DEFAULT_STRING_ENCODING_IS_ASCII
static int __Pyx_sys_getdefaultencoding_not_ascii;
static int __Pyx_init_sys_getdefaultencoding_params(void) {
    PyObject* sys;
    PyObject* default_encoding = NULL;
    PyObject* ascii_chars_u = NULL;
    PyObject* ascii_chars_b = NULL;
    const char* default_encoding_c;
    sys = PyImport_ImportModule("sys");
    if (!sys) goto bad;
    default_encoding = PyObject_CallMethod(sys, (char*) "getdefaultencoding", NULL);
    Py_DECREF(sys);
    if (!default_encoding) goto bad;
    default_encoding_c = PyBytes_AsString(default_encoding);
    if (!default_encoding_c) goto bad;
    if (strcmp(default_encoding_c, "ascii") == 0) {
        __Pyx_sys_getdefaultencoding_not_ascii = 0;
    } else {
        char ascii_chars[128];
        int c;
        for (c = 0; c < 128; c++) {
            ascii_chars[c] = c;
        }
        __Pyx_sys_getdefaultencoding_not_ascii = 1;
        ascii_chars_u = PyUnicode_DecodeASCII(ascii_chars, 128, NULL);
        if (!ascii_chars_u) goto bad;
        ascii_chars_b = PyUnicode_AsEncodedString(ascii_chars_u, default_encoding_c, NULL);
        if (!ascii_chars_b || !PyBytes_Check(ascii_chars_b) || memcmp(ascii_chars, PyBytes_AS_STRING(ascii_chars_b), 128) != 0) {
            PyErr_Format(
                PyExc_ValueError,
                "This module compiled with c_string_encoding=ascii, but default encoding '%.200s' is not a superset of ascii.",
                default_encoding_c);
            goto bad;
        }
        Py_DECREF(ascii_chars_u);
        Py_DECREF(ascii_chars_b);
    }
    Py_DECREF(default_encoding);
    return 0;
bad:
    Py_XDECREF(default_encoding);
    Py_XDECREF(ascii_chars_u);
    Py_XDECREF(ascii_chars_b);
    return -1;
}
#endif
#if __PYX_DEFAULT_STRING_ENCODING_IS_DEFAULT && PY_MAJOR_VERSION >= 3
#define __Pyx_PyUnicode_FromStringAndSize(c_str, size) PyUnicode_DecodeUTF8(c_str, size, NULL)
#else
#define __Pyx_PyUnicode_FromStringAndSize(c_str, size) PyUnicode_Decode(c_str, size, __PYX_DEFAULT_STRING_ENCODING, NULL)
#if __PYX_DEFAULT_STRING_ENCODING_IS_DEFAULT
static char* __PYX_DEFAULT_STRING_ENCODING;
static int __Pyx_init_sys_getdefaultencoding_params(void) {
    PyObject* sys;
    PyObject* default_encoding = NULL;
    char* default_encoding_c;
    sys = PyImport_ImportModule("sys");
    if (!sys) goto bad;
    default_encoding = PyObject_CallMethod(sys, (char*) (const char*) "getdefaultencoding", NULL);
    Py_DECREF(sys);
    if (!default_encoding) goto bad;
    default_encoding_c = PyBytes_AsString(default_encoding);
    if (!default_encoding_c) goto bad;
    __PYX_DEFAULT_STRING_ENCODING = (char*) malloc(strlen(default_encoding_c) + 1);
    if (!__PYX_DEFAULT_STRING_ENCODING) goto bad;
    strcpy(__PYX_DEFAULT_STRING_ENCODING, default_encoding_c);
    Py_DECREF(default_encoding);
    return 0;
bad:
    Py_XDECREF(default_encoding);
    return -1;
}
#endif
#endif


/* Test for GCC > 2.95 */
#if defined(__GNUC__)     && (__GNUC__ > 2 || (__GNUC__ == 2 && (__GNUC_MINOR__ > 95)))
  #define likely(x)   __builtin_expect(!!(x), 1)
  #define unlikely(x) __builtin_expect(!!(x), 0)
#else /* !__GNUC__ or GCC < 2.95 */
  #define likely(x)   (x)
  #define unlikely(x) (x)
#endif /* __GNUC__ */
static CYTHON_INLINE void __Pyx_pretend_to_initialize(void* ptr) { (void)ptr; }

static PyObject *__pyx_m = NULL;
static PyObject *__pyx_d;
static PyObject *__pyx_b;
static PyObject *__pyx_cython_runtime = NULL;
static PyObject *__pyx_empty_tuple;
static PyObject *__pyx_empty_bytes;
static PyObject *__pyx_empty_unicode;
static int __pyx_lineno;
static int __pyx_clineno = 0;
static const char * __pyx_cfilenm= __FILE__;
static const char *__pyx_filename;

/* Header.proto */
#if !defined(CYTHON_CCOMPLEX)
  #if defined(__cplusplus)
    #define CYTHON_CCOMPLEX 1
  #elif (defined(_Complex_I) && !defined(_MSC_VER))
    #define CYTHON_CCOMPLEX 1
  #else
    #define CYTHON_CCOMPLEX 0
  #endif
#endif
#if CYTHON_CCOMPLEX
  #ifdef __cplusplus
    #include <complex>
  #else
    #include <complex.h>
  #endif
#endif
#if CYTHON_CCOMPLEX && !defined(__cplusplus) && defined(__sun__) && defined(__GNUC__)
  #undef _Complex_I
  #define _Complex_I 1.0fj
#endif


static const char *__pyx_f[] = {
  "spacy\\tokenizer.pyx",
  "__init__.pxd",
  "spacy\\lexeme.pxd",
  "stringsource",
  "cymem.pxd",
  "maps.pxd",
  "type.pxd",
  "spacy\\strings.pxd",
  "spacy\\morphology.pxd",
  "spacy\\vocab.pxd",
  "spacy\\tokens\\doc.pxd",
  "spacy\\matcher\\phrasematcher.pxd",
};
/* ForceInitThreads.proto */
#ifndef __PYX_FORCE_INIT_THREADS
  #define __PYX_FORCE_INIT_THREADS 0
#endif

/* NoFastGil.proto */
#define __Pyx_PyGILState_Ensure PyGILState_Ensure
#define __Pyx_PyGILState_Release PyGILState_Release
#define __Pyx_FastGIL_Remember()
#define __Pyx_FastGIL_Forget()
#define __Pyx_FastGilFuncInit()

/* BufferFormatStructs.proto */
#define IS_UNSIGNED(type) (((type) -1) > 0)
struct __Pyx_StructField_;
#define __PYX_BUF_FLAGS_PACKED_STRUCT (1 << 0)
typedef struct {
  const char* name;
  struct __Pyx_StructField_* fields;
  size_t size;
  size_t arraysize[8];
  int ndim;
  char typegroup;
  char is_unsigned;
  int flags;
} __Pyx_TypeInfo;
typedef struct __Pyx_StructField_ {
  __Pyx_TypeInfo* type;
  const char* name;
  size_t offset;
} __Pyx_StructField;
typedef struct {
  __Pyx_StructField* field;
  size_t parent_offset;
} __Pyx_BufFmt_StackElem;
typedef struct {
  __Pyx_StructField root;
  __Pyx_BufFmt_StackElem* head;
  size_t fmt_offset;
  size_t new_count, enc_count;
  size_t struct_alignment;
  int is_complex;
  char enc_type;
  char new_packmode;
  char enc_packmode;
  char is_valid_array;
} __Pyx_BufFmt_Context;

/* Atomics.proto */
#include <pythread.h>
#ifndef CYTHON_ATOMICS
    #define CYTHON_ATOMICS 1
#endif
#define __PYX_CYTHON_ATOMICS_ENABLED() CYTHON_ATOMICS
#define __pyx_atomic_int_type int
#if CYTHON_ATOMICS && (__GNUC__ >= 5 || (__GNUC__ == 4 &&\
                    (__GNUC_MINOR__ > 1 ||\
                    (__GNUC_MINOR__ == 1 && __GNUC_PATCHLEVEL__ >= 2))))
    #define __pyx_atomic_incr_aligned(value) __sync_fetch_and_add(value, 1)
    #define __pyx_atomic_decr_aligned(value) __sync_fetch_and_sub(value, 1)
    #ifdef __PYX_DEBUG_ATOMICS
        #warning "Using GNU atomics"
    #endif
#elif CYTHON_ATOMICS && defined(_MSC_VER) && CYTHON_COMPILING_IN_NOGIL
    #include <intrin.h>
    #undef __pyx_atomic_int_type
    #define __pyx_atomic_int_type long
    #pragma intrinsic (_InterlockedExchangeAdd)
    #define __pyx_atomic_incr_aligned(value) _InterlockedExchangeAdd(value, 1)
    #define __pyx_atomic_decr_aligned(value) _InterlockedExchangeAdd(value, -1)
    #ifdef __PYX_DEBUG_ATOMICS
        #pragma message ("Using MSVC atomics")
    #endif
#else
    #undef CYTHON_ATOMICS
    #define CYTHON_ATOMICS 0
    #ifdef __PYX_DEBUG_ATOMICS
        #warning "Not using atomics"
    #endif
#endif
typedef volatile __pyx_atomic_int_type __pyx_atomic_int;
#if CYTHON_ATOMICS
    #define __pyx_add_acquisition_count(memview)\
             __pyx_atomic_incr_aligned(__pyx_get_slice_count_pointer(memview))
    #define __pyx_sub_acquisition_count(memview)\
            __pyx_atomic_decr_aligned(__pyx_get_slice_count_pointer(memview))
#else
    #define __pyx_add_acquisition_count(memview)\
            __pyx_add_acquisition_count_locked(__pyx_get_slice_count_pointer(memview), memview->lock)
    #define __pyx_sub_acquisition_count(memview)\
            __pyx_sub_acquisition_count_locked(__pyx_get_slice_count_pointer(memview), memview->lock)
#endif

/* MemviewSliceStruct.proto */
struct __pyx_memoryview_obj;
typedef struct {
  struct __pyx_memoryview_obj *memview;
  char *data;
  Py_ssize_t shape[8];
  Py_ssize_t strides[8];
  Py_ssize_t suboffsets[8];
} __Pyx_memviewslice;
#define __Pyx_MemoryView_Len(m)  (m.shape[0])


/* "preshed/maps.pxd":5
 * 
 * 
 * ctypedef uint64_t key_t             # <<<<<<<<<<<<<<
 * 
 * 
 */
typedef uint64_t __pyx_t_7preshed_4maps_key_t;

/* "typedefs.pxd":3
 * from libc.stdint cimport int32_t, uint8_t, uint16_t, uint32_t, uint64_t, uintptr_t
 * 
 * ctypedef float weight_t             # <<<<<<<<<<<<<<
 * ctypedef uint64_t hash_t
 * ctypedef uint64_t class_t
 */
typedef float __pyx_t_5spacy_8typedefs_weight_t;

/* "typedefs.pxd":4
 * 
 * ctypedef float weight_t
 * ctypedef uint64_t hash_t             # <<<<<<<<<<<<<<
 * ctypedef uint64_t class_t
 * ctypedef uint64_t attr_t
 */
typedef uint64_t __pyx_t_5spacy_8typedefs_hash_t;

/* "typedefs.pxd":5
 * ctypedef float weight_t
 * ctypedef uint64_t hash_t
 * ctypedef uint64_t class_t             # <<<<<<<<<<<<<<
 * ctypedef uint64_t attr_t
 * ctypedef uint64_t flags_t
 */
typedef uint64_t __pyx_t_5spacy_8typedefs_class_t;

/* "typedefs.pxd":6
 * ctypedef uint64_t hash_t
 * ctypedef uint64_t class_t
 * ctypedef uint64_t attr_t             # <<<<<<<<<<<<<<
 * ctypedef uint64_t flags_t
 * ctypedef uint16_t len_t
 */
typedef uint64_t __pyx_t_5spacy_8typedefs_attr_t;

/* "typedefs.pxd":7
 * ctypedef uint64_t class_t
 * ctypedef uint64_t attr_t
 * ctypedef uint64_t flags_t             # <<<<<<<<<<<<<<
 * ctypedef uint16_t len_t
 * ctypedef uint16_t tag_t
 */
typedef uint64_t __pyx_t_5spacy_8typedefs_flags_t;

/* "typedefs.pxd":8
 * ctypedef uint64_t attr_t
 * ctypedef uint64_t flags_t
 * ctypedef uint16_t len_t             # <<<<<<<<<<<<<<
 * ctypedef uint16_t tag_t
 */
typedef uint16_t __pyx_t_5spacy_8typedefs_len_t;

/* "typedefs.pxd":9
 * ctypedef uint64_t flags_t
 * ctypedef uint16_t len_t
 * ctypedef uint16_t tag_t             # <<<<<<<<<<<<<<
 */
typedef uint16_t __pyx_t_5spacy_8typedefs_tag_t;

/* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-b2egv6w5/overlay/Lib/site-packages/numpy/__init__.pxd":688
 * # in Cython to enable them only on the right systems.
 * 
 * ctypedef npy_int8       int8_t             # <<<<<<<<<<<<<<
 * ctypedef npy_int16      int16_t
 * ctypedef npy_int32      int32_t
 */
typedef npy_int8 __pyx_t_5numpy_int8_t;

/* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-b2egv6w5/overlay/Lib/site-packages/numpy/__init__.pxd":689
 * 
 * ctypedef npy_int8       int8_t
 * ctypedef npy_int16      int16_t             # <<<<<<<<<<<<<<
 * ctypedef npy_int32      int32_t
 * ctypedef npy_int64      int64_t
 */
typedef npy_int16 __pyx_t_5numpy_int16_t;

/* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-b2egv6w5/overlay/Lib/site-packages/numpy/__init__.pxd":690
 * ctypedef npy_int8       int8_t
 * ctypedef npy_int16      int16_t
 * ctypedef npy_int32      int32_t             # <<<<<<<<<<<<<<
 * ctypedef npy_int64      int64_t
 * #ctypedef npy_int96      int96_t
 */
typedef npy_int32 __pyx_t_5numpy_int32_t;

/* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-b2egv6w5/overlay/Lib/site-packages/numpy/__init__.pxd":691
 * ctypedef npy_int16      int16_t
 * ctypedef npy_int32      int32_t
 * ctypedef npy_int64      int64_t             # <<<<<<<<<<<<<<
 * #ctypedef npy_int96      int96_t
 * #ctypedef npy_int128     int128_t
 */
typedef npy_int64 __pyx_t_5numpy_int64_t;

/* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-b2egv6w5/overlay/Lib/site-packages/numpy/__init__.pxd":695
 * #ctypedef npy_int128     int128_t
 * 
 * ctypedef npy_uint8      uint8_t             # <<<<<<<<<<<<<<
 * ctypedef npy_uint16     uint16_t
 * ctypedef npy_uint32     uint32_t
 */
typedef npy_uint8 __pyx_t_5numpy_uint8_t;

/* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-b2egv6w5/overlay/Lib/site-packages/numpy/__init__.pxd":696
 * 
 * ctypedef npy_uint8      uint8_t
 * ctypedef npy_uint16     uint16_t             # <<<<<<<<<<<<<<
 * ctypedef npy_uint32     uint32_t
 * ctypedef npy_uint64     uint64_t
 */
typedef npy_uint16 __pyx_t_5numpy_uint16_t;

/* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-b2egv6w5/overlay/Lib/site-packages/numpy/__init__.pxd":697
 * ctypedef npy_uint8      uint8_t
 * ctypedef npy_uint16     uint16_t
 * ctypedef npy_uint32     uint32_t             # <<<<<<<<<<<<<<
 * ctypedef npy_uint64     uint64_t
 * #ctypedef npy_uint96     uint96_t
 */
typedef npy_uint32 __pyx_t_5numpy_uint32_t;

/* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-b2egv6w5/overlay/Lib/site-packages/numpy/__init__.pxd":698
 * ctypedef npy_uint16     uint16_t
 * ctypedef npy_uint32     uint32_t
 * ctypedef npy_uint64     uint64_t             # <<<<<<<<<<<<<<
 * #ctypedef npy_uint96     uint96_t
 * #ctypedef npy_uint128    uint128_t
 */
typedef npy_uint64 __pyx_t_5numpy_uint64_t;

/* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-b2egv6w5/overlay/Lib/site-packages/numpy/__init__.pxd":702
 * #ctypedef npy_uint128    uint128_t
 * 
 * ctypedef npy_float32    float32_t             # <<<<<<<<<<<<<<
 * ctypedef npy_float64    float64_t
 * #ctypedef npy_float80    float80_t
 */
typedef npy_float32 __pyx_t_5numpy_float32_t;

/* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-b2egv6w5/overlay/Lib/site-packages/numpy/__init__.pxd":703
 * 
 * ctypedef npy_float32    float32_t
 * ctypedef npy_float64    float64_t             # <<<<<<<<<<<<<<
 * #ctypedef npy_float80    float80_t
 * #ctypedef npy_float128   float128_t
 */
typedef npy_float64 __pyx_t_5numpy_float64_t;

/* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-b2egv6w5/overlay/Lib/site-packages/numpy/__init__.pxd":712
 * # The int types are mapped a bit surprising --
 * # numpy.int corresponds to 'l' and numpy.long to 'q'
 * ctypedef npy_long       int_t             # <<<<<<<<<<<<<<
 * ctypedef npy_longlong   longlong_t
 * 
 */
typedef npy_long __pyx_t_5numpy_int_t;

/* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-b2egv6w5/overlay/Lib/site-packages/numpy/__init__.pxd":713
 * # numpy.int corresponds to 'l' and numpy.long to 'q'
 * ctypedef npy_long       int_t
 * ctypedef npy_longlong   longlong_t             # <<<<<<<<<<<<<<
 * 
 * ctypedef npy_ulong      uint_t
 */
typedef npy_longlong __pyx_t_5numpy_longlong_t;

/* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-b2egv6w5/overlay/Lib/site-packages/numpy/__init__.pxd":715
 * ctypedef npy_longlong   longlong_t
 * 
 * ctypedef npy_ulong      uint_t             # <<<<<<<<<<<<<<
 * ctypedef npy_ulonglong  ulonglong_t
 * 
 */
typedef npy_ulong __pyx_t_5numpy_uint_t;

/* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-b2egv6w5/overlay/Lib/site-packages/numpy/__init__.pxd":716
 * 
 * ctypedef npy_ulong      uint_t
 * ctypedef npy_ulonglong  ulonglong_t             # <<<<<<<<<<<<<<
 * 
 * ctypedef npy_intp       intp_t
 */
typedef npy_ulonglong __pyx_t_5numpy_ulonglong_t;

/* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-b2egv6w5/overlay/Lib/site-packages/numpy/__init__.pxd":718
 * ctypedef npy_ulonglong  ulonglong_t
 * 
 * ctypedef npy_intp       intp_t             # <<<<<<<<<<<<<<
 * ctypedef npy_uintp      uintp_t
 * 
 */
typedef npy_intp __pyx_t_5numpy_intp_t;

/* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-b2egv6w5/overlay/Lib/site-packages/numpy/__init__.pxd":719
 * 
 * ctypedef npy_intp       intp_t
 * ctypedef npy_uintp      uintp_t             # <<<<<<<<<<<<<<
 * 
 * ctypedef npy_double     float_t
 */
typedef npy_uintp __pyx_t_5numpy_uintp_t;

/* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-b2egv6w5/overlay/Lib/site-packages/numpy/__init__.pxd":721
 * ctypedef npy_uintp      uintp_t
 * 
 * ctypedef npy_double     float_t             # <<<<<<<<<<<<<<
 * ctypedef npy_double     double_t
 * ctypedef npy_longdouble longdouble_t
 */
typedef npy_double __pyx_t_5numpy_float_t;

/* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-b2egv6w5/overlay/Lib/site-packages/numpy/__init__.pxd":722
 * 
 * ctypedef npy_double     float_t
 * ctypedef npy_double     double_t             # <<<<<<<<<<<<<<
 * ctypedef npy_longdouble longdouble_t
 * 
 */
typedef npy_double __pyx_t_5numpy_double_t;

/* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-b2egv6w5/overlay/Lib/site-packages/numpy/__init__.pxd":723
 * ctypedef npy_double     float_t
 * ctypedef npy_double     double_t
 * ctypedef npy_longdouble longdouble_t             # <<<<<<<<<<<<<<
 * 
 * ctypedef npy_cfloat      cfloat_t
 */
typedef npy_longdouble __pyx_t_5numpy_longdouble_t;
/* Declarations.proto */
#if CYTHON_CCOMPLEX
  #ifdef __cplusplus
    typedef ::std::complex< float > __pyx_t_float_complex;
  #else
    typedef float _Complex __pyx_t_float_complex;
  #endif
#else
    typedef struct { float real, imag; } __pyx_t_float_complex;
#endif
static CYTHON_INLINE __pyx_t_float_complex __pyx_t_float_complex_from_parts(float, float);

/* Declarations.proto */
#if CYTHON_CCOMPLEX
  #ifdef __cplusplus
    typedef ::std::complex< double > __pyx_t_double_complex;
  #else
    typedef double _Complex __pyx_t_double_complex;
  #endif
#else
    typedef struct { double real, imag; } __pyx_t_double_complex;
#endif
static CYTHON_INLINE __pyx_t_double_complex __pyx_t_double_complex_from_parts(double, double);


/*--- Type declarations ---*/
struct __pyx_obj_5cymem_5cymem_PyMalloc;
struct __pyx_obj_5cymem_5cymem_PyFree;
struct __pyx_obj_5cymem_5cymem_Pool;
struct __pyx_obj_5cymem_5cymem_Address;
struct __pyx_obj_7preshed_4maps_PreshMap;
struct __pyx_obj_7preshed_4maps_PreshMapArray;
struct __pyx_obj_5spacy_7strings_StringStore;
struct __pyx_obj_5spacy_10morphology_Morphology;
struct __pyx_obj_5spacy_5vocab_Vocab;
struct __pyx_obj_5spacy_6tokens_3doc_Doc;
struct __pyx_obj_5spacy_7matcher_13phrasematcher_PhraseMatcher;
struct __pyx_obj_5spacy_6lexeme_Lexeme;
struct __pyx_obj_5spacy_9tokenizer_Tokenizer;
struct __pyx_obj_5spacy_9tokenizer___pyx_scope_struct__pipe;
struct __pyx_obj_5spacy_9tokenizer___pyx_scope_struct_1_explain;
struct __pyx_obj_5spacy_9tokenizer___pyx_scope_struct_2_genexpr;
struct __pyx_obj_5spacy_9tokenizer___pyx_scope_struct_3_genexpr;
struct __pyx_obj_5spacy_9tokenizer___pyx_scope_struct_4_genexpr;
struct __pyx_obj_5spacy_9tokenizer___pyx_scope_struct_5_to_bytes;
struct __pyx_obj_5spacy_9tokenizer___pyx_scope_struct_6_from_bytes;
struct __pyx_array_obj;
struct __pyx_MemviewEnum_obj;
struct __pyx_memoryview_obj;
struct __pyx_memoryviewslice_obj;

/* "cymem/cymem.pxd":1
 * ctypedef void* (*malloc_t)(size_t n)             # <<<<<<<<<<<<<<
 * ctypedef void (*free_t)(void *p)
 * 
 */
typedef void *(*__pyx_t_5cymem_5cymem_malloc_t)(size_t);

/* "cymem/cymem.pxd":2
 * ctypedef void* (*malloc_t)(size_t n)
 * ctypedef void (*free_t)(void *p)             # <<<<<<<<<<<<<<
 * 
 * cdef class PyMalloc:
 */
typedef void (*__pyx_t_5cymem_5cymem_free_t)(void *);
struct __pyx_t_7preshed_4maps_Cell;
struct __pyx_t_7preshed_4maps_Result;
struct __pyx_t_7preshed_4maps_MapStruct;

/* "preshed/maps.pxd":8
 * 
 * 
 * cdef struct Cell:             # <<<<<<<<<<<<<<
 *     key_t key
 *     void* value
 */
struct __pyx_t_7preshed_4maps_Cell {
  __pyx_t_7preshed_4maps_key_t key;
  void *value;
};

/* "preshed/maps.pxd":13
 * 
 * 
 * cdef struct Result:             # <<<<<<<<<<<<<<
 *     int found
 *     void* value
 */
struct __pyx_t_7preshed_4maps_Result {
  int found;
  void *value;
};

/* "preshed/maps.pxd":18
 * 
 * 
 * cdef struct MapStruct:             # <<<<<<<<<<<<<<
 *     Cell* cells
 *     void* value_for_empty_key
 */
struct __pyx_t_7preshed_4maps_MapStruct {
  struct __pyx_t_7preshed_4maps_Cell *cells;
  void *value_for_empty_key;
  void *value_for_del_key;
  __pyx_t_7preshed_4maps_key_t length;
  __pyx_t_7preshed_4maps_key_t filled;
  int is_empty_key_set;
  int is_del_key_set;
};

/* "symbols.pxd":1
 * cdef enum symbol_t:             # <<<<<<<<<<<<<<
 *     NIL
 *     IS_ALPHA
 */
enum __pyx_t_5spacy_7symbols_symbol_t {
  __pyx_e_5spacy_7symbols_NIL,
  __pyx_e_5spacy_7symbols_IS_ALPHA,
  __pyx_e_5spacy_7symbols_IS_ASCII,
  __pyx_e_5spacy_7symbols_IS_DIGIT,
  __pyx_e_5spacy_7symbols_IS_LOWER,
  __pyx_e_5spacy_7symbols_IS_PUNCT,
  __pyx_e_5spacy_7symbols_IS_SPACE,
  __pyx_e_5spacy_7symbols_IS_TITLE,
  __pyx_e_5spacy_7symbols_IS_UPPER,
  __pyx_e_5spacy_7symbols_LIKE_URL,
  __pyx_e_5spacy_7symbols_LIKE_NUM,
  __pyx_e_5spacy_7symbols_LIKE_EMAIL,
  __pyx_e_5spacy_7symbols_IS_STOP,
  __pyx_e_5spacy_7symbols_IS_OOV_DEPRECATED,
  __pyx_e_5spacy_7symbols_IS_BRACKET,
  __pyx_e_5spacy_7symbols_IS_QUOTE,
  __pyx_e_5spacy_7symbols_IS_LEFT_PUNCT,
  __pyx_e_5spacy_7symbols_IS_RIGHT_PUNCT,
  __pyx_e_5spacy_7symbols_IS_CURRENCY,
  __pyx_e_5spacy_7symbols_FLAG19 = 19,
  __pyx_e_5spacy_7symbols_FLAG20,
  __pyx_e_5spacy_7symbols_FLAG21,
  __pyx_e_5spacy_7symbols_FLAG22,
  __pyx_e_5spacy_7symbols_FLAG23,
  __pyx_e_5spacy_7symbols_FLAG24,
  __pyx_e_5spacy_7symbols_FLAG25,
  __pyx_e_5spacy_7symbols_FLAG26,
  __pyx_e_5spacy_7symbols_FLAG27,
  __pyx_e_5spacy_7symbols_FLAG28,
  __pyx_e_5spacy_7symbols_FLAG29,
  __pyx_e_5spacy_7symbols_FLAG30,
  __pyx_e_5spacy_7symbols_FLAG31,
  __pyx_e_5spacy_7symbols_FLAG32,
  __pyx_e_5spacy_7symbols_FLAG33,
  __pyx_e_5spacy_7symbols_FLAG34,
  __pyx_e_5spacy_7symbols_FLAG35,
  __pyx_e_5spacy_7symbols_FLAG36,
  __pyx_e_5spacy_7symbols_FLAG37,
  __pyx_e_5spacy_7symbols_FLAG38,
  __pyx_e_5spacy_7symbols_FLAG39,
  __pyx_e_5spacy_7symbols_FLAG40,
  __pyx_e_5spacy_7symbols_FLAG41,
  __pyx_e_5spacy_7symbols_FLAG42,
  __pyx_e_5spacy_7symbols_FLAG43,
  __pyx_e_5spacy_7symbols_FLAG44,
  __pyx_e_5spacy_7symbols_FLAG45,
  __pyx_e_5spacy_7symbols_FLAG46,
  __pyx_e_5spacy_7symbols_FLAG47,
  __pyx_e_5spacy_7symbols_FLAG48,
  __pyx_e_5spacy_7symbols_FLAG49,
  __pyx_e_5spacy_7symbols_FLAG50,
  __pyx_e_5spacy_7symbols_FLAG51,
  __pyx_e_5spacy_7symbols_FLAG52,
  __pyx_e_5spacy_7symbols_FLAG53,
  __pyx_e_5spacy_7symbols_FLAG54,
  __pyx_e_5spacy_7symbols_FLAG55,
  __pyx_e_5spacy_7symbols_FLAG56,
  __pyx_e_5spacy_7symbols_FLAG57,
  __pyx_e_5spacy_7symbols_FLAG58,
  __pyx_e_5spacy_7symbols_FLAG59,
  __pyx_e_5spacy_7symbols_FLAG60,
  __pyx_e_5spacy_7symbols_FLAG61,
  __pyx_e_5spacy_7symbols_FLAG62,
  __pyx_e_5spacy_7symbols_FLAG63,
  __pyx_e_5spacy_7symbols_ID,
  __pyx_e_5spacy_7symbols_ORTH,
  __pyx_e_5spacy_7symbols_LOWER,
  __pyx_e_5spacy_7symbols_NORM,
  __pyx_e_5spacy_7symbols_SHAPE,
  __pyx_e_5spacy_7symbols_PREFIX,
  __pyx_e_5spacy_7symbols_SUFFIX,
  __pyx_e_5spacy_7symbols_LENGTH,
  __pyx_e_5spacy_7symbols_CLUSTER,
  __pyx_e_5spacy_7symbols_LEMMA,
  __pyx_e_5spacy_7symbols_POS,
  __pyx_e_5spacy_7symbols_TAG,
  __pyx_e_5spacy_7symbols_DEP,
  __pyx_e_5spacy_7symbols_ENT_IOB,
  __pyx_e_5spacy_7symbols_ENT_TYPE,
  __pyx_e_5spacy_7symbols_HEAD,
  __pyx_e_5spacy_7symbols_SENT_START,
  __pyx_e_5spacy_7symbols_SPACY,
  __pyx_e_5spacy_7symbols_PROB,
  __pyx_e_5spacy_7symbols_LANG,
  __pyx_e_5spacy_7symbols_ADJ,
  __pyx_e_5spacy_7symbols_ADP,
  __pyx_e_5spacy_7symbols_ADV,
  __pyx_e_5spacy_7symbols_AUX,
  __pyx_e_5spacy_7symbols_CONJ,
  __pyx_e_5spacy_7symbols_CCONJ,
  __pyx_e_5spacy_7symbols_DET,
  __pyx_e_5spacy_7symbols_INTJ,
  __pyx_e_5spacy_7symbols_NOUN,
  __pyx_e_5spacy_7symbols_NUM,
  __pyx_e_5spacy_7symbols_PART,
  __pyx_e_5spacy_7symbols_PRON,
  __pyx_e_5spacy_7symbols_PROPN,
  __pyx_e_5spacy_7symbols_PUNCT,
  __pyx_e_5spacy_7symbols_SCONJ,
  __pyx_e_5spacy_7symbols_SYM,
  __pyx_e_5spacy_7symbols_VERB,
  __pyx_e_5spacy_7symbols_X,
  __pyx_e_5spacy_7symbols_EOL,
  __pyx_e_5spacy_7symbols_SPACE,
  __pyx_e_5spacy_7symbols_DEPRECATED001,
  __pyx_e_5spacy_7symbols_DEPRECATED002,
  __pyx_e_5spacy_7symbols_DEPRECATED003,
  __pyx_e_5spacy_7symbols_DEPRECATED004,
  __pyx_e_5spacy_7symbols_DEPRECATED005,
  __pyx_e_5spacy_7symbols_DEPRECATED006,
  __pyx_e_5spacy_7symbols_DEPRECATED007,
  __pyx_e_5spacy_7symbols_DEPRECATED008,
  __pyx_e_5spacy_7symbols_DEPRECATED009,
  __pyx_e_5spacy_7symbols_DEPRECATED010,
  __pyx_e_5spacy_7symbols_DEPRECATED011,
  __pyx_e_5spacy_7symbols_DEPRECATED012,
  __pyx_e_5spacy_7symbols_DEPRECATED013,
  __pyx_e_5spacy_7symbols_DEPRECATED014,
  __pyx_e_5spacy_7symbols_DEPRECATED015,
  __pyx_e_5spacy_7symbols_DEPRECATED016,
  __pyx_e_5spacy_7symbols_DEPRECATED017,
  __pyx_e_5spacy_7symbols_DEPRECATED018,
  __pyx_e_5spacy_7symbols_DEPRECATED019,
  __pyx_e_5spacy_7symbols_DEPRECATED020,
  __pyx_e_5spacy_7symbols_DEPRECATED021,
  __pyx_e_5spacy_7symbols_DEPRECATED022,
  __pyx_e_5spacy_7symbols_DEPRECATED023,
  __pyx_e_5spacy_7symbols_DEPRECATED024,
  __pyx_e_5spacy_7symbols_DEPRECATED025,
  __pyx_e_5spacy_7symbols_DEPRECATED026,
  __pyx_e_5spacy_7symbols_DEPRECATED027,
  __pyx_e_5spacy_7symbols_DEPRECATED028,
  __pyx_e_5spacy_7symbols_DEPRECATED029,
  __pyx_e_5spacy_7symbols_DEPRECATED030,
  __pyx_e_5spacy_7symbols_DEPRECATED031,
  __pyx_e_5spacy_7symbols_DEPRECATED032,
  __pyx_e_5spacy_7symbols_DEPRECATED033,
  __pyx_e_5spacy_7symbols_DEPRECATED034,
  __pyx_e_5spacy_7symbols_DEPRECATED035,
  __pyx_e_5spacy_7symbols_DEPRECATED036,
  __pyx_e_5spacy_7symbols_DEPRECATED037,
  __pyx_e_5spacy_7symbols_DEPRECATED038,
  __pyx_e_5spacy_7symbols_DEPRECATED039,
  __pyx_e_5spacy_7symbols_DEPRECATED040,
  __pyx_e_5spacy_7symbols_DEPRECATED041,
  __pyx_e_5spacy_7symbols_DEPRECATED042,
  __pyx_e_5spacy_7symbols_DEPRECATED043,
  __pyx_e_5spacy_7symbols_DEPRECATED044,
  __pyx_e_5spacy_7symbols_DEPRECATED045,
  __pyx_e_5spacy_7symbols_DEPRECATED046,
  __pyx_e_5spacy_7symbols_DEPRECATED047,
  __pyx_e_5spacy_7symbols_DEPRECATED048,
  __pyx_e_5spacy_7symbols_DEPRECATED049,
  __pyx_e_5spacy_7symbols_DEPRECATED050,
  __pyx_e_5spacy_7symbols_DEPRECATED051,
  __pyx_e_5spacy_7symbols_DEPRECATED052,
  __pyx_e_5spacy_7symbols_DEPRECATED053,
  __pyx_e_5spacy_7symbols_DEPRECATED054,
  __pyx_e_5spacy_7symbols_DEPRECATED055,
  __pyx_e_5spacy_7symbols_DEPRECATED056,
  __pyx_e_5spacy_7symbols_DEPRECATED057,
  __pyx_e_5spacy_7symbols_DEPRECATED058,
  __pyx_e_5spacy_7symbols_DEPRECATED059,
  __pyx_e_5spacy_7symbols_DEPRECATED060,
  __pyx_e_5spacy_7symbols_DEPRECATED061,
  __pyx_e_5spacy_7symbols_DEPRECATED062,
  __pyx_e_5spacy_7symbols_DEPRECATED063,
  __pyx_e_5spacy_7symbols_DEPRECATED064,
  __pyx_e_5spacy_7symbols_DEPRECATED065,
  __pyx_e_5spacy_7symbols_DEPRECATED066,
  __pyx_e_5spacy_7symbols_DEPRECATED067,
  __pyx_e_5spacy_7symbols_DEPRECATED068,
  __pyx_e_5spacy_7symbols_DEPRECATED069,
  __pyx_e_5spacy_7symbols_DEPRECATED070,
  __pyx_e_5spacy_7symbols_DEPRECATED071,
  __pyx_e_5spacy_7symbols_DEPRECATED072,
  __pyx_e_5spacy_7symbols_DEPRECATED073,
  __pyx_e_5spacy_7symbols_DEPRECATED074,
  __pyx_e_5spacy_7symbols_DEPRECATED075,
  __pyx_e_5spacy_7symbols_DEPRECATED076,
  __pyx_e_5spacy_7symbols_DEPRECATED077,
  __pyx_e_5spacy_7symbols_DEPRECATED078,
  __pyx_e_5spacy_7symbols_DEPRECATED079,
  __pyx_e_5spacy_7symbols_DEPRECATED080,
  __pyx_e_5spacy_7symbols_DEPRECATED081,
  __pyx_e_5spacy_7symbols_DEPRECATED082,
  __pyx_e_5spacy_7symbols_DEPRECATED083,
  __pyx_e_5spacy_7symbols_DEPRECATED084,
  __pyx_e_5spacy_7symbols_DEPRECATED085,
  __pyx_e_5spacy_7symbols_DEPRECATED086,
  __pyx_e_5spacy_7symbols_DEPRECATED087,
  __pyx_e_5spacy_7symbols_DEPRECATED088,
  __pyx_e_5spacy_7symbols_DEPRECATED089,
  __pyx_e_5spacy_7symbols_DEPRECATED090,
  __pyx_e_5spacy_7symbols_DEPRECATED091,
  __pyx_e_5spacy_7symbols_DEPRECATED092,
  __pyx_e_5spacy_7symbols_DEPRECATED093,
  __pyx_e_5spacy_7symbols_DEPRECATED094,
  __pyx_e_5spacy_7symbols_DEPRECATED095,
  __pyx_e_5spacy_7symbols_DEPRECATED096,
  __pyx_e_5spacy_7symbols_DEPRECATED097,
  __pyx_e_5spacy_7symbols_DEPRECATED098,
  __pyx_e_5spacy_7symbols_DEPRECATED099,
  __pyx_e_5spacy_7symbols_DEPRECATED100,
  __pyx_e_5spacy_7symbols_DEPRECATED101,
  __pyx_e_5spacy_7symbols_DEPRECATED102,
  __pyx_e_5spacy_7symbols_DEPRECATED103,
  __pyx_e_5spacy_7symbols_DEPRECATED104,
  __pyx_e_5spacy_7symbols_DEPRECATED105,
  __pyx_e_5spacy_7symbols_DEPRECATED106,
  __pyx_e_5spacy_7symbols_DEPRECATED107,
  __pyx_e_5spacy_7symbols_DEPRECATED108,
  __pyx_e_5spacy_7symbols_DEPRECATED109,
  __pyx_e_5spacy_7symbols_DEPRECATED110,
  __pyx_e_5spacy_7symbols_DEPRECATED111,
  __pyx_e_5spacy_7symbols_DEPRECATED112,
  __pyx_e_5spacy_7symbols_DEPRECATED113,
  __pyx_e_5spacy_7symbols_DEPRECATED114,
  __pyx_e_5spacy_7symbols_DEPRECATED115,
  __pyx_e_5spacy_7symbols_DEPRECATED116,
  __pyx_e_5spacy_7symbols_DEPRECATED117,
  __pyx_e_5spacy_7symbols_DEPRECATED118,
  __pyx_e_5spacy_7symbols_DEPRECATED119,
  __pyx_e_5spacy_7symbols_DEPRECATED120,
  __pyx_e_5spacy_7symbols_DEPRECATED121,
  __pyx_e_5spacy_7symbols_DEPRECATED122,
  __pyx_e_5spacy_7symbols_DEPRECATED123,
  __pyx_e_5spacy_7symbols_DEPRECATED124,
  __pyx_e_5spacy_7symbols_DEPRECATED125,
  __pyx_e_5spacy_7symbols_DEPRECATED126,
  __pyx_e_5spacy_7symbols_DEPRECATED127,
  __pyx_e_5spacy_7symbols_DEPRECATED128,
  __pyx_e_5spacy_7symbols_DEPRECATED129,
  __pyx_e_5spacy_7symbols_DEPRECATED130,
  __pyx_e_5spacy_7symbols_DEPRECATED131,
  __pyx_e_5spacy_7symbols_DEPRECATED132,
  __pyx_e_5spacy_7symbols_DEPRECATED133,
  __pyx_e_5spacy_7symbols_DEPRECATED134,
  __pyx_e_5spacy_7symbols_DEPRECATED135,
  __pyx_e_5spacy_7symbols_DEPRECATED136,
  __pyx_e_5spacy_7symbols_DEPRECATED137,
  __pyx_e_5spacy_7symbols_DEPRECATED138,
  __pyx_e_5spacy_7symbols_DEPRECATED139,
  __pyx_e_5spacy_7symbols_DEPRECATED140,
  __pyx_e_5spacy_7symbols_DEPRECATED141,
  __pyx_e_5spacy_7symbols_DEPRECATED142,
  __pyx_e_5spacy_7symbols_DEPRECATED143,
  __pyx_e_5spacy_7symbols_DEPRECATED144,
  __pyx_e_5spacy_7symbols_DEPRECATED145,
  __pyx_e_5spacy_7symbols_DEPRECATED146,
  __pyx_e_5spacy_7symbols_DEPRECATED147,
  __pyx_e_5spacy_7symbols_DEPRECATED148,
  __pyx_e_5spacy_7symbols_DEPRECATED149,
  __pyx_e_5spacy_7symbols_DEPRECATED150,
  __pyx_e_5spacy_7symbols_DEPRECATED151,
  __pyx_e_5spacy_7symbols_DEPRECATED152,
  __pyx_e_5spacy_7symbols_DEPRECATED153,
  __pyx_e_5spacy_7symbols_DEPRECATED154,
  __pyx_e_5spacy_7symbols_DEPRECATED155,
  __pyx_e_5spacy_7symbols_DEPRECATED156,
  __pyx_e_5spacy_7symbols_DEPRECATED157,
  __pyx_e_5spacy_7symbols_DEPRECATED158,
  __pyx_e_5spacy_7symbols_DEPRECATED159,
  __pyx_e_5spacy_7symbols_DEPRECATED160,
  __pyx_e_5spacy_7symbols_DEPRECATED161,
  __pyx_e_5spacy_7symbols_DEPRECATED162,
  __pyx_e_5spacy_7symbols_DEPRECATED163,
  __pyx_e_5spacy_7symbols_DEPRECATED164,
  __pyx_e_5spacy_7symbols_DEPRECATED165,
  __pyx_e_5spacy_7symbols_DEPRECATED166,
  __pyx_e_5spacy_7symbols_DEPRECATED167,
  __pyx_e_5spacy_7symbols_DEPRECATED168,
  __pyx_e_5spacy_7symbols_DEPRECATED169,
  __pyx_e_5spacy_7symbols_DEPRECATED170,
  __pyx_e_5spacy_7symbols_DEPRECATED171,
  __pyx_e_5spacy_7symbols_DEPRECATED172,
  __pyx_e_5spacy_7symbols_DEPRECATED173,
  __pyx_e_5spacy_7symbols_DEPRECATED174,
  __pyx_e_5spacy_7symbols_DEPRECATED175,
  __pyx_e_5spacy_7symbols_DEPRECATED176,
  __pyx_e_5spacy_7symbols_DEPRECATED177,
  __pyx_e_5spacy_7symbols_DEPRECATED178,
  __pyx_e_5spacy_7symbols_DEPRECATED179,
  __pyx_e_5spacy_7symbols_DEPRECATED180,
  __pyx_e_5spacy_7symbols_DEPRECATED181,
  __pyx_e_5spacy_7symbols_DEPRECATED182,
  __pyx_e_5spacy_7symbols_DEPRECATED183,
  __pyx_e_5spacy_7symbols_DEPRECATED184,
  __pyx_e_5spacy_7symbols_DEPRECATED185,
  __pyx_e_5spacy_7symbols_DEPRECATED186,
  __pyx_e_5spacy_7symbols_DEPRECATED187,
  __pyx_e_5spacy_7symbols_DEPRECATED188,
  __pyx_e_5spacy_7symbols_DEPRECATED189,
  __pyx_e_5spacy_7symbols_DEPRECATED190,
  __pyx_e_5spacy_7symbols_DEPRECATED191,
  __pyx_e_5spacy_7symbols_DEPRECATED192,
  __pyx_e_5spacy_7symbols_DEPRECATED193,
  __pyx_e_5spacy_7symbols_DEPRECATED194,
  __pyx_e_5spacy_7symbols_DEPRECATED195,
  __pyx_e_5spacy_7symbols_DEPRECATED196,
  __pyx_e_5spacy_7symbols_DEPRECATED197,
  __pyx_e_5spacy_7symbols_DEPRECATED198,
  __pyx_e_5spacy_7symbols_DEPRECATED199,
  __pyx_e_5spacy_7symbols_DEPRECATED200,
  __pyx_e_5spacy_7symbols_DEPRECATED201,
  __pyx_e_5spacy_7symbols_DEPRECATED202,
  __pyx_e_5spacy_7symbols_DEPRECATED203,
  __pyx_e_5spacy_7symbols_DEPRECATED204,
  __pyx_e_5spacy_7symbols_DEPRECATED205,
  __pyx_e_5spacy_7symbols_DEPRECATED206,
  __pyx_e_5spacy_7symbols_DEPRECATED207,
  __pyx_e_5spacy_7symbols_DEPRECATED208,
  __pyx_e_5spacy_7symbols_DEPRECATED209,
  __pyx_e_5spacy_7symbols_DEPRECATED210,
  __pyx_e_5spacy_7symbols_DEPRECATED211,
  __pyx_e_5spacy_7symbols_DEPRECATED212,
  __pyx_e_5spacy_7symbols_DEPRECATED213,
  __pyx_e_5spacy_7symbols_DEPRECATED214,
  __pyx_e_5spacy_7symbols_DEPRECATED215,
  __pyx_e_5spacy_7symbols_DEPRECATED216,
  __pyx_e_5spacy_7symbols_DEPRECATED217,
  __pyx_e_5spacy_7symbols_DEPRECATED218,
  __pyx_e_5spacy_7symbols_DEPRECATED219,
  __pyx_e_5spacy_7symbols_DEPRECATED220,
  __pyx_e_5spacy_7symbols_DEPRECATED221,
  __pyx_e_5spacy_7symbols_DEPRECATED222,
  __pyx_e_5spacy_7symbols_DEPRECATED223,
  __pyx_e_5spacy_7symbols_DEPRECATED224,
  __pyx_e_5spacy_7symbols_DEPRECATED225,
  __pyx_e_5spacy_7symbols_DEPRECATED226,
  __pyx_e_5spacy_7symbols_DEPRECATED227,
  __pyx_e_5spacy_7symbols_DEPRECATED228,
  __pyx_e_5spacy_7symbols_DEPRECATED229,
  __pyx_e_5spacy_7symbols_DEPRECATED230,
  __pyx_e_5spacy_7symbols_DEPRECATED231,
  __pyx_e_5spacy_7symbols_DEPRECATED232,
  __pyx_e_5spacy_7symbols_DEPRECATED233,
  __pyx_e_5spacy_7symbols_DEPRECATED234,
  __pyx_e_5spacy_7symbols_DEPRECATED235,
  __pyx_e_5spacy_7symbols_DEPRECATED236,
  __pyx_e_5spacy_7symbols_DEPRECATED237,
  __pyx_e_5spacy_7symbols_DEPRECATED238,
  __pyx_e_5spacy_7symbols_DEPRECATED239,
  __pyx_e_5spacy_7symbols_DEPRECATED240,
  __pyx_e_5spacy_7symbols_DEPRECATED241,
  __pyx_e_5spacy_7symbols_DEPRECATED242,
  __pyx_e_5spacy_7symbols_DEPRECATED243,
  __pyx_e_5spacy_7symbols_DEPRECATED244,
  __pyx_e_5spacy_7symbols_DEPRECATED245,
  __pyx_e_5spacy_7symbols_DEPRECATED246,
  __pyx_e_5spacy_7symbols_DEPRECATED247,
  __pyx_e_5spacy_7symbols_DEPRECATED248,
  __pyx_e_5spacy_7symbols_DEPRECATED249,
  __pyx_e_5spacy_7symbols_DEPRECATED250,
  __pyx_e_5spacy_7symbols_DEPRECATED251,
  __pyx_e_5spacy_7symbols_DEPRECATED252,
  __pyx_e_5spacy_7symbols_DEPRECATED253,
  __pyx_e_5spacy_7symbols_DEPRECATED254,
  __pyx_e_5spacy_7symbols_DEPRECATED255,
  __pyx_e_5spacy_7symbols_DEPRECATED256,
  __pyx_e_5spacy_7symbols_DEPRECATED257,
  __pyx_e_5spacy_7symbols_DEPRECATED258,
  __pyx_e_5spacy_7symbols_DEPRECATED259,
  __pyx_e_5spacy_7symbols_DEPRECATED260,
  __pyx_e_5spacy_7symbols_DEPRECATED261,
  __pyx_e_5spacy_7symbols_DEPRECATED262,
  __pyx_e_5spacy_7symbols_DEPRECATED263,
  __pyx_e_5spacy_7symbols_DEPRECATED264,
  __pyx_e_5spacy_7symbols_DEPRECATED265,
  __pyx_e_5spacy_7symbols_DEPRECATED266,
  __pyx_e_5spacy_7symbols_DEPRECATED267,
  __pyx_e_5spacy_7symbols_DEPRECATED268,
  __pyx_e_5spacy_7symbols_DEPRECATED269,
  __pyx_e_5spacy_7symbols_DEPRECATED270,
  __pyx_e_5spacy_7symbols_DEPRECATED271,
  __pyx_e_5spacy_7symbols_DEPRECATED272,
  __pyx_e_5spacy_7symbols_DEPRECATED273,
  __pyx_e_5spacy_7symbols_DEPRECATED274,
  __pyx_e_5spacy_7symbols_DEPRECATED275,
  __pyx_e_5spacy_7symbols_DEPRECATED276,
  __pyx_e_5spacy_7symbols_PERSON,
  __pyx_e_5spacy_7symbols_NORP,
  __pyx_e_5spacy_7symbols_FACILITY,
  __pyx_e_5spacy_7symbols_ORG,
  __pyx_e_5spacy_7symbols_GPE,
  __pyx_e_5spacy_7symbols_LOC,
  __pyx_e_5spacy_7symbols_PRODUCT,
  __pyx_e_5spacy_7symbols_EVENT,
  __pyx_e_5spacy_7symbols_WORK_OF_ART,
  __pyx_e_5spacy_7symbols_LANGUAGE,
  __pyx_e_5spacy_7symbols_LAW,
  __pyx_e_5spacy_7symbols_DATE,
  __pyx_e_5spacy_7symbols_TIME,
  __pyx_e_5spacy_7symbols_PERCENT,
  __pyx_e_5spacy_7symbols_MONEY,
  __pyx_e_5spacy_7symbols_QUANTITY,
  __pyx_e_5spacy_7symbols_ORDINAL,
  __pyx_e_5spacy_7symbols_CARDINAL,
  __pyx_e_5spacy_7symbols_acomp,
  __pyx_e_5spacy_7symbols_advcl,
  __pyx_e_5spacy_7symbols_advmod,
  __pyx_e_5spacy_7symbols_agent,
  __pyx_e_5spacy_7symbols_amod,
  __pyx_e_5spacy_7symbols_appos,
  __pyx_e_5spacy_7symbols_attr,
  __pyx_e_5spacy_7symbols_aux,
  __pyx_e_5spacy_7symbols_auxpass,
  __pyx_e_5spacy_7symbols_cc,
  __pyx_e_5spacy_7symbols_ccomp,
  __pyx_e_5spacy_7symbols_complm,
  __pyx_e_5spacy_7symbols_conj,
  __pyx_e_5spacy_7symbols_cop,
  __pyx_e_5spacy_7symbols_csubj,
  __pyx_e_5spacy_7symbols_csubjpass,
  __pyx_e_5spacy_7symbols_dep,
  __pyx_e_5spacy_7symbols_det,
  __pyx_e_5spacy_7symbols_dobj,
  __pyx_e_5spacy_7symbols_expl,
  __pyx_e_5spacy_7symbols_hmod,
  __pyx_e_5spacy_7symbols_hyph,
  __pyx_e_5spacy_7symbols_infmod,
  __pyx_e_5spacy_7symbols_intj,
  __pyx_e_5spacy_7symbols_iobj,
  __pyx_e_5spacy_7symbols_mark,
  __pyx_e_5spacy_7symbols_meta,
  __pyx_e_5spacy_7symbols_neg,
  __pyx_e_5spacy_7symbols_nmod,
  __pyx_e_5spacy_7symbols_nn,
  __pyx_e_5spacy_7symbols_npadvmod,
  __pyx_e_5spacy_7symbols_nsubj,
  __pyx_e_5spacy_7symbols_nsubjpass,
  __pyx_e_5spacy_7symbols_num,
  __pyx_e_5spacy_7symbols_number,
  __pyx_e_5spacy_7symbols_oprd,
  __pyx_e_5spacy_7symbols_obj,
  __pyx_e_5spacy_7symbols_obl,
  __pyx_e_5spacy_7symbols_parataxis,
  __pyx_e_5spacy_7symbols_partmod,
  __pyx_e_5spacy_7symbols_pcomp,
  __pyx_e_5spacy_7symbols_pobj,
  __pyx_e_5spacy_7symbols_poss,
  __pyx_e_5spacy_7symbols_possessive,
  __pyx_e_5spacy_7symbols_preconj,
  __pyx_e_5spacy_7symbols_prep,
  __pyx_e_5spacy_7symbols_prt,
  __pyx_e_5spacy_7symbols_punct,
  __pyx_e_5spacy_7symbols_quantmod,
  __pyx_e_5spacy_7symbols_relcl,
  __pyx_e_5spacy_7symbols_rcmod,
  __pyx_e_5spacy_7symbols_root,
  __pyx_e_5spacy_7symbols_xcomp,
  __pyx_e_5spacy_7symbols_acl,
  __pyx_e_5spacy_7symbols_ENT_KB_ID,
  __pyx_e_5spacy_7symbols_MORPH,
  __pyx_e_5spacy_7symbols_ENT_ID,
  __pyx_e_5spacy_7symbols_IDX,
  __pyx_e_5spacy_7symbols__
};

/* "attrs.pxd":5
 * 
 * 
 * cdef enum attr_id_t:             # <<<<<<<<<<<<<<
 *     NULL_ATTR
 *     IS_ALPHA
 */
enum __pyx_t_5spacy_5attrs_attr_id_t {

  /* "attrs.pxd":96
 *     ENT_KB_ID = symbols.ENT_KB_ID
 *     MORPH
 *     ENT_ID = symbols.ENT_ID             # <<<<<<<<<<<<<<
 * 
 *     IDX
 */
  __pyx_e_5spacy_5attrs_NULL_ATTR,
  __pyx_e_5spacy_5attrs_IS_ALPHA,
  __pyx_e_5spacy_5attrs_IS_ASCII,
  __pyx_e_5spacy_5attrs_IS_DIGIT,
  __pyx_e_5spacy_5attrs_IS_LOWER,
  __pyx_e_5spacy_5attrs_IS_PUNCT,
  __pyx_e_5spacy_5attrs_IS_SPACE,
  __pyx_e_5spacy_5attrs_IS_TITLE,
  __pyx_e_5spacy_5attrs_IS_UPPER,
  __pyx_e_5spacy_5attrs_LIKE_URL,
  __pyx_e_5spacy_5attrs_LIKE_NUM,
  __pyx_e_5spacy_5attrs_LIKE_EMAIL,
  __pyx_e_5spacy_5attrs_IS_STOP,
  __pyx_e_5spacy_5attrs_IS_OOV_DEPRECATED,
  __pyx_e_5spacy_5attrs_IS_BRACKET,
  __pyx_e_5spacy_5attrs_IS_QUOTE,
  __pyx_e_5spacy_5attrs_IS_LEFT_PUNCT,
  __pyx_e_5spacy_5attrs_IS_RIGHT_PUNCT,
  __pyx_e_5spacy_5attrs_IS_CURRENCY,
  __pyx_e_5spacy_5attrs_FLAG19 = 19,
  __pyx_e_5spacy_5attrs_FLAG20,
  __pyx_e_5spacy_5attrs_FLAG21,
  __pyx_e_5spacy_5attrs_FLAG22,
  __pyx_e_5spacy_5attrs_FLAG23,
  __pyx_e_5spacy_5attrs_FLAG24,
  __pyx_e_5spacy_5attrs_FLAG25,
  __pyx_e_5spacy_5attrs_FLAG26,
  __pyx_e_5spacy_5attrs_FLAG27,
  __pyx_e_5spacy_5attrs_FLAG28,
  __pyx_e_5spacy_5attrs_FLAG29,
  __pyx_e_5spacy_5attrs_FLAG30,
  __pyx_e_5spacy_5attrs_FLAG31,
  __pyx_e_5spacy_5attrs_FLAG32,
  __pyx_e_5spacy_5attrs_FLAG33,
  __pyx_e_5spacy_5attrs_FLAG34,
  __pyx_e_5spacy_5attrs_FLAG35,
  __pyx_e_5spacy_5attrs_FLAG36,
  __pyx_e_5spacy_5attrs_FLAG37,
  __pyx_e_5spacy_5attrs_FLAG38,
  __pyx_e_5spacy_5attrs_FLAG39,
  __pyx_e_5spacy_5attrs_FLAG40,
  __pyx_e_5spacy_5attrs_FLAG41,
  __pyx_e_5spacy_5attrs_FLAG42,
  __pyx_e_5spacy_5attrs_FLAG43,
  __pyx_e_5spacy_5attrs_FLAG44,
  __pyx_e_5spacy_5attrs_FLAG45,
  __pyx_e_5spacy_5attrs_FLAG46,
  __pyx_e_5spacy_5attrs_FLAG47,
  __pyx_e_5spacy_5attrs_FLAG48,
  __pyx_e_5spacy_5attrs_FLAG49,
  __pyx_e_5spacy_5attrs_FLAG50,
  __pyx_e_5spacy_5attrs_FLAG51,
  __pyx_e_5spacy_5attrs_FLAG52,
  __pyx_e_5spacy_5attrs_FLAG53,
  __pyx_e_5spacy_5attrs_FLAG54,
  __pyx_e_5spacy_5attrs_FLAG55,
  __pyx_e_5spacy_5attrs_FLAG56,
  __pyx_e_5spacy_5attrs_FLAG57,
  __pyx_e_5spacy_5attrs_FLAG58,
  __pyx_e_5spacy_5attrs_FLAG59,
  __pyx_e_5spacy_5attrs_FLAG60,
  __pyx_e_5spacy_5attrs_FLAG61,
  __pyx_e_5spacy_5attrs_FLAG62,
  __pyx_e_5spacy_5attrs_FLAG63,
  __pyx_e_5spacy_5attrs_ID,
  __pyx_e_5spacy_5attrs_ORTH,
  __pyx_e_5spacy_5attrs_LOWER,
  __pyx_e_5spacy_5attrs_NORM,
  __pyx_e_5spacy_5attrs_SHAPE,
  __pyx_e_5spacy_5attrs_PREFIX,
  __pyx_e_5spacy_5attrs_SUFFIX,
  __pyx_e_5spacy_5attrs_LENGTH,
  __pyx_e_5spacy_5attrs_CLUSTER,
  __pyx_e_5spacy_5attrs_LEMMA,
  __pyx_e_5spacy_5attrs_POS,
  __pyx_e_5spacy_5attrs_TAG,
  __pyx_e_5spacy_5attrs_DEP,
  __pyx_e_5spacy_5attrs_ENT_IOB,
  __pyx_e_5spacy_5attrs_ENT_TYPE,
  __pyx_e_5spacy_5attrs_HEAD,
  __pyx_e_5spacy_5attrs_SENT_START,
  __pyx_e_5spacy_5attrs_SPACY,
  __pyx_e_5spacy_5attrs_PROB,
  __pyx_e_5spacy_5attrs_LANG,
  __pyx_e_5spacy_5attrs_ENT_KB_ID = __pyx_e_5spacy_7symbols_ENT_KB_ID,
  __pyx_e_5spacy_5attrs_MORPH,
  __pyx_e_5spacy_5attrs_ENT_ID = __pyx_e_5spacy_7symbols_ENT_ID,
  __pyx_e_5spacy_5attrs_IDX,
  __pyx_e_5spacy_5attrs_SENT_END
};

/* "parts_of_speech.pxd":4
 * 
 * 
 * cpdef enum univ_pos_t:             # <<<<<<<<<<<<<<
 *     NO_TAG = 0
 *     ADJ = symbols.ADJ
 */
enum __pyx_t_5spacy_15parts_of_speech_univ_pos_t {

  /* "parts_of_speech.pxd":6
 * cpdef enum univ_pos_t:
 *     NO_TAG = 0
 *     ADJ = symbols.ADJ             # <<<<<<<<<<<<<<
 *     ADP
 *     ADV
 */
  __pyx_e_5spacy_15parts_of_speech_NO_TAG = 0,
  __pyx_e_5spacy_15parts_of_speech_ADJ = __pyx_e_5spacy_7symbols_ADJ,
  __pyx_e_5spacy_15parts_of_speech_ADP,
  __pyx_e_5spacy_15parts_of_speech_ADV,
  __pyx_e_5spacy_15parts_of_speech_AUX,
  __pyx_e_5spacy_15parts_of_speech_CONJ,
  __pyx_e_5spacy_15parts_of_speech_CCONJ,
  __pyx_e_5spacy_15parts_of_speech_DET,
  __pyx_e_5spacy_15parts_of_speech_INTJ,
  __pyx_e_5spacy_15parts_of_speech_NOUN,
  __pyx_e_5spacy_15parts_of_speech_NUM,
  __pyx_e_5spacy_15parts_of_speech_PART,
  __pyx_e_5spacy_15parts_of_speech_PRON,
  __pyx_e_5spacy_15parts_of_speech_PROPN,
  __pyx_e_5spacy_15parts_of_speech_PUNCT,
  __pyx_e_5spacy_15parts_of_speech_SCONJ,
  __pyx_e_5spacy_15parts_of_speech_SYM,
  __pyx_e_5spacy_15parts_of_speech_VERB,
  __pyx_e_5spacy_15parts_of_speech_X,
  __pyx_e_5spacy_15parts_of_speech_EOL,
  __pyx_e_5spacy_15parts_of_speech_SPACE
};
struct __pyx_t_5spacy_7structs_LexemeC;
struct __pyx_t_5spacy_7structs_SpanC;
struct __pyx_t_5spacy_7structs_TokenC;
struct __pyx_t_5spacy_7structs_MorphAnalysisC;
struct __pyx_t_5spacy_7structs_KBEntryC;
struct __pyx_t_5spacy_7structs_AliasC;
struct __pyx_t_5spacy_7structs_EdgeC;
struct __pyx_t_5spacy_7structs_GraphC;

/* "structs.pxd":10
 * 
 * 
 * cdef struct LexemeC:             # <<<<<<<<<<<<<<
 *     flags_t flags
 * 
 */
struct __pyx_t_5spacy_7structs_LexemeC {
  __pyx_t_5spacy_8typedefs_flags_t flags;
  __pyx_t_5spacy_8typedefs_attr_t lang;
  __pyx_t_5spacy_8typedefs_attr_t id;
  __pyx_t_5spacy_8typedefs_attr_t length;
  __pyx_t_5spacy_8typedefs_attr_t orth;
  __pyx_t_5spacy_8typedefs_attr_t lower;
  __pyx_t_5spacy_8typedefs_attr_t norm;
  __pyx_t_5spacy_8typedefs_attr_t shape;
  __pyx_t_5spacy_8typedefs_attr_t prefix;
  __pyx_t_5spacy_8typedefs_attr_t suffix;
};

/* "structs.pxd":26
 * 
 * 
 * cdef struct SpanC:             # <<<<<<<<<<<<<<
 *     hash_t id
 *     int start
 */
struct __pyx_t_5spacy_7structs_SpanC {
  __pyx_t_5spacy_8typedefs_hash_t id;
  int start;
  int end;
  int start_char;
  int end_char;
  __pyx_t_5spacy_8typedefs_attr_t label;
  __pyx_t_5spacy_8typedefs_attr_t kb_id;
};

/* "structs.pxd":36
 * 
 * 
 * cdef struct TokenC:             # <<<<<<<<<<<<<<
 *     const LexemeC* lex
 *     uint64_t morph
 */
struct __pyx_t_5spacy_7structs_TokenC {
  struct __pyx_t_5spacy_7structs_LexemeC const *lex;
  uint64_t morph;
  enum __pyx_t_5spacy_15parts_of_speech_univ_pos_t pos;
  int spacy;
  __pyx_t_5spacy_8typedefs_attr_t tag;
  int idx;
  __pyx_t_5spacy_8typedefs_attr_t lemma;
  __pyx_t_5spacy_8typedefs_attr_t norm;
  int head;
  __pyx_t_5spacy_8typedefs_attr_t dep;
  uint32_t l_kids;
  uint32_t r_kids;
  uint32_t l_edge;
  uint32_t r_edge;
  int sent_start;
  int ent_iob;
  __pyx_t_5spacy_8typedefs_attr_t ent_type;
  __pyx_t_5spacy_8typedefs_attr_t ent_kb_id;
  __pyx_t_5spacy_8typedefs_hash_t ent_id;
};

/* "structs.pxd":60
 * 
 * 
 * cdef struct MorphAnalysisC:             # <<<<<<<<<<<<<<
 *     hash_t key
 *     int length
 */
struct __pyx_t_5spacy_7structs_MorphAnalysisC {
  __pyx_t_5spacy_8typedefs_hash_t key;
  int length;
  __pyx_t_5spacy_8typedefs_attr_t *fields;
  __pyx_t_5spacy_8typedefs_attr_t *features;
};

/* "structs.pxd":69
 * 
 * # Internal struct, for storage and disambiguation of entities.
 * cdef struct KBEntryC:             # <<<<<<<<<<<<<<
 * 
 *     # The hash of this entry's unique ID/name in the kB
 */
struct __pyx_t_5spacy_7structs_KBEntryC {
  __pyx_t_5spacy_8typedefs_hash_t entity_hash;
  int32_t vector_index;
  int32_t feats_row;
  float freq;
};

/* "structs.pxd":88
 * # Each alias struct stores a list of Entry pointers with their prior probabilities
 * # for this specific mention/alias.
 * cdef struct AliasC:             # <<<<<<<<<<<<<<
 * 
 *     # All entry candidates for this alias
 */
struct __pyx_t_5spacy_7structs_AliasC {
  std::vector<int64_t>  entry_indices;
  std::vector<float>  probs;
};

/* "structs.pxd":97
 * 
 * 
 * cdef struct EdgeC:             # <<<<<<<<<<<<<<
 *     hash_t label
 *     int32_t head
 */
struct __pyx_t_5spacy_7structs_EdgeC {
  __pyx_t_5spacy_8typedefs_hash_t label;
  int32_t head;
  int32_t tail;
};

/* "structs.pxd":103
 * 
 * 
 * cdef struct GraphC:             # <<<<<<<<<<<<<<
 *     vector[vector[int32_t]] nodes
 *     vector[EdgeC] edges
 */
struct __pyx_t_5spacy_7structs_GraphC {
  std::vector<std::vector<int32_t> >  nodes;
  std::vector<struct __pyx_t_5spacy_7structs_EdgeC>  edges;
  std::vector<float>  weights;
  std::vector<int>  n_heads;
  std::vector<int>  n_tails;
  std::vector<int>  first_head;
  std::vector<int>  first_tail;
  std::unordered_set<int>  *roots;
  std::unordered_map<__pyx_t_5spacy_8typedefs_hash_t,int>  *node_map;
  std::unordered_map<__pyx_t_5spacy_8typedefs_hash_t,int>  *edge_map;
};

/* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-b2egv6w5/overlay/Lib/site-packages/numpy/__init__.pxd":725
 * ctypedef npy_longdouble longdouble_t
 * 
 * ctypedef npy_cfloat      cfloat_t             # <<<<<<<<<<<<<<
 * ctypedef npy_cdouble     cdouble_t
 * ctypedef npy_clongdouble clongdouble_t
 */
typedef npy_cfloat __pyx_t_5numpy_cfloat_t;

/* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-b2egv6w5/overlay/Lib/site-packages/numpy/__init__.pxd":726
 * 
 * ctypedef npy_cfloat      cfloat_t
 * ctypedef npy_cdouble     cdouble_t             # <<<<<<<<<<<<<<
 * ctypedef npy_clongdouble clongdouble_t
 * 
 */
typedef npy_cdouble __pyx_t_5numpy_cdouble_t;

/* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-b2egv6w5/overlay/Lib/site-packages/numpy/__init__.pxd":727
 * ctypedef npy_cfloat      cfloat_t
 * ctypedef npy_cdouble     cdouble_t
 * ctypedef npy_clongdouble clongdouble_t             # <<<<<<<<<<<<<<
 * 
 * ctypedef npy_cdouble     complex_t
 */
typedef npy_clongdouble __pyx_t_5numpy_clongdouble_t;

/* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-b2egv6w5/overlay/Lib/site-packages/numpy/__init__.pxd":729
 * ctypedef npy_clongdouble clongdouble_t
 * 
 * ctypedef npy_cdouble     complex_t             # <<<<<<<<<<<<<<
 * 
 * cdef inline object PyArray_MultiIterNew1(a):
 */
typedef npy_cdouble __pyx_t_5numpy_complex_t;
union __pyx_t_5spacy_7strings_Utf8Str;
typedef union __pyx_t_5spacy_7strings_Utf8Str __pyx_t_5spacy_7strings_Utf8Str;

/* "strings.pxd":17
 * 
 * 
 * ctypedef union Utf8Str:             # <<<<<<<<<<<<<<
 *     unsigned char[8] s
 *     unsigned char* p
 */
union __pyx_t_5spacy_7strings_Utf8Str {
  unsigned char s[8];
  unsigned char *p;
};
union __pyx_t_5spacy_5vocab_LexemesOrTokens;
struct __pyx_t_5spacy_5vocab__Cached;

/* "vocab.pxd":15
 * 
 * 
 * cdef union LexemesOrTokens:             # <<<<<<<<<<<<<<
 *     const LexemeC* const* lexemes
 *     const TokenC* tokens
 */
union __pyx_t_5spacy_5vocab_LexemesOrTokens {
  struct __pyx_t_5spacy_7structs_LexemeC const *const *lexemes;
  struct __pyx_t_5spacy_7structs_TokenC const *tokens;
};

/* "vocab.pxd":20
 * 
 * 
 * cdef struct _Cached:             # <<<<<<<<<<<<<<
 *     LexemesOrTokens data
 *     bint is_lex
 */
struct __pyx_t_5spacy_5vocab__Cached {
  union __pyx_t_5spacy_5vocab_LexemesOrTokens data;
  int is_lex;
  int length;
};

/* "tokens/doc.pxd":14
 * 
 * 
 * ctypedef const LexemeC* const_Lexeme_ptr             # <<<<<<<<<<<<<<
 * ctypedef const TokenC* const_TokenC_ptr
 * 
 */
typedef struct __pyx_t_5spacy_7structs_LexemeC const *__pyx_t_5spacy_6tokens_3doc_const_Lexeme_ptr;

/* "tokens/doc.pxd":15
 * 
 * ctypedef const LexemeC* const_Lexeme_ptr
 * ctypedef const TokenC* const_TokenC_ptr             # <<<<<<<<<<<<<<
 * 
 * ctypedef fused LexemeOrToken:
 */
typedef struct __pyx_t_5spacy_7structs_TokenC const *__pyx_t_5spacy_6tokens_3doc_const_TokenC_ptr;

/* "cymem/cymem.pxd":4
 * ctypedef void (*free_t)(void *p)
 * 
 * cdef class PyMalloc:             # <<<<<<<<<<<<<<
 *     cdef malloc_t malloc
 *     cdef void _set(self, malloc_t malloc)
 */
struct __pyx_obj_5cymem_5cymem_PyMalloc {
  PyObject_HEAD
  struct __pyx_vtabstruct_5cymem_5cymem_PyMalloc *__pyx_vtab;
  __pyx_t_5cymem_5cymem_malloc_t malloc;
};


/* "cymem/cymem.pxd":10
 * cdef PyMalloc WrapMalloc(malloc_t malloc)
 * 
 * cdef class PyFree:             # <<<<<<<<<<<<<<
 *     cdef free_t free
 *     cdef void _set(self, free_t free)
 */
struct __pyx_obj_5cymem_5cymem_PyFree {
  PyObject_HEAD
  struct __pyx_vtabstruct_5cymem_5cymem_PyFree *__pyx_vtab;
  __pyx_t_5cymem_5cymem_free_t free;
};


/* "cymem/cymem.pxd":16
 * cdef PyFree WrapFree(free_t free)
 * 
 * cdef class Pool:             # <<<<<<<<<<<<<<
 *     cdef readonly size_t size
 *     cdef readonly dict addresses
 */
struct __pyx_obj_5cymem_5cymem_Pool {
  PyObject_HEAD
  struct __pyx_vtabstruct_5cymem_5cymem_Pool *__pyx_vtab;
  size_t size;
  PyObject *addresses;
  PyObject *refs;
  struct __pyx_obj_5cymem_5cymem_PyMalloc *pymalloc;
  struct __pyx_obj_5cymem_5cymem_PyFree *pyfree;
};


/* "cymem/cymem.pxd":28
 * 
 * 
 * cdef class Address:             # <<<<<<<<<<<<<<
 *     cdef void* ptr
 *     cdef readonly PyMalloc pymalloc
 */
struct __pyx_obj_5cymem_5cymem_Address {
  PyObject_HEAD
  void *ptr;
  struct __pyx_obj_5cymem_5cymem_PyMalloc *pymalloc;
  struct __pyx_obj_5cymem_5cymem_PyFree *pyfree;
};


/* "preshed/maps.pxd":45
 * 
 * 
 * cdef class PreshMap:             # <<<<<<<<<<<<<<
 *     cdef MapStruct* c_map
 *     cdef Pool mem
 */
struct __pyx_obj_7preshed_4maps_PreshMap {
  PyObject_HEAD
  struct __pyx_vtabstruct_7preshed_4maps_PreshMap *__pyx_vtab;
  struct __pyx_t_7preshed_4maps_MapStruct *c_map;
  struct __pyx_obj_5cymem_5cymem_Pool *mem;
};


/* "preshed/maps.pxd":53
 * 
 * 
 * cdef class PreshMapArray:             # <<<<<<<<<<<<<<
 *     cdef Pool mem
 *     cdef MapStruct* maps
 */
struct __pyx_obj_7preshed_4maps_PreshMapArray {
  PyObject_HEAD
  struct __pyx_vtabstruct_7preshed_4maps_PreshMapArray *__pyx_vtab;
  struct __pyx_obj_5cymem_5cymem_Pool *mem;
  struct __pyx_t_7preshed_4maps_MapStruct *maps;
  size_t length;
};


/* "strings.pxd":22
 * 
 * 
 * cdef class StringStore:             # <<<<<<<<<<<<<<
 *     cdef Pool mem
 * 
 */
struct __pyx_obj_5spacy_7strings_StringStore {
  PyObject_HEAD
  struct __pyx_vtabstruct_5spacy_7strings_StringStore *__pyx_vtab;
  struct __pyx_obj_5cymem_5cymem_Pool *mem;
  std::vector<__pyx_t_5spacy_8typedefs_hash_t>  keys;
  struct __pyx_obj_7preshed_4maps_PreshMap *_map;
};


/* "morphology.pxd":11
 * 
 * 
 * cdef class Morphology:             # <<<<<<<<<<<<<<
 *     cdef readonly Pool mem
 *     cdef readonly StringStore strings
 */
struct __pyx_obj_5spacy_10morphology_Morphology {
  PyObject_HEAD
  struct __pyx_vtabstruct_5spacy_10morphology_Morphology *__pyx_vtab;
  struct __pyx_obj_5cymem_5cymem_Pool *mem;
  struct __pyx_obj_5spacy_7strings_StringStore *strings;
  struct __pyx_obj_7preshed_4maps_PreshMap *tags;
};


/* "vocab.pxd":26
 * 
 * 
 * cdef class Vocab:             # <<<<<<<<<<<<<<
 *     cdef Pool mem
 *     cdef readonly StringStore strings
 */
struct __pyx_obj_5spacy_5vocab_Vocab {
  PyObject_HEAD
  struct __pyx_vtabstruct_5spacy_5vocab_Vocab *__pyx_vtab;
  struct __pyx_obj_5cymem_5cymem_Pool *mem;
  struct __pyx_obj_5spacy_7strings_StringStore *strings;
  struct __pyx_obj_5spacy_10morphology_Morphology *morphology;
  PyObject *_vectors;
  PyObject *_lookups;
  PyObject *writing_system;
  PyObject *get_noun_chunks;
  int length;
  PyObject *_unused_object;
  PyObject *lex_attr_getters;
  PyObject *cfg;
  struct __pyx_obj_7preshed_4maps_PreshMap *_by_orth;
};


/* "tokens/doc.pxd":37
 * 
 * 
 * cdef class Doc:             # <<<<<<<<<<<<<<
 *     cdef readonly Pool mem
 *     cdef readonly Vocab vocab
 */
struct __pyx_obj_5spacy_6tokens_3doc_Doc {
  PyObject_HEAD
  struct __pyx_vtabstruct_5spacy_6tokens_3doc_Doc *__pyx_vtab;
  struct __pyx_obj_5cymem_5cymem_Pool *mem;
  struct __pyx_obj_5spacy_5vocab_Vocab *vocab;
  PyObject *_vector;
  PyObject *_vector_norm;
  PyObject *tensor;
  PyObject *cats;
  PyObject *user_data;
  PyObject *spans;
  struct __pyx_t_5spacy_7structs_TokenC *c;
  float sentiment;
  PyObject *user_hooks;
  PyObject *user_token_hooks;
  PyObject *user_span_hooks;
  int has_unknown_spaces;
  PyObject *_context;
  int length;
  int max_length;
  PyObject *noun_chunks_iterator;
  PyObject *__weakref__;
};


/* "matcher/phrasematcher.pxd":11
 * 
 * 
 * cdef class PhraseMatcher:             # <<<<<<<<<<<<<<
 *     cdef readonly Vocab vocab
 *     cdef attr_id_t attr
 */
struct __pyx_obj_5spacy_7matcher_13phrasematcher_PhraseMatcher {
  PyObject_HEAD
  struct __pyx_vtabstruct_5spacy_7matcher_13phrasematcher_PhraseMatcher *__pyx_vtab;
  struct __pyx_obj_5spacy_5vocab_Vocab *vocab;
  enum __pyx_t_5spacy_5attrs_attr_id_t attr;
  PyObject *_callbacks;
  PyObject *_docs;
  int _validate;
  struct __pyx_t_7preshed_4maps_MapStruct *c_map;
  struct __pyx_obj_5cymem_5cymem_Pool *mem;
  __pyx_t_7preshed_4maps_key_t _terminal_hash;
};


/* "lexeme.pxd":24
 * cdef attr_t OOV_RANK
 * 
 * cdef class Lexeme:             # <<<<<<<<<<<<<<
 *     cdef LexemeC* c
 *     cdef readonly Vocab vocab
 */
struct __pyx_obj_5spacy_6lexeme_Lexeme {
  PyObject_HEAD
  struct __pyx_vtabstruct_5spacy_6lexeme_Lexeme *__pyx_vtab;
  struct __pyx_t_5spacy_7structs_LexemeC *c;
  struct __pyx_obj_5spacy_5vocab_Vocab *vocab;
  __pyx_t_5spacy_8typedefs_attr_t orth;
};


/* "spacy/tokenizer.pxd":13
 * 
 * 
 * cdef class Tokenizer:             # <<<<<<<<<<<<<<
 *     cdef Pool mem
 *     cdef PreshMap _cache
 */
struct __pyx_obj_5spacy_9tokenizer_Tokenizer {
  PyObject_HEAD
  struct __pyx_vtabstruct_5spacy_9tokenizer_Tokenizer *__pyx_vtab;
  struct __pyx_obj_5cymem_5cymem_Pool *mem;
  struct __pyx_obj_7preshed_4maps_PreshMap *_cache;
  struct __pyx_obj_7preshed_4maps_PreshMap *_specials;
  struct __pyx_obj_5spacy_5vocab_Vocab *vocab;
  PyObject *_token_match;
  PyObject *_url_match;
  PyObject *_prefix_search;
  PyObject *_suffix_search;
  PyObject *_infix_finditer;
  PyObject *_rules;
  struct __pyx_obj_5spacy_7matcher_13phrasematcher_PhraseMatcher *_special_matcher;
  int _faster_heuristics;
  int _unused_int2;
};


/* "spacy/tokenizer.pyx":210
 *         return doc
 * 
 *     def pipe(self, texts, batch_size=1000):             # <<<<<<<<<<<<<<
 *         """Tokenize a stream of texts.
 * 
 */
struct __pyx_obj_5spacy_9tokenizer___pyx_scope_struct__pipe {
  PyObject_HEAD
  PyObject *__pyx_v_batch_size;
  struct __pyx_obj_5spacy_9tokenizer_Tokenizer *__pyx_v_self;
  PyObject *__pyx_v_text;
  PyObject *__pyx_v_texts;
  PyObject *__pyx_t_0;
  Py_ssize_t __pyx_t_1;
  PyObject *(*__pyx_t_2)(PyObject *);
};


/* "spacy/tokenizer.pyx":629
 *         self._load_special_cases(self._rules)
 * 
 *     def explain(self, text):             # <<<<<<<<<<<<<<
 *         """A debugging tokenizer that provides information about which
 *         tokenizer rule or pattern was matched for each token. The tokens
 */
struct __pyx_obj_5spacy_9tokenizer___pyx_scope_struct_1_explain {
  PyObject_HEAD
  struct __pyx_obj_5spacy_9tokenizer_Tokenizer *__pyx_v_self;
  PyObject *__pyx_v_special_cases;
  PyObject *__pyx_v_substring;
};


/* "spacy/tokenizer.pyx":663
 *             while substring:
 *                 if substring in special_cases:
 *                     tokens.extend(("SPECIAL-" + str(i + 1), self.vocab.strings[e[ORTH]]) for i, e in enumerate(special_cases[substring]))             # <<<<<<<<<<<<<<
 *                     substring = ''
 *                     continue
 */
struct __pyx_obj_5spacy_9tokenizer___pyx_scope_struct_2_genexpr {
  PyObject_HEAD
  struct __pyx_obj_5spacy_9tokenizer___pyx_scope_struct_1_explain *__pyx_outer_scope;
  PyObject *__pyx_v_e;
  PyObject *__pyx_v_i;
  PyObject *__pyx_t_0;
  PyObject *__pyx_t_1;
  Py_ssize_t __pyx_t_2;
  PyObject *(*__pyx_t_3)(PyObject *);
};


/* "spacy/tokenizer.pyx":672
 *                         break
 *                     if substring in special_cases:
 *                         tokens.extend(("SPECIAL-" + str(i + 1), self.vocab.strings[e[ORTH]]) for i, e in enumerate(special_cases[substring]))             # <<<<<<<<<<<<<<
 *                         substring = ''
 *                         break
 */
struct __pyx_obj_5spacy_9tokenizer___pyx_scope_struct_3_genexpr {
  PyObject_HEAD
  struct __pyx_obj_5spacy_9tokenizer___pyx_scope_struct_1_explain *__pyx_outer_scope;
  PyObject *__pyx_v_e;
  PyObject *__pyx_v_i;
  PyObject *__pyx_t_0;
  PyObject *__pyx_t_1;
  Py_ssize_t __pyx_t_2;
  PyObject *(*__pyx_t_3)(PyObject *);
};


/* "spacy/tokenizer.pyx":700
 *                     substring = ''
 *                 elif substring in special_cases:
 *                     tokens.extend((f"SPECIAL-{i + 1}", self.vocab.strings[e[ORTH]]) for i, e in enumerate(special_cases[substring]))             # <<<<<<<<<<<<<<
 *                     substring = ''
 *                 elif list(infix_finditer(substring)):
 */
struct __pyx_obj_5spacy_9tokenizer___pyx_scope_struct_4_genexpr {
  PyObject_HEAD
  struct __pyx_obj_5spacy_9tokenizer___pyx_scope_struct_1_explain *__pyx_outer_scope;
  PyObject *__pyx_v_e;
  PyObject *__pyx_v_i;
  PyObject *__pyx_t_0;
  PyObject *__pyx_t_1;
  Py_ssize_t __pyx_t_2;
  PyObject *(*__pyx_t_3)(PyObject *);
};


/* "spacy/tokenizer.pyx":788
 *         return self
 * 
 *     def to_bytes(self, *, exclude=tuple()):             # <<<<<<<<<<<<<<
 *         """Serialize the current state to a binary string.
 * 
 */
struct __pyx_obj_5spacy_9tokenizer___pyx_scope_struct_5_to_bytes {
  PyObject_HEAD
  PyObject *__pyx_v_exclude;
  struct __pyx_obj_5spacy_9tokenizer_Tokenizer *__pyx_v_self;
};


/* "spacy/tokenizer.pyx":808
 *         return util.to_bytes(serializers, exclude)
 * 
 *     def from_bytes(self, bytes_data, *, exclude=tuple()):             # <<<<<<<<<<<<<<
 *         """Load state from a binary string.
 * 
 */
struct __pyx_obj_5spacy_9tokenizer___pyx_scope_struct_6_from_bytes {
  PyObject_HEAD
  PyObject *__pyx_v_data;
  PyObject *__pyx_v_exclude;
  struct __pyx_obj_5spacy_9tokenizer_Tokenizer *__pyx_v_self;
};


/* "View.MemoryView":106
 * 
 * @cname("__pyx_array")
 * cdef class array:             # <<<<<<<<<<<<<<
 * 
 *     cdef:
 */
struct __pyx_array_obj {
  PyObject_HEAD
  struct __pyx_vtabstruct_array *__pyx_vtab;
  char *data;
  Py_ssize_t len;
  char *format;
  int ndim;
  Py_ssize_t *_shape;
  Py_ssize_t *_strides;
  Py_ssize_t itemsize;
  PyObject *mode;
  PyObject *_format;
  void (*callback_free_data)(void *);
  int free_data;
  int dtype_is_object;
};


/* "View.MemoryView":280
 * 
 * @cname('__pyx_MemviewEnum')
 * cdef class Enum(object):             # <<<<<<<<<<<<<<
 *     cdef object name
 *     def __init__(self, name):
 */
struct __pyx_MemviewEnum_obj {
  PyObject_HEAD
  PyObject *name;
};


/* "View.MemoryView":331
 * 
 * @cname('__pyx_memoryview')
 * cdef class memoryview(object):             # <<<<<<<<<<<<<<
 * 
 *     cdef object obj
 */
struct __pyx_memoryview_obj {
  PyObject_HEAD
  struct __pyx_vtabstruct_memoryview *__pyx_vtab;
  PyObject *obj;
  PyObject *_size;
  PyObject *_array_interface;
  PyThread_type_lock lock;
  __pyx_atomic_int acquisition_count[2];
  __pyx_atomic_int *acquisition_count_aligned_p;
  Py_buffer view;
  int flags;
  int dtype_is_object;
  __Pyx_TypeInfo *typeinfo;
};


/* "View.MemoryView":967
 * 
 * @cname('__pyx_memoryviewslice')
 * cdef class _memoryviewslice(memoryview):             # <<<<<<<<<<<<<<
 *     "Internal class for passing memoryview slices to Python"
 * 
 */
struct __pyx_memoryviewslice_obj {
  struct __pyx_memoryview_obj __pyx_base;
  __Pyx_memviewslice from_slice;
  PyObject *from_object;
  PyObject *(*to_object_func)(char *);
  int (*to_dtype_func)(char *, PyObject *);
};



/* "cymem/cymem.pxd":4
 * ctypedef void (*free_t)(void *p)
 * 
 * cdef class PyMalloc:             # <<<<<<<<<<<<<<
 *     cdef malloc_t malloc
 *     cdef void _set(self, malloc_t malloc)
 */

struct __pyx_vtabstruct_5cymem_5cymem_PyMalloc {
  void (*_set)(struct __pyx_obj_5cymem_5cymem_PyMalloc *, __pyx_t_5cymem_5cymem_malloc_t);
};
static struct __pyx_vtabstruct_5cymem_5cymem_PyMalloc *__pyx_vtabptr_5cymem_5cymem_PyMalloc;


/* "cymem/cymem.pxd":10
 * cdef PyMalloc WrapMalloc(malloc_t malloc)
 * 
 * cdef class PyFree:             # <<<<<<<<<<<<<<
 *     cdef free_t free
 *     cdef void _set(self, free_t free)
 */

struct __pyx_vtabstruct_5cymem_5cymem_PyFree {
  void (*_set)(struct __pyx_obj_5cymem_5cymem_PyFree *, __pyx_t_5cymem_5cymem_free_t);
};
static struct __pyx_vtabstruct_5cymem_5cymem_PyFree *__pyx_vtabptr_5cymem_5cymem_PyFree;


/* "cymem/cymem.pxd":16
 * cdef PyFree WrapFree(free_t free)
 * 
 * cdef class Pool:             # <<<<<<<<<<<<<<
 *     cdef readonly size_t size
 *     cdef readonly dict addresses
 */

struct __pyx_vtabstruct_5cymem_5cymem_Pool {
  void *(*alloc)(struct __pyx_obj_5cymem_5cymem_Pool *, size_t, size_t);
  void (*free)(struct __pyx_obj_5cymem_5cymem_Pool *, void *);
  void *(*realloc)(struct __pyx_obj_5cymem_5cymem_Pool *, void *, size_t);
};
static struct __pyx_vtabstruct_5cymem_5cymem_Pool *__pyx_vtabptr_5cymem_5cymem_Pool;


/* "preshed/maps.pxd":45
 * 
 * 
 * cdef class PreshMap:             # <<<<<<<<<<<<<<
 *     cdef MapStruct* c_map
 *     cdef Pool mem
 */

struct __pyx_vtabstruct_7preshed_4maps_PreshMap {
  void *(*get)(struct __pyx_obj_7preshed_4maps_PreshMap *, __pyx_t_7preshed_4maps_key_t);
  void (*set)(struct __pyx_obj_7preshed_4maps_PreshMap *, __pyx_t_7preshed_4maps_key_t, void *);
};
static struct __pyx_vtabstruct_7preshed_4maps_PreshMap *__pyx_vtabptr_7preshed_4maps_PreshMap;


/* "preshed/maps.pxd":53
 * 
 * 
 * cdef class PreshMapArray:             # <<<<<<<<<<<<<<
 *     cdef Pool mem
 *     cdef MapStruct* maps
 */

struct __pyx_vtabstruct_7preshed_4maps_PreshMapArray {
  void *(*get)(struct __pyx_obj_7preshed_4maps_PreshMapArray *, size_t, __pyx_t_7preshed_4maps_key_t);
  void (*set)(struct __pyx_obj_7preshed_4maps_PreshMapArray *, size_t, __pyx_t_7preshed_4maps_key_t, void *);
};
static struct __pyx_vtabstruct_7preshed_4maps_PreshMapArray *__pyx_vtabptr_7preshed_4maps_PreshMapArray;


/* "strings.pxd":22
 * 
 * 
 * cdef class StringStore:             # <<<<<<<<<<<<<<
 *     cdef Pool mem
 * 
 */

struct __pyx_vtabstruct_5spacy_7strings_StringStore {
  __pyx_t_5spacy_7strings_Utf8Str const *(*intern_unicode)(struct __pyx_obj_5spacy_7strings_StringStore *, PyObject *);
  __pyx_t_5spacy_7strings_Utf8Str const *(*_intern_utf8)(struct __pyx_obj_5spacy_7strings_StringStore *, char *, int, __pyx_t_5spacy_8typedefs_hash_t *);
};
static struct __pyx_vtabstruct_5spacy_7strings_StringStore *__pyx_vtabptr_5spacy_7strings_StringStore;


/* "morphology.pxd":11
 * 
 * 
 * cdef class Morphology:             # <<<<<<<<<<<<<<
 *     cdef readonly Pool mem
 *     cdef readonly StringStore strings
 */

struct __pyx_vtabstruct_5spacy_10morphology_Morphology {
  struct __pyx_t_5spacy_7structs_MorphAnalysisC (*create_morph_tag)(struct __pyx_obj_5spacy_10morphology_Morphology *, PyObject *);
  int (*insert)(struct __pyx_obj_5spacy_10morphology_Morphology *, struct __pyx_t_5spacy_7structs_MorphAnalysisC);
};
static struct __pyx_vtabstruct_5spacy_10morphology_Morphology *__pyx_vtabptr_5spacy_10morphology_Morphology;


/* "vocab.pxd":26
 * 
 * 
 * cdef class Vocab:             # <<<<<<<<<<<<<<
 *     cdef Pool mem
 *     cdef readonly StringStore strings
 */

struct __pyx_vtabstruct_5spacy_5vocab_Vocab {
  struct __pyx_t_5spacy_7structs_LexemeC const *(*get)(struct __pyx_obj_5spacy_5vocab_Vocab *, struct __pyx_obj_5cymem_5cymem_Pool *, PyObject *);
  struct __pyx_t_5spacy_7structs_LexemeC const *(*get_by_orth)(struct __pyx_obj_5spacy_5vocab_Vocab *, struct __pyx_obj_5cymem_5cymem_Pool *, __pyx_t_5spacy_8typedefs_attr_t);
  struct __pyx_t_5spacy_7structs_TokenC const *(*make_fused_token)(struct __pyx_obj_5spacy_5vocab_Vocab *, PyObject *);
  struct __pyx_t_5spacy_7structs_LexemeC const *(*_new_lexeme)(struct __pyx_obj_5spacy_5vocab_Vocab *, struct __pyx_obj_5cymem_5cymem_Pool *, PyObject *);
  int (*_add_lex_to_vocab)(struct __pyx_obj_5spacy_5vocab_Vocab *, __pyx_t_5spacy_8typedefs_hash_t, struct __pyx_t_5spacy_7structs_LexemeC const *);
};
static struct __pyx_vtabstruct_5spacy_5vocab_Vocab *__pyx_vtabptr_5spacy_5vocab_Vocab;


/* "tokens/doc.pxd":37
 * 
 * 
 * cdef class Doc:             # <<<<<<<<<<<<<<
 *     cdef readonly Pool mem
 *     cdef readonly Vocab vocab
 */

struct __pyx_vtabstruct_5spacy_6tokens_3doc_Doc {
  PyArrayObject *(*to_array)(struct __pyx_obj_5spacy_6tokens_3doc_Doc *, PyObject *, int __pyx_skip_dispatch);
  int (*__pyx_fuse_0push_back)(struct __pyx_obj_5spacy_6tokens_3doc_Doc *, __pyx_t_5spacy_6tokens_3doc_const_Lexeme_ptr, int);
  int (*__pyx_fuse_1push_back)(struct __pyx_obj_5spacy_6tokens_3doc_Doc *, __pyx_t_5spacy_6tokens_3doc_const_TokenC_ptr, int);
};
static struct __pyx_vtabstruct_5spacy_6tokens_3doc_Doc *__pyx_vtabptr_5spacy_6tokens_3doc_Doc;


/* "matcher/phrasematcher.pxd":11
 * 
 * 
 * cdef class PhraseMatcher:             # <<<<<<<<<<<<<<
 *     cdef readonly Vocab vocab
 *     cdef attr_id_t attr
 */

struct __pyx_vtabstruct_5spacy_7matcher_13phrasematcher_PhraseMatcher {
  void (*find_matches)(struct __pyx_obj_5spacy_7matcher_13phrasematcher_PhraseMatcher *, struct __pyx_obj_5spacy_6tokens_3doc_Doc *, int, int, std::vector<struct __pyx_t_5spacy_7structs_SpanC>  *);
};
static struct __pyx_vtabstruct_5spacy_7matcher_13phrasematcher_PhraseMatcher *__pyx_vtabptr_5spacy_7matcher_13phrasematcher_PhraseMatcher;


/* "lexeme.pxd":24
 * cdef attr_t OOV_RANK
 * 
 * cdef class Lexeme:             # <<<<<<<<<<<<<<
 *     cdef LexemeC* c
 *     cdef readonly Vocab vocab
 */

struct __pyx_vtabstruct_5spacy_6lexeme_Lexeme {
  struct __pyx_obj_5spacy_6lexeme_Lexeme *(*from_ptr)(struct __pyx_t_5spacy_7structs_LexemeC *, struct __pyx_obj_5spacy_5vocab_Vocab *);
  void (*set_struct_attr)(struct __pyx_t_5spacy_7structs_LexemeC *, enum __pyx_t_5spacy_5attrs_attr_id_t, __pyx_t_5spacy_8typedefs_attr_t);
  __pyx_t_5spacy_8typedefs_attr_t (*get_struct_attr)(struct __pyx_t_5spacy_7structs_LexemeC const *, enum __pyx_t_5spacy_5attrs_attr_id_t);
  int (*c_check_flag)(struct __pyx_t_5spacy_7structs_LexemeC const *, enum __pyx_t_5spacy_5attrs_attr_id_t);
  int (*c_set_flag)(struct __pyx_t_5spacy_7structs_LexemeC *, enum __pyx_t_5spacy_5attrs_attr_id_t, int);
};
static struct __pyx_vtabstruct_5spacy_6lexeme_Lexeme *__pyx_vtabptr_5spacy_6lexeme_Lexeme;
static CYTHON_INLINE struct __pyx_obj_5spacy_6lexeme_Lexeme *__pyx_f_5spacy_6lexeme_6Lexeme_from_ptr(struct __pyx_t_5spacy_7structs_LexemeC *, struct __pyx_obj_5spacy_5vocab_Vocab *);
static CYTHON_INLINE void __pyx_f_5spacy_6lexeme_6Lexeme_set_struct_attr(struct __pyx_t_5spacy_7structs_LexemeC *, enum __pyx_t_5spacy_5attrs_attr_id_t, __pyx_t_5spacy_8typedefs_attr_t);
static CYTHON_INLINE __pyx_t_5spacy_8typedefs_attr_t __pyx_f_5spacy_6lexeme_6Lexeme_get_struct_attr(struct __pyx_t_5spacy_7structs_LexemeC const *, enum __pyx_t_5spacy_5attrs_attr_id_t);
static CYTHON_INLINE int __pyx_f_5spacy_6lexeme_6Lexeme_c_check_flag(struct __pyx_t_5spacy_7structs_LexemeC const *, enum __pyx_t_5spacy_5attrs_attr_id_t);
static CYTHON_INLINE int __pyx_f_5spacy_6lexeme_6Lexeme_c_set_flag(struct __pyx_t_5spacy_7structs_LexemeC *, enum __pyx_t_5spacy_5attrs_attr_id_t, int);


/* "spacy/tokenizer.pyx":25
 * 
 * 
 * cdef class Tokenizer:             # <<<<<<<<<<<<<<
 *     """Segment text, and create Doc objects with the discovered segment
 *     boundaries.
 */

struct __pyx_vtabstruct_5spacy_9tokenizer_Tokenizer {
  struct __pyx_obj_5spacy_6tokens_3doc_Doc *(*_tokenize_affixes)(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *, PyObject *, int);
  int (*_apply_special_cases)(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *, struct __pyx_obj_5spacy_6tokens_3doc_Doc *);
  void (*_filter_special_spans)(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *, std::vector<struct __pyx_t_5spacy_7structs_SpanC>  &, std::vector<struct __pyx_t_5spacy_7structs_SpanC>  &, int);
  PyObject *(*_prepare_special_spans)(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *, struct __pyx_obj_5spacy_6tokens_3doc_Doc *, std::vector<struct __pyx_t_5spacy_7structs_SpanC>  &);
  int (*_retokenize_special_spans)(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *, struct __pyx_obj_5spacy_6tokens_3doc_Doc *, struct __pyx_t_5spacy_7structs_TokenC *, PyObject *);
  int (*_try_specials_and_cache)(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *, __pyx_t_5spacy_8typedefs_hash_t, struct __pyx_obj_5spacy_6tokens_3doc_Doc *, int *, int);
  int (*_tokenize)(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *, struct __pyx_obj_5spacy_6tokens_3doc_Doc *, PyObject *, __pyx_t_5spacy_8typedefs_hash_t, int *, int);
  PyObject *(*_split_affixes)(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *, struct __pyx_obj_5cymem_5cymem_Pool *, PyObject *, std::vector<struct __pyx_t_5spacy_7structs_LexemeC *>  *, std::vector<struct __pyx_t_5spacy_7structs_LexemeC *>  *, int *, int);
  int (*_attach_tokens)(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *, struct __pyx_obj_5spacy_6tokens_3doc_Doc *, PyObject *, std::vector<struct __pyx_t_5spacy_7structs_LexemeC *>  *, std::vector<struct __pyx_t_5spacy_7structs_LexemeC *>  *, int *, int);
  int (*_save_cached)(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *, struct __pyx_t_5spacy_7structs_TokenC const *, __pyx_t_5spacy_8typedefs_hash_t, int *, int);
};
static struct __pyx_vtabstruct_5spacy_9tokenizer_Tokenizer *__pyx_vtabptr_5spacy_9tokenizer_Tokenizer;


/* "View.MemoryView":106
 * 
 * @cname("__pyx_array")
 * cdef class array:             # <<<<<<<<<<<<<<
 * 
 *     cdef:
 */

struct __pyx_vtabstruct_array {
  PyObject *(*get_memview)(struct __pyx_array_obj *);
};
static struct __pyx_vtabstruct_array *__pyx_vtabptr_array;


/* "View.MemoryView":331
 * 
 * @cname('__pyx_memoryview')
 * cdef class memoryview(object):             # <<<<<<<<<<<<<<
 * 
 *     cdef object obj
 */

struct __pyx_vtabstruct_memoryview {
  char *(*get_item_pointer)(struct __pyx_memoryview_obj *, PyObject *);
  PyObject *(*is_slice)(struct __pyx_memoryview_obj *, PyObject *);
  PyObject *(*setitem_slice_assignment)(struct __pyx_memoryview_obj *, PyObject *, PyObject *);
  PyObject *(*setitem_slice_assign_scalar)(struct __pyx_memoryview_obj *, struct __pyx_memoryview_obj *, PyObject *);
  PyObject *(*setitem_indexed)(struct __pyx_memoryview_obj *, PyObject *, PyObject *);
  PyObject *(*convert_item_to_object)(struct __pyx_memoryview_obj *, char *);
  PyObject *(*assign_item_from_object)(struct __pyx_memoryview_obj *, char *, PyObject *);
};
static struct __pyx_vtabstruct_memoryview *__pyx_vtabptr_memoryview;


/* "View.MemoryView":967
 * 
 * @cname('__pyx_memoryviewslice')
 * cdef class _memoryviewslice(memoryview):             # <<<<<<<<<<<<<<
 *     "Internal class for passing memoryview slices to Python"
 * 
 */

struct __pyx_vtabstruct__memoryviewslice {
  struct __pyx_vtabstruct_memoryview __pyx_base;
};
static struct __pyx_vtabstruct__memoryviewslice *__pyx_vtabptr__memoryviewslice;

/* --- Runtime support code (head) --- */
/* Refnanny.proto */
#ifndef CYTHON_REFNANNY
  #define CYTHON_REFNANNY 0
#endif
#if CYTHON_REFNANNY
  typedef struct {
    void (*INCREF)(void*, PyObject*, int);
    void (*DECREF)(void*, PyObject*, int);
    void (*GOTREF)(void*, PyObject*, int);
    void (*GIVEREF)(void*, PyObject*, int);
    void* (*SetupContext)(const char*, int, const char*);
    void (*FinishContext)(void**);
  } __Pyx_RefNannyAPIStruct;
  static __Pyx_RefNannyAPIStruct *__Pyx_RefNanny = NULL;
  static __Pyx_RefNannyAPIStruct *__Pyx_RefNannyImportAPI(const char *modname);
  #define __Pyx_RefNannyDeclarations void *__pyx_refnanny = NULL;
#ifdef WITH_THREAD
  #define __Pyx_RefNannySetupContext(name, acquire_gil)\
          if (acquire_gil) {\
              PyGILState_STATE __pyx_gilstate_save = PyGILState_Ensure();\
              __pyx_refnanny = __Pyx_RefNanny->SetupContext((name), __LINE__, __FILE__);\
              PyGILState_Release(__pyx_gilstate_save);\
          } else {\
              __pyx_refnanny = __Pyx_RefNanny->SetupContext((name), __LINE__, __FILE__);\
          }
#else
  #define __Pyx_RefNannySetupContext(name, acquire_gil)\
          __pyx_refnanny = __Pyx_RefNanny->SetupContext((name), __LINE__, __FILE__)
#endif
  #define __Pyx_RefNannyFinishContext()\
          __Pyx_RefNanny->FinishContext(&__pyx_refnanny)
  #define __Pyx_INCREF(r)  __Pyx_RefNanny->INCREF(__pyx_refnanny, (PyObject *)(r), __LINE__)
  #define __Pyx_DECREF(r)  __Pyx_RefNanny->DECREF(__pyx_refnanny, (PyObject *)(r), __LINE__)
  #define __Pyx_GOTREF(r)  __Pyx_RefNanny->GOTREF(__pyx_refnanny, (PyObject *)(r), __LINE__)
  #define __Pyx_GIVEREF(r) __Pyx_RefNanny->GIVEREF(__pyx_refnanny, (PyObject *)(r), __LINE__)
  #define __Pyx_XINCREF(r)  do { if((r) != NULL) {__Pyx_INCREF(r); }} while(0)
  #define __Pyx_XDECREF(r)  do { if((r) != NULL) {__Pyx_DECREF(r); }} while(0)
  #define __Pyx_XGOTREF(r)  do { if((r) != NULL) {__Pyx_GOTREF(r); }} while(0)
  #define __Pyx_XGIVEREF(r) do { if((r) != NULL) {__Pyx_GIVEREF(r);}} while(0)
#else
  #define __Pyx_RefNannyDeclarations
  #define __Pyx_RefNannySetupContext(name, acquire_gil)
  #define __Pyx_RefNannyFinishContext()
  #define __Pyx_INCREF(r) Py_INCREF(r)
  #define __Pyx_DECREF(r) Py_DECREF(r)
  #define __Pyx_GOTREF(r)
  #define __Pyx_GIVEREF(r)
  #define __Pyx_XINCREF(r) Py_XINCREF(r)
  #define __Pyx_XDECREF(r) Py_XDECREF(r)
  #define __Pyx_XGOTREF(r)
  #define __Pyx_XGIVEREF(r)
#endif
#define __Pyx_XDECREF_SET(r, v) do {\
        PyObject *tmp = (PyObject *) r;\
        r = v; __Pyx_XDECREF(tmp);\
    } while (0)
#define __Pyx_DECREF_SET(r, v) do {\
        PyObject *tmp = (PyObject *) r;\
        r = v; __Pyx_DECREF(tmp);\
    } while (0)
#define __Pyx_CLEAR(r)    do { PyObject* tmp = ((PyObject*)(r)); r = NULL; __Pyx_DECREF(tmp);} while(0)
#define __Pyx_XCLEAR(r)   do { if((r) != NULL) {PyObject* tmp = ((PyObject*)(r)); r = NULL; __Pyx_DECREF(tmp);}} while(0)

/* PyObjectGetAttrStr.proto */
#if CYTHON_USE_TYPE_SLOTS
static CYTHON_INLINE PyObject* __Pyx_PyObject_GetAttrStr(PyObject* obj, PyObject* attr_name);
#else
#define __Pyx_PyObject_GetAttrStr(o,n) PyObject_GetAttr(o,n)
#endif

/* GetBuiltinName.proto */
static PyObject *__Pyx_GetBuiltinName(PyObject *name);

/* RaiseDoubleKeywords.proto */
static void __Pyx_RaiseDoubleKeywordsError(const char* func_name, PyObject* kw_name);

/* ParseKeywords.proto */
static int __Pyx_ParseOptionalKeywords(PyObject *kwds, PyObject **argnames[],\
    PyObject *kwds2, PyObject *values[], Py_ssize_t num_pos_args,\
    const char* function_name);

/* RaiseArgTupleInvalid.proto */
static void __Pyx_RaiseArgtupleInvalid(const char* func_name, int exact,
    Py_ssize_t num_min, Py_ssize_t num_max, Py_ssize_t num_found);

/* ArgTypeTest.proto */
#define __Pyx_ArgTypeTest(obj, type, none_allowed, name, exact)\
    ((likely((Py_TYPE(obj) == type) | (none_allowed && (obj == Py_None)))) ? 1 :\
        __Pyx__ArgTypeTest(obj, type, name, exact))
static int __Pyx__ArgTypeTest(PyObject *obj, PyTypeObject *type, const char *name, int exact);

/* PyFunctionFastCall.proto */
#if CYTHON_FAST_PYCALL
#define __Pyx_PyFunction_FastCall(func, args, nargs)\
    __Pyx_PyFunction_FastCallDict((func), (args), (nargs), NULL)
#if 1 || PY_VERSION_HEX < 0x030600B1
static PyObject *__Pyx_PyFunction_FastCallDict(PyObject *func, PyObject **args, Py_ssize_t nargs, PyObject *kwargs);
#else
#define __Pyx_PyFunction_FastCallDict(func, args, nargs, kwargs) _PyFunction_FastCallDict(func, args, nargs, kwargs)
#endif
#define __Pyx_BUILD_ASSERT_EXPR(cond)\
    (sizeof(char [1 - 2*!(cond)]) - 1)
#ifndef Py_MEMBER_SIZE
#define Py_MEMBER_SIZE(type, member) sizeof(((type *)0)->member)
#endif
#if CYTHON_FAST_PYCALL
  static size_t __pyx_pyframe_localsplus_offset = 0;
  #include "frameobject.h"
#if PY_VERSION_HEX >= 0x030b00a6
  #ifndef Py_BUILD_CORE
    #define Py_BUILD_CORE 1
  #endif
  #include "internal/pycore_frame.h"
#endif
  #define __Pxy_PyFrame_Initialize_Offsets()\
    ((void)__Pyx_BUILD_ASSERT_EXPR(sizeof(PyFrameObject) == offsetof(PyFrameObject, f_localsplus) + Py_MEMBER_SIZE(PyFrameObject, f_localsplus)),\
     (void)(__pyx_pyframe_localsplus_offset = ((size_t)PyFrame_Type.tp_basicsize) - Py_MEMBER_SIZE(PyFrameObject, f_localsplus)))
  #define __Pyx_PyFrame_GetLocalsplus(frame)\
    (assert(__pyx_pyframe_localsplus_offset), (PyObject **)(((char *)(frame)) + __pyx_pyframe_localsplus_offset))
#endif // CYTHON_FAST_PYCALL
#endif

/* PyObjectCall.proto */
#if CYTHON_COMPILING_IN_CPYTHON
static CYTHON_INLINE PyObject* __Pyx_PyObject_Call(PyObject *func, PyObject *arg, PyObject *kw);
#else
#define __Pyx_PyObject_Call(func, arg, kw) PyObject_Call(func, arg, kw)
#endif

/* PyObjectCallMethO.proto */
#if CYTHON_COMPILING_IN_CPYTHON
static CYTHON_INLINE PyObject* __Pyx_PyObject_CallMethO(PyObject *func, PyObject *arg);
#endif

/* PyObjectCallNoArg.proto */
#if CYTHON_COMPILING_IN_CPYTHON
static CYTHON_INLINE PyObject* __Pyx_PyObject_CallNoArg(PyObject *func);
#else
#define __Pyx_PyObject_CallNoArg(func) __Pyx_PyObject_Call(func, __pyx_empty_tuple, NULL)
#endif

/* PyObjectSetAttrStr.proto */
#if CYTHON_USE_TYPE_SLOTS
#define __Pyx_PyObject_DelAttrStr(o,n) __Pyx_PyObject_SetAttrStr(o, n, NULL)
static CYTHON_INLINE int __Pyx_PyObject_SetAttrStr(PyObject* obj, PyObject* attr_name, PyObject* value);
#else
#define __Pyx_PyObject_DelAttrStr(o,n)   PyObject_DelAttr(o,n)
#define __Pyx_PyObject_SetAttrStr(o,n,v) PyObject_SetAttr(o,n,v)
#endif

/* PyCFunctionFastCall.proto */
#if CYTHON_FAST_PYCCALL
static CYTHON_INLINE PyObject *__Pyx_PyCFunction_FastCall(PyObject *func, PyObject **args, Py_ssize_t nargs);
#else
#define __Pyx_PyCFunction_FastCall(func, args, nargs)  (assert(0), NULL)
#endif

/* PyObjectCallOneArg.proto */
static CYTHON_INLINE PyObject* __Pyx_PyObject_CallOneArg(PyObject *func, PyObject *arg);

/* PyObjectCall2Args.proto */
static CYTHON_UNUSED PyObject* __Pyx_PyObject_Call2Args(PyObject* function, PyObject* arg1, PyObject* arg2);

/* PyDictVersioning.proto */
#if CYTHON_USE_DICT_VERSIONS && CYTHON_USE_TYPE_SLOTS
#define __PYX_DICT_VERSION_INIT  ((PY_UINT64_T) -1)
#define __PYX_GET_DICT_VERSION(dict)  (((PyDictObject*)(dict))->ma_version_tag)
#define __PYX_UPDATE_DICT_CACHE(dict, value, cache_var, version_var)\
    (version_var) = __PYX_GET_DICT_VERSION(dict);\
    (cache_var) = (value);
#define __PYX_PY_DICT_LOOKUP_IF_MODIFIED(VAR, DICT, LOOKUP) {\
    static PY_UINT64_T __pyx_dict_version = 0;\
    static PyObject *__pyx_dict_cached_value = NULL;\
    if (likely(__PYX_GET_DICT_VERSION(DICT) == __pyx_dict_version)) {\
        (VAR) = __pyx_dict_cached_value;\
    } else {\
        (VAR) = __pyx_dict_cached_value = (LOOKUP);\
        __pyx_dict_version = __PYX_GET_DICT_VERSION(DICT);\
    }\
}
static CYTHON_INLINE PY_UINT64_T __Pyx_get_tp_dict_version(PyObject *obj);
static CYTHON_INLINE PY_UINT64_T __Pyx_get_object_dict_version(PyObject *obj);
static CYTHON_INLINE int __Pyx_object_dict_version_matches(PyObject* obj, PY_UINT64_T tp_dict_version, PY_UINT64_T obj_dict_version);
#else
#define __PYX_GET_DICT_VERSION(dict)  (0)
#define __PYX_UPDATE_DICT_CACHE(dict, value, cache_var, version_var)
#define __PYX_PY_DICT_LOOKUP_IF_MODIFIED(VAR, DICT, LOOKUP)  (VAR) = (LOOKUP);
#endif

/* GetModuleGlobalName.proto */
#if CYTHON_USE_DICT_VERSIONS
#define __Pyx_GetModuleGlobalName(var, name)  do {\
    static PY_UINT64_T __pyx_dict_version = 0;\
    static PyObject *__pyx_dict_cached_value = NULL;\
    (var) = (likely(__pyx_dict_version == __PYX_GET_DICT_VERSION(__pyx_d))) ?\
        (likely(__pyx_dict_cached_value) ? __Pyx_NewRef(__pyx_dict_cached_value) : __Pyx_GetBuiltinName(name)) :\
        __Pyx__GetModuleGlobalName(name, &__pyx_dict_version, &__pyx_dict_cached_value);\
} while(0)
#define __Pyx_GetModuleGlobalNameUncached(var, name)  do {\
    PY_UINT64_T __pyx_dict_version;\
    PyObject *__pyx_dict_cached_value;\
    (var) = __Pyx__GetModuleGlobalName(name, &__pyx_dict_version, &__pyx_dict_cached_value);\
} while(0)
static PyObject *__Pyx__GetModuleGlobalName(PyObject *name, PY_UINT64_T *dict_version, PyObject **dict_cached_value);
#else
#define __Pyx_GetModuleGlobalName(var, name)  (var) = __Pyx__GetModuleGlobalName(name)
#define __Pyx_GetModuleGlobalNameUncached(var, name)  (var) = __Pyx__GetModuleGlobalName(name)
static CYTHON_INLINE PyObject *__Pyx__GetModuleGlobalName(PyObject *name);
#endif

/* PyThreadStateGet.proto */
#if CYTHON_FAST_THREAD_STATE
#define __Pyx_PyThreadState_declare  PyThreadState *__pyx_tstate;
#define __Pyx_PyThreadState_assign  __pyx_tstate = __Pyx_PyThreadState_Current;
#define __Pyx_PyErr_Occurred()  __pyx_tstate->curexc_type
#else
#define __Pyx_PyThreadState_declare
#define __Pyx_PyThreadState_assign
#define __Pyx_PyErr_Occurred()  PyErr_Occurred()
#endif

/* PyErrFetchRestore.proto */
#if CYTHON_FAST_THREAD_STATE
#define __Pyx_PyErr_Clear() __Pyx_ErrRestore(NULL, NULL, NULL)
#define __Pyx_ErrRestoreWithState(type, value, tb)  __Pyx_ErrRestoreInState(PyThreadState_GET(), type, value, tb)
#define __Pyx_ErrFetchWithState(type, value, tb)    __Pyx_ErrFetchInState(PyThreadState_GET(), type, value, tb)
#define __Pyx_ErrRestore(type, value, tb)  __Pyx_ErrRestoreInState(__pyx_tstate, type, value, tb)
#define __Pyx_ErrFetch(type, value, tb)    __Pyx_ErrFetchInState(__pyx_tstate, type, value, tb)
static CYTHON_INLINE void __Pyx_ErrRestoreInState(PyThreadState *tstate, PyObject *type, PyObject *value, PyObject *tb);
static CYTHON_INLINE void __Pyx_ErrFetchInState(PyThreadState *tstate, PyObject **type, PyObject **value, PyObject **tb);
#if CYTHON_COMPILING_IN_CPYTHON
#define __Pyx_PyErr_SetNone(exc) (Py_INCREF(exc), __Pyx_ErrRestore((exc), NULL, NULL))
#else
#define __Pyx_PyErr_SetNone(exc) PyErr_SetNone(exc)
#endif
#else
#define __Pyx_PyErr_Clear() PyErr_Clear()
#define __Pyx_PyErr_SetNone(exc) PyErr_SetNone(exc)
#define __Pyx_ErrRestoreWithState(type, value, tb)  PyErr_Restore(type, value, tb)
#define __Pyx_ErrFetchWithState(type, value, tb)  PyErr_Fetch(type, value, tb)
#define __Pyx_ErrRestoreInState(tstate, type, value, tb)  PyErr_Restore(type, value, tb)
#define __Pyx_ErrFetchInState(tstate, type, value, tb)  PyErr_Fetch(type, value, tb)
#define __Pyx_ErrRestore(type, value, tb)  PyErr_Restore(type, value, tb)
#define __Pyx_ErrFetch(type, value, tb)  PyErr_Fetch(type, value, tb)
#endif

/* RaiseException.proto */
static void __Pyx_Raise(PyObject *type, PyObject *value, PyObject *tb, PyObject *cause);

/* GetItemInt.proto */
#define __Pyx_GetItemInt(o, i, type, is_signed, to_py_func, is_list, wraparound, boundscheck)\
    (__Pyx_fits_Py_ssize_t(i, type, is_signed) ?\
    __Pyx_GetItemInt_Fast(o, (Py_ssize_t)i, is_list, wraparound, boundscheck) :\
    (is_list ? (PyErr_SetString(PyExc_IndexError, "list index out of range"), (PyObject*)NULL) :\
               __Pyx_GetItemInt_Generic(o, to_py_func(i))))
#define __Pyx_GetItemInt_List(o, i, type, is_signed, to_py_func, is_list, wraparound, boundscheck)\
    (__Pyx_fits_Py_ssize_t(i, type, is_signed) ?\
    __Pyx_GetItemInt_List_Fast(o, (Py_ssize_t)i, wraparound, boundscheck) :\
    (PyErr_SetString(PyExc_IndexError, "list index out of range"), (PyObject*)NULL))
static CYTHON_INLINE PyObject *__Pyx_GetItemInt_List_Fast(PyObject *o, Py_ssize_t i,
                                                              int wraparound, int boundscheck);
#define __Pyx_GetItemInt_Tuple(o, i, type, is_signed, to_py_func, is_list, wraparound, boundscheck)\
    (__Pyx_fits_Py_ssize_t(i, type, is_signed) ?\
    __Pyx_GetItemInt_Tuple_Fast(o, (Py_ssize_t)i, wraparound, boundscheck) :\
    (PyErr_SetString(PyExc_IndexError, "tuple index out of range"), (PyObject*)NULL))
static CYTHON_INLINE PyObject *__Pyx_GetItemInt_Tuple_Fast(PyObject *o, Py_ssize_t i,
                                                              int wraparound, int boundscheck);
static PyObject *__Pyx_GetItemInt_Generic(PyObject *o, PyObject* j);
static CYTHON_INLINE PyObject *__Pyx_GetItemInt_Fast(PyObject *o, Py_ssize_t i,
                                                     int is_list, int wraparound, int boundscheck);

/* IncludeStringH.proto */
#include <string.h>

/* BytesEquals.proto */
static CYTHON_INLINE int __Pyx_PyBytes_Equals(PyObject* s1, PyObject* s2, int equals);

/* UnicodeEquals.proto */
static CYTHON_INLINE int __Pyx_PyUnicode_Equals(PyObject* s1, PyObject* s2, int equals);

/* StrEquals.proto */
#if PY_MAJOR_VERSION >= 3
#define __Pyx_PyString_Equals __Pyx_PyUnicode_Equals
#else
#define __Pyx_PyString_Equals __Pyx_PyBytes_Equals
#endif

/* ListCompAppend.proto */
#if CYTHON_USE_PYLIST_INTERNALS && CYTHON_ASSUME_SAFE_MACROS
static CYTHON_INLINE int __Pyx_ListComp_Append(PyObject* list, PyObject* x) {
    PyListObject* L = (PyListObject*) list;
    Py_ssize_t len = Py_SIZE(list);
    if (likely(L->allocated > len)) {
        Py_INCREF(x);
        PyList_SET_ITEM(list, len, x);
        __Pyx_SET_SIZE(list, len + 1);
        return 0;
    }
    return PyList_Append(list, x);
}
#else
#define __Pyx_ListComp_Append(L,x) PyList_Append(L,x)
#endif

/* RaiseTooManyValuesToUnpack.proto */
static CYTHON_INLINE void __Pyx_RaiseTooManyValuesError(Py_ssize_t expected);

/* RaiseNeedMoreValuesToUnpack.proto */
static CYTHON_INLINE void __Pyx_RaiseNeedMoreValuesError(Py_ssize_t index);

/* IterFinish.proto */
static CYTHON_INLINE int __Pyx_IterFinish(void);

/* UnpackItemEndCheck.proto */
static int __Pyx_IternextUnpackEndCheck(PyObject *retval, Py_ssize_t expected);

/* AssertionsEnabled.proto */
#define __Pyx_init_assertions_enabled()
#if CYTHON_COMPILING_IN_PYPY && PY_VERSION_HEX < 0x02070600 && !defined(Py_OptimizeFlag)
  #define __pyx_assertions_enabled() (1)
#elif PY_VERSION_HEX < 0x03080000  ||  CYTHON_COMPILING_IN_PYPY  ||  defined(Py_LIMITED_API)
  #define __pyx_assertions_enabled() (!Py_OptimizeFlag)
#elif CYTHON_COMPILING_IN_CPYTHON && PY_VERSION_HEX >= 0x030900A6
  static int __pyx_assertions_enabled_flag;
  #define __pyx_assertions_enabled() (__pyx_assertions_enabled_flag)
  #undef __Pyx_init_assertions_enabled
  static void __Pyx_init_assertions_enabled(void) {
    __pyx_assertions_enabled_flag = ! _PyInterpreterState_GetConfig(__Pyx_PyThreadState_Current->interp)->optimization_level;
  }
#else
  #define __pyx_assertions_enabled() (!Py_OptimizeFlag)
#endif

/* WriteUnraisableException.proto */
static void __Pyx_WriteUnraisable(const char *name, int clineno,
                                  int lineno, const char *filename,
                                  int full_traceback, int nogil);

/* SliceObject.proto */
static CYTHON_INLINE PyObject* __Pyx_PyObject_GetSlice(
        PyObject* obj, Py_ssize_t cstart, Py_ssize_t cstop,
        PyObject** py_start, PyObject** py_stop, PyObject** py_slice,
        int has_cstart, int has_cstop, int wraparound);

/* PySequenceContains.proto */
static CYTHON_INLINE int __Pyx_PySequence_ContainsTF(PyObject* item, PyObject* seq, int eq) {
    int result = PySequence_Contains(seq, item);
    return unlikely(result < 0) ? result : (result == (eq == Py_EQ));
}

/* PyIntCompare.proto */
static CYTHON_INLINE PyObject* __Pyx_PyInt_NeObjC(PyObject *op1, PyObject *op2, long intval, long inplace);

/* None.proto */
static CYTHON_INLINE void __Pyx_RaiseUnboundLocalError(const char *varname);

/* StringJoin.proto */
#if PY_MAJOR_VERSION < 3
#define __Pyx_PyString_Join __Pyx_PyBytes_Join
#define __Pyx_PyBaseString_Join(s, v) (PyUnicode_CheckExact(s) ? PyUnicode_Join(s, v) : __Pyx_PyBytes_Join(s, v))
#else
#define __Pyx_PyString_Join PyUnicode_Join
#define __Pyx_PyBaseString_Join PyUnicode_Join
#endif
#if CYTHON_COMPILING_IN_CPYTHON
    #if PY_MAJOR_VERSION < 3
    #define __Pyx_PyBytes_Join _PyString_Join
    #else
    #define __Pyx_PyBytes_Join _PyBytes_Join
    #endif
#else
static CYTHON_INLINE PyObject* __Pyx_PyBytes_Join(PyObject* sep, PyObject* values);
#endif

/* ObjectGetItem.proto */
#if CYTHON_USE_TYPE_SLOTS
static CYTHON_INLINE PyObject *__Pyx_PyObject_GetItem(PyObject *obj, PyObject* key);
#else
#define __Pyx_PyObject_GetItem(obj, key)  PyObject_GetItem(obj, key)
#endif

/* None.proto */
static CYTHON_INLINE void __Pyx_RaiseClosureNameError(const char *varname);

/* DictGetItem.proto */
#if PY_MAJOR_VERSION >= 3 && !CYTHON_COMPILING_IN_PYPY
static PyObject *__Pyx_PyDict_GetItem(PyObject *d, PyObject* key);
#define __Pyx_PyObject_Dict_GetItem(obj, name)\
    (likely(PyDict_CheckExact(obj)) ?\
     __Pyx_PyDict_GetItem(obj, name) : PyObject_GetItem(obj, name))
#else
#define __Pyx_PyDict_GetItem(d, key) PyObject_GetItem(d, key)
#define __Pyx_PyObject_Dict_GetItem(obj, name)  PyObject_GetItem(obj, name)
#endif

/* PyIntBinop.proto */
#if !CYTHON_COMPILING_IN_PYPY
static PyObject* __Pyx_PyInt_AddObjC(PyObject *op1, PyObject *op2, long intval, int inplace, int zerodivision_check);
#else
#define __Pyx_PyInt_AddObjC(op1, op2, intval, inplace, zerodivision_check)\
    (inplace ? PyNumber_InPlaceAdd(op1, op2) : PyNumber_Add(op1, op2))
#endif

/* PyObjectFormatSimple.proto */
#if CYTHON_COMPILING_IN_PYPY
    #define __Pyx_PyObject_FormatSimple(s, f) (\
        likely(PyUnicode_CheckExact(s)) ? (Py_INCREF(s), s) :\
        PyObject_Format(s, f))
#elif PY_MAJOR_VERSION < 3
    #define __Pyx_PyObject_FormatSimple(s, f) (\
        likely(PyUnicode_CheckExact(s)) ? (Py_INCREF(s), s) :\
        likely(PyString_CheckExact(s)) ? PyUnicode_FromEncodedObject(s, NULL, "strict") :\
        PyObject_Format(s, f))
#elif CYTHON_USE_TYPE_SLOTS
    #define __Pyx_PyObject_FormatSimple(s, f) (\
        likely(PyUnicode_CheckExact(s)) ? (Py_INCREF(s), s) :\
        likely(PyLong_CheckExact(s)) ? PyLong_Type.tp_str(s) :\
        likely(PyFloat_CheckExact(s)) ? PyFloat_Type.tp_str(s) :\
        PyObject_Format(s, f))
#else
    #define __Pyx_PyObject_FormatSimple(s, f) (\
        likely(PyUnicode_CheckExact(s)) ? (Py_INCREF(s), s) :\
        PyObject_Format(s, f))
#endif

/* PyDictContains.proto */
static CYTHON_INLINE int __Pyx_PyDict_ContainsTF(PyObject* item, PyObject* dict, int eq) {
    int result = PyDict_Contains(dict, item);
    return unlikely(result < 0) ? result : (result == (eq == Py_EQ));
}

/* ListExtend.proto */
static CYTHON_INLINE int __Pyx_PyList_Extend(PyObject* L, PyObject* v) {
#if CYTHON_COMPILING_IN_CPYTHON
    PyObject* none = _PyList_Extend((PyListObject*)L, v);
    if (unlikely(!none))
        return -1;
    Py_DECREF(none);
    return 0;
#else
    return PyList_SetSlice(L, PY_SSIZE_T_MAX, PY_SSIZE_T_MAX, v);
#endif
}

/* ListAppend.proto */
#if CYTHON_USE_PYLIST_INTERNALS && CYTHON_ASSUME_SAFE_MACROS
static CYTHON_INLINE int __Pyx_PyList_Append(PyObject* list, PyObject* x) {
    PyListObject* L = (PyListObject*) list;
    Py_ssize_t len = Py_SIZE(list);
    if (likely(L->allocated > len) & likely(len > (L->allocated >> 1))) {
        Py_INCREF(x);
        PyList_SET_ITEM(list, len, x);
        __Pyx_SET_SIZE(list, len + 1);
        return 0;
    }
    return PyList_Append(list, x);
}
#else
#define __Pyx_PyList_Append(L,x) PyList_Append(L,x)
#endif

/* PyIntCompare.proto */
static CYTHON_INLINE PyObject* __Pyx_PyInt_EqObjC(PyObject *op1, PyObject *op2, long intval, long inplace);

/* PyObjectLookupSpecial.proto */
#if CYTHON_USE_PYTYPE_LOOKUP && CYTHON_USE_TYPE_SLOTS
static CYTHON_INLINE PyObject* __Pyx_PyObject_LookupSpecial(PyObject* obj, PyObject* attr_name) {
    PyObject *res;
    PyTypeObject *tp = Py_TYPE(obj);
#if PY_MAJOR_VERSION < 3
    if (unlikely(PyInstance_Check(obj)))
        return __Pyx_PyObject_GetAttrStr(obj, attr_name);
#endif
    res = _PyType_Lookup(tp, attr_name);
    if (likely(res)) {
        descrgetfunc f = Py_TYPE(res)->tp_descr_get;
        if (!f) {
            Py_INCREF(res);
        } else {
            res = f(res, obj, (PyObject *)tp);
        }
    } else {
        PyErr_SetObject(PyExc_AttributeError, attr_name);
    }
    return res;
}
#else
#define __Pyx_PyObject_LookupSpecial(o,n) __Pyx_PyObject_GetAttrStr(o,n)
#endif

/* GetTopmostException.proto */
#if CYTHON_USE_EXC_INFO_STACK
static _PyErr_StackItem * __Pyx_PyErr_GetTopmostException(PyThreadState *tstate);
#endif

/* SaveResetException.proto */
#if CYTHON_FAST_THREAD_STATE
#define __Pyx_ExceptionSave(type, value, tb)  __Pyx__ExceptionSave(__pyx_tstate, type, value, tb)
static CYTHON_INLINE void __Pyx__ExceptionSave(PyThreadState *tstate, PyObject **type, PyObject **value, PyObject **tb);
#define __Pyx_ExceptionReset(type, value, tb)  __Pyx__ExceptionReset(__pyx_tstate, type, value, tb)
static CYTHON_INLINE void __Pyx__ExceptionReset(PyThreadState *tstate, PyObject *type, PyObject *value, PyObject *tb);
#else
#define __Pyx_ExceptionSave(type, value, tb)   PyErr_GetExcInfo(type, value, tb)
#define __Pyx_ExceptionReset(type, value, tb)  PyErr_SetExcInfo(type, value, tb)
#endif

/* GetException.proto */
#if CYTHON_FAST_THREAD_STATE
#define __Pyx_GetException(type, value, tb)  __Pyx__GetException(__pyx_tstate, type, value, tb)
static int __Pyx__GetException(PyThreadState *tstate, PyObject **type, PyObject **value, PyObject **tb);
#else
static int __Pyx_GetException(PyObject **type, PyObject **value, PyObject **tb);
#endif

/* FetchCommonType.proto */
static PyTypeObject* __Pyx_FetchCommonType(PyTypeObject* type);

/* CythonFunctionShared.proto */
#define __Pyx_CyFunction_USED 1
#define __Pyx_CYFUNCTION_STATICMETHOD  0x01
#define __Pyx_CYFUNCTION_CLASSMETHOD   0x02
#define __Pyx_CYFUNCTION_CCLASS        0x04
#define __Pyx_CyFunction_GetClosure(f)\
    (((__pyx_CyFunctionObject *) (f))->func_closure)
#define __Pyx_CyFunction_GetClassObj(f)\
    (((__pyx_CyFunctionObject *) (f))->func_classobj)
#define __Pyx_CyFunction_Defaults(type, f)\
    ((type *)(((__pyx_CyFunctionObject *) (f))->defaults))
#define __Pyx_CyFunction_SetDefaultsGetter(f, g)\
    ((__pyx_CyFunctionObject *) (f))->defaults_getter = (g)
typedef struct {
    PyCFunctionObject func;
#if PY_VERSION_HEX < 0x030500A0
    PyObject *func_weakreflist;
#endif
    PyObject *func_dict;
    PyObject *func_name;
    PyObject *func_qualname;
    PyObject *func_doc;
    PyObject *func_globals;
    PyObject *func_code;
    PyObject *func_closure;
    PyObject *func_classobj;
    void *defaults;
    int defaults_pyobjects;
    size_t defaults_size;  // used by FusedFunction for copying defaults
    int flags;
    PyObject *defaults_tuple;
    PyObject *defaults_kwdict;
    PyObject *(*defaults_getter)(PyObject *);
    PyObject *func_annotations;
} __pyx_CyFunctionObject;
static PyTypeObject *__pyx_CyFunctionType = 0;
#define __Pyx_CyFunction_Check(obj)  (__Pyx_TypeCheck(obj, __pyx_CyFunctionType))
static PyObject *__Pyx_CyFunction_Init(__pyx_CyFunctionObject* op, PyMethodDef *ml,
                                      int flags, PyObject* qualname,
                                      PyObject *self,
                                      PyObject *module, PyObject *globals,
                                      PyObject* code);
static CYTHON_INLINE void *__Pyx_CyFunction_InitDefaults(PyObject *m,
                                                         size_t size,
                                                         int pyobjects);
static CYTHON_INLINE void __Pyx_CyFunction_SetDefaultsTuple(PyObject *m,
                                                            PyObject *tuple);
static CYTHON_INLINE void __Pyx_CyFunction_SetDefaultsKwDict(PyObject *m,
                                                             PyObject *dict);
static CYTHON_INLINE void __Pyx_CyFunction_SetAnnotationsDict(PyObject *m,
                                                              PyObject *dict);
static int __pyx_CyFunction_init(void);

/* CythonFunction.proto */
static PyObject *__Pyx_CyFunction_New(PyMethodDef *ml,
                                      int flags, PyObject* qualname,
                                      PyObject *closure,
                                      PyObject *module, PyObject *globals,
                                      PyObject* code);

/* dict_setdefault.proto */
static CYTHON_INLINE PyObject *__Pyx_PyDict_SetDefault(PyObject *d, PyObject *key, PyObject *default_value, int is_safe_type);

/* UnpackUnboundCMethod.proto */
typedef struct {
    PyObject *type;
    PyObject **method_name;
    PyCFunction func;
    PyObject *method;
    int flag;
} __Pyx_CachedCFunction;

/* CallUnboundCMethod2.proto */
static PyObject* __Pyx__CallUnboundCMethod2(__Pyx_CachedCFunction* cfunc, PyObject* self, PyObject* arg1, PyObject* arg2);
#if CYTHON_COMPILING_IN_CPYTHON && PY_VERSION_HEX >= 0x030600B1
static CYTHON_INLINE PyObject *__Pyx_CallUnboundCMethod2(__Pyx_CachedCFunction *cfunc, PyObject *self, PyObject *arg1, PyObject *arg2);
#else
#define __Pyx_CallUnboundCMethod2(cfunc, self, arg1, arg2)  __Pyx__CallUnboundCMethod2(cfunc, self, arg1, arg2)
#endif

/* PyErrExceptionMatches.proto */
#if CYTHON_FAST_THREAD_STATE
#define __Pyx_PyErr_ExceptionMatches(err) __Pyx_PyErr_ExceptionMatchesInState(__pyx_tstate, err)
static CYTHON_INLINE int __Pyx_PyErr_ExceptionMatchesInState(PyThreadState* tstate, PyObject* err);
#else
#define __Pyx_PyErr_ExceptionMatches(err)  PyErr_ExceptionMatches(err)
#endif

/* tp_new.proto */
#define __Pyx_tp_new(type_obj, args) __Pyx_tp_new_kwargs(type_obj, args, NULL)
static CYTHON_INLINE PyObject* __Pyx_tp_new_kwargs(PyObject* type_obj, PyObject* args, PyObject* kwargs) {
    return (PyObject*) (((PyTypeObject*)type_obj)->tp_new((PyTypeObject*)type_obj, args, kwargs));
}

/* ExtTypeTest.proto */
static CYTHON_INLINE int __Pyx_TypeTest(PyObject *obj, PyTypeObject *type);

/* DivInt[Py_ssize_t].proto */
static CYTHON_INLINE Py_ssize_t __Pyx_div_Py_ssize_t(Py_ssize_t, Py_ssize_t);

/* UnaryNegOverflows.proto */
#define UNARY_NEG_WOULD_OVERFLOW(x)\
        (((x) < 0) & ((unsigned long)(x) == 0-(unsigned long)(x)))

static CYTHON_UNUSED int __pyx_array_getbuffer(PyObject *__pyx_v_self, Py_buffer *__pyx_v_info, int __pyx_v_flags); /*proto*/
static PyObject *__pyx_array_get_memview(struct __pyx_array_obj *); /*proto*/
/* GetAttr.proto */
static CYTHON_INLINE PyObject *__Pyx_GetAttr(PyObject *, PyObject *);

/* decode_c_string_utf16.proto */
static CYTHON_INLINE PyObject *__Pyx_PyUnicode_DecodeUTF16(const char *s, Py_ssize_t size, const char *errors) {
    int byteorder = 0;
    return PyUnicode_DecodeUTF16(s, size, errors, &byteorder);
}
static CYTHON_INLINE PyObject *__Pyx_PyUnicode_DecodeUTF16LE(const char *s, Py_ssize_t size, const char *errors) {
    int byteorder = -1;
    return PyUnicode_DecodeUTF16(s, size, errors, &byteorder);
}
static CYTHON_INLINE PyObject *__Pyx_PyUnicode_DecodeUTF16BE(const char *s, Py_ssize_t size, const char *errors) {
    int byteorder = 1;
    return PyUnicode_DecodeUTF16(s, size, errors, &byteorder);
}

/* decode_c_string.proto */
static CYTHON_INLINE PyObject* __Pyx_decode_c_string(
         const char* cstring, Py_ssize_t start, Py_ssize_t stop,
         const char* encoding, const char* errors,
         PyObject* (*decode_func)(const char *s, Py_ssize_t size, const char *errors));

/* GetAttr3.proto */
static CYTHON_INLINE PyObject *__Pyx_GetAttr3(PyObject *, PyObject *, PyObject *);

/* RaiseNoneIterError.proto */
static CYTHON_INLINE void __Pyx_RaiseNoneNotIterableError(void);

/* SwapException.proto */
#if CYTHON_FAST_THREAD_STATE
#define __Pyx_ExceptionSwap(type, value, tb)  __Pyx__ExceptionSwap(__pyx_tstate, type, value, tb)
static CYTHON_INLINE void __Pyx__ExceptionSwap(PyThreadState *tstate, PyObject **type, PyObject **value, PyObject **tb);
#else
static CYTHON_INLINE void __Pyx_ExceptionSwap(PyObject **type, PyObject **value, PyObject **tb);
#endif

/* Import.proto */
static PyObject *__Pyx_Import(PyObject *name, PyObject *from_list, int level);

/* FastTypeChecks.proto */
#if CYTHON_COMPILING_IN_CPYTHON
#define __Pyx_TypeCheck(obj, type) __Pyx_IsSubtype(Py_TYPE(obj), (PyTypeObject *)type)
static CYTHON_INLINE int __Pyx_IsSubtype(PyTypeObject *a, PyTypeObject *b);
static CYTHON_INLINE int __Pyx_PyErr_GivenExceptionMatches(PyObject *err, PyObject *type);
static CYTHON_INLINE int __Pyx_PyErr_GivenExceptionMatches2(PyObject *err, PyObject *type1, PyObject *type2);
#else
#define __Pyx_TypeCheck(obj, type) PyObject_TypeCheck(obj, (PyTypeObject *)type)
#define __Pyx_PyErr_GivenExceptionMatches(err, type) PyErr_GivenExceptionMatches(err, type)
#define __Pyx_PyErr_GivenExceptionMatches2(err, type1, type2) (PyErr_GivenExceptionMatches(err, type1) || PyErr_GivenExceptionMatches(err, type2))
#endif
#define __Pyx_PyException_Check(obj) __Pyx_TypeCheck(obj, PyExc_Exception)

static CYTHON_UNUSED int __pyx_memoryview_getbuffer(PyObject *__pyx_v_self, Py_buffer *__pyx_v_info, int __pyx_v_flags); /*proto*/
/* DivInt[long].proto */
static CYTHON_INLINE long __Pyx_div_long(long, long);

/* ImportFrom.proto */
static PyObject* __Pyx_ImportFrom(PyObject* module, PyObject* name);

/* HasAttr.proto */
static CYTHON_INLINE int __Pyx_HasAttr(PyObject *, PyObject *);

/* PyObject_GenericGetAttrNoDict.proto */
#if CYTHON_USE_TYPE_SLOTS && CYTHON_USE_PYTYPE_LOOKUP && PY_VERSION_HEX < 0x03070000
static CYTHON_INLINE PyObject* __Pyx_PyObject_GenericGetAttrNoDict(PyObject* obj, PyObject* attr_name);
#else
#define __Pyx_PyObject_GenericGetAttrNoDict PyObject_GenericGetAttr
#endif

/* PyObject_GenericGetAttr.proto */
#if CYTHON_USE_TYPE_SLOTS && CYTHON_USE_PYTYPE_LOOKUP && PY_VERSION_HEX < 0x03070000
static PyObject* __Pyx_PyObject_GenericGetAttr(PyObject* obj, PyObject* attr_name);
#else
#define __Pyx_PyObject_GenericGetAttr PyObject_GenericGetAttr
#endif

/* SetVTable.proto */
static int __Pyx_SetVtable(PyObject *dict, void *vtable);

/* PyObjectGetAttrStrNoError.proto */
static CYTHON_INLINE PyObject* __Pyx_PyObject_GetAttrStrNoError(PyObject* obj, PyObject* attr_name);

/* SetupReduce.proto */
static int __Pyx_setup_reduce(PyObject* type_obj);

/* TypeImport.proto */
#ifndef __PYX_HAVE_RT_ImportType_proto_0_29_37
#define __PYX_HAVE_RT_ImportType_proto_0_29_37
#if __STDC_VERSION__ >= 201112L
#include <stdalign.h>
#endif
#if __STDC_VERSION__ >= 201112L || __cplusplus >= 201103L
#define __PYX_GET_STRUCT_ALIGNMENT_0_29_37(s) alignof(s)
#else
#define __PYX_GET_STRUCT_ALIGNMENT_0_29_37(s) sizeof(void*)
#endif
enum __Pyx_ImportType_CheckSize_0_29_37 {
   __Pyx_ImportType_CheckSize_Error_0_29_37 = 0,
   __Pyx_ImportType_CheckSize_Warn_0_29_37 = 1,
   __Pyx_ImportType_CheckSize_Ignore_0_29_37 = 2
};
static PyTypeObject *__Pyx_ImportType_0_29_37(PyObject* module, const char *module_name, const char *class_name, size_t size, size_t alignment, enum __Pyx_ImportType_CheckSize_0_29_37 check_size);
#endif

/* GetVTable.proto */
static void* __Pyx_GetVtable(PyObject *dict);

/* CLineInTraceback.proto */
#ifdef CYTHON_CLINE_IN_TRACEBACK
#define __Pyx_CLineForTraceback(tstate, c_line)  (((CYTHON_CLINE_IN_TRACEBACK)) ? c_line : 0)
#else
static int __Pyx_CLineForTraceback(PyThreadState *tstate, int c_line);
#endif

/* CodeObjectCache.proto */
typedef struct {
    PyCodeObject* code_object;
    int code_line;
} __Pyx_CodeObjectCacheEntry;
struct __Pyx_CodeObjectCache {
    int count;
    int max_count;
    __Pyx_CodeObjectCacheEntry* entries;
};
static struct __Pyx_CodeObjectCache __pyx_code_cache = {0,0,NULL};
static int __pyx_bisect_code_objects(__Pyx_CodeObjectCacheEntry* entries, int count, int code_line);
static PyCodeObject *__pyx_find_code_object(int code_line);
static void __pyx_insert_code_object(int code_line, PyCodeObject* code_object);

/* AddTraceback.proto */
static void __Pyx_AddTraceback(const char *funcname, int c_line,
                               int py_line, const char *filename);

/* GCCDiagnostics.proto */
#if defined(__GNUC__) && (__GNUC__ > 4 || (__GNUC__ == 4 && __GNUC_MINOR__ >= 6))
#define __Pyx_HAS_GCC_DIAGNOSTIC
#endif

/* CppExceptionConversion.proto */
#ifndef __Pyx_CppExn2PyErr
#include <new>
#include <typeinfo>
#include <stdexcept>
#include <ios>
static void __Pyx_CppExn2PyErr() {
  try {
    if (PyErr_Occurred())
      ; // let the latest Python exn pass through and ignore the current one
    else
      throw;
  } catch (const std::bad_alloc& exn) {
    PyErr_SetString(PyExc_MemoryError, exn.what());
  } catch (const std::bad_cast& exn) {
    PyErr_SetString(PyExc_TypeError, exn.what());
  } catch (const std::bad_typeid& exn) {
    PyErr_SetString(PyExc_TypeError, exn.what());
  } catch (const std::domain_error& exn) {
    PyErr_SetString(PyExc_ValueError, exn.what());
  } catch (const std::invalid_argument& exn) {
    PyErr_SetString(PyExc_ValueError, exn.what());
  } catch (const std::ios_base::failure& exn) {
    PyErr_SetString(PyExc_IOError, exn.what());
  } catch (const std::out_of_range& exn) {
    PyErr_SetString(PyExc_IndexError, exn.what());
  } catch (const std::overflow_error& exn) {
    PyErr_SetString(PyExc_OverflowError, exn.what());
  } catch (const std::range_error& exn) {
    PyErr_SetString(PyExc_ArithmeticError, exn.what());
  } catch (const std::underflow_error& exn) {
    PyErr_SetString(PyExc_ArithmeticError, exn.what());
  } catch (const std::exception& exn) {
    PyErr_SetString(PyExc_RuntimeError, exn.what());
  }
  catch (...)
  {
    PyErr_SetString(PyExc_RuntimeError, "Unknown exception");
  }
}
#endif

/* RealImag.proto */
#if CYTHON_CCOMPLEX
  #ifdef __cplusplus
    #define __Pyx_CREAL(z) ((z).real())
    #define __Pyx_CIMAG(z) ((z).imag())
  #else
    #define __Pyx_CREAL(z) (__real__(z))
    #define __Pyx_CIMAG(z) (__imag__(z))
  #endif
#else
    #define __Pyx_CREAL(z) ((z).real)
    #define __Pyx_CIMAG(z) ((z).imag)
#endif
#if defined(__cplusplus) && CYTHON_CCOMPLEX\
        && (defined(_WIN32) || defined(__clang__) || (defined(__GNUC__) && (__GNUC__ >= 5 || __GNUC__ == 4 && __GNUC_MINOR__ >= 4 )) || __cplusplus >= 201103)
    #define __Pyx_SET_CREAL(z,x) ((z).real(x))
    #define __Pyx_SET_CIMAG(z,y) ((z).imag(y))
#else
    #define __Pyx_SET_CREAL(z,x) __Pyx_CREAL(z) = (x)
    #define __Pyx_SET_CIMAG(z,y) __Pyx_CIMAG(z) = (y)
#endif

/* Arithmetic.proto */
#if CYTHON_CCOMPLEX
    #define __Pyx_c_eq_float(a, b)   ((a)==(b))
    #define __Pyx_c_sum_float(a, b)  ((a)+(b))
    #define __Pyx_c_diff_float(a, b) ((a)-(b))
    #define __Pyx_c_prod_float(a, b) ((a)*(b))
    #define __Pyx_c_quot_float(a, b) ((a)/(b))
    #define __Pyx_c_neg_float(a)     (-(a))
  #ifdef __cplusplus
    #define __Pyx_c_is_zero_float(z) ((z)==(float)0)
    #define __Pyx_c_conj_float(z)    (::std::conj(z))
    #if 1
        #define __Pyx_c_abs_float(z)     (::std::abs(z))
        #define __Pyx_c_pow_float(a, b)  (::std::pow(a, b))
    #endif
  #else
    #define __Pyx_c_is_zero_float(z) ((z)==0)
    #define __Pyx_c_conj_float(z)    (conjf(z))
    #if 1
        #define __Pyx_c_abs_float(z)     (cabsf(z))
        #define __Pyx_c_pow_float(a, b)  (cpowf(a, b))
    #endif
 #endif
#else
    static CYTHON_INLINE int __Pyx_c_eq_float(__pyx_t_float_complex, __pyx_t_float_complex);
    static CYTHON_INLINE __pyx_t_float_complex __Pyx_c_sum_float(__pyx_t_float_complex, __pyx_t_float_complex);
    static CYTHON_INLINE __pyx_t_float_complex __Pyx_c_diff_float(__pyx_t_float_complex, __pyx_t_float_complex);
    static CYTHON_INLINE __pyx_t_float_complex __Pyx_c_prod_float(__pyx_t_float_complex, __pyx_t_float_complex);
    static CYTHON_INLINE __pyx_t_float_complex __Pyx_c_quot_float(__pyx_t_float_complex, __pyx_t_float_complex);
    static CYTHON_INLINE __pyx_t_float_complex __Pyx_c_neg_float(__pyx_t_float_complex);
    static CYTHON_INLINE int __Pyx_c_is_zero_float(__pyx_t_float_complex);
    static CYTHON_INLINE __pyx_t_float_complex __Pyx_c_conj_float(__pyx_t_float_complex);
    #if 1
        static CYTHON_INLINE float __Pyx_c_abs_float(__pyx_t_float_complex);
        static CYTHON_INLINE __pyx_t_float_complex __Pyx_c_pow_float(__pyx_t_float_complex, __pyx_t_float_complex);
    #endif
#endif

/* Arithmetic.proto */
#if CYTHON_CCOMPLEX
    #define __Pyx_c_eq_double(a, b)   ((a)==(b))
    #define __Pyx_c_sum_double(a, b)  ((a)+(b))
    #define __Pyx_c_diff_double(a, b) ((a)-(b))
    #define __Pyx_c_prod_double(a, b) ((a)*(b))
    #define __Pyx_c_quot_double(a, b) ((a)/(b))
    #define __Pyx_c_neg_double(a)     (-(a))
  #ifdef __cplusplus
    #define __Pyx_c_is_zero_double(z) ((z)==(double)0)
    #define __Pyx_c_conj_double(z)    (::std::conj(z))
    #if 1
        #define __Pyx_c_abs_double(z)     (::std::abs(z))
        #define __Pyx_c_pow_double(a, b)  (::std::pow(a, b))
    #endif
  #else
    #define __Pyx_c_is_zero_double(z) ((z)==0)
    #define __Pyx_c_conj_double(z)    (conj(z))
    #if 1
        #define __Pyx_c_abs_double(z)     (cabs(z))
        #define __Pyx_c_pow_double(a, b)  (cpow(a, b))
    #endif
 #endif
#else
    static CYTHON_INLINE int __Pyx_c_eq_double(__pyx_t_double_complex, __pyx_t_double_complex);
    static CYTHON_INLINE __pyx_t_double_complex __Pyx_c_sum_double(__pyx_t_double_complex, __pyx_t_double_complex);
    static CYTHON_INLINE __pyx_t_double_complex __Pyx_c_diff_double(__pyx_t_double_complex, __pyx_t_double_complex);
    static CYTHON_INLINE __pyx_t_double_complex __Pyx_c_prod_double(__pyx_t_double_complex, __pyx_t_double_complex);
    static CYTHON_INLINE __pyx_t_double_complex __Pyx_c_quot_double(__pyx_t_double_complex, __pyx_t_double_complex);
    static CYTHON_INLINE __pyx_t_double_complex __Pyx_c_neg_double(__pyx_t_double_complex);
    static CYTHON_INLINE int __Pyx_c_is_zero_double(__pyx_t_double_complex);
    static CYTHON_INLINE __pyx_t_double_complex __Pyx_c_conj_double(__pyx_t_double_complex);
    #if 1
        static CYTHON_INLINE double __Pyx_c_abs_double(__pyx_t_double_complex);
        static CYTHON_INLINE __pyx_t_double_complex __Pyx_c_pow_double(__pyx_t_double_complex, __pyx_t_double_complex);
    #endif
#endif

/* None.proto */
#include <new>

#if PY_MAJOR_VERSION < 3
    static int __Pyx_GetBuffer(PyObject *obj, Py_buffer *view, int flags);
    static void __Pyx_ReleaseBuffer(Py_buffer *view);
#else
    #define __Pyx_GetBuffer PyObject_GetBuffer
    #define __Pyx_ReleaseBuffer PyBuffer_Release
#endif


/* BufferStructDeclare.proto */
typedef struct {
  Py_ssize_t shape, strides, suboffsets;
} __Pyx_Buf_DimInfo;
typedef struct {
  size_t refcount;
  Py_buffer pybuffer;
} __Pyx_Buffer;
typedef struct {
  __Pyx_Buffer *rcbuffer;
  char *data;
  __Pyx_Buf_DimInfo diminfo[8];
} __Pyx_LocalBuf_ND;

/* MemviewSliceIsContig.proto */
static int __pyx_memviewslice_is_contig(const __Pyx_memviewslice mvs, char order, int ndim);

/* OverlappingSlices.proto */
static int __pyx_slices_overlap(__Pyx_memviewslice *slice1,
                                __Pyx_memviewslice *slice2,
                                int ndim, size_t itemsize);

/* Capsule.proto */
static CYTHON_INLINE PyObject *__pyx_capsule_create(void *p, const char *sig);

/* CIntToPy.proto */
static CYTHON_INLINE PyObject* __Pyx_PyInt_From_int(int value);

/* CIntFromPy.proto */
static CYTHON_INLINE int __Pyx_PyInt_As_int(PyObject *);

/* CIntToPy.proto */
static CYTHON_INLINE PyObject* __Pyx_PyInt_From_long(long value);

/* CIntFromPy.proto */
static CYTHON_INLINE uint64_t __Pyx_PyInt_As_uint64_t(PyObject *);

/* CIntFromPy.proto */
static CYTHON_INLINE long __Pyx_PyInt_As_long(PyObject *);

/* MemviewSliceCopyTemplate.proto */
static __Pyx_memviewslice
__pyx_memoryview_copy_new_contig(const __Pyx_memviewslice *from_mvs,
                                 const char *mode, int ndim,
                                 size_t sizeof_dtype, int contig_flag,
                                 int dtype_is_object);

/* CIntToPy.proto */
static CYTHON_INLINE PyObject* __Pyx_PyInt_From_uint64_t(uint64_t value);

/* MemviewSliceInit.proto */
#define __Pyx_BUF_MAX_NDIMS %(BUF_MAX_NDIMS)d
#define __Pyx_MEMVIEW_DIRECT   1
#define __Pyx_MEMVIEW_PTR      2
#define __Pyx_MEMVIEW_FULL     4
#define __Pyx_MEMVIEW_CONTIG   8
#define __Pyx_MEMVIEW_STRIDED  16
#define __Pyx_MEMVIEW_FOLLOW   32
#define __Pyx_IS_C_CONTIG 1
#define __Pyx_IS_F_CONTIG 2
static int __Pyx_init_memviewslice(
                struct __pyx_memoryview_obj *memview,
                int ndim,
                __Pyx_memviewslice *memviewslice,
                int memview_is_new_reference);
static CYTHON_INLINE int __pyx_add_acquisition_count_locked(
    __pyx_atomic_int *acquisition_count, PyThread_type_lock lock);
static CYTHON_INLINE int __pyx_sub_acquisition_count_locked(
    __pyx_atomic_int *acquisition_count, PyThread_type_lock lock);
#define __pyx_get_slice_count_pointer(memview) (memview->acquisition_count_aligned_p)
#define __pyx_get_slice_count(memview) (*__pyx_get_slice_count_pointer(memview))
#define __PYX_INC_MEMVIEW(slice, have_gil) __Pyx_INC_MEMVIEW(slice, have_gil, __LINE__)
#define __PYX_XDEC_MEMVIEW(slice, have_gil) __Pyx_XDEC_MEMVIEW(slice, have_gil, __LINE__)
static CYTHON_INLINE void __Pyx_INC_MEMVIEW(__Pyx_memviewslice *, int, int);
static CYTHON_INLINE void __Pyx_XDEC_MEMVIEW(__Pyx_memviewslice *, int, int);

/* CIntFromPy.proto */
static CYTHON_INLINE char __Pyx_PyInt_As_char(PyObject *);

/* PyObjectGetMethod.proto */
static int __Pyx_PyObject_GetMethod(PyObject *obj, PyObject *name, PyObject **method);

/* PyObjectCallMethod1.proto */
static PyObject* __Pyx_PyObject_CallMethod1(PyObject* obj, PyObject* method_name, PyObject* arg);

/* CoroutineBase.proto */
typedef PyObject *(*__pyx_coroutine_body_t)(PyObject *, PyThreadState *, PyObject *);
#if CYTHON_USE_EXC_INFO_STACK
#define __Pyx_ExcInfoStruct  _PyErr_StackItem
#else
typedef struct {
    PyObject *exc_type;
    PyObject *exc_value;
    PyObject *exc_traceback;
} __Pyx_ExcInfoStruct;
#endif
typedef struct {
    PyObject_HEAD
    __pyx_coroutine_body_t body;
    PyObject *closure;
    __Pyx_ExcInfoStruct gi_exc_state;
    PyObject *gi_weakreflist;
    PyObject *classobj;
    PyObject *yieldfrom;
    PyObject *gi_name;
    PyObject *gi_qualname;
    PyObject *gi_modulename;
    PyObject *gi_code;
    PyObject *gi_frame;
    int resume_label;
    char is_running;
} __pyx_CoroutineObject;
static __pyx_CoroutineObject *__Pyx__Coroutine_New(
    PyTypeObject *type, __pyx_coroutine_body_t body, PyObject *code, PyObject *closure,
    PyObject *name, PyObject *qualname, PyObject *module_name);
static __pyx_CoroutineObject *__Pyx__Coroutine_NewInit(
            __pyx_CoroutineObject *gen, __pyx_coroutine_body_t body, PyObject *code, PyObject *closure,
            PyObject *name, PyObject *qualname, PyObject *module_name);
static CYTHON_INLINE void __Pyx_Coroutine_ExceptionClear(__Pyx_ExcInfoStruct *self);
static int __Pyx_Coroutine_clear(PyObject *self);
static PyObject *__Pyx_Coroutine_Send(PyObject *self, PyObject *value);
static PyObject *__Pyx_Coroutine_Close(PyObject *self);
static PyObject *__Pyx_Coroutine_Throw(PyObject *gen, PyObject *args);
#if CYTHON_USE_EXC_INFO_STACK
#define __Pyx_Coroutine_SwapException(self)
#define __Pyx_Coroutine_ResetAndClearException(self)  __Pyx_Coroutine_ExceptionClear(&(self)->gi_exc_state)
#else
#define __Pyx_Coroutine_SwapException(self) {\
    __Pyx_ExceptionSwap(&(self)->gi_exc_state.exc_type, &(self)->gi_exc_state.exc_value, &(self)->gi_exc_state.exc_traceback);\
    __Pyx_Coroutine_ResetFrameBackpointer(&(self)->gi_exc_state);\
    }
#define __Pyx_Coroutine_ResetAndClearException(self) {\
    __Pyx_ExceptionReset((self)->gi_exc_state.exc_type, (self)->gi_exc_state.exc_value, (self)->gi_exc_state.exc_traceback);\
    (self)->gi_exc_state.exc_type = (self)->gi_exc_state.exc_value = (self)->gi_exc_state.exc_traceback = NULL;\
    }
#endif
#if CYTHON_FAST_THREAD_STATE
#define __Pyx_PyGen_FetchStopIterationValue(pvalue)\
    __Pyx_PyGen__FetchStopIterationValue(__pyx_tstate, pvalue)
#else
#define __Pyx_PyGen_FetchStopIterationValue(pvalue)\
    __Pyx_PyGen__FetchStopIterationValue(__Pyx_PyThreadState_Current, pvalue)
#endif
static int __Pyx_PyGen__FetchStopIterationValue(PyThreadState *tstate, PyObject **pvalue);
static CYTHON_INLINE void __Pyx_Coroutine_ResetFrameBackpointer(__Pyx_ExcInfoStruct *exc_state);

/* PatchModuleWithCoroutine.proto */
static PyObject* __Pyx_Coroutine_patch_module(PyObject* module, const char* py_code);

/* PatchGeneratorABC.proto */
static int __Pyx_patch_abc(void);

/* Generator.proto */
#define __Pyx_Generator_USED
static PyTypeObject *__pyx_GeneratorType = 0;
#define __Pyx_Generator_CheckExact(obj) (Py_TYPE(obj) == __pyx_GeneratorType)
#define __Pyx_Generator_New(body, code, closure, name, qualname, module_name)\
    __Pyx__Coroutine_New(__pyx_GeneratorType, body, code, closure, name, qualname, module_name)
static PyObject *__Pyx_Generator_Next(PyObject *self);
static int __pyx_Generator_init(void);

/* CheckBinaryVersion.proto */
static int __Pyx_check_binary_version(void);

/* VoidPtrImport.proto */
static int __Pyx_ImportVoidPtr_0_29_37(PyObject *module, const char *name, void **p, const char *sig);

/* FunctionImport.proto */
static int __Pyx_ImportFunction_0_29_37(PyObject *module, const char *funcname, void (**f)(void), const char *sig);

/* InitStrings.proto */
static int __Pyx_InitStrings(__Pyx_StringTabEntry *t);

static struct __pyx_obj_5spacy_6tokens_3doc_Doc *__pyx_f_5spacy_9tokenizer_9Tokenizer__tokenize_affixes(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *__pyx_v_self, PyObject *__pyx_v_string, int __pyx_v_with_special_cases); /* proto*/
static int __pyx_f_5spacy_9tokenizer_9Tokenizer__apply_special_cases(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *__pyx_v_self, struct __pyx_obj_5spacy_6tokens_3doc_Doc *__pyx_v_doc); /* proto*/
static void __pyx_f_5spacy_9tokenizer_9Tokenizer__filter_special_spans(CYTHON_UNUSED struct __pyx_obj_5spacy_9tokenizer_Tokenizer *__pyx_v_self, std::vector<struct __pyx_t_5spacy_7structs_SpanC>  &__pyx_v_original, std::vector<struct __pyx_t_5spacy_7structs_SpanC>  &__pyx_v_filtered, CYTHON_UNUSED int __pyx_v_doc_len); /* proto*/
static PyObject *__pyx_f_5spacy_9tokenizer_9Tokenizer__prepare_special_spans(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *__pyx_v_self, struct __pyx_obj_5spacy_6tokens_3doc_Doc *__pyx_v_doc, std::vector<struct __pyx_t_5spacy_7structs_SpanC>  &__pyx_v_filtered); /* proto*/
static int __pyx_f_5spacy_9tokenizer_9Tokenizer__retokenize_special_spans(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *__pyx_v_self, struct __pyx_obj_5spacy_6tokens_3doc_Doc *__pyx_v_doc, struct __pyx_t_5spacy_7structs_TokenC *__pyx_v_tokens, PyObject *__pyx_v_span_data); /* proto*/
static int __pyx_f_5spacy_9tokenizer_9Tokenizer__try_specials_and_cache(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *__pyx_v_self, __pyx_t_5spacy_8typedefs_hash_t __pyx_v_key, struct __pyx_obj_5spacy_6tokens_3doc_Doc *__pyx_v_tokens, int *__pyx_v_has_special, int __pyx_v_with_special_cases); /* proto*/
static int __pyx_f_5spacy_9tokenizer_9Tokenizer__tokenize(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *__pyx_v_self, struct __pyx_obj_5spacy_6tokens_3doc_Doc *__pyx_v_tokens, PyObject *__pyx_v_span, __pyx_t_5spacy_8typedefs_hash_t __pyx_v_orig_key, int *__pyx_v_has_special, int __pyx_v_with_special_cases); /* proto*/
static PyObject *__pyx_f_5spacy_9tokenizer_9Tokenizer__split_affixes(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *__pyx_v_self, struct __pyx_obj_5cymem_5cymem_Pool *__pyx_v_mem, PyObject *__pyx_v_string, std::vector<struct __pyx_t_5spacy_7structs_LexemeC const *>  *__pyx_v_prefixes, std::vector<struct __pyx_t_5spacy_7structs_LexemeC const *>  *__pyx_v_suffixes, CYTHON_UNUSED int *__pyx_v_has_special, int __pyx_v_with_special_cases); /* proto*/
static int __pyx_f_5spacy_9tokenizer_9Tokenizer__attach_tokens(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *__pyx_v_self, struct __pyx_obj_5spacy_6tokens_3doc_Doc *__pyx_v_tokens, PyObject *__pyx_v_string, std::vector<struct __pyx_t_5spacy_7structs_LexemeC const *>  *__pyx_v_prefixes, std::vector<struct __pyx_t_5spacy_7structs_LexemeC const *>  *__pyx_v_suffixes, int *__pyx_v_has_special, int __pyx_v_with_special_cases); /* proto*/
static int __pyx_f_5spacy_9tokenizer_9Tokenizer__save_cached(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *__pyx_v_self, struct __pyx_t_5spacy_7structs_TokenC const *__pyx_v_tokens, __pyx_t_5spacy_8typedefs_hash_t __pyx_v_key, int *__pyx_v_has_special, int __pyx_v_n); /* proto*/
static CYTHON_INLINE struct __pyx_obj_5spacy_6lexeme_Lexeme *__pyx_f_5spacy_6lexeme_6Lexeme_from_ptr(struct __pyx_t_5spacy_7structs_LexemeC *__pyx_v_lex, struct __pyx_obj_5spacy_5vocab_Vocab *__pyx_v_vocab); /* proto*/
static CYTHON_INLINE void __pyx_f_5spacy_6lexeme_6Lexeme_set_struct_attr(struct __pyx_t_5spacy_7structs_LexemeC *__pyx_v_lex, enum __pyx_t_5spacy_5attrs_attr_id_t __pyx_v_name, __pyx_t_5spacy_8typedefs_attr_t __pyx_v_value); /* proto*/
static CYTHON_INLINE __pyx_t_5spacy_8typedefs_attr_t __pyx_f_5spacy_6lexeme_6Lexeme_get_struct_attr(struct __pyx_t_5spacy_7structs_LexemeC const *__pyx_v_lex, enum __pyx_t_5spacy_5attrs_attr_id_t __pyx_v_feat_name); /* proto*/
static CYTHON_INLINE int __pyx_f_5spacy_6lexeme_6Lexeme_c_check_flag(struct __pyx_t_5spacy_7structs_LexemeC const *__pyx_v_lexeme, enum __pyx_t_5spacy_5attrs_attr_id_t __pyx_v_flag_id); /* proto*/
static CYTHON_INLINE int __pyx_f_5spacy_6lexeme_6Lexeme_c_set_flag(struct __pyx_t_5spacy_7structs_LexemeC *__pyx_v_lex, enum __pyx_t_5spacy_5attrs_attr_id_t __pyx_v_flag_id, int __pyx_v_value); /* proto*/
static PyObject *__pyx_array_get_memview(struct __pyx_array_obj *__pyx_v_self); /* proto*/
static char *__pyx_memoryview_get_item_pointer(struct __pyx_memoryview_obj *__pyx_v_self, PyObject *__pyx_v_index); /* proto*/
static PyObject *__pyx_memoryview_is_slice(struct __pyx_memoryview_obj *__pyx_v_self, PyObject *__pyx_v_obj); /* proto*/
static PyObject *__pyx_memoryview_setitem_slice_assignment(struct __pyx_memoryview_obj *__pyx_v_self, PyObject *__pyx_v_dst, PyObject *__pyx_v_src); /* proto*/
static PyObject *__pyx_memoryview_setitem_slice_assign_scalar(struct __pyx_memoryview_obj *__pyx_v_self, struct __pyx_memoryview_obj *__pyx_v_dst, PyObject *__pyx_v_value); /* proto*/
static PyObject *__pyx_memoryview_setitem_indexed(struct __pyx_memoryview_obj *__pyx_v_self, PyObject *__pyx_v_index, PyObject *__pyx_v_value); /* proto*/
static PyObject *__pyx_memoryview_convert_item_to_object(struct __pyx_memoryview_obj *__pyx_v_self, char *__pyx_v_itemp); /* proto*/
static PyObject *__pyx_memoryview_assign_item_from_object(struct __pyx_memoryview_obj *__pyx_v_self, char *__pyx_v_itemp, PyObject *__pyx_v_value); /* proto*/
static PyObject *__pyx_memoryviewslice_convert_item_to_object(struct __pyx_memoryviewslice_obj *__pyx_v_self, char *__pyx_v_itemp); /* proto*/
static PyObject *__pyx_memoryviewslice_assign_item_from_object(struct __pyx_memoryviewslice_obj *__pyx_v_self, char *__pyx_v_itemp, PyObject *__pyx_v_value); /* proto*/

/* Module declarations from 'cymem.cymem' */
static PyTypeObject *__pyx_ptype_5cymem_5cymem_PyMalloc = 0;
static PyTypeObject *__pyx_ptype_5cymem_5cymem_PyFree = 0;
static PyTypeObject *__pyx_ptype_5cymem_5cymem_Pool = 0;
static PyTypeObject *__pyx_ptype_5cymem_5cymem_Address = 0;

/* Module declarations from 'libcpp.vector' */

/* Module declarations from 'libc.stdint' */

/* Module declarations from 'preshed.maps' */
static PyTypeObject *__pyx_ptype_7preshed_4maps_PreshMap = 0;
static PyTypeObject *__pyx_ptype_7preshed_4maps_PreshMapArray = 0;

/* Module declarations from 'spacy' */

/* Module declarations from 'spacy.symbols' */

/* Module declarations from 'spacy.attrs' */

/* Module declarations from 'libcpp.utility' */

/* Module declarations from 'libcpp.unordered_map' */

/* Module declarations from 'libcpp.unordered_set' */

/* Module declarations from 'spacy.parts_of_speech' */

/* Module declarations from 'spacy.typedefs' */

/* Module declarations from 'spacy.structs' */

/* Module declarations from 'cpython.buffer' */

/* Module declarations from 'libc.string' */

/* Module declarations from 'libc.stdio' */

/* Module declarations from '__builtin__' */

/* Module declarations from 'cpython.type' */
static PyTypeObject *__pyx_ptype_7cpython_4type_type = 0;

/* Module declarations from 'cpython' */

/* Module declarations from 'cpython.object' */

/* Module declarations from 'cpython.ref' */

/* Module declarations from 'cpython.mem' */

/* Module declarations from 'numpy' */

/* Module declarations from 'numpy' */
static PyTypeObject *__pyx_ptype_5numpy_dtype = 0;
static PyTypeObject *__pyx_ptype_5numpy_flatiter = 0;
static PyTypeObject *__pyx_ptype_5numpy_broadcast = 0;
static PyTypeObject *__pyx_ptype_5numpy_ndarray = 0;
static PyTypeObject *__pyx_ptype_5numpy_generic = 0;
static PyTypeObject *__pyx_ptype_5numpy_number = 0;
static PyTypeObject *__pyx_ptype_5numpy_integer = 0;
static PyTypeObject *__pyx_ptype_5numpy_signedinteger = 0;
static PyTypeObject *__pyx_ptype_5numpy_unsignedinteger = 0;
static PyTypeObject *__pyx_ptype_5numpy_inexact = 0;
static PyTypeObject *__pyx_ptype_5numpy_floating = 0;
static PyTypeObject *__pyx_ptype_5numpy_complexfloating = 0;
static PyTypeObject *__pyx_ptype_5numpy_flexible = 0;
static PyTypeObject *__pyx_ptype_5numpy_character = 0;
static PyTypeObject *__pyx_ptype_5numpy_ufunc = 0;

/* Module declarations from 'murmurhash.mrmr' */
static uint64_t (*__pyx_f_10murmurhash_4mrmr_hash64)(void *, int, uint64_t); /*proto*/

/* Module declarations from 'libcpp.set' */

/* Module declarations from 'spacy.strings' */
static PyTypeObject *__pyx_ptype_5spacy_7strings_StringStore = 0;
static __pyx_t_5spacy_8typedefs_hash_t (*__pyx_f_5spacy_7strings_hash_string)(PyObject *, int __pyx_skip_dispatch); /*proto*/

/* Module declarations from 'spacy.morphology' */
static PyTypeObject *__pyx_ptype_5spacy_10morphology_Morphology = 0;

/* Module declarations from 'spacy.vocab' */
static PyTypeObject *__pyx_ptype_5spacy_5vocab_Vocab = 0;
static struct __pyx_t_5spacy_7structs_LexemeC *__pyx_vp_5spacy_5vocab_EMPTY_LEXEME = 0;
#define __pyx_v_5spacy_5vocab_EMPTY_LEXEME (*__pyx_vp_5spacy_5vocab_EMPTY_LEXEME)

/* Module declarations from 'spacy.tokens.doc' */
static PyTypeObject *__pyx_ptype_5spacy_6tokens_3doc_Doc = 0;

/* Module declarations from 'spacy.matcher.phrasematcher' */
static PyTypeObject *__pyx_ptype_5spacy_7matcher_13phrasematcher_PhraseMatcher = 0;

/* Module declarations from 'cython.view' */

/* Module declarations from 'cython' */

/* Module declarations from 'spacy.lexeme' */
static PyTypeObject *__pyx_ptype_5spacy_6lexeme_Lexeme = 0;
static struct __pyx_t_5spacy_7structs_LexemeC *__pyx_vp_5spacy_6lexeme_EMPTY_LEXEME = 0;
#define __pyx_v_5spacy_6lexeme_EMPTY_LEXEME (*__pyx_vp_5spacy_6lexeme_EMPTY_LEXEME)
static __pyx_t_5spacy_8typedefs_attr_t *__pyx_vp_5spacy_6lexeme_OOV_RANK = 0;
#define __pyx_v_5spacy_6lexeme_OOV_RANK (*__pyx_vp_5spacy_6lexeme_OOV_RANK)

/* Module declarations from 'spacy.tokenizer' */
static PyTypeObject *__pyx_ptype_5spacy_9tokenizer_Tokenizer = 0;
static PyTypeObject *__pyx_ptype_5spacy_9tokenizer___pyx_scope_struct__pipe = 0;
static PyTypeObject *__pyx_ptype_5spacy_9tokenizer___pyx_scope_struct_1_explain = 0;
static PyTypeObject *__pyx_ptype_5spacy_9tokenizer___pyx_scope_struct_2_genexpr = 0;
static PyTypeObject *__pyx_ptype_5spacy_9tokenizer___pyx_scope_struct_3_genexpr = 0;
static PyTypeObject *__pyx_ptype_5spacy_9tokenizer___pyx_scope_struct_4_genexpr = 0;
static PyTypeObject *__pyx_ptype_5spacy_9tokenizer___pyx_scope_struct_5_to_bytes = 0;
static PyTypeObject *__pyx_ptype_5spacy_9tokenizer___pyx_scope_struct_6_from_bytes = 0;
static PyTypeObject *__pyx_array_type = 0;
static PyTypeObject *__pyx_MemviewEnum_type = 0;
static PyTypeObject *__pyx_memoryview_type = 0;
static PyTypeObject *__pyx_memoryviewslice_type = 0;
static PyObject *generic = 0;
static PyObject *strided = 0;
static PyObject *indirect = 0;
static PyObject *contiguous = 0;
static PyObject *indirect_contiguous = 0;
static int __pyx_memoryview_thread_locks_used;
static PyThread_type_lock __pyx_memoryview_thread_locks[8];
static int __pyx_f_5spacy_9tokenizer_len_start_cmp(struct __pyx_t_5spacy_7structs_SpanC, struct __pyx_t_5spacy_7structs_SpanC); /*proto*/
static int __pyx_f_5spacy_9tokenizer_start_cmp(struct __pyx_t_5spacy_7structs_SpanC, struct __pyx_t_5spacy_7structs_SpanC); /*proto*/
static struct __pyx_array_obj *__pyx_array_new(PyObject *, Py_ssize_t, char *, char *, char *); /*proto*/
static void *__pyx_align_pointer(void *, size_t); /*proto*/
static PyObject *__pyx_memoryview_new(PyObject *, int, int, __Pyx_TypeInfo *); /*proto*/
static CYTHON_INLINE int __pyx_memoryview_check(PyObject *); /*proto*/
static PyObject *_unellipsify(PyObject *, int); /*proto*/
static PyObject *assert_direct_dimensions(Py_ssize_t *, int); /*proto*/
static struct __pyx_memoryview_obj *__pyx_memview_slice(struct __pyx_memoryview_obj *, PyObject *); /*proto*/
static int __pyx_memoryview_slice_memviewslice(__Pyx_memviewslice *, Py_ssize_t, Py_ssize_t, Py_ssize_t, int, int, int *, Py_ssize_t, Py_ssize_t, Py_ssize_t, int, int, int, int); /*proto*/
static char *__pyx_pybuffer_index(Py_buffer *, char *, Py_ssize_t, Py_ssize_t); /*proto*/
static int __pyx_memslice_transpose(__Pyx_memviewslice *); /*proto*/
static PyObject *__pyx_memoryview_fromslice(__Pyx_memviewslice, int, PyObject *(*)(char *), int (*)(char *, PyObject *), int); /*proto*/
static __Pyx_memviewslice *__pyx_memoryview_get_slice_from_memoryview(struct __pyx_memoryview_obj *, __Pyx_memviewslice *); /*proto*/
static void __pyx_memoryview_slice_copy(struct __pyx_memoryview_obj *, __Pyx_memviewslice *); /*proto*/
static PyObject *__pyx_memoryview_copy_object(struct __pyx_memoryview_obj *); /*proto*/
static PyObject *__pyx_memoryview_copy_object_from_slice(struct __pyx_memoryview_obj *, __Pyx_memviewslice *); /*proto*/
static Py_ssize_t abs_py_ssize_t(Py_ssize_t); /*proto*/
static char __pyx_get_best_slice_order(__Pyx_memviewslice *, int); /*proto*/
static void _copy_strided_to_strided(char *, Py_ssize_t *, char *, Py_ssize_t *, Py_ssize_t *, Py_ssize_t *, int, size_t); /*proto*/
static void copy_strided_to_strided(__Pyx_memviewslice *, __Pyx_memviewslice *, int, size_t); /*proto*/
static Py_ssize_t __pyx_memoryview_slice_get_size(__Pyx_memviewslice *, int); /*proto*/
static Py_ssize_t __pyx_fill_contig_strides_array(Py_ssize_t *, Py_ssize_t *, Py_ssize_t, int, char); /*proto*/
static void *__pyx_memoryview_copy_data_to_temp(__Pyx_memviewslice *, __Pyx_memviewslice *, char, int); /*proto*/
static int __pyx_memoryview_err_extents(int, Py_ssize_t, Py_ssize_t); /*proto*/
static int __pyx_memoryview_err_dim(PyObject *, char *, int); /*proto*/
static int __pyx_memoryview_err(PyObject *, char *); /*proto*/
static int __pyx_memoryview_copy_contents(__Pyx_memviewslice, __Pyx_memviewslice, int, int, int); /*proto*/
static void __pyx_memoryview_broadcast_leading(__Pyx_memviewslice *, int, int); /*proto*/
static void __pyx_memoryview_refcount_copying(__Pyx_memviewslice *, int, int, int); /*proto*/
static void __pyx_memoryview_refcount_objects_in_slice_with_gil(char *, Py_ssize_t *, Py_ssize_t *, int, int); /*proto*/
static void __pyx_memoryview_refcount_objects_in_slice(char *, Py_ssize_t *, Py_ssize_t *, int, int); /*proto*/
static void __pyx_memoryview_slice_assign_scalar(__Pyx_memviewslice *, int, size_t, void *, int); /*proto*/
static void __pyx_memoryview__slice_assign_scalar(char *, Py_ssize_t *, Py_ssize_t *, int, size_t, void *); /*proto*/
static PyObject *__pyx_unpickle_Enum__set_state(struct __pyx_MemviewEnum_obj *, PyObject *); /*proto*/
#define __Pyx_MODULE_NAME "spacy.tokenizer"
extern int __pyx_module_is_main_spacy__tokenizer;
int __pyx_module_is_main_spacy__tokenizer = 0;

/* Implementation of 'spacy.tokenizer' */
static PyObject *__pyx_builtin_ValueError;
static PyObject *__pyx_builtin_range;
static PyObject *__pyx_builtin_reversed;
static PyObject *__pyx_builtin_zip;
static PyObject *__pyx_builtin_enumerate;
static PyObject *__pyx_builtin_ImportError;
static PyObject *__pyx_builtin_MemoryError;
static PyObject *__pyx_builtin_TypeError;
static PyObject *__pyx_builtin_Ellipsis;
static PyObject *__pyx_builtin_id;
static PyObject *__pyx_builtin_IndexError;
static const char __pyx_k_[] = " ";
static const char __pyx_k_O[] = "O";
static const char __pyx_k_a[] = "a^";
static const char __pyx_k_c[] = "c";
static const char __pyx_k_d[] = "d";
static const char __pyx_k_e[] = "e";
static const char __pyx_k_i[] = "i";
static const char __pyx_k_j[] = "j";
static const char __pyx_k_k[] = "k";
static const char __pyx_k_s[] = "s";
static const char __pyx_k_t[] = "t";
static const char __pyx_k__3[] = "";
static const char __pyx_k_id[] = "id";
static const char __pyx_k_rb[] = "rb";
static const char __pyx_k_re[] = "re";
static const char __pyx_k_wb[] = "wb";
static const char __pyx_k_add[] = "add";
static const char __pyx_k_doc[] = "doc";
static const char __pyx_k_end[] = "end";
static const char __pyx_k_exc[] = "exc";
static const char __pyx_k_get[] = "get";
static const char __pyx_k_key[] = "key";
static const char __pyx_k_new[] = "__new__";
static const char __pyx_k_obj[] = "obj";
static const char __pyx_k_zip[] = "zip";
static const char __pyx_k_E025[] = "E025";
static const char __pyx_k_E997[] = "E997";
static const char __pyx_k_NORM[] = "NORM";
static const char __pyx_k_ORTH[] = "ORTH";
static const char __pyx_k_Span[] = "Span";
static const char __pyx_k_args[] = "args";
static const char __pyx_k_attr[] = "attr";
static const char __pyx_k_base[] = "base";
static const char __pyx_k_data[] = "data";
static const char __pyx_k_dict[] = "__dict__";
static const char __pyx_k_exit[] = "__exit__";
static const char __pyx_k_file[] = "file_";
static const char __pyx_k_join[] = "join";
static const char __pyx_k_keys[] = "keys";
static const char __pyx_k_m_id[] = "m_id";
static const char __pyx_k_main[] = "__main__";
static const char __pyx_k_mode[] = "mode";
static const char __pyx_k_name[] = "name";
static const char __pyx_k_ndim[] = "ndim";
static const char __pyx_k_open[] = "open";
static const char __pyx_k_orth[] = "orth";
static const char __pyx_k_pack[] = "pack";
static const char __pyx_k_path[] = "path";
static const char __pyx_k_pipe[] = "pipe";
static const char __pyx_k_read[] = "read";
static const char __pyx_k_self[] = "__self__";
static const char __pyx_k_send[] = "send";
static const char __pyx_k_size[] = "size";
static const char __pyx_k_span[] = "span";
static const char __pyx_k_spec[] = "spec";
static const char __pyx_k_step[] = "step";
static const char __pyx_k_stop[] = "stop";
static const char __pyx_k_test[] = "__test__";
static const char __pyx_k_text[] = "text";
static const char __pyx_k_util[] = "util";
static const char __pyx_k_word[] = "word";
static const char __pyx_k_ASCII[] = "ASCII";
static const char __pyx_k_E1005[] = "E1005";
static const char __pyx_k_INFIX[] = "INFIX";
static const char __pyx_k_TOKEN[] = "TOKEN";
static const char __pyx_k_attrs[] = "attrs";
static const char __pyx_k_chunk[] = "chunk";
static const char __pyx_k_class[] = "__class__";
static const char __pyx_k_close[] = "close";
static const char __pyx_k_enter[] = "__enter__";
static const char __pyx_k_error[] = "error";
static const char __pyx_k_flags[] = "flags";
static const char __pyx_k_items[] = "items";
static const char __pyx_k_label[] = "label";
static const char __pyx_k_match[] = "match";
static const char __pyx_k_range[] = "range";
static const char __pyx_k_regex[] = "regex";
static const char __pyx_k_rules[] = "rules";
static const char __pyx_k_score[] = "score";
static const char __pyx_k_shape[] = "shape";
static const char __pyx_k_space[] = "space";
static const char __pyx_k_spans[] = "spans";
static const char __pyx_k_split[] = "split";
static const char __pyx_k_start[] = "start";
static const char __pyx_k_texts[] = "texts";
static const char __pyx_k_throw[] = "throw";
static const char __pyx_k_vocab[] = "vocab";
static const char __pyx_k_words[] = "words";
static const char __pyx_k_write[] = "write";
static const char __pyx_k_Errors[] = "Errors";
static const char __pyx_k_PREFIX[] = "PREFIX";
static const char __pyx_k_SUFFIX[] = "SUFFIX";
static const char __pyx_k_Scorer[] = "Scorer";
static const char __pyx_k_cached[] = "cached";
static const char __pyx_k_encode[] = "encode";
static const char __pyx_k_errors[] = "errors";
static const char __pyx_k_format[] = "format";
static const char __pyx_k_import[] = "__import__";
static const char __pyx_k_kwargs[] = "kwargs";
static const char __pyx_k_length[] = "length";
static const char __pyx_k_name_2[] = "__name__";
static const char __pyx_k_offset[] = "offset";
static const char __pyx_k_pickle[] = "pickle";
static const char __pyx_k_reduce[] = "__reduce__";
static const char __pyx_k_scorer[] = "scorer";
static const char __pyx_k_search[] = "search";
static const char __pyx_k_self_2[] = "self";
static const char __pyx_k_spaces[] = "spaces";
static const char __pyx_k_string[] = "string";
static const char __pyx_k_struct[] = "struct";
static const char __pyx_k_tokens[] = "tokens";
static const char __pyx_k_unpack[] = "unpack";
static const char __pyx_k_update[] = "update";
static const char __pyx_k_SPECIAL[] = "SPECIAL-";
static const char __pyx_k_compile[] = "compile";
static const char __pyx_k_exclude[] = "exclude";
static const char __pyx_k_explain[] = "explain";
static const char __pyx_k_fortran[] = "fortran";
static const char __pyx_k_genexpr[] = "genexpr";
static const char __pyx_k_infixes[] = "infixes";
static const char __pyx_k_isspace[] = "isspace";
static const char __pyx_k_label_2[] = "label_";
static const char __pyx_k_matches[] = "matches";
static const char __pyx_k_memview[] = "memview";
static const char __pyx_k_pattern[] = "pattern";
static const char __pyx_k_realloc[] = "_realloc";
static const char __pyx_k_symbols[] = "symbols";
static const char __pyx_k_t_words[] = "t_words";
static const char __pyx_k_to_disk[] = "to_disk";
static const char __pyx_k_Ellipsis[] = "Ellipsis";
static const char __pyx_k_examples[] = "examples";
static const char __pyx_k_finditer[] = "finditer";
static const char __pyx_k_getstate[] = "__getstate__";
static const char __pyx_k_itemsize[] = "itemsize";
static const char __pyx_k_pyx_type[] = "__pyx_type";
static const char __pyx_k_reversed[] = "reversed";
static const char __pyx_k_setstate[] = "__setstate__";
static const char __pyx_k_suffixes[] = "suffixes";
static const char __pyx_k_t_spaces[] = "t_spaces";
static const char __pyx_k_to_bytes[] = "to_bytes";
static const char __pyx_k_training[] = "training";
static const char __pyx_k_Tokenizer[] = "Tokenizer";
static const char __pyx_k_TypeError[] = "TypeError";
static const char __pyx_k_URL_MATCH[] = "URL_MATCH";
static const char __pyx_k_enumerate[] = "enumerate";
static const char __pyx_k_from_disk[] = "from_disk";
static const char __pyx_k_pyx_state[] = "__pyx_state";
static const char __pyx_k_reduce_ex[] = "__reduce_ex__";
static const char __pyx_k_substring[] = "substring";
static const char __pyx_k_url_match[] = "url_match";
static const char __pyx_k_IndexError[] = "IndexError";
static const char __pyx_k_ValueError[] = "ValueError";
static const char __pyx_k_batch_size[] = "batch_size";
static const char __pyx_k_bytes_data[] = "bytes_data";
static const char __pyx_k_exceptions[] = "exceptions";
static const char __pyx_k_find_infix[] = "find_infix";
static const char __pyx_k_from_bytes[] = "from_bytes";
static const char __pyx_k_pyx_result[] = "__pyx_result";
static const char __pyx_k_pyx_vtable[] = "__pyx_vtable__";
static const char __pyx_k_setdefault[] = "setdefault";
static const char __pyx_k_substrings[] = "substrings";
static const char __pyx_k_ImportError[] = "ImportError";
static const char __pyx_k_MemoryError[] = "MemoryError";
static const char __pyx_k_PickleError[] = "PickleError";
static const char __pyx_k_TOKEN_MATCH[] = "TOKEN_MATCH";
static const char __pyx_k_ensure_path[] = "ensure_path";
static const char __pyx_k_find_prefix[] = "find_prefix";
static const char __pyx_k_find_suffix[] = "find_suffix";
static const char __pyx_k_flush_cache[] = "_flush_cache";
static const char __pyx_k_reset_cache[] = "_reset_cache";
static const char __pyx_k_serializers[] = "serializers";
static const char __pyx_k_strings_map[] = "strings_map";
static const char __pyx_k_token_attrs[] = "token_attrs";
static const char __pyx_k_token_match[] = "token_match";
static const char __pyx_k_filter_spans[] = "filter_spans";
static const char __pyx_k_final_tokens[] = "final_tokens";
static const char __pyx_k_intify_attrs[] = "intify_attrs";
static const char __pyx_k_pyx_checksum[] = "__pyx_checksum";
static const char __pyx_k_stringsource[] = "stringsource";
static const char __pyx_k_deserializers[] = "deserializers";
static const char __pyx_k_do_deprecated[] = "_do_deprecated";
static const char __pyx_k_prefix_search[] = "prefix_search";
static const char __pyx_k_pyx_getbuffer[] = "__pyx_getbuffer";
static const char __pyx_k_reduce_cython[] = "__reduce_cython__";
static const char __pyx_k_special_cases[] = "special_cases";
static const char __pyx_k_special_token[] = "special_token";
static const char __pyx_k_stale_special[] = "stale_special";
static const char __pyx_k_suffix_search[] = "suffix_search";
static const char __pyx_k_Tokenizer_pipe[] = "Tokenizer.pipe";
static const char __pyx_k_flush_specials[] = "_flush_specials";
static const char __pyx_k_infix_finditer[] = "infix_finditer";
static const char __pyx_k_spans_by_start[] = "spans_by_start";
static const char __pyx_k_special_tokens[] = "special_tokens";
static const char __pyx_k_Tokenizer_score[] = "Tokenizer.score";
static const char __pyx_k_View_MemoryView[] = "View.MemoryView";
static const char __pyx_k_allocate_buffer[] = "allocate_buffer";
static const char __pyx_k_dtype_is_object[] = "dtype_is_object";
static const char __pyx_k_pyx_PickleError[] = "__pyx_PickleError";
static const char __pyx_k_setstate_cython[] = "__setstate_cython__";
static const char __pyx_k_spacy_tokenizer[] = "spacy.tokenizer";
static const char __pyx_k_add_special_case[] = "add_special_case";
static const char __pyx_k_Tokenizer_explain[] = "Tokenizer.explain";
static const char __pyx_k_Tokenizer_to_disk[] = "Tokenizer.to_disk";
static const char __pyx_k_faster_heuristics[] = "faster_heuristics";
static const char __pyx_k_get_regex_pattern[] = "_get_regex_pattern";
static const char __pyx_k_pyx_unpickle_Enum[] = "__pyx_unpickle_Enum";
static const char __pyx_k_validate_examples[] = "validate_examples";
static const char __pyx_k_Tokenizer___reduce[] = "Tokenizer.__reduce__";
static const char __pyx_k_Tokenizer_to_bytes[] = "Tokenizer.to_bytes";
static const char __pyx_k_cline_in_traceback[] = "cline_in_traceback";
static const char __pyx_k_load_special_cases[] = "_load_special_cases";
static const char __pyx_k_score_tokenization[] = "score_tokenization";
static const char __pyx_k_strided_and_direct[] = "<strided and direct>";
static const char __pyx_k_Tokenizer_from_disk[] = "Tokenizer.from_disk";
static const char __pyx_k_spacy_tokenizer_pyx[] = "spacy\\tokenizer.pyx";
static const char __pyx_k_Tokenizer_find_infix[] = "Tokenizer.find_infix";
static const char __pyx_k_Tokenizer_from_bytes[] = "Tokenizer.from_bytes";
static const char __pyx_k_get_words_and_spaces[] = "get_words_and_spaces";
static const char __pyx_k_reload_special_cases[] = "_reload_special_cases";
static const char __pyx_k_strided_and_indirect[] = "<strided and indirect>";
static const char __pyx_k_Tokenizer_find_prefix[] = "Tokenizer.find_prefix";
static const char __pyx_k_Tokenizer_find_suffix[] = "Tokenizer.find_suffix";
static const char __pyx_k_contiguous_and_direct[] = "<contiguous and direct>";
static const char __pyx_k_validate_special_case[] = "_validate_special_case";
static const char __pyx_k_MemoryView_of_r_object[] = "<MemoryView of %r object>";
static const char __pyx_k_Tokenizer__flush_cache[] = "Tokenizer._flush_cache";
static const char __pyx_k_Tokenizer__reset_cache[] = "Tokenizer._reset_cache";
static const char __pyx_k_explain_locals_genexpr[] = "explain.<locals>.genexpr";
static const char __pyx_k_to_bytes_locals_lambda[] = "to_bytes.<locals>.<lambda>";
static const char __pyx_k_MemoryView_of_r_at_0x_x[] = "<MemoryView of %r at 0x%x>";
static const char __pyx_k_contiguous_and_indirect[] = "<contiguous and indirect>";
static const char __pyx_k_Cannot_index_with_type_s[] = "Cannot index with type '%s'";
static const char __pyx_k_from_bytes_locals_lambda[] = "from_bytes.<locals>.<lambda>";
static const char __pyx_k_Invalid_shape_in_axis_d_d[] = "Invalid shape in axis %d: %d.";
static const char __pyx_k_Tokenizer__flush_specials[] = "Tokenizer._flush_specials";
static const char __pyx_k_Tokenizer___init___line_31[] = "Tokenizer.__init__ (line 31)";
static const char __pyx_k_Tokenizer_add_special_case[] = "Tokenizer.add_special_case";
static const char __pyx_k_itemsize_0_for_cython_array[] = "itemsize <= 0 for cython.array";
static const char __pyx_k_Tokenizer__load_special_cases[] = "Tokenizer._load_special_cases";
static const char __pyx_k_unable_to_allocate_array_data[] = "unable to allocate array data.";
static const char __pyx_k_strided_and_direct_or_indirect[] = "<strided and direct or indirect>";
static const char __pyx_k_Tokenizer__reload_special_cases[] = "Tokenizer._reload_special_cases";
static const char __pyx_k_numpy_core_multiarray_failed_to[] = "numpy.core.multiarray failed to import";
static const char __pyx_k_Buffer_view_does_not_expose_stri[] = "Buffer view does not expose strides";
static const char __pyx_k_Can_only_create_a_buffer_that_is[] = "Can only create a buffer that is contiguous in memory.";
static const char __pyx_k_Cannot_assign_to_read_only_memor[] = "Cannot assign to read-only memoryview";
static const char __pyx_k_Cannot_create_writable_memory_vi[] = "Cannot create writable memory view from read-only memoryview";
static const char __pyx_k_Create_a_Tokenizer_to_create_Doc[] = "Create a `Tokenizer`, to create `Doc` objects given unicode text.\n\n        vocab (Vocab): A storage container for lexical types.\n        rules (dict): Exceptions and special-cases for the tokenizer.\n        prefix_search (callable): A function matching the signature of\n            `re.compile(string).search` to match prefixes.\n        suffix_search (callable): A function matching the signature of\n            `re.compile(string).search` to match suffixes.\n        infix_finditer (callable): A function matching the signature of\n            `re.compile(string).finditer` to find infixes.\n        token_match (callable): A function matching the signature of\n            `re.compile(string).match`, for matching strings to be\n            recognized as tokens.\n        url_match (callable): A function matching the signature of\n            `re.compile(string).match`, for matching strings to be\n            recognized as urls.\n        faster_heuristics (bool): Whether to restrict the final\n            Matcher-based pass for rules to those containing affixes or space.\n            Defaults to True.\n\n        EXAMPLE:\n            >>> tokenizer = Tokenizer(nlp.vocab)\n\n        DOCS: https://spacy.io/api/tokenizer#init\n        ";
static const char __pyx_k_Empty_shape_tuple_for_cython_arr[] = "Empty shape tuple for cython.array";
static const char __pyx_k_Incompatible_checksums_0x_x_vs_0[] = "Incompatible checksums (0x%x vs (0xb068931, 0x82a3537, 0x6ae9995) = (name))";
static const char __pyx_k_Indirect_dimensions_not_supporte[] = "Indirect dimensions not supported";
static const char __pyx_k_Invalid_mode_expected_c_or_fortr[] = "Invalid mode, expected 'c' or 'fortran', got %s";
static const char __pyx_k_Out_of_bounds_on_buffer_access_a[] = "Out of bounds on buffer access (axis %d)";
static const char __pyx_k_Tokenizer__validate_special_case[] = "Tokenizer._validate_special_case";
static const char __pyx_k_Unable_to_convert_item_to_object[] = "Unable to convert item to object";
static const char __pyx_k_got_differing_extents_in_dimensi[] = "got differing extents in dimension %d (got %d and %d)";
static const char __pyx_k_no_default___reduce___due_to_non[] = "no default __reduce__ due to non-trivial __cinit__";
static const char __pyx_k_numpy_core_umath_failed_to_impor[] = "numpy.core.umath failed to import";
static const char __pyx_k_unable_to_allocate_shape_and_str[] = "unable to allocate shape and strides.";
static PyObject *__pyx_kp_s_;
static PyObject *__pyx_n_s_ASCII;
static PyObject *__pyx_kp_s_Buffer_view_does_not_expose_stri;
static PyObject *__pyx_kp_s_Can_only_create_a_buffer_that_is;
static PyObject *__pyx_kp_s_Cannot_assign_to_read_only_memor;
static PyObject *__pyx_kp_s_Cannot_create_writable_memory_vi;
static PyObject *__pyx_kp_s_Cannot_index_with_type_s;
static PyObject *__pyx_kp_u_Create_a_Tokenizer_to_create_Doc;
static PyObject *__pyx_n_s_E025;
static PyObject *__pyx_n_s_E1005;
static PyObject *__pyx_n_s_E997;
static PyObject *__pyx_n_s_Ellipsis;
static PyObject *__pyx_kp_s_Empty_shape_tuple_for_cython_arr;
static PyObject *__pyx_n_s_Errors;
static PyObject *__pyx_n_s_INFIX;
static PyObject *__pyx_n_s_ImportError;
static PyObject *__pyx_kp_s_Incompatible_checksums_0x_x_vs_0;
static PyObject *__pyx_n_s_IndexError;
static PyObject *__pyx_kp_s_Indirect_dimensions_not_supporte;
static PyObject *__pyx_kp_s_Invalid_mode_expected_c_or_fortr;
static PyObject *__pyx_kp_s_Invalid_shape_in_axis_d_d;
static PyObject *__pyx_n_s_MemoryError;
static PyObject *__pyx_kp_s_MemoryView_of_r_at_0x_x;
static PyObject *__pyx_kp_s_MemoryView_of_r_object;
static PyObject *__pyx_n_s_NORM;
static PyObject *__pyx_n_b_O;
static PyObject *__pyx_n_s_ORTH;
static PyObject *__pyx_kp_s_Out_of_bounds_on_buffer_access_a;
static PyObject *__pyx_n_s_PREFIX;
static PyObject *__pyx_n_s_PickleError;
static PyObject *__pyx_kp_s_SPECIAL;
static PyObject *__pyx_kp_u_SPECIAL;
static PyObject *__pyx_n_s_SUFFIX;
static PyObject *__pyx_n_s_Scorer;
static PyObject *__pyx_n_s_Span;
static PyObject *__pyx_n_s_TOKEN;
static PyObject *__pyx_n_s_TOKEN_MATCH;
static PyObject *__pyx_n_s_Tokenizer;
static PyObject *__pyx_kp_u_Tokenizer___init___line_31;
static PyObject *__pyx_n_s_Tokenizer___reduce;
static PyObject *__pyx_n_s_Tokenizer__flush_cache;
static PyObject *__pyx_n_s_Tokenizer__flush_specials;
static PyObject *__pyx_n_s_Tokenizer__load_special_cases;
static PyObject *__pyx_n_s_Tokenizer__reload_special_cases;
static PyObject *__pyx_n_s_Tokenizer__reset_cache;
static PyObject *__pyx_n_s_Tokenizer__validate_special_case;
static PyObject *__pyx_n_s_Tokenizer_add_special_case;
static PyObject *__pyx_n_s_Tokenizer_explain;
static PyObject *__pyx_n_s_Tokenizer_find_infix;
static PyObject *__pyx_n_s_Tokenizer_find_prefix;
static PyObject *__pyx_n_s_Tokenizer_find_suffix;
static PyObject *__pyx_n_s_Tokenizer_from_bytes;
static PyObject *__pyx_n_s_Tokenizer_from_disk;
static PyObject *__pyx_n_s_Tokenizer_pipe;
static PyObject *__pyx_kp_s_Tokenizer_score;
static PyObject *__pyx_n_s_Tokenizer_to_bytes;
static PyObject *__pyx_n_s_Tokenizer_to_disk;
static PyObject *__pyx_n_s_TypeError;
static PyObject *__pyx_n_s_URL_MATCH;
static PyObject *__pyx_kp_s_Unable_to_convert_item_to_object;
static PyObject *__pyx_n_s_ValueError;
static PyObject *__pyx_n_s_View_MemoryView;
static PyObject *__pyx_kp_s__3;
static PyObject *__pyx_kp_s_a;
static PyObject *__pyx_n_s_add;
static PyObject *__pyx_n_s_add_special_case;
static PyObject *__pyx_n_s_allocate_buffer;
static PyObject *__pyx_n_s_args;
static PyObject *__pyx_n_s_attr;
static PyObject *__pyx_n_s_attrs;
static PyObject *__pyx_n_s_base;
static PyObject *__pyx_n_s_batch_size;
static PyObject *__pyx_n_s_bytes_data;
static PyObject *__pyx_n_s_c;
static PyObject *__pyx_n_u_c;
static PyObject *__pyx_n_s_cached;
static PyObject *__pyx_n_s_chunk;
static PyObject *__pyx_n_s_class;
static PyObject *__pyx_n_s_cline_in_traceback;
static PyObject *__pyx_n_s_close;
static PyObject *__pyx_n_s_compile;
static PyObject *__pyx_kp_s_contiguous_and_direct;
static PyObject *__pyx_kp_s_contiguous_and_indirect;
static PyObject *__pyx_n_s_d;
static PyObject *__pyx_n_s_data;
static PyObject *__pyx_n_s_deserializers;
static PyObject *__pyx_n_s_dict;
static PyObject *__pyx_n_s_do_deprecated;
static PyObject *__pyx_n_s_doc;
static PyObject *__pyx_n_s_dtype_is_object;
static PyObject *__pyx_n_s_e;
static PyObject *__pyx_n_s_encode;
static PyObject *__pyx_n_s_end;
static PyObject *__pyx_n_s_ensure_path;
static PyObject *__pyx_n_s_enter;
static PyObject *__pyx_n_s_enumerate;
static PyObject *__pyx_n_s_error;
static PyObject *__pyx_n_s_errors;
static PyObject *__pyx_n_s_examples;
static PyObject *__pyx_n_s_exc;
static PyObject *__pyx_n_s_exceptions;
static PyObject *__pyx_n_s_exclude;
static PyObject *__pyx_n_s_exit;
static PyObject *__pyx_n_s_explain;
static PyObject *__pyx_n_s_explain_locals_genexpr;
static PyObject *__pyx_n_s_faster_heuristics;
static PyObject *__pyx_n_s_file;
static PyObject *__pyx_n_s_filter_spans;
static PyObject *__pyx_n_s_final_tokens;
static PyObject *__pyx_n_s_find_infix;
static PyObject *__pyx_n_s_find_prefix;
static PyObject *__pyx_n_s_find_suffix;
static PyObject *__pyx_n_s_finditer;
static PyObject *__pyx_n_s_flags;
static PyObject *__pyx_n_s_flush_cache;
static PyObject *__pyx_n_s_flush_specials;
static PyObject *__pyx_n_s_format;
static PyObject *__pyx_n_s_fortran;
static PyObject *__pyx_n_u_fortran;
static PyObject *__pyx_n_s_from_bytes;
static PyObject *__pyx_n_s_from_bytes_locals_lambda;
static PyObject *__pyx_n_s_from_disk;
static PyObject *__pyx_n_s_genexpr;
static PyObject *__pyx_n_s_get;
static PyObject *__pyx_n_s_get_regex_pattern;
static PyObject *__pyx_n_s_get_words_and_spaces;
static PyObject *__pyx_n_s_getstate;
static PyObject *__pyx_kp_s_got_differing_extents_in_dimensi;
static PyObject *__pyx_n_s_i;
static PyObject *__pyx_n_s_id;
static PyObject *__pyx_n_s_import;
static PyObject *__pyx_n_s_infix_finditer;
static PyObject *__pyx_n_s_infixes;
static PyObject *__pyx_n_s_intify_attrs;
static PyObject *__pyx_n_s_isspace;
static PyObject *__pyx_n_s_items;
static PyObject *__pyx_n_s_itemsize;
static PyObject *__pyx_kp_s_itemsize_0_for_cython_array;
static PyObject *__pyx_n_s_j;
static PyObject *__pyx_n_s_join;
static PyObject *__pyx_n_s_k;
static PyObject *__pyx_n_s_key;
static PyObject *__pyx_n_s_keys;
static PyObject *__pyx_n_s_kwargs;
static PyObject *__pyx_n_s_label;
static PyObject *__pyx_n_s_label_2;
static PyObject *__pyx_n_s_length;
static PyObject *__pyx_n_s_load_special_cases;
static PyObject *__pyx_n_s_m_id;
static PyObject *__pyx_n_s_main;
static PyObject *__pyx_n_s_match;
static PyObject *__pyx_n_s_matches;
static PyObject *__pyx_n_s_memview;
static PyObject *__pyx_n_s_mode;
static PyObject *__pyx_n_s_name;
static PyObject *__pyx_n_s_name_2;
static PyObject *__pyx_n_s_ndim;
static PyObject *__pyx_n_s_new;
static PyObject *__pyx_kp_s_no_default___reduce___due_to_non;
static PyObject *__pyx_kp_s_numpy_core_multiarray_failed_to;
static PyObject *__pyx_kp_s_numpy_core_umath_failed_to_impor;
static PyObject *__pyx_n_s_obj;
static PyObject *__pyx_n_s_offset;
static PyObject *__pyx_n_s_open;
static PyObject *__pyx_n_s_orth;
static PyObject *__pyx_n_s_pack;
static PyObject *__pyx_n_s_path;
static PyObject *__pyx_n_s_pattern;
static PyObject *__pyx_n_s_pickle;
static PyObject *__pyx_n_s_pipe;
static PyObject *__pyx_n_s_prefix_search;
static PyObject *__pyx_n_s_pyx_PickleError;
static PyObject *__pyx_n_s_pyx_checksum;
static PyObject *__pyx_n_s_pyx_getbuffer;
static PyObject *__pyx_n_s_pyx_result;
static PyObject *__pyx_n_s_pyx_state;
static PyObject *__pyx_n_s_pyx_type;
static PyObject *__pyx_n_s_pyx_unpickle_Enum;
static PyObject *__pyx_n_s_pyx_vtable;
static PyObject *__pyx_n_s_range;
static PyObject *__pyx_n_s_rb;
static PyObject *__pyx_n_s_re;
static PyObject *__pyx_n_s_read;
static PyObject *__pyx_n_s_realloc;
static PyObject *__pyx_n_s_reduce;
static PyObject *__pyx_n_s_reduce_cython;
static PyObject *__pyx_n_s_reduce_ex;
static PyObject *__pyx_n_s_regex;
static PyObject *__pyx_n_s_reload_special_cases;
static PyObject *__pyx_n_s_reset_cache;
static PyObject *__pyx_n_s_reversed;
static PyObject *__pyx_n_s_rules;
static PyObject *__pyx_n_s_s;
static PyObject *__pyx_n_s_score;
static PyObject *__pyx_n_s_score_tokenization;
static PyObject *__pyx_n_s_scorer;
static PyObject *__pyx_n_s_search;
static PyObject *__pyx_n_s_self;
static PyObject *__pyx_n_s_self_2;
static PyObject *__pyx_n_s_send;
static PyObject *__pyx_n_s_serializers;
static PyObject *__pyx_n_s_setdefault;
static PyObject *__pyx_n_s_setstate;
static PyObject *__pyx_n_s_setstate_cython;
static PyObject *__pyx_n_s_shape;
static PyObject *__pyx_n_s_size;
static PyObject *__pyx_n_s_space;
static PyObject *__pyx_n_s_spaces;
static PyObject *__pyx_n_s_spacy_tokenizer;
static PyObject *__pyx_kp_s_spacy_tokenizer_pyx;
static PyObject *__pyx_n_s_span;
static PyObject *__pyx_n_s_spans;
static PyObject *__pyx_n_s_spans_by_start;
static PyObject *__pyx_n_s_spec;
static PyObject *__pyx_n_s_special_cases;
static PyObject *__pyx_n_s_special_token;
static PyObject *__pyx_n_s_special_tokens;
static PyObject *__pyx_n_s_split;
static PyObject *__pyx_n_s_stale_special;
static PyObject *__pyx_n_s_start;
static PyObject *__pyx_n_s_step;
static PyObject *__pyx_n_s_stop;
static PyObject *__pyx_kp_s_strided_and_direct;
static PyObject *__pyx_kp_s_strided_and_direct_or_indirect;
static PyObject *__pyx_kp_s_strided_and_indirect;
static PyObject *__pyx_n_s_string;
static PyObject *__pyx_n_s_strings_map;
static PyObject *__pyx_kp_s_stringsource;
static PyObject *__pyx_n_s_struct;
static PyObject *__pyx_n_s_substring;
static PyObject *__pyx_n_s_substrings;
static PyObject *__pyx_n_s_suffix_search;
static PyObject *__pyx_n_s_suffixes;
static PyObject *__pyx_n_s_symbols;
static PyObject *__pyx_n_s_t;
static PyObject *__pyx_n_s_t_spaces;
static PyObject *__pyx_n_s_t_words;
static PyObject *__pyx_n_s_test;
static PyObject *__pyx_n_s_text;
static PyObject *__pyx_n_s_texts;
static PyObject *__pyx_n_s_throw;
static PyObject *__pyx_n_s_to_bytes;
static PyObject *__pyx_n_s_to_bytes_locals_lambda;
static PyObject *__pyx_n_s_to_disk;
static PyObject *__pyx_n_s_token_attrs;
static PyObject *__pyx_n_s_token_match;
static PyObject *__pyx_n_s_tokens;
static PyObject *__pyx_n_s_training;
static PyObject *__pyx_kp_s_unable_to_allocate_array_data;
static PyObject *__pyx_kp_s_unable_to_allocate_shape_and_str;
static PyObject *__pyx_n_s_unpack;
static PyObject *__pyx_n_s_update;
static PyObject *__pyx_n_s_url_match;
static PyObject *__pyx_n_s_util;
static PyObject *__pyx_n_s_validate_examples;
static PyObject *__pyx_n_s_validate_special_case;
static PyObject *__pyx_n_s_vocab;
static PyObject *__pyx_n_s_wb;
static PyObject *__pyx_n_s_word;
static PyObject *__pyx_n_s_words;
static PyObject *__pyx_n_s_write;
static PyObject *__pyx_n_s_zip;
static int __pyx_pf_5spacy_9tokenizer_9Tokenizer___init__(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *__pyx_v_self, struct __pyx_obj_5spacy_5vocab_Vocab *__pyx_v_vocab, PyObject *__pyx_v_rules, PyObject *__pyx_v_prefix_search, PyObject *__pyx_v_suffix_search, PyObject *__pyx_v_infix_finditer, PyObject *__pyx_v_token_match, PyObject *__pyx_v_url_match, PyObject *__pyx_v_faster_heuristics); /* proto */
static PyObject *__pyx_pf_5spacy_9tokenizer_9Tokenizer_11token_match___get__(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *__pyx_v_self); /* proto */
static int __pyx_pf_5spacy_9tokenizer_9Tokenizer_11token_match_2__set__(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *__pyx_v_self, PyObject *__pyx_v_token_match); /* proto */
static PyObject *__pyx_pf_5spacy_9tokenizer_9Tokenizer_9url_match___get__(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *__pyx_v_self); /* proto */
static int __pyx_pf_5spacy_9tokenizer_9Tokenizer_9url_match_2__set__(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *__pyx_v_self, PyObject *__pyx_v_url_match); /* proto */
static PyObject *__pyx_pf_5spacy_9tokenizer_9Tokenizer_13prefix_search___get__(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *__pyx_v_self); /* proto */
static int __pyx_pf_5spacy_9tokenizer_9Tokenizer_13prefix_search_2__set__(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *__pyx_v_self, PyObject *__pyx_v_prefix_search); /* proto */
static PyObject *__pyx_pf_5spacy_9tokenizer_9Tokenizer_13suffix_search___get__(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *__pyx_v_self); /* proto */
static int __pyx_pf_5spacy_9tokenizer_9Tokenizer_13suffix_search_2__set__(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *__pyx_v_self, PyObject *__pyx_v_suffix_search); /* proto */
static PyObject *__pyx_pf_5spacy_9tokenizer_9Tokenizer_14infix_finditer___get__(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *__pyx_v_self); /* proto */
static int __pyx_pf_5spacy_9tokenizer_9Tokenizer_14infix_finditer_2__set__(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *__pyx_v_self, PyObject *__pyx_v_infix_finditer); /* proto */
static PyObject *__pyx_pf_5spacy_9tokenizer_9Tokenizer_5rules___get__(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *__pyx_v_self); /* proto */
static int __pyx_pf_5spacy_9tokenizer_9Tokenizer_5rules_2__set__(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *__pyx_v_self, PyObject *__pyx_v_rules); /* proto */
static PyObject *__pyx_pf_5spacy_9tokenizer_9Tokenizer_17faster_heuristics___get__(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *__pyx_v_self); /* proto */
static int __pyx_pf_5spacy_9tokenizer_9Tokenizer_17faster_heuristics_2__set__(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *__pyx_v_self, PyObject *__pyx_v_faster_heuristics); /* proto */
static PyObject *__pyx_pf_5spacy_9tokenizer_9Tokenizer_2__reduce__(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_5spacy_9tokenizer_9Tokenizer_4__call__(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *__pyx_v_self, PyObject *__pyx_v_string); /* proto */
static PyObject *__pyx_pf_5spacy_9tokenizer_9Tokenizer_6pipe(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *__pyx_v_self, PyObject *__pyx_v_texts, CYTHON_UNUSED PyObject *__pyx_v_batch_size); /* proto */
static PyObject *__pyx_pf_5spacy_9tokenizer_9Tokenizer_9_flush_cache(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_5spacy_9tokenizer_9Tokenizer_11_reset_cache(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *__pyx_v_self, PyObject *__pyx_v_keys); /* proto */
static PyObject *__pyx_pf_5spacy_9tokenizer_9Tokenizer_13_flush_specials(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_5spacy_9tokenizer_9Tokenizer_15find_infix(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *__pyx_v_self, PyObject *__pyx_v_string); /* proto */
static PyObject *__pyx_pf_5spacy_9tokenizer_9Tokenizer_17find_prefix(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *__pyx_v_self, PyObject *__pyx_v_string); /* proto */
static PyObject *__pyx_pf_5spacy_9tokenizer_9Tokenizer_19find_suffix(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *__pyx_v_self, PyObject *__pyx_v_string); /* proto */
static PyObject *__pyx_pf_5spacy_9tokenizer_9Tokenizer_21_load_special_cases(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *__pyx_v_self, PyObject *__pyx_v_special_cases); /* proto */
static PyObject *__pyx_pf_5spacy_9tokenizer_9Tokenizer_23_validate_special_case(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *__pyx_v_self, PyObject *__pyx_v_chunk, PyObject *__pyx_v_substrings); /* proto */
static PyObject *__pyx_pf_5spacy_9tokenizer_9Tokenizer_25add_special_case(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *__pyx_v_self, PyObject *__pyx_v_string, PyObject *__pyx_v_substrings); /* proto */
static PyObject *__pyx_pf_5spacy_9tokenizer_9Tokenizer_27_reload_special_cases(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_5spacy_9tokenizer_9Tokenizer_7explain_genexpr(PyObject *__pyx_self); /* proto */
static PyObject *__pyx_pf_5spacy_9tokenizer_9Tokenizer_7explain_3genexpr(PyObject *__pyx_self); /* proto */
static PyObject *__pyx_pf_5spacy_9tokenizer_9Tokenizer_7explain_6genexpr(PyObject *__pyx_self); /* proto */
static PyObject *__pyx_pf_5spacy_9tokenizer_9Tokenizer_29explain(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *__pyx_v_self, PyObject *__pyx_v_text); /* proto */
static PyObject *__pyx_pf_5spacy_9tokenizer_9Tokenizer_31score(CYTHON_UNUSED struct __pyx_obj_5spacy_9tokenizer_Tokenizer *__pyx_v_self, PyObject *__pyx_v_examples, CYTHON_UNUSED PyObject *__pyx_v_kwargs); /* proto */
static PyObject *__pyx_pf_5spacy_9tokenizer_9Tokenizer_33to_disk(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *__pyx_v_self, PyObject *__pyx_v_path, PyObject *__pyx_v_kwargs); /* proto */
static PyObject *__pyx_pf_5spacy_9tokenizer_9Tokenizer_35from_disk(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *__pyx_v_self, PyObject *__pyx_v_path, PyObject *__pyx_v_exclude); /* proto */
static PyObject *__pyx_lambda_funcdef_lambda3(PyObject *__pyx_self); /* proto */
static PyObject *__pyx_lambda_funcdef_lambda4(PyObject *__pyx_self); /* proto */
static PyObject *__pyx_lambda_funcdef_lambda5(PyObject *__pyx_self); /* proto */
static PyObject *__pyx_lambda_funcdef_lambda6(PyObject *__pyx_self); /* proto */
static PyObject *__pyx_lambda_funcdef_lambda7(PyObject *__pyx_self); /* proto */
static PyObject *__pyx_lambda_funcdef_lambda8(PyObject *__pyx_self); /* proto */
static PyObject *__pyx_lambda_funcdef_lambda9(PyObject *__pyx_self); /* proto */
static PyObject *__pyx_lambda_funcdef_lambda10(PyObject *__pyx_self); /* proto */
static PyObject *__pyx_pf_5spacy_9tokenizer_9Tokenizer_37to_bytes(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *__pyx_v_self, PyObject *__pyx_v_exclude); /* proto */
static PyObject *__pyx_lambda_funcdef_lambda11(PyObject *__pyx_self, PyObject *__pyx_v_b); /* proto */
static PyObject *__pyx_lambda_funcdef_lambda12(PyObject *__pyx_self, PyObject *__pyx_v_b); /* proto */
static PyObject *__pyx_lambda_funcdef_lambda13(PyObject *__pyx_self, PyObject *__pyx_v_b); /* proto */
static PyObject *__pyx_lambda_funcdef_lambda14(PyObject *__pyx_self, PyObject *__pyx_v_b); /* proto */
static PyObject *__pyx_lambda_funcdef_lambda15(PyObject *__pyx_self, PyObject *__pyx_v_b); /* proto */
static PyObject *__pyx_lambda_funcdef_lambda16(PyObject *__pyx_self, PyObject *__pyx_v_b); /* proto */
static PyObject *__pyx_lambda_funcdef_lambda17(PyObject *__pyx_self, PyObject *__pyx_v_b); /* proto */
static PyObject *__pyx_lambda_funcdef_lambda18(PyObject *__pyx_self, PyObject *__pyx_v_b); /* proto */
static PyObject *__pyx_pf_5spacy_9tokenizer_9Tokenizer_39from_bytes(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *__pyx_v_self, PyObject *__pyx_v_bytes_data, PyObject *__pyx_v_exclude); /* proto */
static PyObject *__pyx_pf_5spacy_9tokenizer_9Tokenizer_5vocab___get__(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_5spacy_9tokenizer__get_regex_pattern(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_regex); /* proto */
static int __pyx_array___pyx_pf_15View_dot_MemoryView_5array___cinit__(struct __pyx_array_obj *__pyx_v_self, PyObject *__pyx_v_shape, Py_ssize_t __pyx_v_itemsize, PyObject *__pyx_v_format, PyObject *__pyx_v_mode, int __pyx_v_allocate_buffer); /* proto */
static int __pyx_array___pyx_pf_15View_dot_MemoryView_5array_2__getbuffer__(struct __pyx_array_obj *__pyx_v_self, Py_buffer *__pyx_v_info, int __pyx_v_flags); /* proto */
static void __pyx_array___pyx_pf_15View_dot_MemoryView_5array_4__dealloc__(struct __pyx_array_obj *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_15View_dot_MemoryView_5array_7memview___get__(struct __pyx_array_obj *__pyx_v_self); /* proto */
static Py_ssize_t __pyx_array___pyx_pf_15View_dot_MemoryView_5array_6__len__(struct __pyx_array_obj *__pyx_v_self); /* proto */
static PyObject *__pyx_array___pyx_pf_15View_dot_MemoryView_5array_8__getattr__(struct __pyx_array_obj *__pyx_v_self, PyObject *__pyx_v_attr); /* proto */
static PyObject *__pyx_array___pyx_pf_15View_dot_MemoryView_5array_10__getitem__(struct __pyx_array_obj *__pyx_v_self, PyObject *__pyx_v_item); /* proto */
static int __pyx_array___pyx_pf_15View_dot_MemoryView_5array_12__setitem__(struct __pyx_array_obj *__pyx_v_self, PyObject *__pyx_v_item, PyObject *__pyx_v_value); /* proto */
static PyObject *__pyx_pf___pyx_array___reduce_cython__(CYTHON_UNUSED struct __pyx_array_obj *__pyx_v_self); /* proto */
static PyObject *__pyx_pf___pyx_array_2__setstate_cython__(CYTHON_UNUSED struct __pyx_array_obj *__pyx_v_self, CYTHON_UNUSED PyObject *__pyx_v___pyx_state); /* proto */
static int __pyx_MemviewEnum___pyx_pf_15View_dot_MemoryView_4Enum___init__(struct __pyx_MemviewEnum_obj *__pyx_v_self, PyObject *__pyx_v_name); /* proto */
static PyObject *__pyx_MemviewEnum___pyx_pf_15View_dot_MemoryView_4Enum_2__repr__(struct __pyx_MemviewEnum_obj *__pyx_v_self); /* proto */
static PyObject *__pyx_pf___pyx_MemviewEnum___reduce_cython__(struct __pyx_MemviewEnum_obj *__pyx_v_self); /* proto */
static PyObject *__pyx_pf___pyx_MemviewEnum_2__setstate_cython__(struct __pyx_MemviewEnum_obj *__pyx_v_self, PyObject *__pyx_v___pyx_state); /* proto */
static int __pyx_memoryview___pyx_pf_15View_dot_MemoryView_10memoryview___cinit__(struct __pyx_memoryview_obj *__pyx_v_self, PyObject *__pyx_v_obj, int __pyx_v_flags, int __pyx_v_dtype_is_object); /* proto */
static void __pyx_memoryview___pyx_pf_15View_dot_MemoryView_10memoryview_2__dealloc__(struct __pyx_memoryview_obj *__pyx_v_self); /* proto */
static PyObject *__pyx_memoryview___pyx_pf_15View_dot_MemoryView_10memoryview_4__getitem__(struct __pyx_memoryview_obj *__pyx_v_self, PyObject *__pyx_v_index); /* proto */
static int __pyx_memoryview___pyx_pf_15View_dot_MemoryView_10memoryview_6__setitem__(struct __pyx_memoryview_obj *__pyx_v_self, PyObject *__pyx_v_index, PyObject *__pyx_v_value); /* proto */
static int __pyx_memoryview___pyx_pf_15View_dot_MemoryView_10memoryview_8__getbuffer__(struct __pyx_memoryview_obj *__pyx_v_self, Py_buffer *__pyx_v_info, int __pyx_v_flags); /* proto */
static PyObject *__pyx_pf_15View_dot_MemoryView_10memoryview_1T___get__(struct __pyx_memoryview_obj *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_15View_dot_MemoryView_10memoryview_4base___get__(struct __pyx_memoryview_obj *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_15View_dot_MemoryView_10memoryview_5shape___get__(struct __pyx_memoryview_obj *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_15View_dot_MemoryView_10memoryview_7strides___get__(struct __pyx_memoryview_obj *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_15View_dot_MemoryView_10memoryview_10suboffsets___get__(struct __pyx_memoryview_obj *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_15View_dot_MemoryView_10memoryview_4ndim___get__(struct __pyx_memoryview_obj *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_15View_dot_MemoryView_10memoryview_8itemsize___get__(struct __pyx_memoryview_obj *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_15View_dot_MemoryView_10memoryview_6nbytes___get__(struct __pyx_memoryview_obj *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_15View_dot_MemoryView_10memoryview_4size___get__(struct __pyx_memoryview_obj *__pyx_v_self); /* proto */
static Py_ssize_t __pyx_memoryview___pyx_pf_15View_dot_MemoryView_10memoryview_10__len__(struct __pyx_memoryview_obj *__pyx_v_self); /* proto */
static PyObject *__pyx_memoryview___pyx_pf_15View_dot_MemoryView_10memoryview_12__repr__(struct __pyx_memoryview_obj *__pyx_v_self); /* proto */
static PyObject *__pyx_memoryview___pyx_pf_15View_dot_MemoryView_10memoryview_14__str__(struct __pyx_memoryview_obj *__pyx_v_self); /* proto */
static PyObject *__pyx_memoryview___pyx_pf_15View_dot_MemoryView_10memoryview_16is_c_contig(struct __pyx_memoryview_obj *__pyx_v_self); /* proto */
static PyObject *__pyx_memoryview___pyx_pf_15View_dot_MemoryView_10memoryview_18is_f_contig(struct __pyx_memoryview_obj *__pyx_v_self); /* proto */
static PyObject *__pyx_memoryview___pyx_pf_15View_dot_MemoryView_10memoryview_20copy(struct __pyx_memoryview_obj *__pyx_v_self); /* proto */
static PyObject *__pyx_memoryview___pyx_pf_15View_dot_MemoryView_10memoryview_22copy_fortran(struct __pyx_memoryview_obj *__pyx_v_self); /* proto */
static PyObject *__pyx_pf___pyx_memoryview___reduce_cython__(CYTHON_UNUSED struct __pyx_memoryview_obj *__pyx_v_self); /* proto */
static PyObject *__pyx_pf___pyx_memoryview_2__setstate_cython__(CYTHON_UNUSED struct __pyx_memoryview_obj *__pyx_v_self, CYTHON_UNUSED PyObject *__pyx_v___pyx_state); /* proto */
static void __pyx_memoryviewslice___pyx_pf_15View_dot_MemoryView_16_memoryviewslice___dealloc__(struct __pyx_memoryviewslice_obj *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_15View_dot_MemoryView_16_memoryviewslice_4base___get__(struct __pyx_memoryviewslice_obj *__pyx_v_self); /* proto */
static PyObject *__pyx_pf___pyx_memoryviewslice___reduce_cython__(CYTHON_UNUSED struct __pyx_memoryviewslice_obj *__pyx_v_self); /* proto */
static PyObject *__pyx_pf___pyx_memoryviewslice_2__setstate_cython__(CYTHON_UNUSED struct __pyx_memoryviewslice_obj *__pyx_v_self, CYTHON_UNUSED PyObject *__pyx_v___pyx_state); /* proto */
static PyObject *__pyx_pf_15View_dot_MemoryView___pyx_unpickle_Enum(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v___pyx_type, long __pyx_v___pyx_checksum, PyObject *__pyx_v___pyx_state); /* proto */
static PyObject *__pyx_tp_new_5spacy_9tokenizer_Tokenizer(PyTypeObject *t, PyObject *a, PyObject *k); /*proto*/
static PyObject *__pyx_tp_new_5spacy_9tokenizer___pyx_scope_struct__pipe(PyTypeObject *t, PyObject *a, PyObject *k); /*proto*/
static PyObject *__pyx_tp_new_5spacy_9tokenizer___pyx_scope_struct_1_explain(PyTypeObject *t, PyObject *a, PyObject *k); /*proto*/
static PyObject *__pyx_tp_new_5spacy_9tokenizer___pyx_scope_struct_2_genexpr(PyTypeObject *t, PyObject *a, PyObject *k); /*proto*/
static PyObject *__pyx_tp_new_5spacy_9tokenizer___pyx_scope_struct_3_genexpr(PyTypeObject *t, PyObject *a, PyObject *k); /*proto*/
static PyObject *__pyx_tp_new_5spacy_9tokenizer___pyx_scope_struct_4_genexpr(PyTypeObject *t, PyObject *a, PyObject *k); /*proto*/
static PyObject *__pyx_tp_new_5spacy_9tokenizer___pyx_scope_struct_5_to_bytes(PyTypeObject *t, PyObject *a, PyObject *k); /*proto*/
static PyObject *__pyx_tp_new_5spacy_9tokenizer___pyx_scope_struct_6_from_bytes(PyTypeObject *t, PyObject *a, PyObject *k); /*proto*/
static PyObject *__pyx_tp_new_array(PyTypeObject *t, PyObject *a, PyObject *k); /*proto*/
static PyObject *__pyx_tp_new_Enum(PyTypeObject *t, PyObject *a, PyObject *k); /*proto*/
static PyObject *__pyx_tp_new_memoryview(PyTypeObject *t, PyObject *a, PyObject *k); /*proto*/
static PyObject *__pyx_tp_new__memoryviewslice(PyTypeObject *t, PyObject *a, PyObject *k); /*proto*/
static __Pyx_CachedCFunction __pyx_umethod_PyDict_Type_setdefault = {0, &__pyx_n_s_setdefault, 0, 0, 0};
static PyObject *__pyx_int_0;
static PyObject *__pyx_int_1;
static PyObject *__pyx_int_1000;
static PyObject *__pyx_int_112105877;
static PyObject *__pyx_int_136983863;
static PyObject *__pyx_int_184977713;
static PyObject *__pyx_int_neg_1;
static PyObject *__pyx_k__5;
static PyObject *__pyx_k__6;
static PyObject *__pyx_k__7;
static PyObject *__pyx_tuple__4;
static PyObject *__pyx_tuple__8;
static PyObject *__pyx_tuple__9;
static PyObject *__pyx_slice__24;
static PyObject *__pyx_tuple__10;
static PyObject *__pyx_tuple__11;
static PyObject *__pyx_tuple__12;
static PyObject *__pyx_tuple__13;
static PyObject *__pyx_tuple__14;
static PyObject *__pyx_tuple__15;
static PyObject *__pyx_tuple__16;
static PyObject *__pyx_tuple__17;
static PyObject *__pyx_tuple__18;
static PyObject *__pyx_tuple__19;
static PyObject *__pyx_tuple__20;
static PyObject *__pyx_tuple__21;
static PyObject *__pyx_tuple__22;
static PyObject *__pyx_tuple__23;
static PyObject *__pyx_tuple__25;
static PyObject *__pyx_tuple__26;
static PyObject *__pyx_tuple__27;
static PyObject *__pyx_tuple__28;
static PyObject *__pyx_tuple__29;
static PyObject *__pyx_tuple__31;
static PyObject *__pyx_tuple__32;
static PyObject *__pyx_tuple__34;
static PyObject *__pyx_tuple__36;
static PyObject *__pyx_tuple__38;
static PyObject *__pyx_tuple__40;
static PyObject *__pyx_tuple__42;
static PyObject *__pyx_tuple__44;
static PyObject *__pyx_tuple__46;
static PyObject *__pyx_tuple__48;
static PyObject *__pyx_tuple__50;
static PyObject *__pyx_tuple__52;
static PyObject *__pyx_tuple__54;
static PyObject *__pyx_tuple__56;
static PyObject *__pyx_tuple__58;
static PyObject *__pyx_tuple__60;
static PyObject *__pyx_tuple__62;
static PyObject *__pyx_tuple__64;
static PyObject *__pyx_tuple__66;
static PyObject *__pyx_tuple__67;
static PyObject *__pyx_tuple__68;
static PyObject *__pyx_tuple__69;
static PyObject *__pyx_tuple__70;
static PyObject *__pyx_tuple__71;
static PyObject *__pyx_codeobj__2;
static PyObject *__pyx_codeobj__30;
static PyObject *__pyx_codeobj__33;
static PyObject *__pyx_codeobj__35;
static PyObject *__pyx_codeobj__37;
static PyObject *__pyx_codeobj__39;
static PyObject *__pyx_codeobj__41;
static PyObject *__pyx_codeobj__43;
static PyObject *__pyx_codeobj__45;
static PyObject *__pyx_codeobj__47;
static PyObject *__pyx_codeobj__49;
static PyObject *__pyx_codeobj__51;
static PyObject *__pyx_codeobj__53;
static PyObject *__pyx_codeobj__55;
static PyObject *__pyx_codeobj__57;
static PyObject *__pyx_codeobj__59;
static PyObject *__pyx_codeobj__61;
static PyObject *__pyx_codeobj__63;
static PyObject *__pyx_codeobj__65;
static PyObject *__pyx_codeobj__72;
/* Late includes */

/* "spacy/tokenizer.pyx":31
 *     DOCS: https://spacy.io/api/tokenizer
 *     """
 *     def __init__(self, Vocab vocab, rules=None, prefix_search=None,             # <<<<<<<<<<<<<<
 *                  suffix_search=None, infix_finditer=None, token_match=None,
 *                  url_match=None, faster_heuristics=True):
 */

/* Python wrapper */
static int __pyx_pw_5spacy_9tokenizer_9Tokenizer_1__init__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static char __pyx_doc_5spacy_9tokenizer_9Tokenizer___init__[] = "Create a `Tokenizer`, to create `Doc` objects given unicode text.\n\n        vocab (Vocab): A storage container for lexical types.\n        rules (dict): Exceptions and special-cases for the tokenizer.\n        prefix_search (callable): A function matching the signature of\n            `re.compile(string).search` to match prefixes.\n        suffix_search (callable): A function matching the signature of\n            `re.compile(string).search` to match suffixes.\n        infix_finditer (callable): A function matching the signature of\n            `re.compile(string).finditer` to find infixes.\n        token_match (callable): A function matching the signature of\n            `re.compile(string).match`, for matching strings to be\n            recognized as tokens.\n        url_match (callable): A function matching the signature of\n            `re.compile(string).match`, for matching strings to be\n            recognized as urls.\n        faster_heuristics (bool): Whether to restrict the final\n            Matcher-based pass for rules to those containing affixes or space.\n            Defaults to True.\n\n        EXAMPLE:\n            >>> tokenizer = Tokenizer(nlp.vocab)\n\n        DOCS: https://spacy.io/api/tokenizer#init\n        ";
#if CYTHON_UPDATE_DESCRIPTOR_DOC
struct wrapperbase __pyx_wrapperbase_5spacy_9tokenizer_9Tokenizer___init__;
#endif
static int __pyx_pw_5spacy_9tokenizer_9Tokenizer_1__init__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  struct __pyx_obj_5spacy_5vocab_Vocab *__pyx_v_vocab = 0;
  PyObject *__pyx_v_rules = 0;
  PyObject *__pyx_v_prefix_search = 0;
  PyObject *__pyx_v_suffix_search = 0;
  PyObject *__pyx_v_infix_finditer = 0;
  PyObject *__pyx_v_token_match = 0;
  PyObject *__pyx_v_url_match = 0;
  PyObject *__pyx_v_faster_heuristics = 0;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__init__ (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_vocab,&__pyx_n_s_rules,&__pyx_n_s_prefix_search,&__pyx_n_s_suffix_search,&__pyx_n_s_infix_finditer,&__pyx_n_s_token_match,&__pyx_n_s_url_match,&__pyx_n_s_faster_heuristics,0};
    PyObject* values[8] = {0,0,0,0,0,0,0,0};
    values[1] = ((PyObject *)Py_None);
    values[2] = ((PyObject *)Py_None);

    /* "spacy/tokenizer.pyx":32
 *     """
 *     def __init__(self, Vocab vocab, rules=None, prefix_search=None,
 *                  suffix_search=None, infix_finditer=None, token_match=None,             # <<<<<<<<<<<<<<
 *                  url_match=None, faster_heuristics=True):
 *         """Create a `Tokenizer`, to create `Doc` objects given unicode text.
 */
    values[3] = ((PyObject *)Py_None);
    values[4] = ((PyObject *)Py_None);
    values[5] = ((PyObject *)Py_None);

    /* "spacy/tokenizer.pyx":33
 *     def __init__(self, Vocab vocab, rules=None, prefix_search=None,
 *                  suffix_search=None, infix_finditer=None, token_match=None,
 *                  url_match=None, faster_heuristics=True):             # <<<<<<<<<<<<<<
 *         """Create a `Tokenizer`, to create `Doc` objects given unicode text.
 * 
 */
    values[6] = ((PyObject *)Py_None);
    values[7] = ((PyObject *)Py_True);
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  8: values[7] = PyTuple_GET_ITEM(__pyx_args, 7);
        CYTHON_FALLTHROUGH;
        case  7: values[6] = PyTuple_GET_ITEM(__pyx_args, 6);
        CYTHON_FALLTHROUGH;
        case  6: values[5] = PyTuple_GET_ITEM(__pyx_args, 5);
        CYTHON_FALLTHROUGH;
        case  5: values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
        CYTHON_FALLTHROUGH;
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_vocab)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_rules);
          if (value) { values[1] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_prefix_search);
          if (value) { values[2] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  3:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_suffix_search);
          if (value) { values[3] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  4:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_infix_finditer);
          if (value) { values[4] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  5:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_token_match);
          if (value) { values[5] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  6:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_url_match);
          if (value) { values[6] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  7:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_faster_heuristics);
          if (value) { values[7] = value; kw_args--; }
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "__init__") < 0)) __PYX_ERR(0, 31, __pyx_L3_error)
      }
    } else {
      switch (PyTuple_GET_SIZE(__pyx_args)) {
        case  8: values[7] = PyTuple_GET_ITEM(__pyx_args, 7);
        CYTHON_FALLTHROUGH;
        case  7: values[6] = PyTuple_GET_ITEM(__pyx_args, 6);
        CYTHON_FALLTHROUGH;
        case  6: values[5] = PyTuple_GET_ITEM(__pyx_args, 5);
        CYTHON_FALLTHROUGH;
        case  5: values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
        CYTHON_FALLTHROUGH;
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        break;
        default: goto __pyx_L5_argtuple_error;
      }
    }
    __pyx_v_vocab = ((struct __pyx_obj_5spacy_5vocab_Vocab *)values[0]);
    __pyx_v_rules = values[1];
    __pyx_v_prefix_search = values[2];
    __pyx_v_suffix_search = values[3];
    __pyx_v_infix_finditer = values[4];
    __pyx_v_token_match = values[5];
    __pyx_v_url_match = values[6];
    __pyx_v_faster_heuristics = values[7];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("__init__", 0, 1, 8, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 31, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("spacy.tokenizer.Tokenizer.__init__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return -1;
  __pyx_L4_argument_unpacking_done:;
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_vocab), __pyx_ptype_5spacy_5vocab_Vocab, 1, "vocab", 0))) __PYX_ERR(0, 31, __pyx_L1_error)
  __pyx_r = __pyx_pf_5spacy_9tokenizer_9Tokenizer___init__(((struct __pyx_obj_5spacy_9tokenizer_Tokenizer *)__pyx_v_self), __pyx_v_vocab, __pyx_v_rules, __pyx_v_prefix_search, __pyx_v_suffix_search, __pyx_v_infix_finditer, __pyx_v_token_match, __pyx_v_url_match, __pyx_v_faster_heuristics);

  /* "spacy/tokenizer.pyx":31
 *     DOCS: https://spacy.io/api/tokenizer
 *     """
 *     def __init__(self, Vocab vocab, rules=None, prefix_search=None,             # <<<<<<<<<<<<<<
 *                  suffix_search=None, infix_finditer=None, token_match=None,
 *                  url_match=None, faster_heuristics=True):
 */

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_5spacy_9tokenizer_9Tokenizer___init__(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *__pyx_v_self, struct __pyx_obj_5spacy_5vocab_Vocab *__pyx_v_vocab, PyObject *__pyx_v_rules, PyObject *__pyx_v_prefix_search, PyObject *__pyx_v_suffix_search, PyObject *__pyx_v_infix_finditer, PyObject *__pyx_v_token_match, PyObject *__pyx_v_url_match, PyObject *__pyx_v_faster_heuristics) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__init__", 0);

  /* "spacy/tokenizer.pyx":59
 *         DOCS: https://spacy.io/api/tokenizer#init
 *         """
 *         self.mem = Pool()             # <<<<<<<<<<<<<<
 *         self._cache = PreshMap()
 *         self._specials = PreshMap()
 */
  __pyx_t_1 = __Pyx_PyObject_CallNoArg(((PyObject *)__pyx_ptype_5cymem_5cymem_Pool)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 59, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_GIVEREF(__pyx_t_1);
  __Pyx_GOTREF(__pyx_v_self->mem);
  __Pyx_DECREF(((PyObject *)__pyx_v_self->mem));
  __pyx_v_self->mem = ((struct __pyx_obj_5cymem_5cymem_Pool *)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "spacy/tokenizer.pyx":60
 *         """
 *         self.mem = Pool()
 *         self._cache = PreshMap()             # <<<<<<<<<<<<<<
 *         self._specials = PreshMap()
 *         self.token_match = token_match
 */
  __pyx_t_1 = __Pyx_PyObject_CallNoArg(((PyObject *)__pyx_ptype_7preshed_4maps_PreshMap)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 60, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_GIVEREF(__pyx_t_1);
  __Pyx_GOTREF(__pyx_v_self->_cache);
  __Pyx_DECREF(((PyObject *)__pyx_v_self->_cache));
  __pyx_v_self->_cache = ((struct __pyx_obj_7preshed_4maps_PreshMap *)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "spacy/tokenizer.pyx":61
 *         self.mem = Pool()
 *         self._cache = PreshMap()
 *         self._specials = PreshMap()             # <<<<<<<<<<<<<<
 *         self.token_match = token_match
 *         self.url_match = url_match
 */
  __pyx_t_1 = __Pyx_PyObject_CallNoArg(((PyObject *)__pyx_ptype_7preshed_4maps_PreshMap)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 61, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_GIVEREF(__pyx_t_1);
  __Pyx_GOTREF(__pyx_v_self->_specials);
  __Pyx_DECREF(((PyObject *)__pyx_v_self->_specials));
  __pyx_v_self->_specials = ((struct __pyx_obj_7preshed_4maps_PreshMap *)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "spacy/tokenizer.pyx":62
 *         self._cache = PreshMap()
 *         self._specials = PreshMap()
 *         self.token_match = token_match             # <<<<<<<<<<<<<<
 *         self.url_match = url_match
 *         self.prefix_search = prefix_search
 */
  if (__Pyx_PyObject_SetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_token_match, __pyx_v_token_match) < 0) __PYX_ERR(0, 62, __pyx_L1_error)

  /* "spacy/tokenizer.pyx":63
 *         self._specials = PreshMap()
 *         self.token_match = token_match
 *         self.url_match = url_match             # <<<<<<<<<<<<<<
 *         self.prefix_search = prefix_search
 *         self.suffix_search = suffix_search
 */
  if (__Pyx_PyObject_SetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_url_match, __pyx_v_url_match) < 0) __PYX_ERR(0, 63, __pyx_L1_error)

  /* "spacy/tokenizer.pyx":64
 *         self.token_match = token_match
 *         self.url_match = url_match
 *         self.prefix_search = prefix_search             # <<<<<<<<<<<<<<
 *         self.suffix_search = suffix_search
 *         self.infix_finditer = infix_finditer
 */
  if (__Pyx_PyObject_SetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_prefix_search, __pyx_v_prefix_search) < 0) __PYX_ERR(0, 64, __pyx_L1_error)

  /* "spacy/tokenizer.pyx":65
 *         self.url_match = url_match
 *         self.prefix_search = prefix_search
 *         self.suffix_search = suffix_search             # <<<<<<<<<<<<<<
 *         self.infix_finditer = infix_finditer
 *         self.vocab = vocab
 */
  if (__Pyx_PyObject_SetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_suffix_search, __pyx_v_suffix_search) < 0) __PYX_ERR(0, 65, __pyx_L1_error)

  /* "spacy/tokenizer.pyx":66
 *         self.prefix_search = prefix_search
 *         self.suffix_search = suffix_search
 *         self.infix_finditer = infix_finditer             # <<<<<<<<<<<<<<
 *         self.vocab = vocab
 *         self.faster_heuristics = faster_heuristics
 */
  if (__Pyx_PyObject_SetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_infix_finditer, __pyx_v_infix_finditer) < 0) __PYX_ERR(0, 66, __pyx_L1_error)

  /* "spacy/tokenizer.pyx":67
 *         self.suffix_search = suffix_search
 *         self.infix_finditer = infix_finditer
 *         self.vocab = vocab             # <<<<<<<<<<<<<<
 *         self.faster_heuristics = faster_heuristics
 *         self._rules = {}
 */
  __Pyx_INCREF(((PyObject *)__pyx_v_vocab));
  __Pyx_GIVEREF(((PyObject *)__pyx_v_vocab));
  __Pyx_GOTREF(__pyx_v_self->vocab);
  __Pyx_DECREF(((PyObject *)__pyx_v_self->vocab));
  __pyx_v_self->vocab = __pyx_v_vocab;

  /* "spacy/tokenizer.pyx":68
 *         self.infix_finditer = infix_finditer
 *         self.vocab = vocab
 *         self.faster_heuristics = faster_heuristics             # <<<<<<<<<<<<<<
 *         self._rules = {}
 *         self._special_matcher = PhraseMatcher(self.vocab)
 */
  if (__Pyx_PyObject_SetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_faster_heuristics, __pyx_v_faster_heuristics) < 0) __PYX_ERR(0, 68, __pyx_L1_error)

  /* "spacy/tokenizer.pyx":69
 *         self.vocab = vocab
 *         self.faster_heuristics = faster_heuristics
 *         self._rules = {}             # <<<<<<<<<<<<<<
 *         self._special_matcher = PhraseMatcher(self.vocab)
 *         self._load_special_cases(rules)
 */
  __pyx_t_1 = __Pyx_PyDict_NewPresized(0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 69, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_GIVEREF(__pyx_t_1);
  __Pyx_GOTREF(__pyx_v_self->_rules);
  __Pyx_DECREF(__pyx_v_self->_rules);
  __pyx_v_self->_rules = __pyx_t_1;
  __pyx_t_1 = 0;

  /* "spacy/tokenizer.pyx":70
 *         self.faster_heuristics = faster_heuristics
 *         self._rules = {}
 *         self._special_matcher = PhraseMatcher(self.vocab)             # <<<<<<<<<<<<<<
 *         self._load_special_cases(rules)
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_CallOneArg(((PyObject *)__pyx_ptype_5spacy_7matcher_13phrasematcher_PhraseMatcher), ((PyObject *)__pyx_v_self->vocab)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 70, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_GIVEREF(__pyx_t_1);
  __Pyx_GOTREF(__pyx_v_self->_special_matcher);
  __Pyx_DECREF(((PyObject *)__pyx_v_self->_special_matcher));
  __pyx_v_self->_special_matcher = ((struct __pyx_obj_5spacy_7matcher_13phrasematcher_PhraseMatcher *)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "spacy/tokenizer.pyx":71
 *         self._rules = {}
 *         self._special_matcher = PhraseMatcher(self.vocab)
 *         self._load_special_cases(rules)             # <<<<<<<<<<<<<<
 * 
 *     @property
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_load_special_cases); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 71, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
    }
  }
  __pyx_t_1 = (__pyx_t_3) ? __Pyx_PyObject_Call2Args(__pyx_t_2, __pyx_t_3, __pyx_v_rules) : __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_v_rules);
  __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 71, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "spacy/tokenizer.pyx":31
 *     DOCS: https://spacy.io/api/tokenizer
 *     """
 *     def __init__(self, Vocab vocab, rules=None, prefix_search=None,             # <<<<<<<<<<<<<<
 *                  suffix_search=None, infix_finditer=None, token_match=None,
 *                  url_match=None, faster_heuristics=True):
 */

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("spacy.tokenizer.Tokenizer.__init__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "spacy/tokenizer.pyx":74
 * 
 *     @property
 *     def token_match(self):             # <<<<<<<<<<<<<<
 *         return self._token_match
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_5spacy_9tokenizer_9Tokenizer_11token_match_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_5spacy_9tokenizer_9Tokenizer_11token_match_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5spacy_9tokenizer_9Tokenizer_11token_match___get__(((struct __pyx_obj_5spacy_9tokenizer_Tokenizer *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5spacy_9tokenizer_9Tokenizer_11token_match___get__(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__", 0);

  /* "spacy/tokenizer.pyx":75
 *     @property
 *     def token_match(self):
 *         return self._token_match             # <<<<<<<<<<<<<<
 * 
 *     @token_match.setter
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v_self->_token_match);
  __pyx_r = __pyx_v_self->_token_match;
  goto __pyx_L0;

  /* "spacy/tokenizer.pyx":74
 * 
 *     @property
 *     def token_match(self):             # <<<<<<<<<<<<<<
 *         return self._token_match
 * 
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "spacy/tokenizer.pyx":78
 * 
 *     @token_match.setter
 *     def token_match(self, token_match):             # <<<<<<<<<<<<<<
 *         self._token_match = token_match
 *         self._reload_special_cases()
 */

/* Python wrapper */
static int __pyx_pw_5spacy_9tokenizer_9Tokenizer_11token_match_3__set__(PyObject *__pyx_v_self, PyObject *__pyx_v_token_match); /*proto*/
static int __pyx_pw_5spacy_9tokenizer_9Tokenizer_11token_match_3__set__(PyObject *__pyx_v_self, PyObject *__pyx_v_token_match) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__set__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5spacy_9tokenizer_9Tokenizer_11token_match_2__set__(((struct __pyx_obj_5spacy_9tokenizer_Tokenizer *)__pyx_v_self), ((PyObject *)__pyx_v_token_match));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_5spacy_9tokenizer_9Tokenizer_11token_match_2__set__(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *__pyx_v_self, PyObject *__pyx_v_token_match) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__set__", 0);

  /* "spacy/tokenizer.pyx":79
 *     @token_match.setter
 *     def token_match(self, token_match):
 *         self._token_match = token_match             # <<<<<<<<<<<<<<
 *         self._reload_special_cases()
 * 
 */
  __Pyx_INCREF(__pyx_v_token_match);
  __Pyx_GIVEREF(__pyx_v_token_match);
  __Pyx_GOTREF(__pyx_v_self->_token_match);
  __Pyx_DECREF(__pyx_v_self->_token_match);
  __pyx_v_self->_token_match = __pyx_v_token_match;

  /* "spacy/tokenizer.pyx":80
 *     def token_match(self, token_match):
 *         self._token_match = token_match
 *         self._reload_special_cases()             # <<<<<<<<<<<<<<
 * 
 *     @property
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_reload_special_cases); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 80, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
    }
  }
  __pyx_t_1 = (__pyx_t_3) ? __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_3) : __Pyx_PyObject_CallNoArg(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 80, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "spacy/tokenizer.pyx":78
 * 
 *     @token_match.setter
 *     def token_match(self, token_match):             # <<<<<<<<<<<<<<
 *         self._token_match = token_match
 *         self._reload_special_cases()
 */

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("spacy.tokenizer.Tokenizer.token_match.__set__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "spacy/tokenizer.pyx":83
 * 
 *     @property
 *     def url_match(self):             # <<<<<<<<<<<<<<
 *         return self._url_match
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_5spacy_9tokenizer_9Tokenizer_9url_match_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_5spacy_9tokenizer_9Tokenizer_9url_match_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5spacy_9tokenizer_9Tokenizer_9url_match___get__(((struct __pyx_obj_5spacy_9tokenizer_Tokenizer *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5spacy_9tokenizer_9Tokenizer_9url_match___get__(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__", 0);

  /* "spacy/tokenizer.pyx":84
 *     @property
 *     def url_match(self):
 *         return self._url_match             # <<<<<<<<<<<<<<
 * 
 *     @url_match.setter
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v_self->_url_match);
  __pyx_r = __pyx_v_self->_url_match;
  goto __pyx_L0;

  /* "spacy/tokenizer.pyx":83
 * 
 *     @property
 *     def url_match(self):             # <<<<<<<<<<<<<<
 *         return self._url_match
 * 
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "spacy/tokenizer.pyx":87
 * 
 *     @url_match.setter
 *     def url_match(self, url_match):             # <<<<<<<<<<<<<<
 *         self._url_match = url_match
 *         self._reload_special_cases()
 */

/* Python wrapper */
static int __pyx_pw_5spacy_9tokenizer_9Tokenizer_9url_match_3__set__(PyObject *__pyx_v_self, PyObject *__pyx_v_url_match); /*proto*/
static int __pyx_pw_5spacy_9tokenizer_9Tokenizer_9url_match_3__set__(PyObject *__pyx_v_self, PyObject *__pyx_v_url_match) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__set__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5spacy_9tokenizer_9Tokenizer_9url_match_2__set__(((struct __pyx_obj_5spacy_9tokenizer_Tokenizer *)__pyx_v_self), ((PyObject *)__pyx_v_url_match));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_5spacy_9tokenizer_9Tokenizer_9url_match_2__set__(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *__pyx_v_self, PyObject *__pyx_v_url_match) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__set__", 0);

  /* "spacy/tokenizer.pyx":88
 *     @url_match.setter
 *     def url_match(self, url_match):
 *         self._url_match = url_match             # <<<<<<<<<<<<<<
 *         self._reload_special_cases()
 * 
 */
  __Pyx_INCREF(__pyx_v_url_match);
  __Pyx_GIVEREF(__pyx_v_url_match);
  __Pyx_GOTREF(__pyx_v_self->_url_match);
  __Pyx_DECREF(__pyx_v_self->_url_match);
  __pyx_v_self->_url_match = __pyx_v_url_match;

  /* "spacy/tokenizer.pyx":89
 *     def url_match(self, url_match):
 *         self._url_match = url_match
 *         self._reload_special_cases()             # <<<<<<<<<<<<<<
 * 
 *     @property
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_reload_special_cases); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 89, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
    }
  }
  __pyx_t_1 = (__pyx_t_3) ? __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_3) : __Pyx_PyObject_CallNoArg(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 89, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "spacy/tokenizer.pyx":87
 * 
 *     @url_match.setter
 *     def url_match(self, url_match):             # <<<<<<<<<<<<<<
 *         self._url_match = url_match
 *         self._reload_special_cases()
 */

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("spacy.tokenizer.Tokenizer.url_match.__set__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "spacy/tokenizer.pyx":92
 * 
 *     @property
 *     def prefix_search(self):             # <<<<<<<<<<<<<<
 *         return self._prefix_search
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_5spacy_9tokenizer_9Tokenizer_13prefix_search_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_5spacy_9tokenizer_9Tokenizer_13prefix_search_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5spacy_9tokenizer_9Tokenizer_13prefix_search___get__(((struct __pyx_obj_5spacy_9tokenizer_Tokenizer *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5spacy_9tokenizer_9Tokenizer_13prefix_search___get__(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__", 0);

  /* "spacy/tokenizer.pyx":93
 *     @property
 *     def prefix_search(self):
 *         return self._prefix_search             # <<<<<<<<<<<<<<
 * 
 *     @prefix_search.setter
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v_self->_prefix_search);
  __pyx_r = __pyx_v_self->_prefix_search;
  goto __pyx_L0;

  /* "spacy/tokenizer.pyx":92
 * 
 *     @property
 *     def prefix_search(self):             # <<<<<<<<<<<<<<
 *         return self._prefix_search
 * 
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "spacy/tokenizer.pyx":96
 * 
 *     @prefix_search.setter
 *     def prefix_search(self, prefix_search):             # <<<<<<<<<<<<<<
 *         self._prefix_search = prefix_search
 *         self._reload_special_cases()
 */

/* Python wrapper */
static int __pyx_pw_5spacy_9tokenizer_9Tokenizer_13prefix_search_3__set__(PyObject *__pyx_v_self, PyObject *__pyx_v_prefix_search); /*proto*/
static int __pyx_pw_5spacy_9tokenizer_9Tokenizer_13prefix_search_3__set__(PyObject *__pyx_v_self, PyObject *__pyx_v_prefix_search) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__set__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5spacy_9tokenizer_9Tokenizer_13prefix_search_2__set__(((struct __pyx_obj_5spacy_9tokenizer_Tokenizer *)__pyx_v_self), ((PyObject *)__pyx_v_prefix_search));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_5spacy_9tokenizer_9Tokenizer_13prefix_search_2__set__(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *__pyx_v_self, PyObject *__pyx_v_prefix_search) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__set__", 0);

  /* "spacy/tokenizer.pyx":97
 *     @prefix_search.setter
 *     def prefix_search(self, prefix_search):
 *         self._prefix_search = prefix_search             # <<<<<<<<<<<<<<
 *         self._reload_special_cases()
 * 
 */
  __Pyx_INCREF(__pyx_v_prefix_search);
  __Pyx_GIVEREF(__pyx_v_prefix_search);
  __Pyx_GOTREF(__pyx_v_self->_prefix_search);
  __Pyx_DECREF(__pyx_v_self->_prefix_search);
  __pyx_v_self->_prefix_search = __pyx_v_prefix_search;

  /* "spacy/tokenizer.pyx":98
 *     def prefix_search(self, prefix_search):
 *         self._prefix_search = prefix_search
 *         self._reload_special_cases()             # <<<<<<<<<<<<<<
 * 
 *     @property
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_reload_special_cases); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 98, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
    }
  }
  __pyx_t_1 = (__pyx_t_3) ? __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_3) : __Pyx_PyObject_CallNoArg(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 98, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "spacy/tokenizer.pyx":96
 * 
 *     @prefix_search.setter
 *     def prefix_search(self, prefix_search):             # <<<<<<<<<<<<<<
 *         self._prefix_search = prefix_search
 *         self._reload_special_cases()
 */

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("spacy.tokenizer.Tokenizer.prefix_search.__set__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "spacy/tokenizer.pyx":101
 * 
 *     @property
 *     def suffix_search(self):             # <<<<<<<<<<<<<<
 *         return self._suffix_search
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_5spacy_9tokenizer_9Tokenizer_13suffix_search_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_5spacy_9tokenizer_9Tokenizer_13suffix_search_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5spacy_9tokenizer_9Tokenizer_13suffix_search___get__(((struct __pyx_obj_5spacy_9tokenizer_Tokenizer *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5spacy_9tokenizer_9Tokenizer_13suffix_search___get__(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__", 0);

  /* "spacy/tokenizer.pyx":102
 *     @property
 *     def suffix_search(self):
 *         return self._suffix_search             # <<<<<<<<<<<<<<
 * 
 *     @suffix_search.setter
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v_self->_suffix_search);
  __pyx_r = __pyx_v_self->_suffix_search;
  goto __pyx_L0;

  /* "spacy/tokenizer.pyx":101
 * 
 *     @property
 *     def suffix_search(self):             # <<<<<<<<<<<<<<
 *         return self._suffix_search
 * 
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "spacy/tokenizer.pyx":105
 * 
 *     @suffix_search.setter
 *     def suffix_search(self, suffix_search):             # <<<<<<<<<<<<<<
 *         self._suffix_search = suffix_search
 *         self._reload_special_cases()
 */

/* Python wrapper */
static int __pyx_pw_5spacy_9tokenizer_9Tokenizer_13suffix_search_3__set__(PyObject *__pyx_v_self, PyObject *__pyx_v_suffix_search); /*proto*/
static int __pyx_pw_5spacy_9tokenizer_9Tokenizer_13suffix_search_3__set__(PyObject *__pyx_v_self, PyObject *__pyx_v_suffix_search) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__set__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5spacy_9tokenizer_9Tokenizer_13suffix_search_2__set__(((struct __pyx_obj_5spacy_9tokenizer_Tokenizer *)__pyx_v_self), ((PyObject *)__pyx_v_suffix_search));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_5spacy_9tokenizer_9Tokenizer_13suffix_search_2__set__(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *__pyx_v_self, PyObject *__pyx_v_suffix_search) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__set__", 0);

  /* "spacy/tokenizer.pyx":106
 *     @suffix_search.setter
 *     def suffix_search(self, suffix_search):
 *         self._suffix_search = suffix_search             # <<<<<<<<<<<<<<
 *         self._reload_special_cases()
 * 
 */
  __Pyx_INCREF(__pyx_v_suffix_search);
  __Pyx_GIVEREF(__pyx_v_suffix_search);
  __Pyx_GOTREF(__pyx_v_self->_suffix_search);
  __Pyx_DECREF(__pyx_v_self->_suffix_search);
  __pyx_v_self->_suffix_search = __pyx_v_suffix_search;

  /* "spacy/tokenizer.pyx":107
 *     def suffix_search(self, suffix_search):
 *         self._suffix_search = suffix_search
 *         self._reload_special_cases()             # <<<<<<<<<<<<<<
 * 
 *     @property
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_reload_special_cases); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 107, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
    }
  }
  __pyx_t_1 = (__pyx_t_3) ? __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_3) : __Pyx_PyObject_CallNoArg(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 107, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "spacy/tokenizer.pyx":105
 * 
 *     @suffix_search.setter
 *     def suffix_search(self, suffix_search):             # <<<<<<<<<<<<<<
 *         self._suffix_search = suffix_search
 *         self._reload_special_cases()
 */

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("spacy.tokenizer.Tokenizer.suffix_search.__set__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "spacy/tokenizer.pyx":110
 * 
 *     @property
 *     def infix_finditer(self):             # <<<<<<<<<<<<<<
 *         return self._infix_finditer
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_5spacy_9tokenizer_9Tokenizer_14infix_finditer_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_5spacy_9tokenizer_9Tokenizer_14infix_finditer_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5spacy_9tokenizer_9Tokenizer_14infix_finditer___get__(((struct __pyx_obj_5spacy_9tokenizer_Tokenizer *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5spacy_9tokenizer_9Tokenizer_14infix_finditer___get__(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__", 0);

  /* "spacy/tokenizer.pyx":111
 *     @property
 *     def infix_finditer(self):
 *         return self._infix_finditer             # <<<<<<<<<<<<<<
 * 
 *     @infix_finditer.setter
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v_self->_infix_finditer);
  __pyx_r = __pyx_v_self->_infix_finditer;
  goto __pyx_L0;

  /* "spacy/tokenizer.pyx":110
 * 
 *     @property
 *     def infix_finditer(self):             # <<<<<<<<<<<<<<
 *         return self._infix_finditer
 * 
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "spacy/tokenizer.pyx":114
 * 
 *     @infix_finditer.setter
 *     def infix_finditer(self, infix_finditer):             # <<<<<<<<<<<<<<
 *         self._infix_finditer = infix_finditer
 *         self._reload_special_cases()
 */

/* Python wrapper */
static int __pyx_pw_5spacy_9tokenizer_9Tokenizer_14infix_finditer_3__set__(PyObject *__pyx_v_self, PyObject *__pyx_v_infix_finditer); /*proto*/
static int __pyx_pw_5spacy_9tokenizer_9Tokenizer_14infix_finditer_3__set__(PyObject *__pyx_v_self, PyObject *__pyx_v_infix_finditer) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__set__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5spacy_9tokenizer_9Tokenizer_14infix_finditer_2__set__(((struct __pyx_obj_5spacy_9tokenizer_Tokenizer *)__pyx_v_self), ((PyObject *)__pyx_v_infix_finditer));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_5spacy_9tokenizer_9Tokenizer_14infix_finditer_2__set__(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *__pyx_v_self, PyObject *__pyx_v_infix_finditer) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__set__", 0);

  /* "spacy/tokenizer.pyx":115
 *     @infix_finditer.setter
 *     def infix_finditer(self, infix_finditer):
 *         self._infix_finditer = infix_finditer             # <<<<<<<<<<<<<<
 *         self._reload_special_cases()
 * 
 */
  __Pyx_INCREF(__pyx_v_infix_finditer);
  __Pyx_GIVEREF(__pyx_v_infix_finditer);
  __Pyx_GOTREF(__pyx_v_self->_infix_finditer);
  __Pyx_DECREF(__pyx_v_self->_infix_finditer);
  __pyx_v_self->_infix_finditer = __pyx_v_infix_finditer;

  /* "spacy/tokenizer.pyx":116
 *     def infix_finditer(self, infix_finditer):
 *         self._infix_finditer = infix_finditer
 *         self._reload_special_cases()             # <<<<<<<<<<<<<<
 * 
 *     @property
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_reload_special_cases); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 116, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
    }
  }
  __pyx_t_1 = (__pyx_t_3) ? __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_3) : __Pyx_PyObject_CallNoArg(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 116, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "spacy/tokenizer.pyx":114
 * 
 *     @infix_finditer.setter
 *     def infix_finditer(self, infix_finditer):             # <<<<<<<<<<<<<<
 *         self._infix_finditer = infix_finditer
 *         self._reload_special_cases()
 */

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("spacy.tokenizer.Tokenizer.infix_finditer.__set__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "spacy/tokenizer.pyx":119
 * 
 *     @property
 *     def rules(self):             # <<<<<<<<<<<<<<
 *         return self._rules
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_5spacy_9tokenizer_9Tokenizer_5rules_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_5spacy_9tokenizer_9Tokenizer_5rules_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5spacy_9tokenizer_9Tokenizer_5rules___get__(((struct __pyx_obj_5spacy_9tokenizer_Tokenizer *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5spacy_9tokenizer_9Tokenizer_5rules___get__(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__", 0);

  /* "spacy/tokenizer.pyx":120
 *     @property
 *     def rules(self):
 *         return self._rules             # <<<<<<<<<<<<<<
 * 
 *     @rules.setter
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v_self->_rules);
  __pyx_r = __pyx_v_self->_rules;
  goto __pyx_L0;

  /* "spacy/tokenizer.pyx":119
 * 
 *     @property
 *     def rules(self):             # <<<<<<<<<<<<<<
 *         return self._rules
 * 
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "spacy/tokenizer.pyx":123
 * 
 *     @rules.setter
 *     def rules(self, rules):             # <<<<<<<<<<<<<<
 *         self._rules = {}
 *         self._flush_cache()
 */

/* Python wrapper */
static int __pyx_pw_5spacy_9tokenizer_9Tokenizer_5rules_3__set__(PyObject *__pyx_v_self, PyObject *__pyx_v_rules); /*proto*/
static int __pyx_pw_5spacy_9tokenizer_9Tokenizer_5rules_3__set__(PyObject *__pyx_v_self, PyObject *__pyx_v_rules) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__set__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5spacy_9tokenizer_9Tokenizer_5rules_2__set__(((struct __pyx_obj_5spacy_9tokenizer_Tokenizer *)__pyx_v_self), ((PyObject *)__pyx_v_rules));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_5spacy_9tokenizer_9Tokenizer_5rules_2__set__(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *__pyx_v_self, PyObject *__pyx_v_rules) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__set__", 0);

  /* "spacy/tokenizer.pyx":124
 *     @rules.setter
 *     def rules(self, rules):
 *         self._rules = {}             # <<<<<<<<<<<<<<
 *         self._flush_cache()
 *         self._flush_specials()
 */
  __pyx_t_1 = __Pyx_PyDict_NewPresized(0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 124, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_GIVEREF(__pyx_t_1);
  __Pyx_GOTREF(__pyx_v_self->_rules);
  __Pyx_DECREF(__pyx_v_self->_rules);
  __pyx_v_self->_rules = __pyx_t_1;
  __pyx_t_1 = 0;

  /* "spacy/tokenizer.pyx":125
 *     def rules(self, rules):
 *         self._rules = {}
 *         self._flush_cache()             # <<<<<<<<<<<<<<
 *         self._flush_specials()
 *         self._cache = PreshMap()
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_flush_cache); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 125, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
    }
  }
  __pyx_t_1 = (__pyx_t_3) ? __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_3) : __Pyx_PyObject_CallNoArg(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 125, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "spacy/tokenizer.pyx":126
 *         self._rules = {}
 *         self._flush_cache()
 *         self._flush_specials()             # <<<<<<<<<<<<<<
 *         self._cache = PreshMap()
 *         self._specials = PreshMap()
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_flush_specials); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 126, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
    }
  }
  __pyx_t_1 = (__pyx_t_3) ? __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_3) : __Pyx_PyObject_CallNoArg(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 126, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "spacy/tokenizer.pyx":127
 *         self._flush_cache()
 *         self._flush_specials()
 *         self._cache = PreshMap()             # <<<<<<<<<<<<<<
 *         self._specials = PreshMap()
 *         self._load_special_cases(rules)
 */
  __pyx_t_1 = __Pyx_PyObject_CallNoArg(((PyObject *)__pyx_ptype_7preshed_4maps_PreshMap)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 127, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_GIVEREF(__pyx_t_1);
  __Pyx_GOTREF(__pyx_v_self->_cache);
  __Pyx_DECREF(((PyObject *)__pyx_v_self->_cache));
  __pyx_v_self->_cache = ((struct __pyx_obj_7preshed_4maps_PreshMap *)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "spacy/tokenizer.pyx":128
 *         self._flush_specials()
 *         self._cache = PreshMap()
 *         self._specials = PreshMap()             # <<<<<<<<<<<<<<
 *         self._load_special_cases(rules)
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_CallNoArg(((PyObject *)__pyx_ptype_7preshed_4maps_PreshMap)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 128, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_GIVEREF(__pyx_t_1);
  __Pyx_GOTREF(__pyx_v_self->_specials);
  __Pyx_DECREF(((PyObject *)__pyx_v_self->_specials));
  __pyx_v_self->_specials = ((struct __pyx_obj_7preshed_4maps_PreshMap *)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "spacy/tokenizer.pyx":129
 *         self._cache = PreshMap()
 *         self._specials = PreshMap()
 *         self._load_special_cases(rules)             # <<<<<<<<<<<<<<
 * 
 *     @property
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_load_special_cases); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 129, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
    }
  }
  __pyx_t_1 = (__pyx_t_3) ? __Pyx_PyObject_Call2Args(__pyx_t_2, __pyx_t_3, __pyx_v_rules) : __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_v_rules);
  __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 129, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "spacy/tokenizer.pyx":123
 * 
 *     @rules.setter
 *     def rules(self, rules):             # <<<<<<<<<<<<<<
 *         self._rules = {}
 *         self._flush_cache()
 */

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("spacy.tokenizer.Tokenizer.rules.__set__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "spacy/tokenizer.pyx":132
 * 
 *     @property
 *     def faster_heuristics(self):             # <<<<<<<<<<<<<<
 *         return bool(self._faster_heuristics)
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_5spacy_9tokenizer_9Tokenizer_17faster_heuristics_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_5spacy_9tokenizer_9Tokenizer_17faster_heuristics_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5spacy_9tokenizer_9Tokenizer_17faster_heuristics___get__(((struct __pyx_obj_5spacy_9tokenizer_Tokenizer *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5spacy_9tokenizer_9Tokenizer_17faster_heuristics___get__(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_t_2;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__get__", 0);

  /* "spacy/tokenizer.pyx":133
 *     @property
 *     def faster_heuristics(self):
 *         return bool(self._faster_heuristics)             # <<<<<<<<<<<<<<
 * 
 *     @faster_heuristics.setter
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyInt_From_int(__pyx_v_self->_faster_heuristics); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 133, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyObject_IsTrue(__pyx_t_1); if (unlikely(__pyx_t_2 < 0)) __PYX_ERR(0, 133, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyBool_FromLong((!(!__pyx_t_2))); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 133, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "spacy/tokenizer.pyx":132
 * 
 *     @property
 *     def faster_heuristics(self):             # <<<<<<<<<<<<<<
 *         return bool(self._faster_heuristics)
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("spacy.tokenizer.Tokenizer.faster_heuristics.__get__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "spacy/tokenizer.pyx":136
 * 
 *     @faster_heuristics.setter
 *     def faster_heuristics(self, faster_heuristics):             # <<<<<<<<<<<<<<
 *         self._faster_heuristics = bool(faster_heuristics)
 *         self._reload_special_cases()
 */

/* Python wrapper */
static int __pyx_pw_5spacy_9tokenizer_9Tokenizer_17faster_heuristics_3__set__(PyObject *__pyx_v_self, PyObject *__pyx_v_faster_heuristics); /*proto*/
static int __pyx_pw_5spacy_9tokenizer_9Tokenizer_17faster_heuristics_3__set__(PyObject *__pyx_v_self, PyObject *__pyx_v_faster_heuristics) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__set__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5spacy_9tokenizer_9Tokenizer_17faster_heuristics_2__set__(((struct __pyx_obj_5spacy_9tokenizer_Tokenizer *)__pyx_v_self), ((PyObject *)__pyx_v_faster_heuristics));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_5spacy_9tokenizer_9Tokenizer_17faster_heuristics_2__set__(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *__pyx_v_self, PyObject *__pyx_v_faster_heuristics) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__set__", 0);

  /* "spacy/tokenizer.pyx":137
 *     @faster_heuristics.setter
 *     def faster_heuristics(self, faster_heuristics):
 *         self._faster_heuristics = bool(faster_heuristics)             # <<<<<<<<<<<<<<
 *         self._reload_special_cases()
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_IsTrue(__pyx_v_faster_heuristics); if (unlikely(__pyx_t_1 < 0)) __PYX_ERR(0, 137, __pyx_L1_error)
  __pyx_v_self->_faster_heuristics = (!(!__pyx_t_1));

  /* "spacy/tokenizer.pyx":138
 *     def faster_heuristics(self, faster_heuristics):
 *         self._faster_heuristics = bool(faster_heuristics)
 *         self._reload_special_cases()             # <<<<<<<<<<<<<<
 * 
 *     def __reduce__(self):
 */
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_reload_special_cases); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 138, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_4 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_3))) {
    __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_3);
    if (likely(__pyx_t_4)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
      __Pyx_INCREF(__pyx_t_4);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_3, function);
    }
  }
  __pyx_t_2 = (__pyx_t_4) ? __Pyx_PyObject_CallOneArg(__pyx_t_3, __pyx_t_4) : __Pyx_PyObject_CallNoArg(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
  if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 138, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "spacy/tokenizer.pyx":136
 * 
 *     @faster_heuristics.setter
 *     def faster_heuristics(self, faster_heuristics):             # <<<<<<<<<<<<<<
 *         self._faster_heuristics = bool(faster_heuristics)
 *         self._reload_special_cases()
 */

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_AddTraceback("spacy.tokenizer.Tokenizer.faster_heuristics.__set__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "spacy/tokenizer.pyx":140
 *         self._reload_special_cases()
 * 
 *     def __reduce__(self):             # <<<<<<<<<<<<<<
 *         args = (self.vocab,
 *                 self.rules,
 */

/* Python wrapper */
static PyObject *__pyx_pw_5spacy_9tokenizer_9Tokenizer_3__reduce__(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static char __pyx_doc_5spacy_9tokenizer_9Tokenizer_2__reduce__[] = "Tokenizer.__reduce__(self)";
static PyMethodDef __pyx_mdef_5spacy_9tokenizer_9Tokenizer_3__reduce__ = {"__reduce__", (PyCFunction)__pyx_pw_5spacy_9tokenizer_9Tokenizer_3__reduce__, METH_NOARGS, __pyx_doc_5spacy_9tokenizer_9Tokenizer_2__reduce__};
static PyObject *__pyx_pw_5spacy_9tokenizer_9Tokenizer_3__reduce__(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__reduce__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5spacy_9tokenizer_9Tokenizer_2__reduce__(((struct __pyx_obj_5spacy_9tokenizer_Tokenizer *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5spacy_9tokenizer_9Tokenizer_2__reduce__(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *__pyx_v_self) {
  PyObject *__pyx_v_args = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__reduce__", 0);

  /* "spacy/tokenizer.pyx":142
 *     def __reduce__(self):
 *         args = (self.vocab,
 *                 self.rules,             # <<<<<<<<<<<<<<
 *                 self.prefix_search,
 *                 self.suffix_search,
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_rules); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 142, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);

  /* "spacy/tokenizer.pyx":143
 *         args = (self.vocab,
 *                 self.rules,
 *                 self.prefix_search,             # <<<<<<<<<<<<<<
 *                 self.suffix_search,
 *                 self.infix_finditer,
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_prefix_search); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 143, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);

  /* "spacy/tokenizer.pyx":144
 *                 self.rules,
 *                 self.prefix_search,
 *                 self.suffix_search,             # <<<<<<<<<<<<<<
 *                 self.infix_finditer,
 *                 self.token_match,
 */
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_suffix_search); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 144, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);

  /* "spacy/tokenizer.pyx":145
 *                 self.prefix_search,
 *                 self.suffix_search,
 *                 self.infix_finditer,             # <<<<<<<<<<<<<<
 *                 self.token_match,
 *                 self.url_match)
 */
  __pyx_t_4 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_infix_finditer); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 145, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);

  /* "spacy/tokenizer.pyx":146
 *                 self.suffix_search,
 *                 self.infix_finditer,
 *                 self.token_match,             # <<<<<<<<<<<<<<
 *                 self.url_match)
 *         return (self.__class__, args, None, None)
 */
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_token_match); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 146, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);

  /* "spacy/tokenizer.pyx":147
 *                 self.infix_finditer,
 *                 self.token_match,
 *                 self.url_match)             # <<<<<<<<<<<<<<
 *         return (self.__class__, args, None, None)
 * 
 */
  __pyx_t_6 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_url_match); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 147, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);

  /* "spacy/tokenizer.pyx":141
 * 
 *     def __reduce__(self):
 *         args = (self.vocab,             # <<<<<<<<<<<<<<
 *                 self.rules,
 *                 self.prefix_search,
 */
  __pyx_t_7 = PyTuple_New(7); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 141, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __Pyx_INCREF(((PyObject *)__pyx_v_self->vocab));
  __Pyx_GIVEREF(((PyObject *)__pyx_v_self->vocab));
  PyTuple_SET_ITEM(__pyx_t_7, 0, ((PyObject *)__pyx_v_self->vocab));
  __Pyx_GIVEREF(__pyx_t_1);
  PyTuple_SET_ITEM(__pyx_t_7, 1, __pyx_t_1);
  __Pyx_GIVEREF(__pyx_t_2);
  PyTuple_SET_ITEM(__pyx_t_7, 2, __pyx_t_2);
  __Pyx_GIVEREF(__pyx_t_3);
  PyTuple_SET_ITEM(__pyx_t_7, 3, __pyx_t_3);
  __Pyx_GIVEREF(__pyx_t_4);
  PyTuple_SET_ITEM(__pyx_t_7, 4, __pyx_t_4);
  __Pyx_GIVEREF(__pyx_t_5);
  PyTuple_SET_ITEM(__pyx_t_7, 5, __pyx_t_5);
  __Pyx_GIVEREF(__pyx_t_6);
  PyTuple_SET_ITEM(__pyx_t_7, 6, __pyx_t_6);
  __pyx_t_1 = 0;
  __pyx_t_2 = 0;
  __pyx_t_3 = 0;
  __pyx_t_4 = 0;
  __pyx_t_5 = 0;
  __pyx_t_6 = 0;
  __pyx_v_args = ((PyObject*)__pyx_t_7);
  __pyx_t_7 = 0;

  /* "spacy/tokenizer.pyx":148
 *                 self.token_match,
 *                 self.url_match)
 *         return (self.__class__, args, None, None)             # <<<<<<<<<<<<<<
 * 
 *     def __call__(self, str string):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_7 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_class); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 148, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __pyx_t_6 = PyTuple_New(4); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 148, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __Pyx_GIVEREF(__pyx_t_7);
  PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_t_7);
  __Pyx_INCREF(__pyx_v_args);
  __Pyx_GIVEREF(__pyx_v_args);
  PyTuple_SET_ITEM(__pyx_t_6, 1, __pyx_v_args);
  __Pyx_INCREF(Py_None);
  __Pyx_GIVEREF(Py_None);
  PyTuple_SET_ITEM(__pyx_t_6, 2, Py_None);
  __Pyx_INCREF(Py_None);
  __Pyx_GIVEREF(Py_None);
  PyTuple_SET_ITEM(__pyx_t_6, 3, Py_None);
  __pyx_t_7 = 0;
  __pyx_r = __pyx_t_6;
  __pyx_t_6 = 0;
  goto __pyx_L0;

  /* "spacy/tokenizer.pyx":140
 *         self._reload_special_cases()
 * 
 *     def __reduce__(self):             # <<<<<<<<<<<<<<
 *         args = (self.vocab,
 *                 self.rules,
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_AddTraceback("spacy.tokenizer.Tokenizer.__reduce__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_args);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "spacy/tokenizer.pyx":150
 *         return (self.__class__, args, None, None)
 * 
 *     def __call__(self, str string):             # <<<<<<<<<<<<<<
 *         """Tokenize a string.
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_5spacy_9tokenizer_9Tokenizer_5__call__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static char __pyx_doc_5spacy_9tokenizer_9Tokenizer_4__call__[] = "Tokenize a string.\n\n        string (str): The string to tokenize.\n        RETURNS (Doc): A container for linguistic annotations.\n\n        DOCS: https://spacy.io/api/tokenizer#call\n        ";
#if CYTHON_UPDATE_DESCRIPTOR_DOC
struct wrapperbase __pyx_wrapperbase_5spacy_9tokenizer_9Tokenizer_4__call__;
#endif
static PyObject *__pyx_pw_5spacy_9tokenizer_9Tokenizer_5__call__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_string = 0;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__call__ (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_string,0};
    PyObject* values[1] = {0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_string)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "__call__") < 0)) __PYX_ERR(0, 150, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 1) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
    }
    __pyx_v_string = ((PyObject*)values[0]);
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("__call__", 1, 1, 1, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 150, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("spacy.tokenizer.Tokenizer.__call__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_string), (&PyString_Type), 1, "string", 1))) __PYX_ERR(0, 150, __pyx_L1_error)
  __pyx_r = __pyx_pf_5spacy_9tokenizer_9Tokenizer_4__call__(((struct __pyx_obj_5spacy_9tokenizer_Tokenizer *)__pyx_v_self), __pyx_v_string);

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5spacy_9tokenizer_9Tokenizer_4__call__(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *__pyx_v_self, PyObject *__pyx_v_string) {
  struct __pyx_obj_5spacy_6tokens_3doc_Doc *__pyx_v_doc = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_t_2;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__call__", 0);

  /* "spacy/tokenizer.pyx":158
 *         DOCS: https://spacy.io/api/tokenizer#call
 *         """
 *         doc = self._tokenize_affixes(string, True)             # <<<<<<<<<<<<<<
 *         self._apply_special_cases(doc)
 *         return doc
 */
  __pyx_t_1 = ((PyObject *)((struct __pyx_vtabstruct_5spacy_9tokenizer_Tokenizer *)__pyx_v_self->__pyx_vtab)->_tokenize_affixes(__pyx_v_self, __pyx_v_string, 1)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 158, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_v_doc = ((struct __pyx_obj_5spacy_6tokens_3doc_Doc *)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "spacy/tokenizer.pyx":159
 *         """
 *         doc = self._tokenize_affixes(string, True)
 *         self._apply_special_cases(doc)             # <<<<<<<<<<<<<<
 *         return doc
 * 
 */
  __pyx_t_2 = ((struct __pyx_vtabstruct_5spacy_9tokenizer_Tokenizer *)__pyx_v_self->__pyx_vtab)->_apply_special_cases(__pyx_v_self, __pyx_v_doc); if (unlikely(__pyx_t_2 == ((int)-1))) __PYX_ERR(0, 159, __pyx_L1_error)

  /* "spacy/tokenizer.pyx":160
 *         doc = self._tokenize_affixes(string, True)
 *         self._apply_special_cases(doc)
 *         return doc             # <<<<<<<<<<<<<<
 * 
 *     @cython.boundscheck(False)
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_doc));
  __pyx_r = ((PyObject *)__pyx_v_doc);
  goto __pyx_L0;

  /* "spacy/tokenizer.pyx":150
 *         return (self.__class__, args, None, None)
 * 
 *     def __call__(self, str string):             # <<<<<<<<<<<<<<
 *         """Tokenize a string.
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("spacy.tokenizer.Tokenizer.__call__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_doc);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "spacy/tokenizer.pyx":163
 * 
 *     @cython.boundscheck(False)
 *     cdef Doc _tokenize_affixes(self, str string, bint with_special_cases):             # <<<<<<<<<<<<<<
 *         """Tokenize according to affix and token_match settings.
 * 
 */

static struct __pyx_obj_5spacy_6tokens_3doc_Doc *__pyx_f_5spacy_9tokenizer_9Tokenizer__tokenize_affixes(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *__pyx_v_self, PyObject *__pyx_v_string, int __pyx_v_with_special_cases) {
  int __pyx_v_length;
  struct __pyx_obj_5spacy_6tokens_3doc_Doc *__pyx_v_doc = 0;
  int __pyx_v_i;
  int __pyx_v_start;
  int __pyx_v_has_special;
  int __pyx_v_in_ws;
  PyObject *__pyx_v_span = 0;
  PyObject *__pyx_v_uc = NULL;
  __pyx_t_5spacy_8typedefs_hash_t __pyx_v_key;
  struct __pyx_obj_5spacy_6tokens_3doc_Doc *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  Py_ssize_t __pyx_t_1;
  int __pyx_t_2;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *(*__pyx_t_6)(PyObject *);
  PyObject *__pyx_t_7 = NULL;
  __pyx_t_5spacy_8typedefs_hash_t __pyx_t_8;
  int __pyx_t_9;
  int __pyx_t_10;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("_tokenize_affixes", 0);

  /* "spacy/tokenizer.pyx":169
 *         RETURNS (Doc): A container for linguistic annotations.
 *         """
 *         if len(string) >= (2 ** 30):             # <<<<<<<<<<<<<<
 *             raise ValueError(Errors.E025.format(length=len(string)))
 *         cdef int length = len(string)
 */
  __pyx_t_1 = PyObject_Length(__pyx_v_string); if (unlikely(__pyx_t_1 == ((Py_ssize_t)-1))) __PYX_ERR(0, 169, __pyx_L1_error)
  __pyx_t_2 = ((__pyx_t_1 >= 0x40000000) != 0);
  if (unlikely(__pyx_t_2)) {

    /* "spacy/tokenizer.pyx":170
 *         """
 *         if len(string) >= (2 ** 30):
 *             raise ValueError(Errors.E025.format(length=len(string)))             # <<<<<<<<<<<<<<
 *         cdef int length = len(string)
 *         cdef Doc doc = Doc(self.vocab)
 */
    __Pyx_GetModuleGlobalName(__pyx_t_3, __pyx_n_s_Errors); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 170, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_t_3, __pyx_n_s_E025); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 170, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_4, __pyx_n_s_format); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 170, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __pyx_t_4 = __Pyx_PyDict_NewPresized(1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 170, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_1 = PyObject_Length(__pyx_v_string); if (unlikely(__pyx_t_1 == ((Py_ssize_t)-1))) __PYX_ERR(0, 170, __pyx_L1_error)
    __pyx_t_5 = PyInt_FromSsize_t(__pyx_t_1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 170, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    if (PyDict_SetItem(__pyx_t_4, __pyx_n_s_length, __pyx_t_5) < 0) __PYX_ERR(0, 170, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_5 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_empty_tuple, __pyx_t_4); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 170, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __pyx_t_4 = __Pyx_PyObject_CallOneArg(__pyx_builtin_ValueError, __pyx_t_5); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 170, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_Raise(__pyx_t_4, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __PYX_ERR(0, 170, __pyx_L1_error)

    /* "spacy/tokenizer.pyx":169
 *         RETURNS (Doc): A container for linguistic annotations.
 *         """
 *         if len(string) >= (2 ** 30):             # <<<<<<<<<<<<<<
 *             raise ValueError(Errors.E025.format(length=len(string)))
 *         cdef int length = len(string)
 */
  }

  /* "spacy/tokenizer.pyx":171
 *         if len(string) >= (2 ** 30):
 *             raise ValueError(Errors.E025.format(length=len(string)))
 *         cdef int length = len(string)             # <<<<<<<<<<<<<<
 *         cdef Doc doc = Doc(self.vocab)
 *         if length == 0:
 */
  __pyx_t_1 = PyObject_Length(__pyx_v_string); if (unlikely(__pyx_t_1 == ((Py_ssize_t)-1))) __PYX_ERR(0, 171, __pyx_L1_error)
  __pyx_v_length = __pyx_t_1;

  /* "spacy/tokenizer.pyx":172
 *             raise ValueError(Errors.E025.format(length=len(string)))
 *         cdef int length = len(string)
 *         cdef Doc doc = Doc(self.vocab)             # <<<<<<<<<<<<<<
 *         if length == 0:
 *             return doc
 */
  __pyx_t_4 = __Pyx_PyObject_CallOneArg(((PyObject *)__pyx_ptype_5spacy_6tokens_3doc_Doc), ((PyObject *)__pyx_v_self->vocab)); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 172, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_v_doc = ((struct __pyx_obj_5spacy_6tokens_3doc_Doc *)__pyx_t_4);
  __pyx_t_4 = 0;

  /* "spacy/tokenizer.pyx":173
 *         cdef int length = len(string)
 *         cdef Doc doc = Doc(self.vocab)
 *         if length == 0:             # <<<<<<<<<<<<<<
 *             return doc
 *         cdef int i = 0
 */
  __pyx_t_2 = ((__pyx_v_length == 0) != 0);
  if (__pyx_t_2) {

    /* "spacy/tokenizer.pyx":174
 *         cdef Doc doc = Doc(self.vocab)
 *         if length == 0:
 *             return doc             # <<<<<<<<<<<<<<
 *         cdef int i = 0
 *         cdef int start = 0
 */
    __Pyx_XDECREF(((PyObject *)__pyx_r));
    __Pyx_INCREF(((PyObject *)__pyx_v_doc));
    __pyx_r = __pyx_v_doc;
    goto __pyx_L0;

    /* "spacy/tokenizer.pyx":173
 *         cdef int length = len(string)
 *         cdef Doc doc = Doc(self.vocab)
 *         if length == 0:             # <<<<<<<<<<<<<<
 *             return doc
 *         cdef int i = 0
 */
  }

  /* "spacy/tokenizer.pyx":175
 *         if length == 0:
 *             return doc
 *         cdef int i = 0             # <<<<<<<<<<<<<<
 *         cdef int start = 0
 *         cdef int has_special = 0
 */
  __pyx_v_i = 0;

  /* "spacy/tokenizer.pyx":176
 *             return doc
 *         cdef int i = 0
 *         cdef int start = 0             # <<<<<<<<<<<<<<
 *         cdef int has_special = 0
 *         cdef bint in_ws = string[0].isspace()
 */
  __pyx_v_start = 0;

  /* "spacy/tokenizer.pyx":177
 *         cdef int i = 0
 *         cdef int start = 0
 *         cdef int has_special = 0             # <<<<<<<<<<<<<<
 *         cdef bint in_ws = string[0].isspace()
 *         cdef str span
 */
  __pyx_v_has_special = 0;

  /* "spacy/tokenizer.pyx":178
 *         cdef int start = 0
 *         cdef int has_special = 0
 *         cdef bint in_ws = string[0].isspace()             # <<<<<<<<<<<<<<
 *         cdef str span
 *         # The task here is much like string.split, but not quite
 */
  __pyx_t_5 = __Pyx_GetItemInt(__pyx_v_string, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 178, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_5, __pyx_n_s_isspace); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 178, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_t_5 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_3))) {
    __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_3);
    if (likely(__pyx_t_5)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
      __Pyx_INCREF(__pyx_t_5);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_3, function);
    }
  }
  __pyx_t_4 = (__pyx_t_5) ? __Pyx_PyObject_CallOneArg(__pyx_t_3, __pyx_t_5) : __Pyx_PyObject_CallNoArg(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
  if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 178, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_2 = __Pyx_PyObject_IsTrue(__pyx_t_4); if (unlikely((__pyx_t_2 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 178, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_v_in_ws = __pyx_t_2;

  /* "spacy/tokenizer.pyx":184
 *         # spans that are exactly ' '. So, our sequences will all be separated
 *         # by either ' ' or nothing.
 *         for uc in string:             # <<<<<<<<<<<<<<
 *             if uc.isspace() != in_ws:
 *                 if start < i:
 */
  __pyx_t_4 = PyObject_GetIter(__pyx_v_string); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 184, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_6 = Py_TYPE(__pyx_t_4)->tp_iternext; if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 184, __pyx_L1_error)
  for (;;) {
    {
      __pyx_t_3 = __pyx_t_6(__pyx_t_4);
      if (unlikely(!__pyx_t_3)) {
        PyObject* exc_type = PyErr_Occurred();
        if (exc_type) {
          if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
          else __PYX_ERR(0, 184, __pyx_L1_error)
        }
        break;
      }
      __Pyx_GOTREF(__pyx_t_3);
    }
    __Pyx_XDECREF_SET(__pyx_v_uc, __pyx_t_3);
    __pyx_t_3 = 0;

    /* "spacy/tokenizer.pyx":185
 *         # by either ' ' or nothing.
 *         for uc in string:
 *             if uc.isspace() != in_ws:             # <<<<<<<<<<<<<<
 *                 if start < i:
 *                     # When we want to make this fast, get the data buffer once
 */
    __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_v_uc, __pyx_n_s_isspace); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 185, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_7 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_5))) {
      __pyx_t_7 = PyMethod_GET_SELF(__pyx_t_5);
      if (likely(__pyx_t_7)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
        __Pyx_INCREF(__pyx_t_7);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_5, function);
      }
    }
    __pyx_t_3 = (__pyx_t_7) ? __Pyx_PyObject_CallOneArg(__pyx_t_5, __pyx_t_7) : __Pyx_PyObject_CallNoArg(__pyx_t_5);
    __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
    if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 185, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_5 = __Pyx_PyBool_FromLong(__pyx_v_in_ws); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 185, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_7 = PyObject_RichCompare(__pyx_t_3, __pyx_t_5, Py_NE); __Pyx_XGOTREF(__pyx_t_7); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 185, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_2 = __Pyx_PyObject_IsTrue(__pyx_t_7); if (unlikely(__pyx_t_2 < 0)) __PYX_ERR(0, 185, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    if (__pyx_t_2) {

      /* "spacy/tokenizer.pyx":186
 *         for uc in string:
 *             if uc.isspace() != in_ws:
 *                 if start < i:             # <<<<<<<<<<<<<<
 *                     # When we want to make this fast, get the data buffer once
 *                     # with PyUnicode_AS_DATA, and then maintain a start_byte
 */
      __pyx_t_2 = ((__pyx_v_start < __pyx_v_i) != 0);
      if (__pyx_t_2) {

        /* "spacy/tokenizer.pyx":191
 *                     # and end_byte, so we can call hash64 directly. That way
 *                     # we don't have to create the slice when we hit the cache.
 *                     span = string[start:i]             # <<<<<<<<<<<<<<
 *                     key = hash_string(span)
 *                     if not self._try_specials_and_cache(key, doc, &has_special, with_special_cases):
 */
        if (unlikely(__pyx_v_string == Py_None)) {
          PyErr_SetString(PyExc_TypeError, "'NoneType' object is not subscriptable");
          __PYX_ERR(0, 191, __pyx_L1_error)
        }
        __pyx_t_7 = PySequence_GetSlice(__pyx_v_string, __pyx_v_start, __pyx_v_i); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 191, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_7);
        __Pyx_XDECREF_SET(__pyx_v_span, ((PyObject*)__pyx_t_7));
        __pyx_t_7 = 0;

        /* "spacy/tokenizer.pyx":192
 *                     # we don't have to create the slice when we hit the cache.
 *                     span = string[start:i]
 *                     key = hash_string(span)             # <<<<<<<<<<<<<<
 *                     if not self._try_specials_and_cache(key, doc, &has_special, with_special_cases):
 *                         self._tokenize(doc, span, key, &has_special, with_special_cases)
 */
        __pyx_t_8 = __pyx_f_5spacy_7strings_hash_string(__pyx_v_span, 0); if (unlikely(__pyx_t_8 == ((__pyx_t_5spacy_8typedefs_hash_t)0))) __PYX_ERR(0, 192, __pyx_L1_error)
        __pyx_v_key = __pyx_t_8;

        /* "spacy/tokenizer.pyx":193
 *                     span = string[start:i]
 *                     key = hash_string(span)
 *                     if not self._try_specials_and_cache(key, doc, &has_special, with_special_cases):             # <<<<<<<<<<<<<<
 *                         self._tokenize(doc, span, key, &has_special, with_special_cases)
 *                 if uc == ' ':
 */
        __pyx_t_9 = ((struct __pyx_vtabstruct_5spacy_9tokenizer_Tokenizer *)__pyx_v_self->__pyx_vtab)->_try_specials_and_cache(__pyx_v_self, __pyx_v_key, __pyx_v_doc, (&__pyx_v_has_special), __pyx_v_with_special_cases); if (unlikely(__pyx_t_9 == ((int)-1))) __PYX_ERR(0, 193, __pyx_L1_error)
        __pyx_t_2 = ((!(__pyx_t_9 != 0)) != 0);
        if (__pyx_t_2) {

          /* "spacy/tokenizer.pyx":194
 *                     key = hash_string(span)
 *                     if not self._try_specials_and_cache(key, doc, &has_special, with_special_cases):
 *                         self._tokenize(doc, span, key, &has_special, with_special_cases)             # <<<<<<<<<<<<<<
 *                 if uc == ' ':
 *                     doc.c[doc.length - 1].spacy = True
 */
          __pyx_t_9 = ((struct __pyx_vtabstruct_5spacy_9tokenizer_Tokenizer *)__pyx_v_self->__pyx_vtab)->_tokenize(__pyx_v_self, __pyx_v_doc, __pyx_v_span, __pyx_v_key, (&__pyx_v_has_special), __pyx_v_with_special_cases); if (unlikely(__pyx_t_9 == ((int)-1))) __PYX_ERR(0, 194, __pyx_L1_error)

          /* "spacy/tokenizer.pyx":193
 *                     span = string[start:i]
 *                     key = hash_string(span)
 *                     if not self._try_specials_and_cache(key, doc, &has_special, with_special_cases):             # <<<<<<<<<<<<<<
 *                         self._tokenize(doc, span, key, &has_special, with_special_cases)
 *                 if uc == ' ':
 */
        }

        /* "spacy/tokenizer.pyx":186
 *         for uc in string:
 *             if uc.isspace() != in_ws:
 *                 if start < i:             # <<<<<<<<<<<<<<
 *                     # When we want to make this fast, get the data buffer once
 *                     # with PyUnicode_AS_DATA, and then maintain a start_byte
 */
      }

      /* "spacy/tokenizer.pyx":195
 *                     if not self._try_specials_and_cache(key, doc, &has_special, with_special_cases):
 *                         self._tokenize(doc, span, key, &has_special, with_special_cases)
 *                 if uc == ' ':             # <<<<<<<<<<<<<<
 *                     doc.c[doc.length - 1].spacy = True
 *                     start = i + 1
 */
      __pyx_t_2 = (__Pyx_PyString_Equals(__pyx_v_uc, __pyx_kp_s_, Py_EQ)); if (unlikely(__pyx_t_2 < 0)) __PYX_ERR(0, 195, __pyx_L1_error)
      if (__pyx_t_2) {

        /* "spacy/tokenizer.pyx":196
 *                         self._tokenize(doc, span, key, &has_special, with_special_cases)
 *                 if uc == ' ':
 *                     doc.c[doc.length - 1].spacy = True             # <<<<<<<<<<<<<<
 *                     start = i + 1
 *                 else:
 */
        (__pyx_v_doc->c[(__pyx_v_doc->length - 1)]).spacy = 1;

        /* "spacy/tokenizer.pyx":197
 *                 if uc == ' ':
 *                     doc.c[doc.length - 1].spacy = True
 *                     start = i + 1             # <<<<<<<<<<<<<<
 *                 else:
 *                     start = i
 */
        __pyx_v_start = (__pyx_v_i + 1);

        /* "spacy/tokenizer.pyx":195
 *                     if not self._try_specials_and_cache(key, doc, &has_special, with_special_cases):
 *                         self._tokenize(doc, span, key, &has_special, with_special_cases)
 *                 if uc == ' ':             # <<<<<<<<<<<<<<
 *                     doc.c[doc.length - 1].spacy = True
 *                     start = i + 1
 */
        goto __pyx_L10;
      }

      /* "spacy/tokenizer.pyx":199
 *                     start = i + 1
 *                 else:
 *                     start = i             # <<<<<<<<<<<<<<
 *                 in_ws = not in_ws
 *             i += 1
 */
      /*else*/ {
        __pyx_v_start = __pyx_v_i;
      }
      __pyx_L10:;

      /* "spacy/tokenizer.pyx":200
 *                 else:
 *                     start = i
 *                 in_ws = not in_ws             # <<<<<<<<<<<<<<
 *             i += 1
 *         if start < i:
 */
      __pyx_v_in_ws = (!(__pyx_v_in_ws != 0));

      /* "spacy/tokenizer.pyx":185
 *         # by either ' ' or nothing.
 *         for uc in string:
 *             if uc.isspace() != in_ws:             # <<<<<<<<<<<<<<
 *                 if start < i:
 *                     # When we want to make this fast, get the data buffer once
 */
    }

    /* "spacy/tokenizer.pyx":201
 *                     start = i
 *                 in_ws = not in_ws
 *             i += 1             # <<<<<<<<<<<<<<
 *         if start < i:
 *             span = string[start:]
 */
    __pyx_v_i = (__pyx_v_i + 1);

    /* "spacy/tokenizer.pyx":184
 *         # spans that are exactly ' '. So, our sequences will all be separated
 *         # by either ' ' or nothing.
 *         for uc in string:             # <<<<<<<<<<<<<<
 *             if uc.isspace() != in_ws:
 *                 if start < i:
 */
  }
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;

  /* "spacy/tokenizer.pyx":202
 *                 in_ws = not in_ws
 *             i += 1
 *         if start < i:             # <<<<<<<<<<<<<<
 *             span = string[start:]
 *             key = hash_string(span)
 */
  __pyx_t_2 = ((__pyx_v_start < __pyx_v_i) != 0);
  if (__pyx_t_2) {

    /* "spacy/tokenizer.pyx":203
 *             i += 1
 *         if start < i:
 *             span = string[start:]             # <<<<<<<<<<<<<<
 *             key = hash_string(span)
 *             if not self._try_specials_and_cache(key, doc, &has_special, with_special_cases):
 */
    if (unlikely(__pyx_v_string == Py_None)) {
      PyErr_SetString(PyExc_TypeError, "'NoneType' object is not subscriptable");
      __PYX_ERR(0, 203, __pyx_L1_error)
    }
    __pyx_t_4 = PySequence_GetSlice(__pyx_v_string, __pyx_v_start, PY_SSIZE_T_MAX); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 203, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_XDECREF_SET(__pyx_v_span, ((PyObject*)__pyx_t_4));
    __pyx_t_4 = 0;

    /* "spacy/tokenizer.pyx":204
 *         if start < i:
 *             span = string[start:]
 *             key = hash_string(span)             # <<<<<<<<<<<<<<
 *             if not self._try_specials_and_cache(key, doc, &has_special, with_special_cases):
 *                 self._tokenize(doc, span, key, &has_special, with_special_cases)
 */
    __pyx_t_8 = __pyx_f_5spacy_7strings_hash_string(__pyx_v_span, 0); if (unlikely(__pyx_t_8 == ((__pyx_t_5spacy_8typedefs_hash_t)0))) __PYX_ERR(0, 204, __pyx_L1_error)
    __pyx_v_key = __pyx_t_8;

    /* "spacy/tokenizer.pyx":205
 *             span = string[start:]
 *             key = hash_string(span)
 *             if not self._try_specials_and_cache(key, doc, &has_special, with_special_cases):             # <<<<<<<<<<<<<<
 *                 self._tokenize(doc, span, key, &has_special, with_special_cases)
 *             doc.c[doc.length - 1].spacy = string[-1] == " " and not in_ws
 */
    __pyx_t_9 = ((struct __pyx_vtabstruct_5spacy_9tokenizer_Tokenizer *)__pyx_v_self->__pyx_vtab)->_try_specials_and_cache(__pyx_v_self, __pyx_v_key, __pyx_v_doc, (&__pyx_v_has_special), __pyx_v_with_special_cases); if (unlikely(__pyx_t_9 == ((int)-1))) __PYX_ERR(0, 205, __pyx_L1_error)
    __pyx_t_2 = ((!(__pyx_t_9 != 0)) != 0);
    if (__pyx_t_2) {

      /* "spacy/tokenizer.pyx":206
 *             key = hash_string(span)
 *             if not self._try_specials_and_cache(key, doc, &has_special, with_special_cases):
 *                 self._tokenize(doc, span, key, &has_special, with_special_cases)             # <<<<<<<<<<<<<<
 *             doc.c[doc.length - 1].spacy = string[-1] == " " and not in_ws
 *         return doc
 */
      __pyx_t_9 = ((struct __pyx_vtabstruct_5spacy_9tokenizer_Tokenizer *)__pyx_v_self->__pyx_vtab)->_tokenize(__pyx_v_self, __pyx_v_doc, __pyx_v_span, __pyx_v_key, (&__pyx_v_has_special), __pyx_v_with_special_cases); if (unlikely(__pyx_t_9 == ((int)-1))) __PYX_ERR(0, 206, __pyx_L1_error)

      /* "spacy/tokenizer.pyx":205
 *             span = string[start:]
 *             key = hash_string(span)
 *             if not self._try_specials_and_cache(key, doc, &has_special, with_special_cases):             # <<<<<<<<<<<<<<
 *                 self._tokenize(doc, span, key, &has_special, with_special_cases)
 *             doc.c[doc.length - 1].spacy = string[-1] == " " and not in_ws
 */
    }

    /* "spacy/tokenizer.pyx":207
 *             if not self._try_specials_and_cache(key, doc, &has_special, with_special_cases):
 *                 self._tokenize(doc, span, key, &has_special, with_special_cases)
 *             doc.c[doc.length - 1].spacy = string[-1] == " " and not in_ws             # <<<<<<<<<<<<<<
 *         return doc
 * 
 */
    __pyx_t_4 = __Pyx_GetItemInt(__pyx_v_string, -1L, long, 1, __Pyx_PyInt_From_long, 0, 1, 0); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 207, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_10 = (__Pyx_PyString_Equals(__pyx_t_4, __pyx_kp_s_, Py_EQ)); if (unlikely(__pyx_t_10 < 0)) __PYX_ERR(0, 207, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    if (__pyx_t_10) {
    } else {
      __pyx_t_2 = __pyx_t_10;
      goto __pyx_L13_bool_binop_done;
    }
    __pyx_t_10 = ((!(__pyx_v_in_ws != 0)) != 0);
    __pyx_t_2 = __pyx_t_10;
    __pyx_L13_bool_binop_done:;
    (__pyx_v_doc->c[(__pyx_v_doc->length - 1)]).spacy = __pyx_t_2;

    /* "spacy/tokenizer.pyx":202
 *                 in_ws = not in_ws
 *             i += 1
 *         if start < i:             # <<<<<<<<<<<<<<
 *             span = string[start:]
 *             key = hash_string(span)
 */
  }

  /* "spacy/tokenizer.pyx":208
 *                 self._tokenize(doc, span, key, &has_special, with_special_cases)
 *             doc.c[doc.length - 1].spacy = string[-1] == " " and not in_ws
 *         return doc             # <<<<<<<<<<<<<<
 * 
 *     def pipe(self, texts, batch_size=1000):
 */
  __Pyx_XDECREF(((PyObject *)__pyx_r));
  __Pyx_INCREF(((PyObject *)__pyx_v_doc));
  __pyx_r = __pyx_v_doc;
  goto __pyx_L0;

  /* "spacy/tokenizer.pyx":163
 * 
 *     @cython.boundscheck(False)
 *     cdef Doc _tokenize_affixes(self, str string, bint with_special_cases):             # <<<<<<<<<<<<<<
 *         """Tokenize according to affix and token_match settings.
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_AddTraceback("spacy.tokenizer.Tokenizer._tokenize_affixes", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_doc);
  __Pyx_XDECREF(__pyx_v_span);
  __Pyx_XDECREF(__pyx_v_uc);
  __Pyx_XGIVEREF((PyObject *)__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}
static PyObject *__pyx_gb_5spacy_9tokenizer_9Tokenizer_8generator(__pyx_CoroutineObject *__pyx_generator, CYTHON_UNUSED PyThreadState *__pyx_tstate, PyObject *__pyx_sent_value); /* proto */

/* "spacy/tokenizer.pyx":210
 *         return doc
 * 
 *     def pipe(self, texts, batch_size=1000):             # <<<<<<<<<<<<<<
 *         """Tokenize a stream of texts.
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_5spacy_9tokenizer_9Tokenizer_7pipe(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static char __pyx_doc_5spacy_9tokenizer_9Tokenizer_6pipe[] = "Tokenizer.pipe(self, texts, batch_size=1000)\nTokenize a stream of texts.\n\n        texts: A sequence of unicode texts.\n        batch_size (int): Number of texts to accumulate in an internal buffer.\n        Defaults to 1000.\n        YIELDS (Doc): A sequence of Doc objects, in order.\n\n        DOCS: https://spacy.io/api/tokenizer#pipe\n        ";
static PyMethodDef __pyx_mdef_5spacy_9tokenizer_9Tokenizer_7pipe = {"pipe", (PyCFunction)(void*)(PyCFunctionWithKeywords)__pyx_pw_5spacy_9tokenizer_9Tokenizer_7pipe, METH_VARARGS|METH_KEYWORDS, __pyx_doc_5spacy_9tokenizer_9Tokenizer_6pipe};
static PyObject *__pyx_pw_5spacy_9tokenizer_9Tokenizer_7pipe(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_texts = 0;
  CYTHON_UNUSED PyObject *__pyx_v_batch_size = 0;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("pipe (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_texts,&__pyx_n_s_batch_size,0};
    PyObject* values[2] = {0,0};
    values[1] = ((PyObject *)__pyx_int_1000);
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_texts)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_batch_size);
          if (value) { values[1] = value; kw_args--; }
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "pipe") < 0)) __PYX_ERR(0, 210, __pyx_L3_error)
      }
    } else {
      switch (PyTuple_GET_SIZE(__pyx_args)) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        break;
        default: goto __pyx_L5_argtuple_error;
      }
    }
    __pyx_v_texts = values[0];
    __pyx_v_batch_size = values[1];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("pipe", 0, 1, 2, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 210, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("spacy.tokenizer.Tokenizer.pipe", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5spacy_9tokenizer_9Tokenizer_6pipe(((struct __pyx_obj_5spacy_9tokenizer_Tokenizer *)__pyx_v_self), __pyx_v_texts, __pyx_v_batch_size);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5spacy_9tokenizer_9Tokenizer_6pipe(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *__pyx_v_self, PyObject *__pyx_v_texts, CYTHON_UNUSED PyObject *__pyx_v_batch_size) {
  struct __pyx_obj_5spacy_9tokenizer___pyx_scope_struct__pipe *__pyx_cur_scope;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("pipe", 0);
  __pyx_cur_scope = (struct __pyx_obj_5spacy_9tokenizer___pyx_scope_struct__pipe *)__pyx_tp_new_5spacy_9tokenizer___pyx_scope_struct__pipe(__pyx_ptype_5spacy_9tokenizer___pyx_scope_struct__pipe, __pyx_empty_tuple, NULL);
  if (unlikely(!__pyx_cur_scope)) {
    __pyx_cur_scope = ((struct __pyx_obj_5spacy_9tokenizer___pyx_scope_struct__pipe *)Py_None);
    __Pyx_INCREF(Py_None);
    __PYX_ERR(0, 210, __pyx_L1_error)
  } else {
    __Pyx_GOTREF(__pyx_cur_scope);
  }
  __pyx_cur_scope->__pyx_v_self = __pyx_v_self;
  __Pyx_INCREF((PyObject *)__pyx_cur_scope->__pyx_v_self);
  __Pyx_GIVEREF((PyObject *)__pyx_cur_scope->__pyx_v_self);
  __pyx_cur_scope->__pyx_v_texts = __pyx_v_texts;
  __Pyx_INCREF(__pyx_cur_scope->__pyx_v_texts);
  __Pyx_GIVEREF(__pyx_cur_scope->__pyx_v_texts);
  __pyx_cur_scope->__pyx_v_batch_size = __pyx_v_batch_size;
  __Pyx_INCREF(__pyx_cur_scope->__pyx_v_batch_size);
  __Pyx_GIVEREF(__pyx_cur_scope->__pyx_v_batch_size);
  {
    __pyx_CoroutineObject *gen = __Pyx_Generator_New((__pyx_coroutine_body_t) __pyx_gb_5spacy_9tokenizer_9Tokenizer_8generator, __pyx_codeobj__2, (PyObject *) __pyx_cur_scope, __pyx_n_s_pipe, __pyx_n_s_Tokenizer_pipe, __pyx_n_s_spacy_tokenizer); if (unlikely(!gen)) __PYX_ERR(0, 210, __pyx_L1_error)
    __Pyx_DECREF(__pyx_cur_scope);
    __Pyx_RefNannyFinishContext();
    return (PyObject *) gen;
  }

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_AddTraceback("spacy.tokenizer.Tokenizer.pipe", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __Pyx_DECREF(((PyObject *)__pyx_cur_scope));
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_gb_5spacy_9tokenizer_9Tokenizer_8generator(__pyx_CoroutineObject *__pyx_generator, CYTHON_UNUSED PyThreadState *__pyx_tstate, PyObject *__pyx_sent_value) /* generator body */
{
  struct __pyx_obj_5spacy_9tokenizer___pyx_scope_struct__pipe *__pyx_cur_scope = ((struct __pyx_obj_5spacy_9tokenizer___pyx_scope_struct__pipe *)__pyx_generator->closure);
  PyObject *__pyx_r = NULL;
  PyObject *__pyx_t_1 = NULL;
  Py_ssize_t __pyx_t_2;
  PyObject *(*__pyx_t_3)(PyObject *);
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("pipe", 0);
  switch (__pyx_generator->resume_label) {
    case 0: goto __pyx_L3_first_run;
    case 1: goto __pyx_L6_resume_from_yield;
    default: /* CPython raises the right error here */
    __Pyx_RefNannyFinishContext();
    return NULL;
  }
  __pyx_L3_first_run:;
  if (unlikely(!__pyx_sent_value)) __PYX_ERR(0, 210, __pyx_L1_error)

  /* "spacy/tokenizer.pyx":220
 *         DOCS: https://spacy.io/api/tokenizer#pipe
 *         """
 *         for text in texts:             # <<<<<<<<<<<<<<
 *             yield self(text)
 * 
 */
  if (likely(PyList_CheckExact(__pyx_cur_scope->__pyx_v_texts)) || PyTuple_CheckExact(__pyx_cur_scope->__pyx_v_texts)) {
    __pyx_t_1 = __pyx_cur_scope->__pyx_v_texts; __Pyx_INCREF(__pyx_t_1); __pyx_t_2 = 0;
    __pyx_t_3 = NULL;
  } else {
    __pyx_t_2 = -1; __pyx_t_1 = PyObject_GetIter(__pyx_cur_scope->__pyx_v_texts); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 220, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_3 = Py_TYPE(__pyx_t_1)->tp_iternext; if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 220, __pyx_L1_error)
  }
  for (;;) {
    if (likely(!__pyx_t_3)) {
      if (likely(PyList_CheckExact(__pyx_t_1))) {
        if (__pyx_t_2 >= PyList_GET_SIZE(__pyx_t_1)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_4 = PyList_GET_ITEM(__pyx_t_1, __pyx_t_2); __Pyx_INCREF(__pyx_t_4); __pyx_t_2++; if (unlikely(0 < 0)) __PYX_ERR(0, 220, __pyx_L1_error)
        #else
        __pyx_t_4 = PySequence_ITEM(__pyx_t_1, __pyx_t_2); __pyx_t_2++; if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 220, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_4);
        #endif
      } else {
        if (__pyx_t_2 >= PyTuple_GET_SIZE(__pyx_t_1)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_4 = PyTuple_GET_ITEM(__pyx_t_1, __pyx_t_2); __Pyx_INCREF(__pyx_t_4); __pyx_t_2++; if (unlikely(0 < 0)) __PYX_ERR(0, 220, __pyx_L1_error)
        #else
        __pyx_t_4 = PySequence_ITEM(__pyx_t_1, __pyx_t_2); __pyx_t_2++; if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 220, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_4);
        #endif
      }
    } else {
      __pyx_t_4 = __pyx_t_3(__pyx_t_1);
      if (unlikely(!__pyx_t_4)) {
        PyObject* exc_type = PyErr_Occurred();
        if (exc_type) {
          if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
          else __PYX_ERR(0, 220, __pyx_L1_error)
        }
        break;
      }
      __Pyx_GOTREF(__pyx_t_4);
    }
    __Pyx_XGOTREF(__pyx_cur_scope->__pyx_v_text);
    __Pyx_XDECREF_SET(__pyx_cur_scope->__pyx_v_text, __pyx_t_4);
    __Pyx_GIVEREF(__pyx_t_4);
    __pyx_t_4 = 0;

    /* "spacy/tokenizer.pyx":221
 *         """
 *         for text in texts:
 *             yield self(text)             # <<<<<<<<<<<<<<
 * 
 *     def _flush_cache(self):
 */
    __Pyx_INCREF(((PyObject *)__pyx_cur_scope->__pyx_v_self));
    __pyx_t_5 = ((PyObject *)__pyx_cur_scope->__pyx_v_self); __pyx_t_6 = NULL;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_5))) {
      __pyx_t_6 = PyMethod_GET_SELF(__pyx_t_5);
      if (likely(__pyx_t_6)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
        __Pyx_INCREF(__pyx_t_6);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_5, function);
      }
    }
    __pyx_t_4 = (__pyx_t_6) ? __Pyx_PyObject_Call2Args(__pyx_t_5, __pyx_t_6, __pyx_cur_scope->__pyx_v_text) : __Pyx_PyObject_CallOneArg(__pyx_t_5, __pyx_cur_scope->__pyx_v_text);
    __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
    if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 221, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_r = __pyx_t_4;
    __pyx_t_4 = 0;
    __Pyx_XGIVEREF(__pyx_t_1);
    __pyx_cur_scope->__pyx_t_0 = __pyx_t_1;
    __pyx_cur_scope->__pyx_t_1 = __pyx_t_2;
    __pyx_cur_scope->__pyx_t_2 = __pyx_t_3;
    __Pyx_XGIVEREF(__pyx_r);
    __Pyx_RefNannyFinishContext();
    __Pyx_Coroutine_ResetAndClearException(__pyx_generator);
    /* return from generator, yielding value */
    __pyx_generator->resume_label = 1;
    return __pyx_r;
    __pyx_L6_resume_from_yield:;
    __pyx_t_1 = __pyx_cur_scope->__pyx_t_0;
    __pyx_cur_scope->__pyx_t_0 = 0;
    __Pyx_XGOTREF(__pyx_t_1);
    __pyx_t_2 = __pyx_cur_scope->__pyx_t_1;
    __pyx_t_3 = __pyx_cur_scope->__pyx_t_2;
    if (unlikely(!__pyx_sent_value)) __PYX_ERR(0, 221, __pyx_L1_error)

    /* "spacy/tokenizer.pyx":220
 *         DOCS: https://spacy.io/api/tokenizer#pipe
 *         """
 *         for text in texts:             # <<<<<<<<<<<<<<
 *             yield self(text)
 * 
 */
  }
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  CYTHON_MAYBE_UNUSED_VAR(__pyx_cur_scope);

  /* "spacy/tokenizer.pyx":210
 *         return doc
 * 
 *     def pipe(self, texts, batch_size=1000):             # <<<<<<<<<<<<<<
 *         """Tokenize a stream of texts.
 * 
 */

  /* function exit code */
  PyErr_SetNone(PyExc_StopIteration);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_AddTraceback("pipe", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_r); __pyx_r = 0;
  #if !CYTHON_USE_EXC_INFO_STACK
  __Pyx_Coroutine_ResetAndClearException(__pyx_generator);
  #endif
  __pyx_generator->resume_label = -1;
  __Pyx_Coroutine_clear((PyObject*)__pyx_generator);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "spacy/tokenizer.pyx":223
 *             yield self(text)
 * 
 *     def _flush_cache(self):             # <<<<<<<<<<<<<<
 *         self._reset_cache([key for key in self._cache])
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_5spacy_9tokenizer_9Tokenizer_10_flush_cache(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static char __pyx_doc_5spacy_9tokenizer_9Tokenizer_9_flush_cache[] = "Tokenizer._flush_cache(self)";
static PyMethodDef __pyx_mdef_5spacy_9tokenizer_9Tokenizer_10_flush_cache = {"_flush_cache", (PyCFunction)__pyx_pw_5spacy_9tokenizer_9Tokenizer_10_flush_cache, METH_NOARGS, __pyx_doc_5spacy_9tokenizer_9Tokenizer_9_flush_cache};
static PyObject *__pyx_pw_5spacy_9tokenizer_9Tokenizer_10_flush_cache(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("_flush_cache (wrapper)", 0);
  __pyx_r = __pyx_pf_5spacy_9tokenizer_9Tokenizer_9_flush_cache(((struct __pyx_obj_5spacy_9tokenizer_Tokenizer *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5spacy_9tokenizer_9Tokenizer_9_flush_cache(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *__pyx_v_self) {
  PyObject *__pyx_v_key = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  Py_ssize_t __pyx_t_5;
  PyObject *(*__pyx_t_6)(PyObject *);
  PyObject *__pyx_t_7 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("_flush_cache", 0);

  /* "spacy/tokenizer.pyx":224
 * 
 *     def _flush_cache(self):
 *         self._reset_cache([key for key in self._cache])             # <<<<<<<<<<<<<<
 * 
 *     def _reset_cache(self, keys):
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_reset_cache); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 224, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = PyList_New(0); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 224, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  if (likely(PyList_CheckExact(((PyObject *)__pyx_v_self->_cache))) || PyTuple_CheckExact(((PyObject *)__pyx_v_self->_cache))) {
    __pyx_t_4 = ((PyObject *)__pyx_v_self->_cache); __Pyx_INCREF(__pyx_t_4); __pyx_t_5 = 0;
    __pyx_t_6 = NULL;
  } else {
    __pyx_t_5 = -1; __pyx_t_4 = PyObject_GetIter(((PyObject *)__pyx_v_self->_cache)); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 224, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_6 = Py_TYPE(__pyx_t_4)->tp_iternext; if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 224, __pyx_L1_error)
  }
  for (;;) {
    if (likely(!__pyx_t_6)) {
      if (likely(PyList_CheckExact(__pyx_t_4))) {
        if (__pyx_t_5 >= PyList_GET_SIZE(__pyx_t_4)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_7 = PyList_GET_ITEM(__pyx_t_4, __pyx_t_5); __Pyx_INCREF(__pyx_t_7); __pyx_t_5++; if (unlikely(0 < 0)) __PYX_ERR(0, 224, __pyx_L1_error)
        #else
        __pyx_t_7 = PySequence_ITEM(__pyx_t_4, __pyx_t_5); __pyx_t_5++; if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 224, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_7);
        #endif
      } else {
        if (__pyx_t_5 >= PyTuple_GET_SIZE(__pyx_t_4)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_7 = PyTuple_GET_ITEM(__pyx_t_4, __pyx_t_5); __Pyx_INCREF(__pyx_t_7); __pyx_t_5++; if (unlikely(0 < 0)) __PYX_ERR(0, 224, __pyx_L1_error)
        #else
        __pyx_t_7 = PySequence_ITEM(__pyx_t_4, __pyx_t_5); __pyx_t_5++; if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 224, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_7);
        #endif
      }
    } else {
      __pyx_t_7 = __pyx_t_6(__pyx_t_4);
      if (unlikely(!__pyx_t_7)) {
        PyObject* exc_type = PyErr_Occurred();
        if (exc_type) {
          if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
          else __PYX_ERR(0, 224, __pyx_L1_error)
        }
        break;
      }
      __Pyx_GOTREF(__pyx_t_7);
    }
    __Pyx_XDECREF_SET(__pyx_v_key, __pyx_t_7);
    __pyx_t_7 = 0;
    if (unlikely(__Pyx_ListComp_Append(__pyx_t_3, (PyObject*)__pyx_v_key))) __PYX_ERR(0, 224, __pyx_L1_error)
  }
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_4 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_4)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_4);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
    }
  }
  __pyx_t_1 = (__pyx_t_4) ? __Pyx_PyObject_Call2Args(__pyx_t_2, __pyx_t_4, __pyx_t_3) : __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 224, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "spacy/tokenizer.pyx":223
 *             yield self(text)
 * 
 *     def _flush_cache(self):             # <<<<<<<<<<<<<<
 *         self._reset_cache([key for key in self._cache])
 * 
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_AddTraceback("spacy.tokenizer.Tokenizer._flush_cache", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_key);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "spacy/tokenizer.pyx":226
 *         self._reset_cache([key for key in self._cache])
 * 
 *     def _reset_cache(self, keys):             # <<<<<<<<<<<<<<
 *         for k in keys:
 *             cached = <_Cached*>self._cache.get(k)
 */

/* Python wrapper */
static PyObject *__pyx_pw_5spacy_9tokenizer_9Tokenizer_12_reset_cache(PyObject *__pyx_v_self, PyObject *__pyx_v_keys); /*proto*/
static char __pyx_doc_5spacy_9tokenizer_9Tokenizer_11_reset_cache[] = "Tokenizer._reset_cache(self, keys)";
static PyMethodDef __pyx_mdef_5spacy_9tokenizer_9Tokenizer_12_reset_cache = {"_reset_cache", (PyCFunction)__pyx_pw_5spacy_9tokenizer_9Tokenizer_12_reset_cache, METH_O, __pyx_doc_5spacy_9tokenizer_9Tokenizer_11_reset_cache};
static PyObject *__pyx_pw_5spacy_9tokenizer_9Tokenizer_12_reset_cache(PyObject *__pyx_v_self, PyObject *__pyx_v_keys) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("_reset_cache (wrapper)", 0);
  __pyx_r = __pyx_pf_5spacy_9tokenizer_9Tokenizer_11_reset_cache(((struct __pyx_obj_5spacy_9tokenizer_Tokenizer *)__pyx_v_self), ((PyObject *)__pyx_v_keys));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5spacy_9tokenizer_9Tokenizer_11_reset_cache(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *__pyx_v_self, PyObject *__pyx_v_keys) {
  PyObject *__pyx_v_k = NULL;
  struct __pyx_t_5spacy_5vocab__Cached *__pyx_v_cached;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  Py_ssize_t __pyx_t_2;
  PyObject *(*__pyx_t_3)(PyObject *);
  PyObject *__pyx_t_4 = NULL;
  __pyx_t_7preshed_4maps_key_t __pyx_t_5;
  int __pyx_t_6;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("_reset_cache", 0);

  /* "spacy/tokenizer.pyx":227
 * 
 *     def _reset_cache(self, keys):
 *         for k in keys:             # <<<<<<<<<<<<<<
 *             cached = <_Cached*>self._cache.get(k)
 *             del self._cache[k]
 */
  if (likely(PyList_CheckExact(__pyx_v_keys)) || PyTuple_CheckExact(__pyx_v_keys)) {
    __pyx_t_1 = __pyx_v_keys; __Pyx_INCREF(__pyx_t_1); __pyx_t_2 = 0;
    __pyx_t_3 = NULL;
  } else {
    __pyx_t_2 = -1; __pyx_t_1 = PyObject_GetIter(__pyx_v_keys); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 227, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_3 = Py_TYPE(__pyx_t_1)->tp_iternext; if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 227, __pyx_L1_error)
  }
  for (;;) {
    if (likely(!__pyx_t_3)) {
      if (likely(PyList_CheckExact(__pyx_t_1))) {
        if (__pyx_t_2 >= PyList_GET_SIZE(__pyx_t_1)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_4 = PyList_GET_ITEM(__pyx_t_1, __pyx_t_2); __Pyx_INCREF(__pyx_t_4); __pyx_t_2++; if (unlikely(0 < 0)) __PYX_ERR(0, 227, __pyx_L1_error)
        #else
        __pyx_t_4 = PySequence_ITEM(__pyx_t_1, __pyx_t_2); __pyx_t_2++; if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 227, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_4);
        #endif
      } else {
        if (__pyx_t_2 >= PyTuple_GET_SIZE(__pyx_t_1)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_4 = PyTuple_GET_ITEM(__pyx_t_1, __pyx_t_2); __Pyx_INCREF(__pyx_t_4); __pyx_t_2++; if (unlikely(0 < 0)) __PYX_ERR(0, 227, __pyx_L1_error)
        #else
        __pyx_t_4 = PySequence_ITEM(__pyx_t_1, __pyx_t_2); __pyx_t_2++; if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 227, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_4);
        #endif
      }
    } else {
      __pyx_t_4 = __pyx_t_3(__pyx_t_1);
      if (unlikely(!__pyx_t_4)) {
        PyObject* exc_type = PyErr_Occurred();
        if (exc_type) {
          if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
          else __PYX_ERR(0, 227, __pyx_L1_error)
        }
        break;
      }
      __Pyx_GOTREF(__pyx_t_4);
    }
    __Pyx_XDECREF_SET(__pyx_v_k, __pyx_t_4);
    __pyx_t_4 = 0;

    /* "spacy/tokenizer.pyx":228
 *     def _reset_cache(self, keys):
 *         for k in keys:
 *             cached = <_Cached*>self._cache.get(k)             # <<<<<<<<<<<<<<
 *             del self._cache[k]
 *             if cached is not NULL:
 */
    __pyx_t_5 = __Pyx_PyInt_As_uint64_t(__pyx_v_k); if (unlikely((__pyx_t_5 == ((uint64_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 228, __pyx_L1_error)
    __pyx_v_cached = ((struct __pyx_t_5spacy_5vocab__Cached *)((struct __pyx_vtabstruct_7preshed_4maps_PreshMap *)__pyx_v_self->_cache->__pyx_vtab)->get(__pyx_v_self->_cache, __pyx_t_5));

    /* "spacy/tokenizer.pyx":229
 *         for k in keys:
 *             cached = <_Cached*>self._cache.get(k)
 *             del self._cache[k]             # <<<<<<<<<<<<<<
 *             if cached is not NULL:
 *                 self.mem.free(cached)
 */
    if (unlikely(PyObject_DelItem(((PyObject *)__pyx_v_self->_cache), __pyx_v_k) < 0)) __PYX_ERR(0, 229, __pyx_L1_error)

    /* "spacy/tokenizer.pyx":230
 *             cached = <_Cached*>self._cache.get(k)
 *             del self._cache[k]
 *             if cached is not NULL:             # <<<<<<<<<<<<<<
 *                 self.mem.free(cached)
 * 
 */
    __pyx_t_6 = ((__pyx_v_cached != NULL) != 0);
    if (__pyx_t_6) {

      /* "spacy/tokenizer.pyx":231
 *             del self._cache[k]
 *             if cached is not NULL:
 *                 self.mem.free(cached)             # <<<<<<<<<<<<<<
 * 
 *     def _flush_specials(self):
 */
      ((struct __pyx_vtabstruct_5cymem_5cymem_Pool *)__pyx_v_self->mem->__pyx_vtab)->free(__pyx_v_self->mem, __pyx_v_cached); if (unlikely(PyErr_Occurred())) __PYX_ERR(0, 231, __pyx_L1_error)

      /* "spacy/tokenizer.pyx":230
 *             cached = <_Cached*>self._cache.get(k)
 *             del self._cache[k]
 *             if cached is not NULL:             # <<<<<<<<<<<<<<
 *                 self.mem.free(cached)
 * 
 */
    }

    /* "spacy/tokenizer.pyx":227
 * 
 *     def _reset_cache(self, keys):
 *         for k in keys:             # <<<<<<<<<<<<<<
 *             cached = <_Cached*>self._cache.get(k)
 *             del self._cache[k]
 */
  }
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "spacy/tokenizer.pyx":226
 *         self._reset_cache([key for key in self._cache])
 * 
 *     def _reset_cache(self, keys):             # <<<<<<<<<<<<<<
 *         for k in keys:
 *             cached = <_Cached*>self._cache.get(k)
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_AddTraceback("spacy.tokenizer.Tokenizer._reset_cache", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_k);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "spacy/tokenizer.pyx":233
 *                 self.mem.free(cached)
 * 
 *     def _flush_specials(self):             # <<<<<<<<<<<<<<
 *         self._special_matcher = PhraseMatcher(self.vocab)
 *         for k in self._specials:
 */

/* Python wrapper */
static PyObject *__pyx_pw_5spacy_9tokenizer_9Tokenizer_14_flush_specials(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static char __pyx_doc_5spacy_9tokenizer_9Tokenizer_13_flush_specials[] = "Tokenizer._flush_specials(self)";
static PyMethodDef __pyx_mdef_5spacy_9tokenizer_9Tokenizer_14_flush_specials = {"_flush_specials", (PyCFunction)__pyx_pw_5spacy_9tokenizer_9Tokenizer_14_flush_specials, METH_NOARGS, __pyx_doc_5spacy_9tokenizer_9Tokenizer_13_flush_specials};
static PyObject *__pyx_pw_5spacy_9tokenizer_9Tokenizer_14_flush_specials(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("_flush_specials (wrapper)", 0);
  __pyx_r = __pyx_pf_5spacy_9tokenizer_9Tokenizer_13_flush_specials(((struct __pyx_obj_5spacy_9tokenizer_Tokenizer *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5spacy_9tokenizer_9Tokenizer_13_flush_specials(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *__pyx_v_self) {
  PyObject *__pyx_v_k = NULL;
  struct __pyx_t_5spacy_5vocab__Cached *__pyx_v_cached;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  Py_ssize_t __pyx_t_2;
  PyObject *(*__pyx_t_3)(PyObject *);
  PyObject *__pyx_t_4 = NULL;
  __pyx_t_7preshed_4maps_key_t __pyx_t_5;
  int __pyx_t_6;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("_flush_specials", 0);

  /* "spacy/tokenizer.pyx":234
 * 
 *     def _flush_specials(self):
 *         self._special_matcher = PhraseMatcher(self.vocab)             # <<<<<<<<<<<<<<
 *         for k in self._specials:
 *             cached = <_Cached*>self._specials.get(k)
 */
  __pyx_t_1 = __Pyx_PyObject_CallOneArg(((PyObject *)__pyx_ptype_5spacy_7matcher_13phrasematcher_PhraseMatcher), ((PyObject *)__pyx_v_self->vocab)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 234, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_GIVEREF(__pyx_t_1);
  __Pyx_GOTREF(__pyx_v_self->_special_matcher);
  __Pyx_DECREF(((PyObject *)__pyx_v_self->_special_matcher));
  __pyx_v_self->_special_matcher = ((struct __pyx_obj_5spacy_7matcher_13phrasematcher_PhraseMatcher *)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "spacy/tokenizer.pyx":235
 *     def _flush_specials(self):
 *         self._special_matcher = PhraseMatcher(self.vocab)
 *         for k in self._specials:             # <<<<<<<<<<<<<<
 *             cached = <_Cached*>self._specials.get(k)
 *             del self._specials[k]
 */
  if (likely(PyList_CheckExact(((PyObject *)__pyx_v_self->_specials))) || PyTuple_CheckExact(((PyObject *)__pyx_v_self->_specials))) {
    __pyx_t_1 = ((PyObject *)__pyx_v_self->_specials); __Pyx_INCREF(__pyx_t_1); __pyx_t_2 = 0;
    __pyx_t_3 = NULL;
  } else {
    __pyx_t_2 = -1; __pyx_t_1 = PyObject_GetIter(((PyObject *)__pyx_v_self->_specials)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 235, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_3 = Py_TYPE(__pyx_t_1)->tp_iternext; if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 235, __pyx_L1_error)
  }
  for (;;) {
    if (likely(!__pyx_t_3)) {
      if (likely(PyList_CheckExact(__pyx_t_1))) {
        if (__pyx_t_2 >= PyList_GET_SIZE(__pyx_t_1)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_4 = PyList_GET_ITEM(__pyx_t_1, __pyx_t_2); __Pyx_INCREF(__pyx_t_4); __pyx_t_2++; if (unlikely(0 < 0)) __PYX_ERR(0, 235, __pyx_L1_error)
        #else
        __pyx_t_4 = PySequence_ITEM(__pyx_t_1, __pyx_t_2); __pyx_t_2++; if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 235, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_4);
        #endif
      } else {
        if (__pyx_t_2 >= PyTuple_GET_SIZE(__pyx_t_1)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_4 = PyTuple_GET_ITEM(__pyx_t_1, __pyx_t_2); __Pyx_INCREF(__pyx_t_4); __pyx_t_2++; if (unlikely(0 < 0)) __PYX_ERR(0, 235, __pyx_L1_error)
        #else
        __pyx_t_4 = PySequence_ITEM(__pyx_t_1, __pyx_t_2); __pyx_t_2++; if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 235, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_4);
        #endif
      }
    } else {
      __pyx_t_4 = __pyx_t_3(__pyx_t_1);
      if (unlikely(!__pyx_t_4)) {
        PyObject* exc_type = PyErr_Occurred();
        if (exc_type) {
          if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
          else __PYX_ERR(0, 235, __pyx_L1_error)
        }
        break;
      }
      __Pyx_GOTREF(__pyx_t_4);
    }
    __Pyx_XDECREF_SET(__pyx_v_k, __pyx_t_4);
    __pyx_t_4 = 0;

    /* "spacy/tokenizer.pyx":236
 *         self._special_matcher = PhraseMatcher(self.vocab)
 *         for k in self._specials:
 *             cached = <_Cached*>self._specials.get(k)             # <<<<<<<<<<<<<<
 *             del self._specials[k]
 *             if cached is not NULL:
 */
    __pyx_t_5 = __Pyx_PyInt_As_uint64_t(__pyx_v_k); if (unlikely((__pyx_t_5 == ((uint64_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 236, __pyx_L1_error)
    __pyx_v_cached = ((struct __pyx_t_5spacy_5vocab__Cached *)((struct __pyx_vtabstruct_7preshed_4maps_PreshMap *)__pyx_v_self->_specials->__pyx_vtab)->get(__pyx_v_self->_specials, __pyx_t_5));

    /* "spacy/tokenizer.pyx":237
 *         for k in self._specials:
 *             cached = <_Cached*>self._specials.get(k)
 *             del self._specials[k]             # <<<<<<<<<<<<<<
 *             if cached is not NULL:
 *                 self.mem.free(cached)
 */
    if (unlikely(PyObject_DelItem(((PyObject *)__pyx_v_self->_specials), __pyx_v_k) < 0)) __PYX_ERR(0, 237, __pyx_L1_error)

    /* "spacy/tokenizer.pyx":238
 *             cached = <_Cached*>self._specials.get(k)
 *             del self._specials[k]
 *             if cached is not NULL:             # <<<<<<<<<<<<<<
 *                 self.mem.free(cached)
 * 
 */
    __pyx_t_6 = ((__pyx_v_cached != NULL) != 0);
    if (__pyx_t_6) {

      /* "spacy/tokenizer.pyx":239
 *             del self._specials[k]
 *             if cached is not NULL:
 *                 self.mem.free(cached)             # <<<<<<<<<<<<<<
 * 
 *     cdef int _apply_special_cases(self, Doc doc) except -1:
 */
      ((struct __pyx_vtabstruct_5cymem_5cymem_Pool *)__pyx_v_self->mem->__pyx_vtab)->free(__pyx_v_self->mem, __pyx_v_cached); if (unlikely(PyErr_Occurred())) __PYX_ERR(0, 239, __pyx_L1_error)

      /* "spacy/tokenizer.pyx":238
 *             cached = <_Cached*>self._specials.get(k)
 *             del self._specials[k]
 *             if cached is not NULL:             # <<<<<<<<<<<<<<
 *                 self.mem.free(cached)
 * 
 */
    }

    /* "spacy/tokenizer.pyx":235
 *     def _flush_specials(self):
 *         self._special_matcher = PhraseMatcher(self.vocab)
 *         for k in self._specials:             # <<<<<<<<<<<<<<
 *             cached = <_Cached*>self._specials.get(k)
 *             del self._specials[k]
 */
  }
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "spacy/tokenizer.pyx":233
 *                 self.mem.free(cached)
 * 
 *     def _flush_specials(self):             # <<<<<<<<<<<<<<
 *         self._special_matcher = PhraseMatcher(self.vocab)
 *         for k in self._specials:
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_AddTraceback("spacy.tokenizer.Tokenizer._flush_specials", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_k);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "spacy/tokenizer.pyx":241
 *                 self.mem.free(cached)
 * 
 *     cdef int _apply_special_cases(self, Doc doc) except -1:             # <<<<<<<<<<<<<<
 *         """Retokenize doc according to special cases.
 * 
 */

static int __pyx_f_5spacy_9tokenizer_9Tokenizer__apply_special_cases(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *__pyx_v_self, struct __pyx_obj_5spacy_6tokens_3doc_Doc *__pyx_v_doc) {
  int __pyx_v_i;
  int __pyx_v_max_length;
  int __pyx_v_modify_in_place;
  struct __pyx_obj_5cymem_5cymem_Pool *__pyx_v_mem = 0;
  std::vector<struct __pyx_t_5spacy_7structs_SpanC>  __pyx_v_c_matches;
  std::vector<struct __pyx_t_5spacy_7structs_SpanC>  __pyx_v_c_filtered;
  int __pyx_v_offset;
  int __pyx_v_modified_doc_length;
  PyObject *__pyx_v_span_data = NULL;
  struct __pyx_t_5spacy_7structs_TokenC *__pyx_v_tokens;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_t_2;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  PyObject *(*__pyx_t_7)(PyObject *);
  int __pyx_t_8;
  struct __pyx_t_5spacy_7structs_TokenC *__pyx_t_9;
  void *__pyx_t_10;
  int __pyx_t_11;
  int __pyx_t_12;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("_apply_special_cases", 0);

  /* "spacy/tokenizer.pyx":247
 *         """
 *         cdef int i
 *         cdef int max_length = 0             # <<<<<<<<<<<<<<
 *         cdef bint modify_in_place
 *         cdef Pool mem = Pool()
 */
  __pyx_v_max_length = 0;

  /* "spacy/tokenizer.pyx":249
 *         cdef int max_length = 0
 *         cdef bint modify_in_place
 *         cdef Pool mem = Pool()             # <<<<<<<<<<<<<<
 *         cdef vector[SpanC] c_matches
 *         cdef vector[SpanC] c_filtered
 */
  __pyx_t_1 = __Pyx_PyObject_CallNoArg(((PyObject *)__pyx_ptype_5cymem_5cymem_Pool)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 249, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_v_mem = ((struct __pyx_obj_5cymem_5cymem_Pool *)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "spacy/tokenizer.pyx":255
 *         cdef int modified_doc_length
 *         # Find matches for special cases
 *         self._special_matcher.find_matches(doc, 0, doc.length, &c_matches)             # <<<<<<<<<<<<<<
 *         # Skip processing if no matches
 *         if c_matches.size() == 0:
 */
  ((struct __pyx_vtabstruct_5spacy_7matcher_13phrasematcher_PhraseMatcher *)__pyx_v_self->_special_matcher->__pyx_vtab)->find_matches(__pyx_v_self->_special_matcher, __pyx_v_doc, 0, __pyx_v_doc->length, (&__pyx_v_c_matches));

  /* "spacy/tokenizer.pyx":257
 *         self._special_matcher.find_matches(doc, 0, doc.length, &c_matches)
 *         # Skip processing if no matches
 *         if c_matches.size() == 0:             # <<<<<<<<<<<<<<
 *             return True
 *         self._filter_special_spans(c_matches, c_filtered, doc.length)
 */
  __pyx_t_2 = ((__pyx_v_c_matches.size() == 0) != 0);
  if (__pyx_t_2) {

    /* "spacy/tokenizer.pyx":258
 *         # Skip processing if no matches
 *         if c_matches.size() == 0:
 *             return True             # <<<<<<<<<<<<<<
 *         self._filter_special_spans(c_matches, c_filtered, doc.length)
 *         # Put span info in span.start-indexed dict and calculate maximum
 */
    __pyx_r = 1;
    goto __pyx_L0;

    /* "spacy/tokenizer.pyx":257
 *         self._special_matcher.find_matches(doc, 0, doc.length, &c_matches)
 *         # Skip processing if no matches
 *         if c_matches.size() == 0:             # <<<<<<<<<<<<<<
 *             return True
 *         self._filter_special_spans(c_matches, c_filtered, doc.length)
 */
  }

  /* "spacy/tokenizer.pyx":259
 *         if c_matches.size() == 0:
 *             return True
 *         self._filter_special_spans(c_matches, c_filtered, doc.length)             # <<<<<<<<<<<<<<
 *         # Put span info in span.start-indexed dict and calculate maximum
 *         # intermediate document size
 */
  ((struct __pyx_vtabstruct_5spacy_9tokenizer_Tokenizer *)__pyx_v_self->__pyx_vtab)->_filter_special_spans(__pyx_v_self, __pyx_v_c_matches, __pyx_v_c_filtered, __pyx_v_doc->length);

  /* "spacy/tokenizer.pyx":262
 *         # Put span info in span.start-indexed dict and calculate maximum
 *         # intermediate document size
 *         (span_data, max_length, modify_in_place) = self._prepare_special_spans(doc, c_filtered)             # <<<<<<<<<<<<<<
 *         # If modifications never increase doc length, can modify in place
 *         if modify_in_place:
 */
  __pyx_t_1 = ((struct __pyx_vtabstruct_5spacy_9tokenizer_Tokenizer *)__pyx_v_self->__pyx_vtab)->_prepare_special_spans(__pyx_v_self, __pyx_v_doc, __pyx_v_c_filtered); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 262, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if ((likely(PyTuple_CheckExact(__pyx_t_1))) || (PyList_CheckExact(__pyx_t_1))) {
    PyObject* sequence = __pyx_t_1;
    Py_ssize_t size = __Pyx_PySequence_SIZE(sequence);
    if (unlikely(size != 3)) {
      if (size > 3) __Pyx_RaiseTooManyValuesError(3);
      else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
      __PYX_ERR(0, 262, __pyx_L1_error)
    }
    #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
    if (likely(PyTuple_CheckExact(sequence))) {
      __pyx_t_3 = PyTuple_GET_ITEM(sequence, 0); 
      __pyx_t_4 = PyTuple_GET_ITEM(sequence, 1); 
      __pyx_t_5 = PyTuple_GET_ITEM(sequence, 2); 
    } else {
      __pyx_t_3 = PyList_GET_ITEM(sequence, 0); 
      __pyx_t_4 = PyList_GET_ITEM(sequence, 1); 
      __pyx_t_5 = PyList_GET_ITEM(sequence, 2); 
    }
    __Pyx_INCREF(__pyx_t_3);
    __Pyx_INCREF(__pyx_t_4);
    __Pyx_INCREF(__pyx_t_5);
    #else
    __pyx_t_3 = PySequence_ITEM(sequence, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 262, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_4 = PySequence_ITEM(sequence, 1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 262, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_5 = PySequence_ITEM(sequence, 2); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 262, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    #endif
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  } else {
    Py_ssize_t index = -1;
    __pyx_t_6 = PyObject_GetIter(__pyx_t_1); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 262, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_7 = Py_TYPE(__pyx_t_6)->tp_iternext;
    index = 0; __pyx_t_3 = __pyx_t_7(__pyx_t_6); if (unlikely(!__pyx_t_3)) goto __pyx_L4_unpacking_failed;
    __Pyx_GOTREF(__pyx_t_3);
    index = 1; __pyx_t_4 = __pyx_t_7(__pyx_t_6); if (unlikely(!__pyx_t_4)) goto __pyx_L4_unpacking_failed;
    __Pyx_GOTREF(__pyx_t_4);
    index = 2; __pyx_t_5 = __pyx_t_7(__pyx_t_6); if (unlikely(!__pyx_t_5)) goto __pyx_L4_unpacking_failed;
    __Pyx_GOTREF(__pyx_t_5);
    if (__Pyx_IternextUnpackEndCheck(__pyx_t_7(__pyx_t_6), 3) < 0) __PYX_ERR(0, 262, __pyx_L1_error)
    __pyx_t_7 = NULL;
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    goto __pyx_L5_unpacking_done;
    __pyx_L4_unpacking_failed:;
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __pyx_t_7 = NULL;
    if (__Pyx_IterFinish() == 0) __Pyx_RaiseNeedMoreValuesError(index);
    __PYX_ERR(0, 262, __pyx_L1_error)
    __pyx_L5_unpacking_done:;
  }
  __pyx_t_8 = __Pyx_PyInt_As_int(__pyx_t_4); if (unlikely((__pyx_t_8 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 262, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_2 = __Pyx_PyObject_IsTrue(__pyx_t_5); if (unlikely((__pyx_t_2 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 262, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_v_span_data = __pyx_t_3;
  __pyx_t_3 = 0;
  __pyx_v_max_length = __pyx_t_8;
  __pyx_v_modify_in_place = __pyx_t_2;

  /* "spacy/tokenizer.pyx":264
 *         (span_data, max_length, modify_in_place) = self._prepare_special_spans(doc, c_filtered)
 *         # If modifications never increase doc length, can modify in place
 *         if modify_in_place:             # <<<<<<<<<<<<<<
 *             tokens = doc.c
 *         # Otherwise create a separate array to store modified tokens
 */
  __pyx_t_2 = (__pyx_v_modify_in_place != 0);
  if (__pyx_t_2) {

    /* "spacy/tokenizer.pyx":265
 *         # If modifications never increase doc length, can modify in place
 *         if modify_in_place:
 *             tokens = doc.c             # <<<<<<<<<<<<<<
 *         # Otherwise create a separate array to store modified tokens
 *         else:
 */
    __pyx_t_9 = __pyx_v_doc->c;
    __pyx_v_tokens = __pyx_t_9;

    /* "spacy/tokenizer.pyx":264
 *         (span_data, max_length, modify_in_place) = self._prepare_special_spans(doc, c_filtered)
 *         # If modifications never increase doc length, can modify in place
 *         if modify_in_place:             # <<<<<<<<<<<<<<
 *             tokens = doc.c
 *         # Otherwise create a separate array to store modified tokens
 */
    goto __pyx_L6;
  }

  /* "spacy/tokenizer.pyx":268
 *         # Otherwise create a separate array to store modified tokens
 *         else:
 *             assert max_length > 0             # <<<<<<<<<<<<<<
 *             tokens = <TokenC*>mem.alloc(max_length, sizeof(TokenC))
 *         # Modify tokenization according to filtered special cases
 */
  /*else*/ {
    #ifndef CYTHON_WITHOUT_ASSERTIONS
    if (unlikely(__pyx_assertions_enabled())) {
      if (unlikely(!((__pyx_v_max_length > 0) != 0))) {
        PyErr_SetNone(PyExc_AssertionError);
        __PYX_ERR(0, 268, __pyx_L1_error)
      }
    }
    #endif

    /* "spacy/tokenizer.pyx":269
 *         else:
 *             assert max_length > 0
 *             tokens = <TokenC*>mem.alloc(max_length, sizeof(TokenC))             # <<<<<<<<<<<<<<
 *         # Modify tokenization according to filtered special cases
 *         offset = self._retokenize_special_spans(doc, tokens, span_data)
 */
    __pyx_t_10 = ((struct __pyx_vtabstruct_5cymem_5cymem_Pool *)__pyx_v_mem->__pyx_vtab)->alloc(__pyx_v_mem, __pyx_v_max_length, (sizeof(struct __pyx_t_5spacy_7structs_TokenC))); if (unlikely(__pyx_t_10 == ((void *)NULL))) __PYX_ERR(0, 269, __pyx_L1_error)
    __pyx_v_tokens = ((struct __pyx_t_5spacy_7structs_TokenC *)__pyx_t_10);
  }
  __pyx_L6:;

  /* "spacy/tokenizer.pyx":271
 *             tokens = <TokenC*>mem.alloc(max_length, sizeof(TokenC))
 *         # Modify tokenization according to filtered special cases
 *         offset = self._retokenize_special_spans(doc, tokens, span_data)             # <<<<<<<<<<<<<<
 *         # Allocate more memory for doc if needed
 *         modified_doc_length = doc.length + offset
 */
  __pyx_v_offset = ((struct __pyx_vtabstruct_5spacy_9tokenizer_Tokenizer *)__pyx_v_self->__pyx_vtab)->_retokenize_special_spans(__pyx_v_self, __pyx_v_doc, __pyx_v_tokens, __pyx_v_span_data);

  /* "spacy/tokenizer.pyx":273
 *         offset = self._retokenize_special_spans(doc, tokens, span_data)
 *         # Allocate more memory for doc if needed
 *         modified_doc_length = doc.length + offset             # <<<<<<<<<<<<<<
 *         while modified_doc_length >= doc.max_length:
 *             doc._realloc(doc.max_length * 2)
 */
  __pyx_v_modified_doc_length = (__pyx_v_doc->length + __pyx_v_offset);

  /* "spacy/tokenizer.pyx":274
 *         # Allocate more memory for doc if needed
 *         modified_doc_length = doc.length + offset
 *         while modified_doc_length >= doc.max_length:             # <<<<<<<<<<<<<<
 *             doc._realloc(doc.max_length * 2)
 *         # If not modified in place, copy tokens back to doc
 */
  while (1) {
    __pyx_t_2 = ((__pyx_v_modified_doc_length >= __pyx_v_doc->max_length) != 0);
    if (!__pyx_t_2) break;

    /* "spacy/tokenizer.pyx":275
 *         modified_doc_length = doc.length + offset
 *         while modified_doc_length >= doc.max_length:
 *             doc._realloc(doc.max_length * 2)             # <<<<<<<<<<<<<<
 *         # If not modified in place, copy tokens back to doc
 *         if not modify_in_place:
 */
    __pyx_t_5 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_doc), __pyx_n_s_realloc); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 275, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_4 = __Pyx_PyInt_From_long((__pyx_v_doc->max_length * 2)); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 275, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_3 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_5))) {
      __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_5);
      if (likely(__pyx_t_3)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
        __Pyx_INCREF(__pyx_t_3);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_5, function);
      }
    }
    __pyx_t_1 = (__pyx_t_3) ? __Pyx_PyObject_Call2Args(__pyx_t_5, __pyx_t_3, __pyx_t_4) : __Pyx_PyObject_CallOneArg(__pyx_t_5, __pyx_t_4);
    __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 275, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  }

  /* "spacy/tokenizer.pyx":277
 *             doc._realloc(doc.max_length * 2)
 *         # If not modified in place, copy tokens back to doc
 *         if not modify_in_place:             # <<<<<<<<<<<<<<
 *             memcpy(doc.c, tokens, max_length * sizeof(TokenC))
 *         for i in range(doc.length + offset, doc.length):
 */
  __pyx_t_2 = ((!(__pyx_v_modify_in_place != 0)) != 0);
  if (__pyx_t_2) {

    /* "spacy/tokenizer.pyx":278
 *         # If not modified in place, copy tokens back to doc
 *         if not modify_in_place:
 *             memcpy(doc.c, tokens, max_length * sizeof(TokenC))             # <<<<<<<<<<<<<<
 *         for i in range(doc.length + offset, doc.length):
 *             memset(&doc.c[i], 0, sizeof(TokenC))
 */
    (void)(memcpy(__pyx_v_doc->c, __pyx_v_tokens, (__pyx_v_max_length * (sizeof(struct __pyx_t_5spacy_7structs_TokenC)))));

    /* "spacy/tokenizer.pyx":277
 *             doc._realloc(doc.max_length * 2)
 *         # If not modified in place, copy tokens back to doc
 *         if not modify_in_place:             # <<<<<<<<<<<<<<
 *             memcpy(doc.c, tokens, max_length * sizeof(TokenC))
 *         for i in range(doc.length + offset, doc.length):
 */
  }

  /* "spacy/tokenizer.pyx":279
 *         if not modify_in_place:
 *             memcpy(doc.c, tokens, max_length * sizeof(TokenC))
 *         for i in range(doc.length + offset, doc.length):             # <<<<<<<<<<<<<<
 *             memset(&doc.c[i], 0, sizeof(TokenC))
 *             doc.c[i].lex = &EMPTY_LEXEME
 */
  __pyx_t_8 = __pyx_v_doc->length;
  __pyx_t_11 = __pyx_t_8;
  for (__pyx_t_12 = (__pyx_v_doc->length + __pyx_v_offset); __pyx_t_12 < __pyx_t_11; __pyx_t_12+=1) {
    __pyx_v_i = __pyx_t_12;

    /* "spacy/tokenizer.pyx":280
 *             memcpy(doc.c, tokens, max_length * sizeof(TokenC))
 *         for i in range(doc.length + offset, doc.length):
 *             memset(&doc.c[i], 0, sizeof(TokenC))             # <<<<<<<<<<<<<<
 *             doc.c[i].lex = &EMPTY_LEXEME
 *         doc.length = doc.length + offset
 */
    (void)(memset((&(__pyx_v_doc->c[__pyx_v_i])), 0, (sizeof(struct __pyx_t_5spacy_7structs_TokenC))));

    /* "spacy/tokenizer.pyx":281
 *         for i in range(doc.length + offset, doc.length):
 *             memset(&doc.c[i], 0, sizeof(TokenC))
 *             doc.c[i].lex = &EMPTY_LEXEME             # <<<<<<<<<<<<<<
 *         doc.length = doc.length + offset
 *         return True
 */
    (__pyx_v_doc->c[__pyx_v_i]).lex = (&__pyx_v_5spacy_6lexeme_EMPTY_LEXEME);
  }

  /* "spacy/tokenizer.pyx":282
 *             memset(&doc.c[i], 0, sizeof(TokenC))
 *             doc.c[i].lex = &EMPTY_LEXEME
 *         doc.length = doc.length + offset             # <<<<<<<<<<<<<<
 *         return True
 * 
 */
  __pyx_v_doc->length = (__pyx_v_doc->length + __pyx_v_offset);

  /* "spacy/tokenizer.pyx":283
 *             doc.c[i].lex = &EMPTY_LEXEME
 *         doc.length = doc.length + offset
 *         return True             # <<<<<<<<<<<<<<
 * 
 *     cdef void _filter_special_spans(self, vector[SpanC] &original, vector[SpanC] &filtered, int doc_len) nogil:
 */
  __pyx_r = 1;
  goto __pyx_L0;

  /* "spacy/tokenizer.pyx":241
 *                 self.mem.free(cached)
 * 
 *     cdef int _apply_special_cases(self, Doc doc) except -1:             # <<<<<<<<<<<<<<
 *         """Retokenize doc according to special cases.
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_AddTraceback("spacy.tokenizer.Tokenizer._apply_special_cases", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_mem);
  __Pyx_XDECREF(__pyx_v_span_data);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "spacy/tokenizer.pyx":285
 *         return True
 * 
 *     cdef void _filter_special_spans(self, vector[SpanC] &original, vector[SpanC] &filtered, int doc_len) nogil:             # <<<<<<<<<<<<<<
 * 
 *         cdef int seen_i
 */

static void __pyx_f_5spacy_9tokenizer_9Tokenizer__filter_special_spans(CYTHON_UNUSED struct __pyx_obj_5spacy_9tokenizer_Tokenizer *__pyx_v_self, std::vector<struct __pyx_t_5spacy_7structs_SpanC>  &__pyx_v_original, std::vector<struct __pyx_t_5spacy_7structs_SpanC>  &__pyx_v_filtered, CYTHON_UNUSED int __pyx_v_doc_len) {
  int __pyx_v_seen_i;
  struct __pyx_t_5spacy_7structs_SpanC __pyx_v_span;
  std::set<int>  __pyx_v_seen_tokens;
  int __pyx_v_orig_i;
  int __pyx_t_1;
  int __pyx_t_2;
  int __pyx_t_3;
  int __pyx_t_4;
  int __pyx_t_5;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;

  /* "spacy/tokenizer.pyx":290
 *         cdef SpanC span
 *         cdef stdset[int] seen_tokens
 *         stdsort(original.begin(), original.end(), len_start_cmp)             # <<<<<<<<<<<<<<
 *         cdef int orig_i = original.size() - 1
 *         while orig_i >= 0:
 */
  sort(__pyx_v_original.begin(), __pyx_v_original.end(), __pyx_f_5spacy_9tokenizer_len_start_cmp);

  /* "spacy/tokenizer.pyx":291
 *         cdef stdset[int] seen_tokens
 *         stdsort(original.begin(), original.end(), len_start_cmp)
 *         cdef int orig_i = original.size() - 1             # <<<<<<<<<<<<<<
 *         while orig_i >= 0:
 *             span = original[orig_i]
 */
  __pyx_v_orig_i = (__pyx_v_original.size() - 1);

  /* "spacy/tokenizer.pyx":292
 *         stdsort(original.begin(), original.end(), len_start_cmp)
 *         cdef int orig_i = original.size() - 1
 *         while orig_i >= 0:             # <<<<<<<<<<<<<<
 *             span = original[orig_i]
 *             if not seen_tokens.count(span.start) and not seen_tokens.count(span.end - 1):
 */
  while (1) {
    __pyx_t_1 = ((__pyx_v_orig_i >= 0) != 0);
    if (!__pyx_t_1) break;

    /* "spacy/tokenizer.pyx":293
 *         cdef int orig_i = original.size() - 1
 *         while orig_i >= 0:
 *             span = original[orig_i]             # <<<<<<<<<<<<<<
 *             if not seen_tokens.count(span.start) and not seen_tokens.count(span.end - 1):
 *                 filtered.push_back(span)
 */
    __pyx_v_span = (__pyx_v_original[__pyx_v_orig_i]);

    /* "spacy/tokenizer.pyx":294
 *         while orig_i >= 0:
 *             span = original[orig_i]
 *             if not seen_tokens.count(span.start) and not seen_tokens.count(span.end - 1):             # <<<<<<<<<<<<<<
 *                 filtered.push_back(span)
 *             for seen_i in range(span.start, span.end):
 */
    __pyx_t_2 = ((!(__pyx_v_seen_tokens.count(__pyx_v_span.start) != 0)) != 0);
    if (__pyx_t_2) {
    } else {
      __pyx_t_1 = __pyx_t_2;
      goto __pyx_L6_bool_binop_done;
    }
    __pyx_t_2 = ((!(__pyx_v_seen_tokens.count((__pyx_v_span.end - 1)) != 0)) != 0);
    __pyx_t_1 = __pyx_t_2;
    __pyx_L6_bool_binop_done:;
    if (__pyx_t_1) {

      /* "spacy/tokenizer.pyx":295
 *             span = original[orig_i]
 *             if not seen_tokens.count(span.start) and not seen_tokens.count(span.end - 1):
 *                 filtered.push_back(span)             # <<<<<<<<<<<<<<
 *             for seen_i in range(span.start, span.end):
 *                 seen_tokens.insert(seen_i)
 */
      try {
        __pyx_v_filtered.push_back(__pyx_v_span);
      } catch(...) {
        #ifdef WITH_THREAD
        PyGILState_STATE __pyx_gilstate_save = __Pyx_PyGILState_Ensure();
        #endif
        __Pyx_CppExn2PyErr();
        #ifdef WITH_THREAD
        __Pyx_PyGILState_Release(__pyx_gilstate_save);
        #endif
        __PYX_ERR(0, 295, __pyx_L1_error)
      }

      /* "spacy/tokenizer.pyx":294
 *         while orig_i >= 0:
 *             span = original[orig_i]
 *             if not seen_tokens.count(span.start) and not seen_tokens.count(span.end - 1):             # <<<<<<<<<<<<<<
 *                 filtered.push_back(span)
 *             for seen_i in range(span.start, span.end):
 */
    }

    /* "spacy/tokenizer.pyx":296
 *             if not seen_tokens.count(span.start) and not seen_tokens.count(span.end - 1):
 *                 filtered.push_back(span)
 *             for seen_i in range(span.start, span.end):             # <<<<<<<<<<<<<<
 *                 seen_tokens.insert(seen_i)
 *             orig_i -= 1
 */
    __pyx_t_3 = __pyx_v_span.end;
    __pyx_t_4 = __pyx_t_3;
    for (__pyx_t_5 = __pyx_v_span.start; __pyx_t_5 < __pyx_t_4; __pyx_t_5+=1) {
      __pyx_v_seen_i = __pyx_t_5;

      /* "spacy/tokenizer.pyx":297
 *                 filtered.push_back(span)
 *             for seen_i in range(span.start, span.end):
 *                 seen_tokens.insert(seen_i)             # <<<<<<<<<<<<<<
 *             orig_i -= 1
 *         stdsort(filtered.begin(), filtered.end(), start_cmp)
 */
      try {
        __pyx_v_seen_tokens.insert(__pyx_v_seen_i);
      } catch(...) {
        #ifdef WITH_THREAD
        PyGILState_STATE __pyx_gilstate_save = __Pyx_PyGILState_Ensure();
        #endif
        __Pyx_CppExn2PyErr();
        #ifdef WITH_THREAD
        __Pyx_PyGILState_Release(__pyx_gilstate_save);
        #endif
        __PYX_ERR(0, 297, __pyx_L1_error)
      }
    }

    /* "spacy/tokenizer.pyx":298
 *             for seen_i in range(span.start, span.end):
 *                 seen_tokens.insert(seen_i)
 *             orig_i -= 1             # <<<<<<<<<<<<<<
 *         stdsort(filtered.begin(), filtered.end(), start_cmp)
 * 
 */
    __pyx_v_orig_i = (__pyx_v_orig_i - 1);
  }

  /* "spacy/tokenizer.pyx":299
 *                 seen_tokens.insert(seen_i)
 *             orig_i -= 1
 *         stdsort(filtered.begin(), filtered.end(), start_cmp)             # <<<<<<<<<<<<<<
 * 
 *     cdef object _prepare_special_spans(self, Doc doc, vector[SpanC] &filtered):
 */
  sort(__pyx_v_filtered.begin(), __pyx_v_filtered.end(), __pyx_f_5spacy_9tokenizer_start_cmp);

  /* "spacy/tokenizer.pyx":285
 *         return True
 * 
 *     cdef void _filter_special_spans(self, vector[SpanC] &original, vector[SpanC] &filtered, int doc_len) nogil:             # <<<<<<<<<<<<<<
 * 
 *         cdef int seen_i
 */

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_WriteUnraisable("spacy.tokenizer.Tokenizer._filter_special_spans", __pyx_clineno, __pyx_lineno, __pyx_filename, 1, 1);
  __pyx_L0:;
}

/* "spacy/tokenizer.pyx":301
 *         stdsort(filtered.begin(), filtered.end(), start_cmp)
 * 
 *     cdef object _prepare_special_spans(self, Doc doc, vector[SpanC] &filtered):             # <<<<<<<<<<<<<<
 *         spans = [doc[match.start:match.end] for match in filtered]
 *         cdef bint modify_in_place = True
 */

static PyObject *__pyx_f_5spacy_9tokenizer_9Tokenizer__prepare_special_spans(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *__pyx_v_self, struct __pyx_obj_5spacy_6tokens_3doc_Doc *__pyx_v_doc, std::vector<struct __pyx_t_5spacy_7structs_SpanC>  &__pyx_v_filtered) {
  PyObject *__pyx_v_spans = NULL;
  int __pyx_v_modify_in_place;
  int __pyx_v_curr_length;
  int __pyx_v_max_length;
  int __pyx_v_span_length_diff;
  PyObject *__pyx_v_span_data = NULL;
  PyObject *__pyx_v_span = NULL;
  PyObject *__pyx_v_rule = NULL;
  struct __pyx_t_5spacy_7structs_SpanC __pyx_v_match;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  std::vector<struct __pyx_t_5spacy_7structs_SpanC> ::iterator __pyx_t_2;
  struct __pyx_t_5spacy_7structs_SpanC __pyx_t_3;
  PyObject *__pyx_t_4 = NULL;
  int __pyx_t_5;
  Py_ssize_t __pyx_t_6;
  PyObject *__pyx_t_7 = NULL;
  PyObject *__pyx_t_8 = NULL;
  PyObject *__pyx_t_9 = NULL;
  PyObject *__pyx_t_10 = NULL;
  int __pyx_t_11;
  Py_ssize_t __pyx_t_12;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("_prepare_special_spans", 0);

  /* "spacy/tokenizer.pyx":302
 * 
 *     cdef object _prepare_special_spans(self, Doc doc, vector[SpanC] &filtered):
 *         spans = [doc[match.start:match.end] for match in filtered]             # <<<<<<<<<<<<<<
 *         cdef bint modify_in_place = True
 *         cdef int curr_length = doc.length
 */
  __pyx_t_1 = PyList_New(0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 302, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __pyx_v_filtered.begin();
  for (;;) {
    if (!(__pyx_t_2 != __pyx_v_filtered.end())) break;
    __pyx_t_3 = *__pyx_t_2;
    ++__pyx_t_2;
    __pyx_v_match = __pyx_t_3;
    __pyx_t_4 = __Pyx_PyObject_GetSlice(((PyObject *)__pyx_v_doc), __pyx_v_match.start, __pyx_v_match.end, NULL, NULL, NULL, 1, 1, 1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 302, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    if (unlikely(__Pyx_ListComp_Append(__pyx_t_1, (PyObject*)__pyx_t_4))) __PYX_ERR(0, 302, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  }
  __pyx_v_spans = ((PyObject*)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "spacy/tokenizer.pyx":303
 *     cdef object _prepare_special_spans(self, Doc doc, vector[SpanC] &filtered):
 *         spans = [doc[match.start:match.end] for match in filtered]
 *         cdef bint modify_in_place = True             # <<<<<<<<<<<<<<
 *         cdef int curr_length = doc.length
 *         cdef int max_length = 0
 */
  __pyx_v_modify_in_place = 1;

  /* "spacy/tokenizer.pyx":304
 *         spans = [doc[match.start:match.end] for match in filtered]
 *         cdef bint modify_in_place = True
 *         cdef int curr_length = doc.length             # <<<<<<<<<<<<<<
 *         cdef int max_length = 0
 *         cdef int span_length_diff = 0
 */
  __pyx_t_5 = __pyx_v_doc->length;
  __pyx_v_curr_length = __pyx_t_5;

  /* "spacy/tokenizer.pyx":305
 *         cdef bint modify_in_place = True
 *         cdef int curr_length = doc.length
 *         cdef int max_length = 0             # <<<<<<<<<<<<<<
 *         cdef int span_length_diff = 0
 *         span_data = {}
 */
  __pyx_v_max_length = 0;

  /* "spacy/tokenizer.pyx":306
 *         cdef int curr_length = doc.length
 *         cdef int max_length = 0
 *         cdef int span_length_diff = 0             # <<<<<<<<<<<<<<
 *         span_data = {}
 *         for span in spans:
 */
  __pyx_v_span_length_diff = 0;

  /* "spacy/tokenizer.pyx":307
 *         cdef int max_length = 0
 *         cdef int span_length_diff = 0
 *         span_data = {}             # <<<<<<<<<<<<<<
 *         for span in spans:
 *             rule = self._rules.get(span.text, None)
 */
  __pyx_t_1 = __Pyx_PyDict_NewPresized(0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 307, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_v_span_data = ((PyObject*)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "spacy/tokenizer.pyx":308
 *         cdef int span_length_diff = 0
 *         span_data = {}
 *         for span in spans:             # <<<<<<<<<<<<<<
 *             rule = self._rules.get(span.text, None)
 *             span_length_diff = 0
 */
  __pyx_t_1 = __pyx_v_spans; __Pyx_INCREF(__pyx_t_1); __pyx_t_6 = 0;
  for (;;) {
    if (__pyx_t_6 >= PyList_GET_SIZE(__pyx_t_1)) break;
    #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
    __pyx_t_4 = PyList_GET_ITEM(__pyx_t_1, __pyx_t_6); __Pyx_INCREF(__pyx_t_4); __pyx_t_6++; if (unlikely(0 < 0)) __PYX_ERR(0, 308, __pyx_L1_error)
    #else
    __pyx_t_4 = PySequence_ITEM(__pyx_t_1, __pyx_t_6); __pyx_t_6++; if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 308, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    #endif
    __Pyx_XDECREF_SET(__pyx_v_span, __pyx_t_4);
    __pyx_t_4 = 0;

    /* "spacy/tokenizer.pyx":309
 *         span_data = {}
 *         for span in spans:
 *             rule = self._rules.get(span.text, None)             # <<<<<<<<<<<<<<
 *             span_length_diff = 0
 *             if rule:
 */
    __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_v_self->_rules, __pyx_n_s_get); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 309, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_v_span, __pyx_n_s_text); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 309, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __pyx_t_9 = NULL;
    __pyx_t_5 = 0;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_7))) {
      __pyx_t_9 = PyMethod_GET_SELF(__pyx_t_7);
      if (likely(__pyx_t_9)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_7);
        __Pyx_INCREF(__pyx_t_9);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_7, function);
        __pyx_t_5 = 1;
      }
    }
    #if CYTHON_FAST_PYCALL
    if (PyFunction_Check(__pyx_t_7)) {
      PyObject *__pyx_temp[3] = {__pyx_t_9, __pyx_t_8, Py_None};
      __pyx_t_4 = __Pyx_PyFunction_FastCall(__pyx_t_7, __pyx_temp+1-__pyx_t_5, 2+__pyx_t_5); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 309, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_9); __pyx_t_9 = 0;
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    } else
    #endif
    #if CYTHON_FAST_PYCCALL
    if (__Pyx_PyFastCFunction_Check(__pyx_t_7)) {
      PyObject *__pyx_temp[3] = {__pyx_t_9, __pyx_t_8, Py_None};
      __pyx_t_4 = __Pyx_PyCFunction_FastCall(__pyx_t_7, __pyx_temp+1-__pyx_t_5, 2+__pyx_t_5); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 309, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_9); __pyx_t_9 = 0;
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    } else
    #endif
    {
      __pyx_t_10 = PyTuple_New(2+__pyx_t_5); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 309, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_10);
      if (__pyx_t_9) {
        __Pyx_GIVEREF(__pyx_t_9); PyTuple_SET_ITEM(__pyx_t_10, 0, __pyx_t_9); __pyx_t_9 = NULL;
      }
      __Pyx_GIVEREF(__pyx_t_8);
      PyTuple_SET_ITEM(__pyx_t_10, 0+__pyx_t_5, __pyx_t_8);
      __Pyx_INCREF(Py_None);
      __Pyx_GIVEREF(Py_None);
      PyTuple_SET_ITEM(__pyx_t_10, 1+__pyx_t_5, Py_None);
      __pyx_t_8 = 0;
      __pyx_t_4 = __Pyx_PyObject_Call(__pyx_t_7, __pyx_t_10, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 309, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
    }
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __Pyx_XDECREF_SET(__pyx_v_rule, __pyx_t_4);
    __pyx_t_4 = 0;

    /* "spacy/tokenizer.pyx":310
 *         for span in spans:
 *             rule = self._rules.get(span.text, None)
 *             span_length_diff = 0             # <<<<<<<<<<<<<<
 *             if rule:
 *                 span_length_diff = len(rule) - (span.end - span.start)
 */
    __pyx_v_span_length_diff = 0;

    /* "spacy/tokenizer.pyx":311
 *             rule = self._rules.get(span.text, None)
 *             span_length_diff = 0
 *             if rule:             # <<<<<<<<<<<<<<
 *                 span_length_diff = len(rule) - (span.end - span.start)
 *             if span_length_diff > 0:
 */
    __pyx_t_11 = __Pyx_PyObject_IsTrue(__pyx_v_rule); if (unlikely(__pyx_t_11 < 0)) __PYX_ERR(0, 311, __pyx_L1_error)
    if (__pyx_t_11) {

      /* "spacy/tokenizer.pyx":312
 *             span_length_diff = 0
 *             if rule:
 *                 span_length_diff = len(rule) - (span.end - span.start)             # <<<<<<<<<<<<<<
 *             if span_length_diff > 0:
 *                 modify_in_place = False
 */
      __pyx_t_12 = PyObject_Length(__pyx_v_rule); if (unlikely(__pyx_t_12 == ((Py_ssize_t)-1))) __PYX_ERR(0, 312, __pyx_L1_error)
      __pyx_t_4 = PyInt_FromSsize_t(__pyx_t_12); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 312, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_v_span, __pyx_n_s_end); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 312, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_7);
      __pyx_t_10 = __Pyx_PyObject_GetAttrStr(__pyx_v_span, __pyx_n_s_start); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 312, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_10);
      __pyx_t_8 = PyNumber_Subtract(__pyx_t_7, __pyx_t_10); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 312, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
      __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
      __pyx_t_10 = PyNumber_Subtract(__pyx_t_4, __pyx_t_8); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 312, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_10);
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __pyx_t_5 = __Pyx_PyInt_As_int(__pyx_t_10); if (unlikely((__pyx_t_5 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 312, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
      __pyx_v_span_length_diff = __pyx_t_5;

      /* "spacy/tokenizer.pyx":311
 *             rule = self._rules.get(span.text, None)
 *             span_length_diff = 0
 *             if rule:             # <<<<<<<<<<<<<<
 *                 span_length_diff = len(rule) - (span.end - span.start)
 *             if span_length_diff > 0:
 */
    }

    /* "spacy/tokenizer.pyx":313
 *             if rule:
 *                 span_length_diff = len(rule) - (span.end - span.start)
 *             if span_length_diff > 0:             # <<<<<<<<<<<<<<
 *                 modify_in_place = False
 *             curr_length += span_length_diff
 */
    __pyx_t_11 = ((__pyx_v_span_length_diff > 0) != 0);
    if (__pyx_t_11) {

      /* "spacy/tokenizer.pyx":314
 *                 span_length_diff = len(rule) - (span.end - span.start)
 *             if span_length_diff > 0:
 *                 modify_in_place = False             # <<<<<<<<<<<<<<
 *             curr_length += span_length_diff
 *             if curr_length > max_length:
 */
      __pyx_v_modify_in_place = 0;

      /* "spacy/tokenizer.pyx":313
 *             if rule:
 *                 span_length_diff = len(rule) - (span.end - span.start)
 *             if span_length_diff > 0:             # <<<<<<<<<<<<<<
 *                 modify_in_place = False
 *             curr_length += span_length_diff
 */
    }

    /* "spacy/tokenizer.pyx":315
 *             if span_length_diff > 0:
 *                 modify_in_place = False
 *             curr_length += span_length_diff             # <<<<<<<<<<<<<<
 *             if curr_length > max_length:
 *                 max_length = curr_length
 */
    __pyx_v_curr_length = (__pyx_v_curr_length + __pyx_v_span_length_diff);

    /* "spacy/tokenizer.pyx":316
 *                 modify_in_place = False
 *             curr_length += span_length_diff
 *             if curr_length > max_length:             # <<<<<<<<<<<<<<
 *                 max_length = curr_length
 *             span_data[span.start] = (span.text, span.start, span.end, span_length_diff)
 */
    __pyx_t_11 = ((__pyx_v_curr_length > __pyx_v_max_length) != 0);
    if (__pyx_t_11) {

      /* "spacy/tokenizer.pyx":317
 *             curr_length += span_length_diff
 *             if curr_length > max_length:
 *                 max_length = curr_length             # <<<<<<<<<<<<<<
 *             span_data[span.start] = (span.text, span.start, span.end, span_length_diff)
 *         return (span_data, max_length, modify_in_place)
 */
      __pyx_v_max_length = __pyx_v_curr_length;

      /* "spacy/tokenizer.pyx":316
 *                 modify_in_place = False
 *             curr_length += span_length_diff
 *             if curr_length > max_length:             # <<<<<<<<<<<<<<
 *                 max_length = curr_length
 *             span_data[span.start] = (span.text, span.start, span.end, span_length_diff)
 */
    }

    /* "spacy/tokenizer.pyx":318
 *             if curr_length > max_length:
 *                 max_length = curr_length
 *             span_data[span.start] = (span.text, span.start, span.end, span_length_diff)             # <<<<<<<<<<<<<<
 *         return (span_data, max_length, modify_in_place)
 * 
 */
    __pyx_t_10 = __Pyx_PyObject_GetAttrStr(__pyx_v_span, __pyx_n_s_text); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 318, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_10);
    __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_v_span, __pyx_n_s_start); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 318, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_v_span, __pyx_n_s_end); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 318, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_7 = __Pyx_PyInt_From_int(__pyx_v_span_length_diff); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 318, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __pyx_t_9 = PyTuple_New(4); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 318, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_9);
    __Pyx_GIVEREF(__pyx_t_10);
    PyTuple_SET_ITEM(__pyx_t_9, 0, __pyx_t_10);
    __Pyx_GIVEREF(__pyx_t_8);
    PyTuple_SET_ITEM(__pyx_t_9, 1, __pyx_t_8);
    __Pyx_GIVEREF(__pyx_t_4);
    PyTuple_SET_ITEM(__pyx_t_9, 2, __pyx_t_4);
    __Pyx_GIVEREF(__pyx_t_7);
    PyTuple_SET_ITEM(__pyx_t_9, 3, __pyx_t_7);
    __pyx_t_10 = 0;
    __pyx_t_8 = 0;
    __pyx_t_4 = 0;
    __pyx_t_7 = 0;
    __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_v_span, __pyx_n_s_start); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 318, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    if (unlikely(PyDict_SetItem(__pyx_v_span_data, __pyx_t_7, __pyx_t_9) < 0)) __PYX_ERR(0, 318, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;

    /* "spacy/tokenizer.pyx":308
 *         cdef int span_length_diff = 0
 *         span_data = {}
 *         for span in spans:             # <<<<<<<<<<<<<<
 *             rule = self._rules.get(span.text, None)
 *             span_length_diff = 0
 */
  }
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "spacy/tokenizer.pyx":319
 *                 max_length = curr_length
 *             span_data[span.start] = (span.text, span.start, span.end, span_length_diff)
 *         return (span_data, max_length, modify_in_place)             # <<<<<<<<<<<<<<
 * 
 *     cdef int _retokenize_special_spans(self, Doc doc, TokenC* tokens, object span_data):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyInt_From_int(__pyx_v_max_length); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 319, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_9 = __Pyx_PyBool_FromLong(__pyx_v_modify_in_place); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 319, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_9);
  __pyx_t_7 = PyTuple_New(3); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 319, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __Pyx_INCREF(__pyx_v_span_data);
  __Pyx_GIVEREF(__pyx_v_span_data);
  PyTuple_SET_ITEM(__pyx_t_7, 0, __pyx_v_span_data);
  __Pyx_GIVEREF(__pyx_t_1);
  PyTuple_SET_ITEM(__pyx_t_7, 1, __pyx_t_1);
  __Pyx_GIVEREF(__pyx_t_9);
  PyTuple_SET_ITEM(__pyx_t_7, 2, __pyx_t_9);
  __pyx_t_1 = 0;
  __pyx_t_9 = 0;
  __pyx_r = __pyx_t_7;
  __pyx_t_7 = 0;
  goto __pyx_L0;

  /* "spacy/tokenizer.pyx":301
 *         stdsort(filtered.begin(), filtered.end(), start_cmp)
 * 
 *     cdef object _prepare_special_spans(self, Doc doc, vector[SpanC] &filtered):             # <<<<<<<<<<<<<<
 *         spans = [doc[match.start:match.end] for match in filtered]
 *         cdef bint modify_in_place = True
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_XDECREF(__pyx_t_9);
  __Pyx_XDECREF(__pyx_t_10);
  __Pyx_AddTraceback("spacy.tokenizer.Tokenizer._prepare_special_spans", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_spans);
  __Pyx_XDECREF(__pyx_v_span_data);
  __Pyx_XDECREF(__pyx_v_span);
  __Pyx_XDECREF(__pyx_v_rule);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "spacy/tokenizer.pyx":321
 *         return (span_data, max_length, modify_in_place)
 * 
 *     cdef int _retokenize_special_spans(self, Doc doc, TokenC* tokens, object span_data):             # <<<<<<<<<<<<<<
 *         cdef int i = 0
 *         cdef int j = 0
 */

static int __pyx_f_5spacy_9tokenizer_9Tokenizer__retokenize_special_spans(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *__pyx_v_self, struct __pyx_obj_5spacy_6tokens_3doc_Doc *__pyx_v_doc, struct __pyx_t_5spacy_7structs_TokenC *__pyx_v_tokens, PyObject *__pyx_v_span_data) {
  int __pyx_v_i;
  int __pyx_v_j;
  int __pyx_v_offset;
  struct __pyx_t_5spacy_5vocab__Cached *__pyx_v_cached;
  int __pyx_v_idx_offset;
  int __pyx_v_orig_final_spacy;
  int __pyx_v_orig_idx;
  int __pyx_v_span_start;
  int __pyx_v_span_end;
  PyObject *__pyx_v_span = NULL;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  int __pyx_t_3;
  int __pyx_t_4;
  __pyx_t_5spacy_8typedefs_hash_t __pyx_t_5;
  int __pyx_t_6;
  int __pyx_t_7;
  PyObject *__pyx_t_8 = NULL;
  PyObject *__pyx_t_9 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("_retokenize_special_spans", 0);

  /* "spacy/tokenizer.pyx":322
 * 
 *     cdef int _retokenize_special_spans(self, Doc doc, TokenC* tokens, object span_data):
 *         cdef int i = 0             # <<<<<<<<<<<<<<
 *         cdef int j = 0
 *         cdef int offset = 0
 */
  __pyx_v_i = 0;

  /* "spacy/tokenizer.pyx":323
 *     cdef int _retokenize_special_spans(self, Doc doc, TokenC* tokens, object span_data):
 *         cdef int i = 0
 *         cdef int j = 0             # <<<<<<<<<<<<<<
 *         cdef int offset = 0
 *         cdef _Cached* cached
 */
  __pyx_v_j = 0;

  /* "spacy/tokenizer.pyx":324
 *         cdef int i = 0
 *         cdef int j = 0
 *         cdef int offset = 0             # <<<<<<<<<<<<<<
 *         cdef _Cached* cached
 *         cdef int idx_offset = 0
 */
  __pyx_v_offset = 0;

  /* "spacy/tokenizer.pyx":326
 *         cdef int offset = 0
 *         cdef _Cached* cached
 *         cdef int idx_offset = 0             # <<<<<<<<<<<<<<
 *         cdef int orig_final_spacy
 *         cdef int orig_idx
 */
  __pyx_v_idx_offset = 0;

  /* "spacy/tokenizer.pyx":331
 *         cdef int span_start
 *         cdef int span_end
 *         while i < doc.length:             # <<<<<<<<<<<<<<
 *             if i not in span_data:
 *                 tokens[i + offset] = doc.c[i]
 */
  while (1) {
    __pyx_t_1 = ((__pyx_v_i < __pyx_v_doc->length) != 0);
    if (!__pyx_t_1) break;

    /* "spacy/tokenizer.pyx":332
 *         cdef int span_end
 *         while i < doc.length:
 *             if i not in span_data:             # <<<<<<<<<<<<<<
 *                 tokens[i + offset] = doc.c[i]
 *                 i += 1
 */
    __pyx_t_2 = __Pyx_PyInt_From_int(__pyx_v_i); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 332, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_1 = (__Pyx_PySequence_ContainsTF(__pyx_t_2, __pyx_v_span_data, Py_NE)); if (unlikely(__pyx_t_1 < 0)) __PYX_ERR(0, 332, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_3 = (__pyx_t_1 != 0);
    if (__pyx_t_3) {

      /* "spacy/tokenizer.pyx":333
 *         while i < doc.length:
 *             if i not in span_data:
 *                 tokens[i + offset] = doc.c[i]             # <<<<<<<<<<<<<<
 *                 i += 1
 *             else:
 */
      (__pyx_v_tokens[(__pyx_v_i + __pyx_v_offset)]) = (__pyx_v_doc->c[__pyx_v_i]);

      /* "spacy/tokenizer.pyx":334
 *             if i not in span_data:
 *                 tokens[i + offset] = doc.c[i]
 *                 i += 1             # <<<<<<<<<<<<<<
 *             else:
 *                 span = span_data[i]
 */
      __pyx_v_i = (__pyx_v_i + 1);

      /* "spacy/tokenizer.pyx":332
 *         cdef int span_end
 *         while i < doc.length:
 *             if i not in span_data:             # <<<<<<<<<<<<<<
 *                 tokens[i + offset] = doc.c[i]
 *                 i += 1
 */
      goto __pyx_L5;
    }

    /* "spacy/tokenizer.pyx":336
 *                 i += 1
 *             else:
 *                 span = span_data[i]             # <<<<<<<<<<<<<<
 *                 span_start = span[1]
 *                 span_end = span[2]
 */
    /*else*/ {
      __pyx_t_2 = __Pyx_GetItemInt(__pyx_v_span_data, __pyx_v_i, int, 1, __Pyx_PyInt_From_int, 0, 1, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 336, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_XDECREF_SET(__pyx_v_span, __pyx_t_2);
      __pyx_t_2 = 0;

      /* "spacy/tokenizer.pyx":337
 *             else:
 *                 span = span_data[i]
 *                 span_start = span[1]             # <<<<<<<<<<<<<<
 *                 span_end = span[2]
 *                 cached = <_Cached*>self._specials.get(hash_string(span[0]))
 */
      __pyx_t_2 = __Pyx_GetItemInt(__pyx_v_span, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 337, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_4 = __Pyx_PyInt_As_int(__pyx_t_2); if (unlikely((__pyx_t_4 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 337, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_v_span_start = __pyx_t_4;

      /* "spacy/tokenizer.pyx":338
 *                 span = span_data[i]
 *                 span_start = span[1]
 *                 span_end = span[2]             # <<<<<<<<<<<<<<
 *                 cached = <_Cached*>self._specials.get(hash_string(span[0]))
 *                 if cached == NULL:
 */
      __pyx_t_2 = __Pyx_GetItemInt(__pyx_v_span, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 338, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_4 = __Pyx_PyInt_As_int(__pyx_t_2); if (unlikely((__pyx_t_4 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 338, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_v_span_end = __pyx_t_4;

      /* "spacy/tokenizer.pyx":339
 *                 span_start = span[1]
 *                 span_end = span[2]
 *                 cached = <_Cached*>self._specials.get(hash_string(span[0]))             # <<<<<<<<<<<<<<
 *                 if cached == NULL:
 *                     # Copy original tokens if no rule found
 */
      __pyx_t_2 = __Pyx_GetItemInt(__pyx_v_span, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 339, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      if (!(likely(PyString_CheckExact(__pyx_t_2))||((__pyx_t_2) == Py_None)||((void)PyErr_Format(PyExc_TypeError, "Expected %.16s, got %.200s", "str", Py_TYPE(__pyx_t_2)->tp_name), 0))) __PYX_ERR(0, 339, __pyx_L1_error)
      __pyx_t_5 = __pyx_f_5spacy_7strings_hash_string(((PyObject*)__pyx_t_2), 0); if (unlikely(__pyx_t_5 == ((__pyx_t_5spacy_8typedefs_hash_t)0))) __PYX_ERR(0, 339, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_v_cached = ((struct __pyx_t_5spacy_5vocab__Cached *)((struct __pyx_vtabstruct_7preshed_4maps_PreshMap *)__pyx_v_self->_specials->__pyx_vtab)->get(__pyx_v_self->_specials, __pyx_t_5));

      /* "spacy/tokenizer.pyx":340
 *                 span_end = span[2]
 *                 cached = <_Cached*>self._specials.get(hash_string(span[0]))
 *                 if cached == NULL:             # <<<<<<<<<<<<<<
 *                     # Copy original tokens if no rule found
 *                     for j in range(span_end - span_start):
 */
      __pyx_t_3 = ((__pyx_v_cached == NULL) != 0);
      if (__pyx_t_3) {

        /* "spacy/tokenizer.pyx":342
 *                 if cached == NULL:
 *                     # Copy original tokens if no rule found
 *                     for j in range(span_end - span_start):             # <<<<<<<<<<<<<<
 *                         tokens[i + offset + j] = doc.c[i + j]
 *                     i += span_end - span_start
 */
        __pyx_t_4 = (__pyx_v_span_end - __pyx_v_span_start);
        __pyx_t_6 = __pyx_t_4;
        for (__pyx_t_7 = 0; __pyx_t_7 < __pyx_t_6; __pyx_t_7+=1) {
          __pyx_v_j = __pyx_t_7;

          /* "spacy/tokenizer.pyx":343
 *                     # Copy original tokens if no rule found
 *                     for j in range(span_end - span_start):
 *                         tokens[i + offset + j] = doc.c[i + j]             # <<<<<<<<<<<<<<
 *                     i += span_end - span_start
 *                 else:
 */
          (__pyx_v_tokens[((__pyx_v_i + __pyx_v_offset) + __pyx_v_j)]) = (__pyx_v_doc->c[(__pyx_v_i + __pyx_v_j)]);
        }

        /* "spacy/tokenizer.pyx":344
 *                     for j in range(span_end - span_start):
 *                         tokens[i + offset + j] = doc.c[i + j]
 *                     i += span_end - span_start             # <<<<<<<<<<<<<<
 *                 else:
 *                     # Copy special case tokens into doc and adjust token and
 */
        __pyx_v_i = (__pyx_v_i + (__pyx_v_span_end - __pyx_v_span_start));

        /* "spacy/tokenizer.pyx":340
 *                 span_end = span[2]
 *                 cached = <_Cached*>self._specials.get(hash_string(span[0]))
 *                 if cached == NULL:             # <<<<<<<<<<<<<<
 *                     # Copy original tokens if no rule found
 *                     for j in range(span_end - span_start):
 */
        goto __pyx_L6;
      }

      /* "spacy/tokenizer.pyx":348
 *                     # Copy special case tokens into doc and adjust token and
 *                     # character offsets
 *                     idx_offset = 0             # <<<<<<<<<<<<<<
 *                     orig_final_spacy = doc.c[span_end - 1].spacy
 *                     orig_idx = doc.c[i].idx
 */
      /*else*/ {
        __pyx_v_idx_offset = 0;

        /* "spacy/tokenizer.pyx":349
 *                     # character offsets
 *                     idx_offset = 0
 *                     orig_final_spacy = doc.c[span_end - 1].spacy             # <<<<<<<<<<<<<<
 *                     orig_idx = doc.c[i].idx
 *                     for j in range(cached.length):
 */
        __pyx_t_3 = (__pyx_v_doc->c[(__pyx_v_span_end - 1)]).spacy;
        __pyx_v_orig_final_spacy = __pyx_t_3;

        /* "spacy/tokenizer.pyx":350
 *                     idx_offset = 0
 *                     orig_final_spacy = doc.c[span_end - 1].spacy
 *                     orig_idx = doc.c[i].idx             # <<<<<<<<<<<<<<
 *                     for j in range(cached.length):
 *                         tokens[i + offset + j] = cached.data.tokens[j]
 */
        __pyx_t_4 = (__pyx_v_doc->c[__pyx_v_i]).idx;
        __pyx_v_orig_idx = __pyx_t_4;

        /* "spacy/tokenizer.pyx":351
 *                     orig_final_spacy = doc.c[span_end - 1].spacy
 *                     orig_idx = doc.c[i].idx
 *                     for j in range(cached.length):             # <<<<<<<<<<<<<<
 *                         tokens[i + offset + j] = cached.data.tokens[j]
 *                         tokens[i + offset + j].idx = orig_idx + idx_offset
 */
        __pyx_t_4 = __pyx_v_cached->length;
        __pyx_t_6 = __pyx_t_4;
        for (__pyx_t_7 = 0; __pyx_t_7 < __pyx_t_6; __pyx_t_7+=1) {
          __pyx_v_j = __pyx_t_7;

          /* "spacy/tokenizer.pyx":352
 *                     orig_idx = doc.c[i].idx
 *                     for j in range(cached.length):
 *                         tokens[i + offset + j] = cached.data.tokens[j]             # <<<<<<<<<<<<<<
 *                         tokens[i + offset + j].idx = orig_idx + idx_offset
 *                         idx_offset += cached.data.tokens[j].lex.length
 */
          (__pyx_v_tokens[((__pyx_v_i + __pyx_v_offset) + __pyx_v_j)]) = (__pyx_v_cached->data.tokens[__pyx_v_j]);

          /* "spacy/tokenizer.pyx":353
 *                     for j in range(cached.length):
 *                         tokens[i + offset + j] = cached.data.tokens[j]
 *                         tokens[i + offset + j].idx = orig_idx + idx_offset             # <<<<<<<<<<<<<<
 *                         idx_offset += cached.data.tokens[j].lex.length
 *                         if cached.data.tokens[j].spacy:
 */
          (__pyx_v_tokens[((__pyx_v_i + __pyx_v_offset) + __pyx_v_j)]).idx = (__pyx_v_orig_idx + __pyx_v_idx_offset);

          /* "spacy/tokenizer.pyx":354
 *                         tokens[i + offset + j] = cached.data.tokens[j]
 *                         tokens[i + offset + j].idx = orig_idx + idx_offset
 *                         idx_offset += cached.data.tokens[j].lex.length             # <<<<<<<<<<<<<<
 *                         if cached.data.tokens[j].spacy:
 *                             idx_offset += 1
 */
          __pyx_v_idx_offset = (__pyx_v_idx_offset + (__pyx_v_cached->data.tokens[__pyx_v_j]).lex->length);

          /* "spacy/tokenizer.pyx":355
 *                         tokens[i + offset + j].idx = orig_idx + idx_offset
 *                         idx_offset += cached.data.tokens[j].lex.length
 *                         if cached.data.tokens[j].spacy:             # <<<<<<<<<<<<<<
 *                             idx_offset += 1
 *                     tokens[i + offset + cached.length - 1].spacy = orig_final_spacy
 */
          __pyx_t_3 = ((__pyx_v_cached->data.tokens[__pyx_v_j]).spacy != 0);
          if (__pyx_t_3) {

            /* "spacy/tokenizer.pyx":356
 *                         idx_offset += cached.data.tokens[j].lex.length
 *                         if cached.data.tokens[j].spacy:
 *                             idx_offset += 1             # <<<<<<<<<<<<<<
 *                     tokens[i + offset + cached.length - 1].spacy = orig_final_spacy
 *                     i += span_end - span_start
 */
            __pyx_v_idx_offset = (__pyx_v_idx_offset + 1);

            /* "spacy/tokenizer.pyx":355
 *                         tokens[i + offset + j].idx = orig_idx + idx_offset
 *                         idx_offset += cached.data.tokens[j].lex.length
 *                         if cached.data.tokens[j].spacy:             # <<<<<<<<<<<<<<
 *                             idx_offset += 1
 *                     tokens[i + offset + cached.length - 1].spacy = orig_final_spacy
 */
          }
        }

        /* "spacy/tokenizer.pyx":357
 *                         if cached.data.tokens[j].spacy:
 *                             idx_offset += 1
 *                     tokens[i + offset + cached.length - 1].spacy = orig_final_spacy             # <<<<<<<<<<<<<<
 *                     i += span_end - span_start
 *                     offset += span[3]
 */
        (__pyx_v_tokens[(((__pyx_v_i + __pyx_v_offset) + __pyx_v_cached->length) - 1)]).spacy = __pyx_v_orig_final_spacy;

        /* "spacy/tokenizer.pyx":358
 *                             idx_offset += 1
 *                     tokens[i + offset + cached.length - 1].spacy = orig_final_spacy
 *                     i += span_end - span_start             # <<<<<<<<<<<<<<
 *                     offset += span[3]
 *         return offset
 */
        __pyx_v_i = (__pyx_v_i + (__pyx_v_span_end - __pyx_v_span_start));

        /* "spacy/tokenizer.pyx":359
 *                     tokens[i + offset + cached.length - 1].spacy = orig_final_spacy
 *                     i += span_end - span_start
 *                     offset += span[3]             # <<<<<<<<<<<<<<
 *         return offset
 * 
 */
        __pyx_t_2 = __Pyx_PyInt_From_int(__pyx_v_offset); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 359, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
        __pyx_t_8 = __Pyx_GetItemInt(__pyx_v_span, 3, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 359, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_8);
        __pyx_t_9 = PyNumber_InPlaceAdd(__pyx_t_2, __pyx_t_8); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 359, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_9);
        __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
        __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
        __pyx_t_4 = __Pyx_PyInt_As_int(__pyx_t_9); if (unlikely((__pyx_t_4 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 359, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
        __pyx_v_offset = __pyx_t_4;
      }
      __pyx_L6:;
    }
    __pyx_L5:;
  }

  /* "spacy/tokenizer.pyx":360
 *                     i += span_end - span_start
 *                     offset += span[3]
 *         return offset             # <<<<<<<<<<<<<<
 * 
 *     cdef int _try_specials_and_cache(self, hash_t key, Doc tokens, int* has_special, bint with_special_cases) except -1:
 */
  __pyx_r = __pyx_v_offset;
  goto __pyx_L0;

  /* "spacy/tokenizer.pyx":321
 *         return (span_data, max_length, modify_in_place)
 * 
 *     cdef int _retokenize_special_spans(self, Doc doc, TokenC* tokens, object span_data):             # <<<<<<<<<<<<<<
 *         cdef int i = 0
 *         cdef int j = 0
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_XDECREF(__pyx_t_9);
  __Pyx_WriteUnraisable("spacy.tokenizer.Tokenizer._retokenize_special_spans", __pyx_clineno, __pyx_lineno, __pyx_filename, 1, 0);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_span);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "spacy/tokenizer.pyx":362
 *         return offset
 * 
 *     cdef int _try_specials_and_cache(self, hash_t key, Doc tokens, int* has_special, bint with_special_cases) except -1:             # <<<<<<<<<<<<<<
 *         cdef bint specials_hit = 0
 *         cdef bint cache_hit = 0
 */

static int __pyx_f_5spacy_9tokenizer_9Tokenizer__try_specials_and_cache(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *__pyx_v_self, __pyx_t_5spacy_8typedefs_hash_t __pyx_v_key, struct __pyx_obj_5spacy_6tokens_3doc_Doc *__pyx_v_tokens, int *__pyx_v_has_special, int __pyx_v_with_special_cases) {
  int __pyx_v_specials_hit;
  int __pyx_v_cache_hit;
  int __pyx_v_i;
  struct __pyx_t_5spacy_5vocab__Cached *__pyx_v_cached;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  int __pyx_t_2;
  int __pyx_t_3;
  int __pyx_t_4;
  int __pyx_t_5;
  int __pyx_t_6;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("_try_specials_and_cache", 0);

  /* "spacy/tokenizer.pyx":363
 * 
 *     cdef int _try_specials_and_cache(self, hash_t key, Doc tokens, int* has_special, bint with_special_cases) except -1:
 *         cdef bint specials_hit = 0             # <<<<<<<<<<<<<<
 *         cdef bint cache_hit = 0
 *         cdef int i
 */
  __pyx_v_specials_hit = 0;

  /* "spacy/tokenizer.pyx":364
 *     cdef int _try_specials_and_cache(self, hash_t key, Doc tokens, int* has_special, bint with_special_cases) except -1:
 *         cdef bint specials_hit = 0
 *         cdef bint cache_hit = 0             # <<<<<<<<<<<<<<
 *         cdef int i
 *         if with_special_cases:
 */
  __pyx_v_cache_hit = 0;

  /* "spacy/tokenizer.pyx":366
 *         cdef bint cache_hit = 0
 *         cdef int i
 *         if with_special_cases:             # <<<<<<<<<<<<<<
 *             cached = <_Cached*>self._specials.get(key)
 *             if cached == NULL:
 */
  __pyx_t_1 = (__pyx_v_with_special_cases != 0);
  if (__pyx_t_1) {

    /* "spacy/tokenizer.pyx":367
 *         cdef int i
 *         if with_special_cases:
 *             cached = <_Cached*>self._specials.get(key)             # <<<<<<<<<<<<<<
 *             if cached == NULL:
 *                 specials_hit = False
 */
    __pyx_v_cached = ((struct __pyx_t_5spacy_5vocab__Cached *)((struct __pyx_vtabstruct_7preshed_4maps_PreshMap *)__pyx_v_self->_specials->__pyx_vtab)->get(__pyx_v_self->_specials, __pyx_v_key));

    /* "spacy/tokenizer.pyx":368
 *         if with_special_cases:
 *             cached = <_Cached*>self._specials.get(key)
 *             if cached == NULL:             # <<<<<<<<<<<<<<
 *                 specials_hit = False
 *             else:
 */
    __pyx_t_1 = ((__pyx_v_cached == NULL) != 0);
    if (__pyx_t_1) {

      /* "spacy/tokenizer.pyx":369
 *             cached = <_Cached*>self._specials.get(key)
 *             if cached == NULL:
 *                 specials_hit = False             # <<<<<<<<<<<<<<
 *             else:
 *                 for i in range(cached.length):
 */
      __pyx_v_specials_hit = 0;

      /* "spacy/tokenizer.pyx":368
 *         if with_special_cases:
 *             cached = <_Cached*>self._specials.get(key)
 *             if cached == NULL:             # <<<<<<<<<<<<<<
 *                 specials_hit = False
 *             else:
 */
      goto __pyx_L4;
    }

    /* "spacy/tokenizer.pyx":371
 *                 specials_hit = False
 *             else:
 *                 for i in range(cached.length):             # <<<<<<<<<<<<<<
 *                     tokens.push_back(&cached.data.tokens[i], False)
 *                 has_special[0] = 1
 */
    /*else*/ {
      __pyx_t_2 = __pyx_v_cached->length;
      __pyx_t_3 = __pyx_t_2;
      for (__pyx_t_4 = 0; __pyx_t_4 < __pyx_t_3; __pyx_t_4+=1) {
        __pyx_v_i = __pyx_t_4;

        /* "spacy/tokenizer.pyx":372
 *             else:
 *                 for i in range(cached.length):
 *                     tokens.push_back(&cached.data.tokens[i], False)             # <<<<<<<<<<<<<<
 *                 has_special[0] = 1
 *                 specials_hit = True
 */
        __pyx_t_5 = ((struct __pyx_vtabstruct_5spacy_6tokens_3doc_Doc *)__pyx_v_tokens->__pyx_vtab)->__pyx_fuse_1push_back(__pyx_v_tokens, (&(__pyx_v_cached->data.tokens[__pyx_v_i])), 0); if (unlikely(__pyx_t_5 == ((int)-1))) __PYX_ERR(0, 372, __pyx_L1_error)
      }

      /* "spacy/tokenizer.pyx":373
 *                 for i in range(cached.length):
 *                     tokens.push_back(&cached.data.tokens[i], False)
 *                 has_special[0] = 1             # <<<<<<<<<<<<<<
 *                 specials_hit = True
 *         if not specials_hit:
 */
      (__pyx_v_has_special[0]) = 1;

      /* "spacy/tokenizer.pyx":374
 *                     tokens.push_back(&cached.data.tokens[i], False)
 *                 has_special[0] = 1
 *                 specials_hit = True             # <<<<<<<<<<<<<<
 *         if not specials_hit:
 *             cached = <_Cached*>self._cache.get(key)
 */
      __pyx_v_specials_hit = 1;
    }
    __pyx_L4:;

    /* "spacy/tokenizer.pyx":366
 *         cdef bint cache_hit = 0
 *         cdef int i
 *         if with_special_cases:             # <<<<<<<<<<<<<<
 *             cached = <_Cached*>self._specials.get(key)
 *             if cached == NULL:
 */
  }

  /* "spacy/tokenizer.pyx":375
 *                 has_special[0] = 1
 *                 specials_hit = True
 *         if not specials_hit:             # <<<<<<<<<<<<<<
 *             cached = <_Cached*>self._cache.get(key)
 *             if cached == NULL:
 */
  __pyx_t_1 = ((!(__pyx_v_specials_hit != 0)) != 0);
  if (__pyx_t_1) {

    /* "spacy/tokenizer.pyx":376
 *                 specials_hit = True
 *         if not specials_hit:
 *             cached = <_Cached*>self._cache.get(key)             # <<<<<<<<<<<<<<
 *             if cached == NULL:
 *                 cache_hit = False
 */
    __pyx_v_cached = ((struct __pyx_t_5spacy_5vocab__Cached *)((struct __pyx_vtabstruct_7preshed_4maps_PreshMap *)__pyx_v_self->_cache->__pyx_vtab)->get(__pyx_v_self->_cache, __pyx_v_key));

    /* "spacy/tokenizer.pyx":377
 *         if not specials_hit:
 *             cached = <_Cached*>self._cache.get(key)
 *             if cached == NULL:             # <<<<<<<<<<<<<<
 *                 cache_hit = False
 *             else:
 */
    __pyx_t_1 = ((__pyx_v_cached == NULL) != 0);
    if (__pyx_t_1) {

      /* "spacy/tokenizer.pyx":378
 *             cached = <_Cached*>self._cache.get(key)
 *             if cached == NULL:
 *                 cache_hit = False             # <<<<<<<<<<<<<<
 *             else:
 *                 if cached.is_lex:
 */
      __pyx_v_cache_hit = 0;

      /* "spacy/tokenizer.pyx":377
 *         if not specials_hit:
 *             cached = <_Cached*>self._cache.get(key)
 *             if cached == NULL:             # <<<<<<<<<<<<<<
 *                 cache_hit = False
 *             else:
 */
      goto __pyx_L8;
    }

    /* "spacy/tokenizer.pyx":380
 *                 cache_hit = False
 *             else:
 *                 if cached.is_lex:             # <<<<<<<<<<<<<<
 *                     for i in range(cached.length):
 *                         tokens.push_back(cached.data.lexemes[i], False)
 */
    /*else*/ {
      __pyx_t_1 = (__pyx_v_cached->is_lex != 0);
      if (__pyx_t_1) {

        /* "spacy/tokenizer.pyx":381
 *             else:
 *                 if cached.is_lex:
 *                     for i in range(cached.length):             # <<<<<<<<<<<<<<
 *                         tokens.push_back(cached.data.lexemes[i], False)
 *                 else:
 */
        __pyx_t_2 = __pyx_v_cached->length;
        __pyx_t_3 = __pyx_t_2;
        for (__pyx_t_4 = 0; __pyx_t_4 < __pyx_t_3; __pyx_t_4+=1) {
          __pyx_v_i = __pyx_t_4;

          /* "spacy/tokenizer.pyx":382
 *                 if cached.is_lex:
 *                     for i in range(cached.length):
 *                         tokens.push_back(cached.data.lexemes[i], False)             # <<<<<<<<<<<<<<
 *                 else:
 *                     for i in range(cached.length):
 */
          __pyx_t_5 = ((struct __pyx_vtabstruct_5spacy_6tokens_3doc_Doc *)__pyx_v_tokens->__pyx_vtab)->__pyx_fuse_0push_back(__pyx_v_tokens, (__pyx_v_cached->data.lexemes[__pyx_v_i]), 0); if (unlikely(__pyx_t_5 == ((int)-1))) __PYX_ERR(0, 382, __pyx_L1_error)
        }

        /* "spacy/tokenizer.pyx":380
 *                 cache_hit = False
 *             else:
 *                 if cached.is_lex:             # <<<<<<<<<<<<<<
 *                     for i in range(cached.length):
 *                         tokens.push_back(cached.data.lexemes[i], False)
 */
        goto __pyx_L9;
      }

      /* "spacy/tokenizer.pyx":384
 *                         tokens.push_back(cached.data.lexemes[i], False)
 *                 else:
 *                     for i in range(cached.length):             # <<<<<<<<<<<<<<
 *                         tokens.push_back(&cached.data.tokens[i], False)
 *                 cache_hit = True
 */
      /*else*/ {
        __pyx_t_2 = __pyx_v_cached->length;
        __pyx_t_3 = __pyx_t_2;
        for (__pyx_t_4 = 0; __pyx_t_4 < __pyx_t_3; __pyx_t_4+=1) {
          __pyx_v_i = __pyx_t_4;

          /* "spacy/tokenizer.pyx":385
 *                 else:
 *                     for i in range(cached.length):
 *                         tokens.push_back(&cached.data.tokens[i], False)             # <<<<<<<<<<<<<<
 *                 cache_hit = True
 *         if not specials_hit and not cache_hit:
 */
          __pyx_t_5 = ((struct __pyx_vtabstruct_5spacy_6tokens_3doc_Doc *)__pyx_v_tokens->__pyx_vtab)->__pyx_fuse_1push_back(__pyx_v_tokens, (&(__pyx_v_cached->data.tokens[__pyx_v_i])), 0); if (unlikely(__pyx_t_5 == ((int)-1))) __PYX_ERR(0, 385, __pyx_L1_error)
        }
      }
      __pyx_L9:;

      /* "spacy/tokenizer.pyx":386
 *                     for i in range(cached.length):
 *                         tokens.push_back(&cached.data.tokens[i], False)
 *                 cache_hit = True             # <<<<<<<<<<<<<<
 *         if not specials_hit and not cache_hit:
 *             return False
 */
      __pyx_v_cache_hit = 1;
    }
    __pyx_L8:;

    /* "spacy/tokenizer.pyx":375
 *                 has_special[0] = 1
 *                 specials_hit = True
 *         if not specials_hit:             # <<<<<<<<<<<<<<
 *             cached = <_Cached*>self._cache.get(key)
 *             if cached == NULL:
 */
  }

  /* "spacy/tokenizer.pyx":387
 *                         tokens.push_back(&cached.data.tokens[i], False)
 *                 cache_hit = True
 *         if not specials_hit and not cache_hit:             # <<<<<<<<<<<<<<
 *             return False
 *         return True
 */
  __pyx_t_6 = ((!(__pyx_v_specials_hit != 0)) != 0);
  if (__pyx_t_6) {
  } else {
    __pyx_t_1 = __pyx_t_6;
    goto __pyx_L15_bool_binop_done;
  }
  __pyx_t_6 = ((!(__pyx_v_cache_hit != 0)) != 0);
  __pyx_t_1 = __pyx_t_6;
  __pyx_L15_bool_binop_done:;
  if (__pyx_t_1) {

    /* "spacy/tokenizer.pyx":388
 *                 cache_hit = True
 *         if not specials_hit and not cache_hit:
 *             return False             # <<<<<<<<<<<<<<
 *         return True
 * 
 */
    __pyx_r = 0;
    goto __pyx_L0;

    /* "spacy/tokenizer.pyx":387
 *                         tokens.push_back(&cached.data.tokens[i], False)
 *                 cache_hit = True
 *         if not specials_hit and not cache_hit:             # <<<<<<<<<<<<<<
 *             return False
 *         return True
 */
  }

  /* "spacy/tokenizer.pyx":389
 *         if not specials_hit and not cache_hit:
 *             return False
 *         return True             # <<<<<<<<<<<<<<
 * 
 *     cdef int _tokenize(self, Doc tokens, str span, hash_t orig_key, int* has_special, bint with_special_cases) except -1:
 */
  __pyx_r = 1;
  goto __pyx_L0;

  /* "spacy/tokenizer.pyx":362
 *         return offset
 * 
 *     cdef int _try_specials_and_cache(self, hash_t key, Doc tokens, int* has_special, bint with_special_cases) except -1:             # <<<<<<<<<<<<<<
 *         cdef bint specials_hit = 0
 *         cdef bint cache_hit = 0
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_AddTraceback("spacy.tokenizer.Tokenizer._try_specials_and_cache", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "spacy/tokenizer.pyx":391
 *         return True
 * 
 *     cdef int _tokenize(self, Doc tokens, str span, hash_t orig_key, int* has_special, bint with_special_cases) except -1:             # <<<<<<<<<<<<<<
 *         cdef vector[LexemeC*] prefixes
 *         cdef vector[LexemeC*] suffixes
 */

static int __pyx_f_5spacy_9tokenizer_9Tokenizer__tokenize(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *__pyx_v_self, struct __pyx_obj_5spacy_6tokens_3doc_Doc *__pyx_v_tokens, PyObject *__pyx_v_span, __pyx_t_5spacy_8typedefs_hash_t __pyx_v_orig_key, int *__pyx_v_has_special, int __pyx_v_with_special_cases) {
  std::vector<struct __pyx_t_5spacy_7structs_LexemeC *>  __pyx_v_prefixes;
  std::vector<struct __pyx_t_5spacy_7structs_LexemeC *>  __pyx_v_suffixes;
  int __pyx_v_orig_size;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("_tokenize", 0);
  __Pyx_INCREF(__pyx_v_span);

  /* "spacy/tokenizer.pyx":395
 *         cdef vector[LexemeC*] suffixes
 *         cdef int orig_size
 *         orig_size = tokens.length             # <<<<<<<<<<<<<<
 *         span = self._split_affixes(tokens.mem, span, &prefixes, &suffixes,
 *                                    has_special, with_special_cases)
 */
  __pyx_t_1 = __pyx_v_tokens->length;
  __pyx_v_orig_size = __pyx_t_1;

  /* "spacy/tokenizer.pyx":396
 *         cdef int orig_size
 *         orig_size = tokens.length
 *         span = self._split_affixes(tokens.mem, span, &prefixes, &suffixes,             # <<<<<<<<<<<<<<
 *                                    has_special, with_special_cases)
 *         self._attach_tokens(tokens, span, &prefixes, &suffixes, has_special,
 */
  __pyx_t_2 = ((PyObject *)__pyx_v_tokens->mem);
  __Pyx_INCREF(__pyx_t_2);

  /* "spacy/tokenizer.pyx":397
 *         orig_size = tokens.length
 *         span = self._split_affixes(tokens.mem, span, &prefixes, &suffixes,
 *                                    has_special, with_special_cases)             # <<<<<<<<<<<<<<
 *         self._attach_tokens(tokens, span, &prefixes, &suffixes, has_special,
 *                             with_special_cases)
 */
  __pyx_t_3 = ((struct __pyx_vtabstruct_5spacy_9tokenizer_Tokenizer *)__pyx_v_self->__pyx_vtab)->_split_affixes(__pyx_v_self, ((struct __pyx_obj_5cymem_5cymem_Pool *)__pyx_t_2), __pyx_v_span, (&__pyx_v_prefixes), (&__pyx_v_suffixes), __pyx_v_has_special, __pyx_v_with_special_cases); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 396, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF_SET(__pyx_v_span, ((PyObject*)__pyx_t_3));
  __pyx_t_3 = 0;

  /* "spacy/tokenizer.pyx":398
 *         span = self._split_affixes(tokens.mem, span, &prefixes, &suffixes,
 *                                    has_special, with_special_cases)
 *         self._attach_tokens(tokens, span, &prefixes, &suffixes, has_special,             # <<<<<<<<<<<<<<
 *                             with_special_cases)
 *         self._save_cached(&tokens.c[orig_size], orig_key, has_special,
 */
  __pyx_t_1 = ((struct __pyx_vtabstruct_5spacy_9tokenizer_Tokenizer *)__pyx_v_self->__pyx_vtab)->_attach_tokens(__pyx_v_self, __pyx_v_tokens, __pyx_v_span, (&__pyx_v_prefixes), (&__pyx_v_suffixes), __pyx_v_has_special, __pyx_v_with_special_cases); if (unlikely(__pyx_t_1 == ((int)-1))) __PYX_ERR(0, 398, __pyx_L1_error)

  /* "spacy/tokenizer.pyx":400
 *         self._attach_tokens(tokens, span, &prefixes, &suffixes, has_special,
 *                             with_special_cases)
 *         self._save_cached(&tokens.c[orig_size], orig_key, has_special,             # <<<<<<<<<<<<<<
 *                           tokens.length - orig_size)
 * 
 */
  __pyx_t_1 = ((struct __pyx_vtabstruct_5spacy_9tokenizer_Tokenizer *)__pyx_v_self->__pyx_vtab)->_save_cached(__pyx_v_self, (&(__pyx_v_tokens->c[__pyx_v_orig_size])), __pyx_v_orig_key, __pyx_v_has_special, (__pyx_v_tokens->length - __pyx_v_orig_size)); if (unlikely(__pyx_t_1 == ((int)-1))) __PYX_ERR(0, 400, __pyx_L1_error)

  /* "spacy/tokenizer.pyx":391
 *         return True
 * 
 *     cdef int _tokenize(self, Doc tokens, str span, hash_t orig_key, int* has_special, bint with_special_cases) except -1:             # <<<<<<<<<<<<<<
 *         cdef vector[LexemeC*] prefixes
 *         cdef vector[LexemeC*] suffixes
 */

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("spacy.tokenizer.Tokenizer._tokenize", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_span);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "spacy/tokenizer.pyx":403
 *                           tokens.length - orig_size)
 * 
 *     cdef str _split_affixes(             # <<<<<<<<<<<<<<
 *         self,
 *         Pool mem,
 */

static PyObject *__pyx_f_5spacy_9tokenizer_9Tokenizer__split_affixes(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *__pyx_v_self, struct __pyx_obj_5cymem_5cymem_Pool *__pyx_v_mem, PyObject *__pyx_v_string, std::vector<struct __pyx_t_5spacy_7structs_LexemeC const *>  *__pyx_v_prefixes, std::vector<struct __pyx_t_5spacy_7structs_LexemeC const *>  *__pyx_v_suffixes, CYTHON_UNUSED int *__pyx_v_has_special, int __pyx_v_with_special_cases) {
  PyObject *__pyx_v_prefix = 0;
  PyObject *__pyx_v_suffix = 0;
  PyObject *__pyx_v_minus_pre = 0;
  PyObject *__pyx_v_minus_suf = 0;
  size_t __pyx_v_last_size;
  PyObject *__pyx_v_pre_len = NULL;
  PyObject *__pyx_v_suf_len = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  int __pyx_t_2;
  Py_ssize_t __pyx_t_3;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  __pyx_t_5spacy_8typedefs_hash_t __pyx_t_7;
  Py_ssize_t __pyx_t_8;
  struct __pyx_t_5spacy_7structs_LexemeC const *__pyx_t_9;
  PyObject *__pyx_t_10 = NULL;
  Py_ssize_t __pyx_t_11;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("_split_affixes", 0);
  __Pyx_INCREF(__pyx_v_string);

  /* "spacy/tokenizer.pyx":416
 *         cdef str minus_pre
 *         cdef str minus_suf
 *         cdef size_t last_size = 0             # <<<<<<<<<<<<<<
 *         while string and len(string) != last_size:
 *             if self.token_match and self.token_match(string):
 */
  __pyx_v_last_size = 0;

  /* "spacy/tokenizer.pyx":417
 *         cdef str minus_suf
 *         cdef size_t last_size = 0
 *         while string and len(string) != last_size:             # <<<<<<<<<<<<<<
 *             if self.token_match and self.token_match(string):
 *                 break
 */
  while (1) {
    __pyx_t_2 = __Pyx_PyObject_IsTrue(__pyx_v_string); if (unlikely(__pyx_t_2 < 0)) __PYX_ERR(0, 417, __pyx_L1_error)
    if (__pyx_t_2) {
    } else {
      __pyx_t_1 = __pyx_t_2;
      goto __pyx_L5_bool_binop_done;
    }
    __pyx_t_3 = PyObject_Length(__pyx_v_string); if (unlikely(__pyx_t_3 == ((Py_ssize_t)-1))) __PYX_ERR(0, 417, __pyx_L1_error)
    __pyx_t_2 = ((__pyx_t_3 != __pyx_v_last_size) != 0);
    __pyx_t_1 = __pyx_t_2;
    __pyx_L5_bool_binop_done:;
    if (!__pyx_t_1) break;

    /* "spacy/tokenizer.pyx":418
 *         cdef size_t last_size = 0
 *         while string and len(string) != last_size:
 *             if self.token_match and self.token_match(string):             # <<<<<<<<<<<<<<
 *                 break
 *             if with_special_cases and self._specials.get(hash_string(string)) != NULL:
 */
    __pyx_t_4 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_token_match); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 418, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_2 = __Pyx_PyObject_IsTrue(__pyx_t_4); if (unlikely(__pyx_t_2 < 0)) __PYX_ERR(0, 418, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    if (__pyx_t_2) {
    } else {
      __pyx_t_1 = __pyx_t_2;
      goto __pyx_L8_bool_binop_done;
    }
    __pyx_t_5 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_token_match); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 418, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_6 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_5))) {
      __pyx_t_6 = PyMethod_GET_SELF(__pyx_t_5);
      if (likely(__pyx_t_6)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
        __Pyx_INCREF(__pyx_t_6);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_5, function);
      }
    }
    __pyx_t_4 = (__pyx_t_6) ? __Pyx_PyObject_Call2Args(__pyx_t_5, __pyx_t_6, __pyx_v_string) : __Pyx_PyObject_CallOneArg(__pyx_t_5, __pyx_v_string);
    __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
    if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 418, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_2 = __Pyx_PyObject_IsTrue(__pyx_t_4); if (unlikely(__pyx_t_2 < 0)) __PYX_ERR(0, 418, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __pyx_t_1 = __pyx_t_2;
    __pyx_L8_bool_binop_done:;
    if (__pyx_t_1) {

      /* "spacy/tokenizer.pyx":419
 *         while string and len(string) != last_size:
 *             if self.token_match and self.token_match(string):
 *                 break             # <<<<<<<<<<<<<<
 *             if with_special_cases and self._specials.get(hash_string(string)) != NULL:
 *                 break
 */
      goto __pyx_L4_break;

      /* "spacy/tokenizer.pyx":418
 *         cdef size_t last_size = 0
 *         while string and len(string) != last_size:
 *             if self.token_match and self.token_match(string):             # <<<<<<<<<<<<<<
 *                 break
 *             if with_special_cases and self._specials.get(hash_string(string)) != NULL:
 */
    }

    /* "spacy/tokenizer.pyx":420
 *             if self.token_match and self.token_match(string):
 *                 break
 *             if with_special_cases and self._specials.get(hash_string(string)) != NULL:             # <<<<<<<<<<<<<<
 *                 break
 *             last_size = len(string)
 */
    __pyx_t_2 = (__pyx_v_with_special_cases != 0);
    if (__pyx_t_2) {
    } else {
      __pyx_t_1 = __pyx_t_2;
      goto __pyx_L11_bool_binop_done;
    }
    __pyx_t_7 = __pyx_f_5spacy_7strings_hash_string(__pyx_v_string, 0); if (unlikely(__pyx_t_7 == ((__pyx_t_5spacy_8typedefs_hash_t)0))) __PYX_ERR(0, 420, __pyx_L1_error)
    __pyx_t_2 = ((((struct __pyx_vtabstruct_7preshed_4maps_PreshMap *)__pyx_v_self->_specials->__pyx_vtab)->get(__pyx_v_self->_specials, __pyx_t_7) != NULL) != 0);
    __pyx_t_1 = __pyx_t_2;
    __pyx_L11_bool_binop_done:;
    if (__pyx_t_1) {

      /* "spacy/tokenizer.pyx":421
 *                 break
 *             if with_special_cases and self._specials.get(hash_string(string)) != NULL:
 *                 break             # <<<<<<<<<<<<<<
 *             last_size = len(string)
 *             pre_len = self.find_prefix(string)
 */
      goto __pyx_L4_break;

      /* "spacy/tokenizer.pyx":420
 *             if self.token_match and self.token_match(string):
 *                 break
 *             if with_special_cases and self._specials.get(hash_string(string)) != NULL:             # <<<<<<<<<<<<<<
 *                 break
 *             last_size = len(string)
 */
    }

    /* "spacy/tokenizer.pyx":422
 *             if with_special_cases and self._specials.get(hash_string(string)) != NULL:
 *                 break
 *             last_size = len(string)             # <<<<<<<<<<<<<<
 *             pre_len = self.find_prefix(string)
 *             if pre_len != 0:
 */
    __pyx_t_3 = PyObject_Length(__pyx_v_string); if (unlikely(__pyx_t_3 == ((Py_ssize_t)-1))) __PYX_ERR(0, 422, __pyx_L1_error)
    __pyx_v_last_size = __pyx_t_3;

    /* "spacy/tokenizer.pyx":423
 *                 break
 *             last_size = len(string)
 *             pre_len = self.find_prefix(string)             # <<<<<<<<<<<<<<
 *             if pre_len != 0:
 *                 prefix = string[:pre_len]
 */
    __pyx_t_5 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_find_prefix); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 423, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_6 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_5))) {
      __pyx_t_6 = PyMethod_GET_SELF(__pyx_t_5);
      if (likely(__pyx_t_6)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
        __Pyx_INCREF(__pyx_t_6);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_5, function);
      }
    }
    __pyx_t_4 = (__pyx_t_6) ? __Pyx_PyObject_Call2Args(__pyx_t_5, __pyx_t_6, __pyx_v_string) : __Pyx_PyObject_CallOneArg(__pyx_t_5, __pyx_v_string);
    __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
    if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 423, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_XDECREF_SET(__pyx_v_pre_len, __pyx_t_4);
    __pyx_t_4 = 0;

    /* "spacy/tokenizer.pyx":424
 *             last_size = len(string)
 *             pre_len = self.find_prefix(string)
 *             if pre_len != 0:             # <<<<<<<<<<<<<<
 *                 prefix = string[:pre_len]
 *                 minus_pre = string[pre_len:]
 */
    __pyx_t_4 = __Pyx_PyInt_NeObjC(__pyx_v_pre_len, __pyx_int_0, 0, 0); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 424, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_1 = __Pyx_PyObject_IsTrue(__pyx_t_4); if (unlikely(__pyx_t_1 < 0)) __PYX_ERR(0, 424, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    if (__pyx_t_1) {

      /* "spacy/tokenizer.pyx":425
 *             pre_len = self.find_prefix(string)
 *             if pre_len != 0:
 *                 prefix = string[:pre_len]             # <<<<<<<<<<<<<<
 *                 minus_pre = string[pre_len:]
 *                 if minus_pre and with_special_cases and self._specials.get(hash_string(minus_pre)) != NULL:
 */
      if (unlikely(__pyx_v_string == Py_None)) {
        PyErr_SetString(PyExc_TypeError, "'NoneType' object is not subscriptable");
        __PYX_ERR(0, 425, __pyx_L1_error)
      }
      __Pyx_INCREF(__pyx_v_pre_len);
      __pyx_t_4 = __pyx_v_pre_len;
      __pyx_t_1 = (__pyx_t_4 == Py_None);
      if (__pyx_t_1) {
        __pyx_t_3 = PY_SSIZE_T_MAX;
      } else {
        __pyx_t_8 = __Pyx_PyIndex_AsSsize_t(__pyx_t_4); if (unlikely((__pyx_t_8 == (Py_ssize_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 425, __pyx_L1_error)
        __pyx_t_3 = __pyx_t_8;
      }
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __pyx_t_4 = PySequence_GetSlice(__pyx_v_string, 0, __pyx_t_3); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 425, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_XDECREF_SET(__pyx_v_prefix, ((PyObject*)__pyx_t_4));
      __pyx_t_4 = 0;

      /* "spacy/tokenizer.pyx":426
 *             if pre_len != 0:
 *                 prefix = string[:pre_len]
 *                 minus_pre = string[pre_len:]             # <<<<<<<<<<<<<<
 *                 if minus_pre and with_special_cases and self._specials.get(hash_string(minus_pre)) != NULL:
 *                     string = minus_pre
 */
      if (unlikely(__pyx_v_string == Py_None)) {
        PyErr_SetString(PyExc_TypeError, "'NoneType' object is not subscriptable");
        __PYX_ERR(0, 426, __pyx_L1_error)
      }
      __Pyx_INCREF(__pyx_v_pre_len);
      __pyx_t_4 = __pyx_v_pre_len;
      __pyx_t_1 = (__pyx_t_4 == Py_None);
      if (__pyx_t_1) {
        __pyx_t_3 = 0;
      } else {
        __pyx_t_8 = __Pyx_PyIndex_AsSsize_t(__pyx_t_4); if (unlikely((__pyx_t_8 == (Py_ssize_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 426, __pyx_L1_error)
        __pyx_t_3 = __pyx_t_8;
      }
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __pyx_t_4 = PySequence_GetSlice(__pyx_v_string, __pyx_t_3, PY_SSIZE_T_MAX); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 426, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_XDECREF_SET(__pyx_v_minus_pre, ((PyObject*)__pyx_t_4));
      __pyx_t_4 = 0;

      /* "spacy/tokenizer.pyx":427
 *                 prefix = string[:pre_len]
 *                 minus_pre = string[pre_len:]
 *                 if minus_pre and with_special_cases and self._specials.get(hash_string(minus_pre)) != NULL:             # <<<<<<<<<<<<<<
 *                     string = minus_pre
 *                     prefixes.push_back(self.vocab.get(mem, prefix))
 */
      __pyx_t_2 = __Pyx_PyObject_IsTrue(__pyx_v_minus_pre); if (unlikely(__pyx_t_2 < 0)) __PYX_ERR(0, 427, __pyx_L1_error)
      if (__pyx_t_2) {
      } else {
        __pyx_t_1 = __pyx_t_2;
        goto __pyx_L15_bool_binop_done;
      }
      __pyx_t_2 = (__pyx_v_with_special_cases != 0);
      if (__pyx_t_2) {
      } else {
        __pyx_t_1 = __pyx_t_2;
        goto __pyx_L15_bool_binop_done;
      }
      __pyx_t_7 = __pyx_f_5spacy_7strings_hash_string(__pyx_v_minus_pre, 0); if (unlikely(__pyx_t_7 == ((__pyx_t_5spacy_8typedefs_hash_t)0))) __PYX_ERR(0, 427, __pyx_L1_error)
      __pyx_t_2 = ((((struct __pyx_vtabstruct_7preshed_4maps_PreshMap *)__pyx_v_self->_specials->__pyx_vtab)->get(__pyx_v_self->_specials, __pyx_t_7) != NULL) != 0);
      __pyx_t_1 = __pyx_t_2;
      __pyx_L15_bool_binop_done:;
      if (__pyx_t_1) {

        /* "spacy/tokenizer.pyx":428
 *                 minus_pre = string[pre_len:]
 *                 if minus_pre and with_special_cases and self._specials.get(hash_string(minus_pre)) != NULL:
 *                     string = minus_pre             # <<<<<<<<<<<<<<
 *                     prefixes.push_back(self.vocab.get(mem, prefix))
 *                     break
 */
        __Pyx_INCREF(__pyx_v_minus_pre);
        __Pyx_DECREF_SET(__pyx_v_string, __pyx_v_minus_pre);

        /* "spacy/tokenizer.pyx":429
 *                 if minus_pre and with_special_cases and self._specials.get(hash_string(minus_pre)) != NULL:
 *                     string = minus_pre
 *                     prefixes.push_back(self.vocab.get(mem, prefix))             # <<<<<<<<<<<<<<
 *                     break
 *             suf_len = self.find_suffix(string[pre_len:])
 */
        __pyx_t_9 = ((struct __pyx_vtabstruct_5spacy_5vocab_Vocab *)__pyx_v_self->vocab->__pyx_vtab)->get(__pyx_v_self->vocab, __pyx_v_mem, __pyx_v_prefix); if (unlikely(__pyx_t_9 == ((struct __pyx_t_5spacy_7structs_LexemeC const *)NULL))) __PYX_ERR(0, 429, __pyx_L1_error)
        try {
          __pyx_v_prefixes->push_back(__pyx_t_9);
        } catch(...) {
          __Pyx_CppExn2PyErr();
          __PYX_ERR(0, 429, __pyx_L1_error)
        }

        /* "spacy/tokenizer.pyx":430
 *                     string = minus_pre
 *                     prefixes.push_back(self.vocab.get(mem, prefix))
 *                     break             # <<<<<<<<<<<<<<
 *             suf_len = self.find_suffix(string[pre_len:])
 *             if suf_len != 0:
 */
        goto __pyx_L4_break;

        /* "spacy/tokenizer.pyx":427
 *                 prefix = string[:pre_len]
 *                 minus_pre = string[pre_len:]
 *                 if minus_pre and with_special_cases and self._specials.get(hash_string(minus_pre)) != NULL:             # <<<<<<<<<<<<<<
 *                     string = minus_pre
 *                     prefixes.push_back(self.vocab.get(mem, prefix))
 */
      }

      /* "spacy/tokenizer.pyx":424
 *             last_size = len(string)
 *             pre_len = self.find_prefix(string)
 *             if pre_len != 0:             # <<<<<<<<<<<<<<
 *                 prefix = string[:pre_len]
 *                 minus_pre = string[pre_len:]
 */
    }

    /* "spacy/tokenizer.pyx":431
 *                     prefixes.push_back(self.vocab.get(mem, prefix))
 *                     break
 *             suf_len = self.find_suffix(string[pre_len:])             # <<<<<<<<<<<<<<
 *             if suf_len != 0:
 *                 suffix = string[-suf_len:]
 */
    __pyx_t_5 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_find_suffix); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 431, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    if (unlikely(__pyx_v_string == Py_None)) {
      PyErr_SetString(PyExc_TypeError, "'NoneType' object is not subscriptable");
      __PYX_ERR(0, 431, __pyx_L1_error)
    }
    __Pyx_INCREF(__pyx_v_pre_len);
    __pyx_t_6 = __pyx_v_pre_len;
    __pyx_t_1 = (__pyx_t_6 == Py_None);
    if (__pyx_t_1) {
      __pyx_t_3 = 0;
    } else {
      __pyx_t_8 = __Pyx_PyIndex_AsSsize_t(__pyx_t_6); if (unlikely((__pyx_t_8 == (Py_ssize_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 431, __pyx_L1_error)
      __pyx_t_3 = __pyx_t_8;
    }
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __pyx_t_6 = PySequence_GetSlice(__pyx_v_string, __pyx_t_3, PY_SSIZE_T_MAX); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 431, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_t_10 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_5))) {
      __pyx_t_10 = PyMethod_GET_SELF(__pyx_t_5);
      if (likely(__pyx_t_10)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
        __Pyx_INCREF(__pyx_t_10);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_5, function);
      }
    }
    __pyx_t_4 = (__pyx_t_10) ? __Pyx_PyObject_Call2Args(__pyx_t_5, __pyx_t_10, __pyx_t_6) : __Pyx_PyObject_CallOneArg(__pyx_t_5, __pyx_t_6);
    __Pyx_XDECREF(__pyx_t_10); __pyx_t_10 = 0;
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 431, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_XDECREF_SET(__pyx_v_suf_len, __pyx_t_4);
    __pyx_t_4 = 0;

    /* "spacy/tokenizer.pyx":432
 *                     break
 *             suf_len = self.find_suffix(string[pre_len:])
 *             if suf_len != 0:             # <<<<<<<<<<<<<<
 *                 suffix = string[-suf_len:]
 *                 minus_suf = string[:-suf_len]
 */
    __pyx_t_4 = __Pyx_PyInt_NeObjC(__pyx_v_suf_len, __pyx_int_0, 0, 0); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 432, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_1 = __Pyx_PyObject_IsTrue(__pyx_t_4); if (unlikely(__pyx_t_1 < 0)) __PYX_ERR(0, 432, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    if (__pyx_t_1) {

      /* "spacy/tokenizer.pyx":433
 *             suf_len = self.find_suffix(string[pre_len:])
 *             if suf_len != 0:
 *                 suffix = string[-suf_len:]             # <<<<<<<<<<<<<<
 *                 minus_suf = string[:-suf_len]
 *                 if minus_suf and with_special_cases and self._specials.get(hash_string(minus_suf)) != NULL:
 */
      if (unlikely(__pyx_v_string == Py_None)) {
        PyErr_SetString(PyExc_TypeError, "'NoneType' object is not subscriptable");
        __PYX_ERR(0, 433, __pyx_L1_error)
      }
      __pyx_t_4 = PyNumber_Negative(__pyx_v_suf_len); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 433, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __pyx_t_1 = (__pyx_t_4 == Py_None);
      if (__pyx_t_1) {
        __pyx_t_3 = 0;
      } else {
        __pyx_t_8 = __Pyx_PyIndex_AsSsize_t(__pyx_t_4); if (unlikely((__pyx_t_8 == (Py_ssize_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 433, __pyx_L1_error)
        __pyx_t_3 = __pyx_t_8;
      }
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __pyx_t_4 = PySequence_GetSlice(__pyx_v_string, __pyx_t_3, PY_SSIZE_T_MAX); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 433, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_XDECREF_SET(__pyx_v_suffix, ((PyObject*)__pyx_t_4));
      __pyx_t_4 = 0;

      /* "spacy/tokenizer.pyx":434
 *             if suf_len != 0:
 *                 suffix = string[-suf_len:]
 *                 minus_suf = string[:-suf_len]             # <<<<<<<<<<<<<<
 *                 if minus_suf and with_special_cases and self._specials.get(hash_string(minus_suf)) != NULL:
 *                     string = minus_suf
 */
      if (unlikely(__pyx_v_string == Py_None)) {
        PyErr_SetString(PyExc_TypeError, "'NoneType' object is not subscriptable");
        __PYX_ERR(0, 434, __pyx_L1_error)
      }
      __pyx_t_4 = PyNumber_Negative(__pyx_v_suf_len); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 434, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __pyx_t_1 = (__pyx_t_4 == Py_None);
      if (__pyx_t_1) {
        __pyx_t_3 = PY_SSIZE_T_MAX;
      } else {
        __pyx_t_8 = __Pyx_PyIndex_AsSsize_t(__pyx_t_4); if (unlikely((__pyx_t_8 == (Py_ssize_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 434, __pyx_L1_error)
        __pyx_t_3 = __pyx_t_8;
      }
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __pyx_t_4 = PySequence_GetSlice(__pyx_v_string, 0, __pyx_t_3); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 434, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_XDECREF_SET(__pyx_v_minus_suf, ((PyObject*)__pyx_t_4));
      __pyx_t_4 = 0;

      /* "spacy/tokenizer.pyx":435
 *                 suffix = string[-suf_len:]
 *                 minus_suf = string[:-suf_len]
 *                 if minus_suf and with_special_cases and self._specials.get(hash_string(minus_suf)) != NULL:             # <<<<<<<<<<<<<<
 *                     string = minus_suf
 *                     suffixes.push_back(self.vocab.get(mem, suffix))
 */
      __pyx_t_2 = __Pyx_PyObject_IsTrue(__pyx_v_minus_suf); if (unlikely(__pyx_t_2 < 0)) __PYX_ERR(0, 435, __pyx_L1_error)
      if (__pyx_t_2) {
      } else {
        __pyx_t_1 = __pyx_t_2;
        goto __pyx_L20_bool_binop_done;
      }
      __pyx_t_2 = (__pyx_v_with_special_cases != 0);
      if (__pyx_t_2) {
      } else {
        __pyx_t_1 = __pyx_t_2;
        goto __pyx_L20_bool_binop_done;
      }
      __pyx_t_7 = __pyx_f_5spacy_7strings_hash_string(__pyx_v_minus_suf, 0); if (unlikely(__pyx_t_7 == ((__pyx_t_5spacy_8typedefs_hash_t)0))) __PYX_ERR(0, 435, __pyx_L1_error)
      __pyx_t_2 = ((((struct __pyx_vtabstruct_7preshed_4maps_PreshMap *)__pyx_v_self->_specials->__pyx_vtab)->get(__pyx_v_self->_specials, __pyx_t_7) != NULL) != 0);
      __pyx_t_1 = __pyx_t_2;
      __pyx_L20_bool_binop_done:;
      if (__pyx_t_1) {

        /* "spacy/tokenizer.pyx":436
 *                 minus_suf = string[:-suf_len]
 *                 if minus_suf and with_special_cases and self._specials.get(hash_string(minus_suf)) != NULL:
 *                     string = minus_suf             # <<<<<<<<<<<<<<
 *                     suffixes.push_back(self.vocab.get(mem, suffix))
 *                     break
 */
        __Pyx_INCREF(__pyx_v_minus_suf);
        __Pyx_DECREF_SET(__pyx_v_string, __pyx_v_minus_suf);

        /* "spacy/tokenizer.pyx":437
 *                 if minus_suf and with_special_cases and self._specials.get(hash_string(minus_suf)) != NULL:
 *                     string = minus_suf
 *                     suffixes.push_back(self.vocab.get(mem, suffix))             # <<<<<<<<<<<<<<
 *                     break
 *             if pre_len and suf_len and (pre_len + suf_len) <= len(string):
 */
        __pyx_t_9 = ((struct __pyx_vtabstruct_5spacy_5vocab_Vocab *)__pyx_v_self->vocab->__pyx_vtab)->get(__pyx_v_self->vocab, __pyx_v_mem, __pyx_v_suffix); if (unlikely(__pyx_t_9 == ((struct __pyx_t_5spacy_7structs_LexemeC const *)NULL))) __PYX_ERR(0, 437, __pyx_L1_error)
        try {
          __pyx_v_suffixes->push_back(__pyx_t_9);
        } catch(...) {
          __Pyx_CppExn2PyErr();
          __PYX_ERR(0, 437, __pyx_L1_error)
        }

        /* "spacy/tokenizer.pyx":438
 *                     string = minus_suf
 *                     suffixes.push_back(self.vocab.get(mem, suffix))
 *                     break             # <<<<<<<<<<<<<<
 *             if pre_len and suf_len and (pre_len + suf_len) <= len(string):
 *                 string = string[pre_len:-suf_len]
 */
        goto __pyx_L4_break;

        /* "spacy/tokenizer.pyx":435
 *                 suffix = string[-suf_len:]
 *                 minus_suf = string[:-suf_len]
 *                 if minus_suf and with_special_cases and self._specials.get(hash_string(minus_suf)) != NULL:             # <<<<<<<<<<<<<<
 *                     string = minus_suf
 *                     suffixes.push_back(self.vocab.get(mem, suffix))
 */
      }

      /* "spacy/tokenizer.pyx":432
 *                     break
 *             suf_len = self.find_suffix(string[pre_len:])
 *             if suf_len != 0:             # <<<<<<<<<<<<<<
 *                 suffix = string[-suf_len:]
 *                 minus_suf = string[:-suf_len]
 */
    }

    /* "spacy/tokenizer.pyx":439
 *                     suffixes.push_back(self.vocab.get(mem, suffix))
 *                     break
 *             if pre_len and suf_len and (pre_len + suf_len) <= len(string):             # <<<<<<<<<<<<<<
 *                 string = string[pre_len:-suf_len]
 *                 prefixes.push_back(self.vocab.get(mem, prefix))
 */
    __pyx_t_2 = __Pyx_PyObject_IsTrue(__pyx_v_pre_len); if (unlikely(__pyx_t_2 < 0)) __PYX_ERR(0, 439, __pyx_L1_error)
    if (__pyx_t_2) {
    } else {
      __pyx_t_1 = __pyx_t_2;
      goto __pyx_L24_bool_binop_done;
    }
    __pyx_t_2 = __Pyx_PyObject_IsTrue(__pyx_v_suf_len); if (unlikely(__pyx_t_2 < 0)) __PYX_ERR(0, 439, __pyx_L1_error)
    if (__pyx_t_2) {
    } else {
      __pyx_t_1 = __pyx_t_2;
      goto __pyx_L24_bool_binop_done;
    }
    __pyx_t_4 = PyNumber_Add(__pyx_v_pre_len, __pyx_v_suf_len); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 439, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_3 = PyObject_Length(__pyx_v_string); if (unlikely(__pyx_t_3 == ((Py_ssize_t)-1))) __PYX_ERR(0, 439, __pyx_L1_error)
    __pyx_t_5 = PyInt_FromSsize_t(__pyx_t_3); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 439, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_6 = PyObject_RichCompare(__pyx_t_4, __pyx_t_5, Py_LE); __Pyx_XGOTREF(__pyx_t_6); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 439, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_2 = __Pyx_PyObject_IsTrue(__pyx_t_6); if (unlikely(__pyx_t_2 < 0)) __PYX_ERR(0, 439, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __pyx_t_1 = __pyx_t_2;
    __pyx_L24_bool_binop_done:;
    if (__pyx_t_1) {

      /* "spacy/tokenizer.pyx":440
 *                     break
 *             if pre_len and suf_len and (pre_len + suf_len) <= len(string):
 *                 string = string[pre_len:-suf_len]             # <<<<<<<<<<<<<<
 *                 prefixes.push_back(self.vocab.get(mem, prefix))
 *                 suffixes.push_back(self.vocab.get(mem, suffix))
 */
      if (unlikely(__pyx_v_string == Py_None)) {
        PyErr_SetString(PyExc_TypeError, "'NoneType' object is not subscriptable");
        __PYX_ERR(0, 440, __pyx_L1_error)
      }
      __Pyx_INCREF(__pyx_v_pre_len);
      __pyx_t_6 = __pyx_v_pre_len;
      __pyx_t_1 = (__pyx_t_6 == Py_None);
      if (__pyx_t_1) {
        __pyx_t_3 = 0;
      } else {
        __pyx_t_8 = __Pyx_PyIndex_AsSsize_t(__pyx_t_6); if (unlikely((__pyx_t_8 == (Py_ssize_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 440, __pyx_L1_error)
        __pyx_t_3 = __pyx_t_8;
      }
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      __pyx_t_6 = PyNumber_Negative(__pyx_v_suf_len); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 440, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __pyx_t_1 = (__pyx_t_6 == Py_None);
      if (__pyx_t_1) {
        __pyx_t_8 = PY_SSIZE_T_MAX;
      } else {
        __pyx_t_11 = __Pyx_PyIndex_AsSsize_t(__pyx_t_6); if (unlikely((__pyx_t_11 == (Py_ssize_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 440, __pyx_L1_error)
        __pyx_t_8 = __pyx_t_11;
      }
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      __pyx_t_6 = PySequence_GetSlice(__pyx_v_string, __pyx_t_3, __pyx_t_8); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 440, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_DECREF_SET(__pyx_v_string, ((PyObject*)__pyx_t_6));
      __pyx_t_6 = 0;

      /* "spacy/tokenizer.pyx":441
 *             if pre_len and suf_len and (pre_len + suf_len) <= len(string):
 *                 string = string[pre_len:-suf_len]
 *                 prefixes.push_back(self.vocab.get(mem, prefix))             # <<<<<<<<<<<<<<
 *                 suffixes.push_back(self.vocab.get(mem, suffix))
 *             elif pre_len:
 */
      if (unlikely(!__pyx_v_prefix)) { __Pyx_RaiseUnboundLocalError("prefix"); __PYX_ERR(0, 441, __pyx_L1_error) }
      __pyx_t_9 = ((struct __pyx_vtabstruct_5spacy_5vocab_Vocab *)__pyx_v_self->vocab->__pyx_vtab)->get(__pyx_v_self->vocab, __pyx_v_mem, __pyx_v_prefix); if (unlikely(__pyx_t_9 == ((struct __pyx_t_5spacy_7structs_LexemeC const *)NULL))) __PYX_ERR(0, 441, __pyx_L1_error)
      try {
        __pyx_v_prefixes->push_back(__pyx_t_9);
      } catch(...) {
        __Pyx_CppExn2PyErr();
        __PYX_ERR(0, 441, __pyx_L1_error)
      }

      /* "spacy/tokenizer.pyx":442
 *                 string = string[pre_len:-suf_len]
 *                 prefixes.push_back(self.vocab.get(mem, prefix))
 *                 suffixes.push_back(self.vocab.get(mem, suffix))             # <<<<<<<<<<<<<<
 *             elif pre_len:
 *                 string = minus_pre
 */
      if (unlikely(!__pyx_v_suffix)) { __Pyx_RaiseUnboundLocalError("suffix"); __PYX_ERR(0, 442, __pyx_L1_error) }
      __pyx_t_9 = ((struct __pyx_vtabstruct_5spacy_5vocab_Vocab *)__pyx_v_self->vocab->__pyx_vtab)->get(__pyx_v_self->vocab, __pyx_v_mem, __pyx_v_suffix); if (unlikely(__pyx_t_9 == ((struct __pyx_t_5spacy_7structs_LexemeC const *)NULL))) __PYX_ERR(0, 442, __pyx_L1_error)
      try {
        __pyx_v_suffixes->push_back(__pyx_t_9);
      } catch(...) {
        __Pyx_CppExn2PyErr();
        __PYX_ERR(0, 442, __pyx_L1_error)
      }

      /* "spacy/tokenizer.pyx":439
 *                     suffixes.push_back(self.vocab.get(mem, suffix))
 *                     break
 *             if pre_len and suf_len and (pre_len + suf_len) <= len(string):             # <<<<<<<<<<<<<<
 *                 string = string[pre_len:-suf_len]
 *                 prefixes.push_back(self.vocab.get(mem, prefix))
 */
      goto __pyx_L23;
    }

    /* "spacy/tokenizer.pyx":443
 *                 prefixes.push_back(self.vocab.get(mem, prefix))
 *                 suffixes.push_back(self.vocab.get(mem, suffix))
 *             elif pre_len:             # <<<<<<<<<<<<<<
 *                 string = minus_pre
 *                 prefixes.push_back(self.vocab.get(mem, prefix))
 */
    __pyx_t_1 = __Pyx_PyObject_IsTrue(__pyx_v_pre_len); if (unlikely(__pyx_t_1 < 0)) __PYX_ERR(0, 443, __pyx_L1_error)
    if (__pyx_t_1) {

      /* "spacy/tokenizer.pyx":444
 *                 suffixes.push_back(self.vocab.get(mem, suffix))
 *             elif pre_len:
 *                 string = minus_pre             # <<<<<<<<<<<<<<
 *                 prefixes.push_back(self.vocab.get(mem, prefix))
 *             elif suf_len:
 */
      if (unlikely(!__pyx_v_minus_pre)) { __Pyx_RaiseUnboundLocalError("minus_pre"); __PYX_ERR(0, 444, __pyx_L1_error) }
      __Pyx_INCREF(__pyx_v_minus_pre);
      __Pyx_DECREF_SET(__pyx_v_string, __pyx_v_minus_pre);

      /* "spacy/tokenizer.pyx":445
 *             elif pre_len:
 *                 string = minus_pre
 *                 prefixes.push_back(self.vocab.get(mem, prefix))             # <<<<<<<<<<<<<<
 *             elif suf_len:
 *                 string = minus_suf
 */
      if (unlikely(!__pyx_v_prefix)) { __Pyx_RaiseUnboundLocalError("prefix"); __PYX_ERR(0, 445, __pyx_L1_error) }
      __pyx_t_9 = ((struct __pyx_vtabstruct_5spacy_5vocab_Vocab *)__pyx_v_self->vocab->__pyx_vtab)->get(__pyx_v_self->vocab, __pyx_v_mem, __pyx_v_prefix); if (unlikely(__pyx_t_9 == ((struct __pyx_t_5spacy_7structs_LexemeC const *)NULL))) __PYX_ERR(0, 445, __pyx_L1_error)
      try {
        __pyx_v_prefixes->push_back(__pyx_t_9);
      } catch(...) {
        __Pyx_CppExn2PyErr();
        __PYX_ERR(0, 445, __pyx_L1_error)
      }

      /* "spacy/tokenizer.pyx":443
 *                 prefixes.push_back(self.vocab.get(mem, prefix))
 *                 suffixes.push_back(self.vocab.get(mem, suffix))
 *             elif pre_len:             # <<<<<<<<<<<<<<
 *                 string = minus_pre
 *                 prefixes.push_back(self.vocab.get(mem, prefix))
 */
      goto __pyx_L23;
    }

    /* "spacy/tokenizer.pyx":446
 *                 string = minus_pre
 *                 prefixes.push_back(self.vocab.get(mem, prefix))
 *             elif suf_len:             # <<<<<<<<<<<<<<
 *                 string = minus_suf
 *                 suffixes.push_back(self.vocab.get(mem, suffix))
 */
    __pyx_t_1 = __Pyx_PyObject_IsTrue(__pyx_v_suf_len); if (unlikely(__pyx_t_1 < 0)) __PYX_ERR(0, 446, __pyx_L1_error)
    if (__pyx_t_1) {

      /* "spacy/tokenizer.pyx":447
 *                 prefixes.push_back(self.vocab.get(mem, prefix))
 *             elif suf_len:
 *                 string = minus_suf             # <<<<<<<<<<<<<<
 *                 suffixes.push_back(self.vocab.get(mem, suffix))
 *         return string
 */
      if (unlikely(!__pyx_v_minus_suf)) { __Pyx_RaiseUnboundLocalError("minus_suf"); __PYX_ERR(0, 447, __pyx_L1_error) }
      __Pyx_INCREF(__pyx_v_minus_suf);
      __Pyx_DECREF_SET(__pyx_v_string, __pyx_v_minus_suf);

      /* "spacy/tokenizer.pyx":448
 *             elif suf_len:
 *                 string = minus_suf
 *                 suffixes.push_back(self.vocab.get(mem, suffix))             # <<<<<<<<<<<<<<
 *         return string
 * 
 */
      if (unlikely(!__pyx_v_suffix)) { __Pyx_RaiseUnboundLocalError("suffix"); __PYX_ERR(0, 448, __pyx_L1_error) }
      __pyx_t_9 = ((struct __pyx_vtabstruct_5spacy_5vocab_Vocab *)__pyx_v_self->vocab->__pyx_vtab)->get(__pyx_v_self->vocab, __pyx_v_mem, __pyx_v_suffix); if (unlikely(__pyx_t_9 == ((struct __pyx_t_5spacy_7structs_LexemeC const *)NULL))) __PYX_ERR(0, 448, __pyx_L1_error)
      try {
        __pyx_v_suffixes->push_back(__pyx_t_9);
      } catch(...) {
        __Pyx_CppExn2PyErr();
        __PYX_ERR(0, 448, __pyx_L1_error)
      }

      /* "spacy/tokenizer.pyx":446
 *                 string = minus_pre
 *                 prefixes.push_back(self.vocab.get(mem, prefix))
 *             elif suf_len:             # <<<<<<<<<<<<<<
 *                 string = minus_suf
 *                 suffixes.push_back(self.vocab.get(mem, suffix))
 */
    }
    __pyx_L23:;
  }
  __pyx_L4_break:;

  /* "spacy/tokenizer.pyx":449
 *                 string = minus_suf
 *                 suffixes.push_back(self.vocab.get(mem, suffix))
 *         return string             # <<<<<<<<<<<<<<
 * 
 *     cdef int _attach_tokens(self, Doc tokens, str string,
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v_string);
  __pyx_r = __pyx_v_string;
  goto __pyx_L0;

  /* "spacy/tokenizer.pyx":403
 *                           tokens.length - orig_size)
 * 
 *     cdef str _split_affixes(             # <<<<<<<<<<<<<<
 *         self,
 *         Pool mem,
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_10);
  __Pyx_AddTraceback("spacy.tokenizer.Tokenizer._split_affixes", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_prefix);
  __Pyx_XDECREF(__pyx_v_suffix);
  __Pyx_XDECREF(__pyx_v_minus_pre);
  __Pyx_XDECREF(__pyx_v_minus_suf);
  __Pyx_XDECREF(__pyx_v_pre_len);
  __Pyx_XDECREF(__pyx_v_suf_len);
  __Pyx_XDECREF(__pyx_v_string);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "spacy/tokenizer.pyx":451
 *         return string
 * 
 *     cdef int _attach_tokens(self, Doc tokens, str string,             # <<<<<<<<<<<<<<
 *                             vector[const LexemeC*] *prefixes,
 *                             vector[const LexemeC*] *suffixes,
 */

static int __pyx_f_5spacy_9tokenizer_9Tokenizer__attach_tokens(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *__pyx_v_self, struct __pyx_obj_5spacy_6tokens_3doc_Doc *__pyx_v_tokens, PyObject *__pyx_v_string, std::vector<struct __pyx_t_5spacy_7structs_LexemeC const *>  *__pyx_v_prefixes, std::vector<struct __pyx_t_5spacy_7structs_LexemeC const *>  *__pyx_v_suffixes, int *__pyx_v_has_special, int __pyx_v_with_special_cases) {
  struct __pyx_t_5spacy_7structs_LexemeC const *__pyx_v_lexeme;
  PyObject *__pyx_v_span = 0;
  int __pyx_v_i;
  PyObject *__pyx_v_matches = NULL;
  PyObject *__pyx_v_start = NULL;
  long __pyx_v_start_before_infixes;
  PyObject *__pyx_v_match = NULL;
  PyObject *__pyx_v_infix_start = NULL;
  PyObject *__pyx_v_infix_end = NULL;
  PyObject *__pyx_v_infix_span = NULL;
  std::vector<struct __pyx_t_5spacy_7structs_LexemeC const *> ::reverse_iterator __pyx_v_it;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  std::vector<struct __pyx_t_5spacy_7structs_LexemeC const *> ::size_type __pyx_t_2;
  std::vector<struct __pyx_t_5spacy_7structs_LexemeC const *> ::size_type __pyx_t_3;
  int __pyx_t_4;
  int __pyx_t_5;
  __pyx_t_5spacy_8typedefs_hash_t __pyx_t_6;
  PyObject *__pyx_t_7 = NULL;
  int __pyx_t_8;
  PyObject *__pyx_t_9 = NULL;
  PyObject *__pyx_t_10 = NULL;
  struct __pyx_t_5spacy_7structs_LexemeC const *__pyx_t_11;
  long __pyx_t_12;
  Py_ssize_t __pyx_t_13;
  PyObject *(*__pyx_t_14)(PyObject *);
  PyObject *__pyx_t_15 = NULL;
  Py_ssize_t __pyx_t_16;
  Py_ssize_t __pyx_t_17;
  Py_ssize_t __pyx_t_18;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("_attach_tokens", 0);

  /* "spacy/tokenizer.pyx":459
 *         cdef str span
 *         cdef int i
 *         if prefixes.size():             # <<<<<<<<<<<<<<
 *             for i in range(prefixes.size()):
 *                 tokens.push_back(prefixes[0][i], False)
 */
  __pyx_t_1 = (__pyx_v_prefixes->size() != 0);
  if (__pyx_t_1) {

    /* "spacy/tokenizer.pyx":460
 *         cdef int i
 *         if prefixes.size():
 *             for i in range(prefixes.size()):             # <<<<<<<<<<<<<<
 *                 tokens.push_back(prefixes[0][i], False)
 *         if string:
 */
    __pyx_t_2 = __pyx_v_prefixes->size();
    __pyx_t_3 = __pyx_t_2;
    for (__pyx_t_4 = 0; __pyx_t_4 < __pyx_t_3; __pyx_t_4+=1) {
      __pyx_v_i = __pyx_t_4;

      /* "spacy/tokenizer.pyx":461
 *         if prefixes.size():
 *             for i in range(prefixes.size()):
 *                 tokens.push_back(prefixes[0][i], False)             # <<<<<<<<<<<<<<
 *         if string:
 *             if self._try_specials_and_cache(hash_string(string), tokens, has_special, with_special_cases):
 */
      __pyx_t_5 = ((struct __pyx_vtabstruct_5spacy_6tokens_3doc_Doc *)__pyx_v_tokens->__pyx_vtab)->__pyx_fuse_0push_back(__pyx_v_tokens, ((__pyx_v_prefixes[0])[__pyx_v_i]), 0); if (unlikely(__pyx_t_5 == ((int)-1))) __PYX_ERR(0, 461, __pyx_L1_error)
    }

    /* "spacy/tokenizer.pyx":459
 *         cdef str span
 *         cdef int i
 *         if prefixes.size():             # <<<<<<<<<<<<<<
 *             for i in range(prefixes.size()):
 *                 tokens.push_back(prefixes[0][i], False)
 */
  }

  /* "spacy/tokenizer.pyx":462
 *             for i in range(prefixes.size()):
 *                 tokens.push_back(prefixes[0][i], False)
 *         if string:             # <<<<<<<<<<<<<<
 *             if self._try_specials_and_cache(hash_string(string), tokens, has_special, with_special_cases):
 *                 pass
 */
  __pyx_t_1 = __Pyx_PyObject_IsTrue(__pyx_v_string); if (unlikely(__pyx_t_1 < 0)) __PYX_ERR(0, 462, __pyx_L1_error)
  if (__pyx_t_1) {

    /* "spacy/tokenizer.pyx":463
 *                 tokens.push_back(prefixes[0][i], False)
 *         if string:
 *             if self._try_specials_and_cache(hash_string(string), tokens, has_special, with_special_cases):             # <<<<<<<<<<<<<<
 *                 pass
 *             elif (
 */
    __pyx_t_6 = __pyx_f_5spacy_7strings_hash_string(__pyx_v_string, 0); if (unlikely(__pyx_t_6 == ((__pyx_t_5spacy_8typedefs_hash_t)0))) __PYX_ERR(0, 463, __pyx_L1_error)
    __pyx_t_4 = ((struct __pyx_vtabstruct_5spacy_9tokenizer_Tokenizer *)__pyx_v_self->__pyx_vtab)->_try_specials_and_cache(__pyx_v_self, __pyx_t_6, __pyx_v_tokens, __pyx_v_has_special, __pyx_v_with_special_cases); if (unlikely(__pyx_t_4 == ((int)-1))) __PYX_ERR(0, 463, __pyx_L1_error)
    __pyx_t_1 = (__pyx_t_4 != 0);
    if (__pyx_t_1) {
      goto __pyx_L7;
    }

    /* "spacy/tokenizer.pyx":466
 *                 pass
 *             elif (
 *                 (self.token_match and self.token_match(string)) or             # <<<<<<<<<<<<<<
 *                 (self.url_match and self.url_match(string))
 *             ):
 */
    __pyx_t_7 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_token_match); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 466, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __pyx_t_8 = __Pyx_PyObject_IsTrue(__pyx_t_7); if (unlikely(__pyx_t_8 < 0)) __PYX_ERR(0, 466, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    if (!__pyx_t_8) {
      goto __pyx_L9_next_or;
    } else {
    }
    __pyx_t_9 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_token_match); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 466, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_9);
    __pyx_t_10 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_9))) {
      __pyx_t_10 = PyMethod_GET_SELF(__pyx_t_9);
      if (likely(__pyx_t_10)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_9);
        __Pyx_INCREF(__pyx_t_10);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_9, function);
      }
    }
    __pyx_t_7 = (__pyx_t_10) ? __Pyx_PyObject_Call2Args(__pyx_t_9, __pyx_t_10, __pyx_v_string) : __Pyx_PyObject_CallOneArg(__pyx_t_9, __pyx_v_string);
    __Pyx_XDECREF(__pyx_t_10); __pyx_t_10 = 0;
    if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 466, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
    __pyx_t_8 = __Pyx_PyObject_IsTrue(__pyx_t_7); if (unlikely(__pyx_t_8 < 0)) __PYX_ERR(0, 466, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    if (!__pyx_t_8) {
    } else {
      __pyx_t_1 = __pyx_t_8;
      goto __pyx_L8_bool_binop_done;
    }
    __pyx_L9_next_or:;

    /* "spacy/tokenizer.pyx":467
 *             elif (
 *                 (self.token_match and self.token_match(string)) or
 *                 (self.url_match and self.url_match(string))             # <<<<<<<<<<<<<<
 *             ):
 * 
 */
    __pyx_t_7 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_url_match); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 467, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __pyx_t_8 = __Pyx_PyObject_IsTrue(__pyx_t_7); if (unlikely(__pyx_t_8 < 0)) __PYX_ERR(0, 467, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    if (__pyx_t_8) {
    } else {
      __pyx_t_1 = __pyx_t_8;
      goto __pyx_L8_bool_binop_done;
    }
    __pyx_t_9 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_url_match); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 467, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_9);
    __pyx_t_10 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_9))) {
      __pyx_t_10 = PyMethod_GET_SELF(__pyx_t_9);
      if (likely(__pyx_t_10)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_9);
        __Pyx_INCREF(__pyx_t_10);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_9, function);
      }
    }
    __pyx_t_7 = (__pyx_t_10) ? __Pyx_PyObject_Call2Args(__pyx_t_9, __pyx_t_10, __pyx_v_string) : __Pyx_PyObject_CallOneArg(__pyx_t_9, __pyx_v_string);
    __Pyx_XDECREF(__pyx_t_10); __pyx_t_10 = 0;
    if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 467, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
    __pyx_t_8 = __Pyx_PyObject_IsTrue(__pyx_t_7); if (unlikely(__pyx_t_8 < 0)) __PYX_ERR(0, 467, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __pyx_t_1 = __pyx_t_8;
    __pyx_L8_bool_binop_done:;

    /* "spacy/tokenizer.pyx":465
 *             if self._try_specials_and_cache(hash_string(string), tokens, has_special, with_special_cases):
 *                 pass
 *             elif (             # <<<<<<<<<<<<<<
 *                 (self.token_match and self.token_match(string)) or
 *                 (self.url_match and self.url_match(string))
 */
    if (__pyx_t_1) {

      /* "spacy/tokenizer.pyx":473
 *                 # fix up the outermost one, with reference to the original.
 *                 # See Issue #859
 *                 tokens.push_back(self.vocab.get(tokens.mem, string), False)             # <<<<<<<<<<<<<<
 *             else:
 *                 matches = self.find_infix(string)
 */
      __pyx_t_7 = ((PyObject *)__pyx_v_tokens->mem);
      __Pyx_INCREF(__pyx_t_7);
      __pyx_t_11 = ((struct __pyx_vtabstruct_5spacy_5vocab_Vocab *)__pyx_v_self->vocab->__pyx_vtab)->get(__pyx_v_self->vocab, ((struct __pyx_obj_5cymem_5cymem_Pool *)__pyx_t_7), __pyx_v_string); if (unlikely(__pyx_t_11 == ((struct __pyx_t_5spacy_7structs_LexemeC const *)NULL))) __PYX_ERR(0, 473, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
      __pyx_t_4 = ((struct __pyx_vtabstruct_5spacy_6tokens_3doc_Doc *)__pyx_v_tokens->__pyx_vtab)->__pyx_fuse_0push_back(__pyx_v_tokens, __pyx_t_11, 0); if (unlikely(__pyx_t_4 == ((int)-1))) __PYX_ERR(0, 473, __pyx_L1_error)

      /* "spacy/tokenizer.pyx":465
 *             if self._try_specials_and_cache(hash_string(string), tokens, has_special, with_special_cases):
 *                 pass
 *             elif (             # <<<<<<<<<<<<<<
 *                 (self.token_match and self.token_match(string)) or
 *                 (self.url_match and self.url_match(string))
 */
      goto __pyx_L7;
    }

    /* "spacy/tokenizer.pyx":475
 *                 tokens.push_back(self.vocab.get(tokens.mem, string), False)
 *             else:
 *                 matches = self.find_infix(string)             # <<<<<<<<<<<<<<
 *                 if not matches:
 *                     tokens.push_back(self.vocab.get(tokens.mem, string), False)
 */
    /*else*/ {
      __pyx_t_9 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_find_infix); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 475, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_9);
      __pyx_t_10 = NULL;
      if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_9))) {
        __pyx_t_10 = PyMethod_GET_SELF(__pyx_t_9);
        if (likely(__pyx_t_10)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_9);
          __Pyx_INCREF(__pyx_t_10);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_9, function);
        }
      }
      __pyx_t_7 = (__pyx_t_10) ? __Pyx_PyObject_Call2Args(__pyx_t_9, __pyx_t_10, __pyx_v_string) : __Pyx_PyObject_CallOneArg(__pyx_t_9, __pyx_v_string);
      __Pyx_XDECREF(__pyx_t_10); __pyx_t_10 = 0;
      if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 475, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_7);
      __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
      __pyx_v_matches = __pyx_t_7;
      __pyx_t_7 = 0;

      /* "spacy/tokenizer.pyx":476
 *             else:
 *                 matches = self.find_infix(string)
 *                 if not matches:             # <<<<<<<<<<<<<<
 *                     tokens.push_back(self.vocab.get(tokens.mem, string), False)
 *                 else:
 */
      __pyx_t_1 = __Pyx_PyObject_IsTrue(__pyx_v_matches); if (unlikely(__pyx_t_1 < 0)) __PYX_ERR(0, 476, __pyx_L1_error)
      __pyx_t_8 = ((!__pyx_t_1) != 0);
      if (__pyx_t_8) {

        /* "spacy/tokenizer.pyx":477
 *                 matches = self.find_infix(string)
 *                 if not matches:
 *                     tokens.push_back(self.vocab.get(tokens.mem, string), False)             # <<<<<<<<<<<<<<
 *                 else:
 *                     # Let's say we have dyn-o-mite-dave - the regex finds the
 */
        __pyx_t_7 = ((PyObject *)__pyx_v_tokens->mem);
        __Pyx_INCREF(__pyx_t_7);
        __pyx_t_11 = ((struct __pyx_vtabstruct_5spacy_5vocab_Vocab *)__pyx_v_self->vocab->__pyx_vtab)->get(__pyx_v_self->vocab, ((struct __pyx_obj_5cymem_5cymem_Pool *)__pyx_t_7), __pyx_v_string); if (unlikely(__pyx_t_11 == ((struct __pyx_t_5spacy_7structs_LexemeC const *)NULL))) __PYX_ERR(0, 477, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
        __pyx_t_4 = ((struct __pyx_vtabstruct_5spacy_6tokens_3doc_Doc *)__pyx_v_tokens->__pyx_vtab)->__pyx_fuse_0push_back(__pyx_v_tokens, __pyx_t_11, 0); if (unlikely(__pyx_t_4 == ((int)-1))) __PYX_ERR(0, 477, __pyx_L1_error)

        /* "spacy/tokenizer.pyx":476
 *             else:
 *                 matches = self.find_infix(string)
 *                 if not matches:             # <<<<<<<<<<<<<<
 *                     tokens.push_back(self.vocab.get(tokens.mem, string), False)
 *                 else:
 */
        goto __pyx_L12;
      }

      /* "spacy/tokenizer.pyx":481
 *                     # Let's say we have dyn-o-mite-dave - the regex finds the
 *                     # start and end positions of the hyphens
 *                     start = 0             # <<<<<<<<<<<<<<
 *                     start_before_infixes = start
 *                     for match in matches:
 */
      /*else*/ {
        __Pyx_INCREF(__pyx_int_0);
        __pyx_v_start = __pyx_int_0;

        /* "spacy/tokenizer.pyx":482
 *                     # start and end positions of the hyphens
 *                     start = 0
 *                     start_before_infixes = start             # <<<<<<<<<<<<<<
 *                     for match in matches:
 *                         infix_start = match.start()
 */
        __pyx_t_12 = __Pyx_PyInt_As_long(__pyx_v_start); if (unlikely((__pyx_t_12 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 482, __pyx_L1_error)
        __pyx_v_start_before_infixes = __pyx_t_12;

        /* "spacy/tokenizer.pyx":483
 *                     start = 0
 *                     start_before_infixes = start
 *                     for match in matches:             # <<<<<<<<<<<<<<
 *                         infix_start = match.start()
 *                         infix_end = match.end()
 */
        if (likely(PyList_CheckExact(__pyx_v_matches)) || PyTuple_CheckExact(__pyx_v_matches)) {
          __pyx_t_7 = __pyx_v_matches; __Pyx_INCREF(__pyx_t_7); __pyx_t_13 = 0;
          __pyx_t_14 = NULL;
        } else {
          __pyx_t_13 = -1; __pyx_t_7 = PyObject_GetIter(__pyx_v_matches); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 483, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_7);
          __pyx_t_14 = Py_TYPE(__pyx_t_7)->tp_iternext; if (unlikely(!__pyx_t_14)) __PYX_ERR(0, 483, __pyx_L1_error)
        }
        for (;;) {
          if (likely(!__pyx_t_14)) {
            if (likely(PyList_CheckExact(__pyx_t_7))) {
              if (__pyx_t_13 >= PyList_GET_SIZE(__pyx_t_7)) break;
              #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
              __pyx_t_9 = PyList_GET_ITEM(__pyx_t_7, __pyx_t_13); __Pyx_INCREF(__pyx_t_9); __pyx_t_13++; if (unlikely(0 < 0)) __PYX_ERR(0, 483, __pyx_L1_error)
              #else
              __pyx_t_9 = PySequence_ITEM(__pyx_t_7, __pyx_t_13); __pyx_t_13++; if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 483, __pyx_L1_error)
              __Pyx_GOTREF(__pyx_t_9);
              #endif
            } else {
              if (__pyx_t_13 >= PyTuple_GET_SIZE(__pyx_t_7)) break;
              #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
              __pyx_t_9 = PyTuple_GET_ITEM(__pyx_t_7, __pyx_t_13); __Pyx_INCREF(__pyx_t_9); __pyx_t_13++; if (unlikely(0 < 0)) __PYX_ERR(0, 483, __pyx_L1_error)
              #else
              __pyx_t_9 = PySequence_ITEM(__pyx_t_7, __pyx_t_13); __pyx_t_13++; if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 483, __pyx_L1_error)
              __Pyx_GOTREF(__pyx_t_9);
              #endif
            }
          } else {
            __pyx_t_9 = __pyx_t_14(__pyx_t_7);
            if (unlikely(!__pyx_t_9)) {
              PyObject* exc_type = PyErr_Occurred();
              if (exc_type) {
                if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
                else __PYX_ERR(0, 483, __pyx_L1_error)
              }
              break;
            }
            __Pyx_GOTREF(__pyx_t_9);
          }
          __Pyx_XDECREF_SET(__pyx_v_match, __pyx_t_9);
          __pyx_t_9 = 0;

          /* "spacy/tokenizer.pyx":484
 *                     start_before_infixes = start
 *                     for match in matches:
 *                         infix_start = match.start()             # <<<<<<<<<<<<<<
 *                         infix_end = match.end()
 * 
 */
          __pyx_t_10 = __Pyx_PyObject_GetAttrStr(__pyx_v_match, __pyx_n_s_start); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 484, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_10);
          __pyx_t_15 = NULL;
          if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_10))) {
            __pyx_t_15 = PyMethod_GET_SELF(__pyx_t_10);
            if (likely(__pyx_t_15)) {
              PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_10);
              __Pyx_INCREF(__pyx_t_15);
              __Pyx_INCREF(function);
              __Pyx_DECREF_SET(__pyx_t_10, function);
            }
          }
          __pyx_t_9 = (__pyx_t_15) ? __Pyx_PyObject_CallOneArg(__pyx_t_10, __pyx_t_15) : __Pyx_PyObject_CallNoArg(__pyx_t_10);
          __Pyx_XDECREF(__pyx_t_15); __pyx_t_15 = 0;
          if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 484, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_9);
          __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
          __Pyx_XDECREF_SET(__pyx_v_infix_start, __pyx_t_9);
          __pyx_t_9 = 0;

          /* "spacy/tokenizer.pyx":485
 *                     for match in matches:
 *                         infix_start = match.start()
 *                         infix_end = match.end()             # <<<<<<<<<<<<<<
 * 
 *                         if infix_start == start_before_infixes:
 */
          __pyx_t_10 = __Pyx_PyObject_GetAttrStr(__pyx_v_match, __pyx_n_s_end); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 485, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_10);
          __pyx_t_15 = NULL;
          if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_10))) {
            __pyx_t_15 = PyMethod_GET_SELF(__pyx_t_10);
            if (likely(__pyx_t_15)) {
              PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_10);
              __Pyx_INCREF(__pyx_t_15);
              __Pyx_INCREF(function);
              __Pyx_DECREF_SET(__pyx_t_10, function);
            }
          }
          __pyx_t_9 = (__pyx_t_15) ? __Pyx_PyObject_CallOneArg(__pyx_t_10, __pyx_t_15) : __Pyx_PyObject_CallNoArg(__pyx_t_10);
          __Pyx_XDECREF(__pyx_t_15); __pyx_t_15 = 0;
          if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 485, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_9);
          __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
          __Pyx_XDECREF_SET(__pyx_v_infix_end, __pyx_t_9);
          __pyx_t_9 = 0;

          /* "spacy/tokenizer.pyx":487
 *                         infix_end = match.end()
 * 
 *                         if infix_start == start_before_infixes:             # <<<<<<<<<<<<<<
 *                             continue
 * 
 */
          __pyx_t_9 = __Pyx_PyInt_From_long(__pyx_v_start_before_infixes); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 487, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_9);
          __pyx_t_10 = PyObject_RichCompare(__pyx_v_infix_start, __pyx_t_9, Py_EQ); __Pyx_XGOTREF(__pyx_t_10); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 487, __pyx_L1_error)
          __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
          __pyx_t_8 = __Pyx_PyObject_IsTrue(__pyx_t_10); if (unlikely(__pyx_t_8 < 0)) __PYX_ERR(0, 487, __pyx_L1_error)
          __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
          if (__pyx_t_8) {

            /* "spacy/tokenizer.pyx":488
 * 
 *                         if infix_start == start_before_infixes:
 *                             continue             # <<<<<<<<<<<<<<
 * 
 *                         if infix_start != start:
 */
            goto __pyx_L13_continue;

            /* "spacy/tokenizer.pyx":487
 *                         infix_end = match.end()
 * 
 *                         if infix_start == start_before_infixes:             # <<<<<<<<<<<<<<
 *                             continue
 * 
 */
          }

          /* "spacy/tokenizer.pyx":490
 *                             continue
 * 
 *                         if infix_start != start:             # <<<<<<<<<<<<<<
 *                             span = string[start:infix_start]
 *                             tokens.push_back(self.vocab.get(tokens.mem, span), False)
 */
          __pyx_t_10 = PyObject_RichCompare(__pyx_v_infix_start, __pyx_v_start, Py_NE); __Pyx_XGOTREF(__pyx_t_10); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 490, __pyx_L1_error)
          __pyx_t_8 = __Pyx_PyObject_IsTrue(__pyx_t_10); if (unlikely(__pyx_t_8 < 0)) __PYX_ERR(0, 490, __pyx_L1_error)
          __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
          if (__pyx_t_8) {

            /* "spacy/tokenizer.pyx":491
 * 
 *                         if infix_start != start:
 *                             span = string[start:infix_start]             # <<<<<<<<<<<<<<
 *                             tokens.push_back(self.vocab.get(tokens.mem, span), False)
 * 
 */
            if (unlikely(__pyx_v_string == Py_None)) {
              PyErr_SetString(PyExc_TypeError, "'NoneType' object is not subscriptable");
              __PYX_ERR(0, 491, __pyx_L1_error)
            }
            __Pyx_INCREF(__pyx_v_start);
            __pyx_t_10 = __pyx_v_start;
            __pyx_t_8 = (__pyx_t_10 == Py_None);
            if (__pyx_t_8) {
              __pyx_t_16 = 0;
            } else {
              __pyx_t_17 = __Pyx_PyIndex_AsSsize_t(__pyx_t_10); if (unlikely((__pyx_t_17 == (Py_ssize_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 491, __pyx_L1_error)
              __pyx_t_16 = __pyx_t_17;
            }
            __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
            __Pyx_INCREF(__pyx_v_infix_start);
            __pyx_t_10 = __pyx_v_infix_start;
            __pyx_t_8 = (__pyx_t_10 == Py_None);
            if (__pyx_t_8) {
              __pyx_t_17 = PY_SSIZE_T_MAX;
            } else {
              __pyx_t_18 = __Pyx_PyIndex_AsSsize_t(__pyx_t_10); if (unlikely((__pyx_t_18 == (Py_ssize_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 491, __pyx_L1_error)
              __pyx_t_17 = __pyx_t_18;
            }
            __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
            __pyx_t_10 = PySequence_GetSlice(__pyx_v_string, __pyx_t_16, __pyx_t_17); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 491, __pyx_L1_error)
            __Pyx_GOTREF(__pyx_t_10);
            __Pyx_XDECREF_SET(__pyx_v_span, ((PyObject*)__pyx_t_10));
            __pyx_t_10 = 0;

            /* "spacy/tokenizer.pyx":492
 *                         if infix_start != start:
 *                             span = string[start:infix_start]
 *                             tokens.push_back(self.vocab.get(tokens.mem, span), False)             # <<<<<<<<<<<<<<
 * 
 *                         if infix_start != infix_end:
 */
            __pyx_t_10 = ((PyObject *)__pyx_v_tokens->mem);
            __Pyx_INCREF(__pyx_t_10);
            __pyx_t_11 = ((struct __pyx_vtabstruct_5spacy_5vocab_Vocab *)__pyx_v_self->vocab->__pyx_vtab)->get(__pyx_v_self->vocab, ((struct __pyx_obj_5cymem_5cymem_Pool *)__pyx_t_10), __pyx_v_span); if (unlikely(__pyx_t_11 == ((struct __pyx_t_5spacy_7structs_LexemeC const *)NULL))) __PYX_ERR(0, 492, __pyx_L1_error)
            __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
            __pyx_t_4 = ((struct __pyx_vtabstruct_5spacy_6tokens_3doc_Doc *)__pyx_v_tokens->__pyx_vtab)->__pyx_fuse_0push_back(__pyx_v_tokens, __pyx_t_11, 0); if (unlikely(__pyx_t_4 == ((int)-1))) __PYX_ERR(0, 492, __pyx_L1_error)

            /* "spacy/tokenizer.pyx":490
 *                             continue
 * 
 *                         if infix_start != start:             # <<<<<<<<<<<<<<
 *                             span = string[start:infix_start]
 *                             tokens.push_back(self.vocab.get(tokens.mem, span), False)
 */
          }

          /* "spacy/tokenizer.pyx":494
 *                             tokens.push_back(self.vocab.get(tokens.mem, span), False)
 * 
 *                         if infix_start != infix_end:             # <<<<<<<<<<<<<<
 *                             # If infix_start != infix_end, it means the infix
 *                             # token is non-empty. Empty infix tokens are useful
 */
          __pyx_t_10 = PyObject_RichCompare(__pyx_v_infix_start, __pyx_v_infix_end, Py_NE); __Pyx_XGOTREF(__pyx_t_10); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 494, __pyx_L1_error)
          __pyx_t_8 = __Pyx_PyObject_IsTrue(__pyx_t_10); if (unlikely(__pyx_t_8 < 0)) __PYX_ERR(0, 494, __pyx_L1_error)
          __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
          if (__pyx_t_8) {

            /* "spacy/tokenizer.pyx":499
 *                             # for tokenization in some languages (see
 *                             # https://github.com/explosion/spaCy/issues/768)
 *                             infix_span = string[infix_start:infix_end]             # <<<<<<<<<<<<<<
 *                             tokens.push_back(self.vocab.get(tokens.mem, infix_span), False)
 *                         start = infix_end
 */
            if (unlikely(__pyx_v_string == Py_None)) {
              PyErr_SetString(PyExc_TypeError, "'NoneType' object is not subscriptable");
              __PYX_ERR(0, 499, __pyx_L1_error)
            }
            __Pyx_INCREF(__pyx_v_infix_start);
            __pyx_t_10 = __pyx_v_infix_start;
            __pyx_t_8 = (__pyx_t_10 == Py_None);
            if (__pyx_t_8) {
              __pyx_t_17 = 0;
            } else {
              __pyx_t_16 = __Pyx_PyIndex_AsSsize_t(__pyx_t_10); if (unlikely((__pyx_t_16 == (Py_ssize_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 499, __pyx_L1_error)
              __pyx_t_17 = __pyx_t_16;
            }
            __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
            __Pyx_INCREF(__pyx_v_infix_end);
            __pyx_t_10 = __pyx_v_infix_end;
            __pyx_t_8 = (__pyx_t_10 == Py_None);
            if (__pyx_t_8) {
              __pyx_t_16 = PY_SSIZE_T_MAX;
            } else {
              __pyx_t_18 = __Pyx_PyIndex_AsSsize_t(__pyx_t_10); if (unlikely((__pyx_t_18 == (Py_ssize_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 499, __pyx_L1_error)
              __pyx_t_16 = __pyx_t_18;
            }
            __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
            __pyx_t_10 = PySequence_GetSlice(__pyx_v_string, __pyx_t_17, __pyx_t_16); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 499, __pyx_L1_error)
            __Pyx_GOTREF(__pyx_t_10);
            __Pyx_XDECREF_SET(__pyx_v_infix_span, __pyx_t_10);
            __pyx_t_10 = 0;

            /* "spacy/tokenizer.pyx":500
 *                             # https://github.com/explosion/spaCy/issues/768)
 *                             infix_span = string[infix_start:infix_end]
 *                             tokens.push_back(self.vocab.get(tokens.mem, infix_span), False)             # <<<<<<<<<<<<<<
 *                         start = infix_end
 *                     span = string[start:]
 */
            __pyx_t_10 = ((PyObject *)__pyx_v_tokens->mem);
            __Pyx_INCREF(__pyx_t_10);
            if (!(likely(PyString_CheckExact(__pyx_v_infix_span))||((void)PyErr_Format(PyExc_TypeError, "Expected %.16s, got %.200s", "str", Py_TYPE(__pyx_v_infix_span)->tp_name), 0))) __PYX_ERR(0, 500, __pyx_L1_error)
            __pyx_t_11 = ((struct __pyx_vtabstruct_5spacy_5vocab_Vocab *)__pyx_v_self->vocab->__pyx_vtab)->get(__pyx_v_self->vocab, ((struct __pyx_obj_5cymem_5cymem_Pool *)__pyx_t_10), ((PyObject*)__pyx_v_infix_span)); if (unlikely(__pyx_t_11 == ((struct __pyx_t_5spacy_7structs_LexemeC const *)NULL))) __PYX_ERR(0, 500, __pyx_L1_error)
            __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
            __pyx_t_4 = ((struct __pyx_vtabstruct_5spacy_6tokens_3doc_Doc *)__pyx_v_tokens->__pyx_vtab)->__pyx_fuse_0push_back(__pyx_v_tokens, __pyx_t_11, 0); if (unlikely(__pyx_t_4 == ((int)-1))) __PYX_ERR(0, 500, __pyx_L1_error)

            /* "spacy/tokenizer.pyx":494
 *                             tokens.push_back(self.vocab.get(tokens.mem, span), False)
 * 
 *                         if infix_start != infix_end:             # <<<<<<<<<<<<<<
 *                             # If infix_start != infix_end, it means the infix
 *                             # token is non-empty. Empty infix tokens are useful
 */
          }

          /* "spacy/tokenizer.pyx":501
 *                             infix_span = string[infix_start:infix_end]
 *                             tokens.push_back(self.vocab.get(tokens.mem, infix_span), False)
 *                         start = infix_end             # <<<<<<<<<<<<<<
 *                     span = string[start:]
 *                     if span:
 */
          __Pyx_INCREF(__pyx_v_infix_end);
          __Pyx_DECREF_SET(__pyx_v_start, __pyx_v_infix_end);

          /* "spacy/tokenizer.pyx":483
 *                     start = 0
 *                     start_before_infixes = start
 *                     for match in matches:             # <<<<<<<<<<<<<<
 *                         infix_start = match.start()
 *                         infix_end = match.end()
 */
          __pyx_L13_continue:;
        }
        __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;

        /* "spacy/tokenizer.pyx":502
 *                             tokens.push_back(self.vocab.get(tokens.mem, infix_span), False)
 *                         start = infix_end
 *                     span = string[start:]             # <<<<<<<<<<<<<<
 *                     if span:
 *                         tokens.push_back(self.vocab.get(tokens.mem, span), False)
 */
        if (unlikely(__pyx_v_string == Py_None)) {
          PyErr_SetString(PyExc_TypeError, "'NoneType' object is not subscriptable");
          __PYX_ERR(0, 502, __pyx_L1_error)
        }
        __Pyx_INCREF(__pyx_v_start);
        __pyx_t_7 = __pyx_v_start;
        __pyx_t_8 = (__pyx_t_7 == Py_None);
        if (__pyx_t_8) {
          __pyx_t_13 = 0;
        } else {
          __pyx_t_16 = __Pyx_PyIndex_AsSsize_t(__pyx_t_7); if (unlikely((__pyx_t_16 == (Py_ssize_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 502, __pyx_L1_error)
          __pyx_t_13 = __pyx_t_16;
        }
        __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
        __pyx_t_7 = PySequence_GetSlice(__pyx_v_string, __pyx_t_13, PY_SSIZE_T_MAX); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 502, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_7);
        __Pyx_XDECREF_SET(__pyx_v_span, ((PyObject*)__pyx_t_7));
        __pyx_t_7 = 0;

        /* "spacy/tokenizer.pyx":503
 *                         start = infix_end
 *                     span = string[start:]
 *                     if span:             # <<<<<<<<<<<<<<
 *                         tokens.push_back(self.vocab.get(tokens.mem, span), False)
 *         cdef vector[const LexemeC*].reverse_iterator it = suffixes.rbegin()
 */
        __pyx_t_8 = __Pyx_PyObject_IsTrue(__pyx_v_span); if (unlikely(__pyx_t_8 < 0)) __PYX_ERR(0, 503, __pyx_L1_error)
        if (__pyx_t_8) {

          /* "spacy/tokenizer.pyx":504
 *                     span = string[start:]
 *                     if span:
 *                         tokens.push_back(self.vocab.get(tokens.mem, span), False)             # <<<<<<<<<<<<<<
 *         cdef vector[const LexemeC*].reverse_iterator it = suffixes.rbegin()
 *         while it != suffixes.rend():
 */
          __pyx_t_7 = ((PyObject *)__pyx_v_tokens->mem);
          __Pyx_INCREF(__pyx_t_7);
          __pyx_t_11 = ((struct __pyx_vtabstruct_5spacy_5vocab_Vocab *)__pyx_v_self->vocab->__pyx_vtab)->get(__pyx_v_self->vocab, ((struct __pyx_obj_5cymem_5cymem_Pool *)__pyx_t_7), __pyx_v_span); if (unlikely(__pyx_t_11 == ((struct __pyx_t_5spacy_7structs_LexemeC const *)NULL))) __PYX_ERR(0, 504, __pyx_L1_error)
          __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
          __pyx_t_4 = ((struct __pyx_vtabstruct_5spacy_6tokens_3doc_Doc *)__pyx_v_tokens->__pyx_vtab)->__pyx_fuse_0push_back(__pyx_v_tokens, __pyx_t_11, 0); if (unlikely(__pyx_t_4 == ((int)-1))) __PYX_ERR(0, 504, __pyx_L1_error)

          /* "spacy/tokenizer.pyx":503
 *                         start = infix_end
 *                     span = string[start:]
 *                     if span:             # <<<<<<<<<<<<<<
 *                         tokens.push_back(self.vocab.get(tokens.mem, span), False)
 *         cdef vector[const LexemeC*].reverse_iterator it = suffixes.rbegin()
 */
        }
      }
      __pyx_L12:;
    }
    __pyx_L7:;

    /* "spacy/tokenizer.pyx":462
 *             for i in range(prefixes.size()):
 *                 tokens.push_back(prefixes[0][i], False)
 *         if string:             # <<<<<<<<<<<<<<
 *             if self._try_specials_and_cache(hash_string(string), tokens, has_special, with_special_cases):
 *                 pass
 */
  }

  /* "spacy/tokenizer.pyx":505
 *                     if span:
 *                         tokens.push_back(self.vocab.get(tokens.mem, span), False)
 *         cdef vector[const LexemeC*].reverse_iterator it = suffixes.rbegin()             # <<<<<<<<<<<<<<
 *         while it != suffixes.rend():
 *             lexeme = deref(it)
 */
  __pyx_v_it = __pyx_v_suffixes->rbegin();

  /* "spacy/tokenizer.pyx":506
 *                         tokens.push_back(self.vocab.get(tokens.mem, span), False)
 *         cdef vector[const LexemeC*].reverse_iterator it = suffixes.rbegin()
 *         while it != suffixes.rend():             # <<<<<<<<<<<<<<
 *             lexeme = deref(it)
 *             preinc(it)
 */
  while (1) {
    __pyx_t_8 = ((__pyx_v_it != __pyx_v_suffixes->rend()) != 0);
    if (!__pyx_t_8) break;

    /* "spacy/tokenizer.pyx":507
 *         cdef vector[const LexemeC*].reverse_iterator it = suffixes.rbegin()
 *         while it != suffixes.rend():
 *             lexeme = deref(it)             # <<<<<<<<<<<<<<
 *             preinc(it)
 *             tokens.push_back(lexeme, False)
 */
    __pyx_v_lexeme = (*__pyx_v_it);

    /* "spacy/tokenizer.pyx":508
 *         while it != suffixes.rend():
 *             lexeme = deref(it)
 *             preinc(it)             # <<<<<<<<<<<<<<
 *             tokens.push_back(lexeme, False)
 * 
 */
    (void)((++__pyx_v_it));

    /* "spacy/tokenizer.pyx":509
 *             lexeme = deref(it)
 *             preinc(it)
 *             tokens.push_back(lexeme, False)             # <<<<<<<<<<<<<<
 * 
 *     cdef int _save_cached(self, const TokenC* tokens, hash_t key,
 */
    __pyx_t_4 = ((struct __pyx_vtabstruct_5spacy_6tokens_3doc_Doc *)__pyx_v_tokens->__pyx_vtab)->__pyx_fuse_0push_back(__pyx_v_tokens, __pyx_v_lexeme, 0); if (unlikely(__pyx_t_4 == ((int)-1))) __PYX_ERR(0, 509, __pyx_L1_error)
  }

  /* "spacy/tokenizer.pyx":451
 *         return string
 * 
 *     cdef int _attach_tokens(self, Doc tokens, str string,             # <<<<<<<<<<<<<<
 *                             vector[const LexemeC*] *prefixes,
 *                             vector[const LexemeC*] *suffixes,
 */

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_XDECREF(__pyx_t_9);
  __Pyx_XDECREF(__pyx_t_10);
  __Pyx_XDECREF(__pyx_t_15);
  __Pyx_AddTraceback("spacy.tokenizer.Tokenizer._attach_tokens", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_span);
  __Pyx_XDECREF(__pyx_v_matches);
  __Pyx_XDECREF(__pyx_v_start);
  __Pyx_XDECREF(__pyx_v_match);
  __Pyx_XDECREF(__pyx_v_infix_start);
  __Pyx_XDECREF(__pyx_v_infix_end);
  __Pyx_XDECREF(__pyx_v_infix_span);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "spacy/tokenizer.pyx":511
 *             tokens.push_back(lexeme, False)
 * 
 *     cdef int _save_cached(self, const TokenC* tokens, hash_t key,             # <<<<<<<<<<<<<<
 *                           int* has_special, int n) except -1:
 *         cdef int i
 */

static int __pyx_f_5spacy_9tokenizer_9Tokenizer__save_cached(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *__pyx_v_self, struct __pyx_t_5spacy_7structs_TokenC const *__pyx_v_tokens, __pyx_t_5spacy_8typedefs_hash_t __pyx_v_key, int *__pyx_v_has_special, int __pyx_v_n) {
  int __pyx_v_i;
  struct __pyx_t_5spacy_5vocab__Cached *__pyx_v_cached;
  struct __pyx_t_5spacy_7structs_LexemeC const **__pyx_v_lexemes;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  int __pyx_t_2;
  int __pyx_t_3;
  int __pyx_t_4;
  void *__pyx_t_5;
  struct __pyx_t_5spacy_7structs_LexemeC const *__pyx_t_6;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("_save_cached", 0);

  /* "spacy/tokenizer.pyx":514
 *                           int* has_special, int n) except -1:
 *         cdef int i
 *         if n <= 0:             # <<<<<<<<<<<<<<
 *             # avoid mem alloc of zero length
 *             return 0
 */
  __pyx_t_1 = ((__pyx_v_n <= 0) != 0);
  if (__pyx_t_1) {

    /* "spacy/tokenizer.pyx":516
 *         if n <= 0:
 *             # avoid mem alloc of zero length
 *             return 0             # <<<<<<<<<<<<<<
 *         for i in range(n):
 *             if self.vocab._by_orth.get(tokens[i].lex.orth) == NULL:
 */
    __pyx_r = 0;
    goto __pyx_L0;

    /* "spacy/tokenizer.pyx":514
 *                           int* has_special, int n) except -1:
 *         cdef int i
 *         if n <= 0:             # <<<<<<<<<<<<<<
 *             # avoid mem alloc of zero length
 *             return 0
 */
  }

  /* "spacy/tokenizer.pyx":517
 *             # avoid mem alloc of zero length
 *             return 0
 *         for i in range(n):             # <<<<<<<<<<<<<<
 *             if self.vocab._by_orth.get(tokens[i].lex.orth) == NULL:
 *                 return 0
 */
  __pyx_t_2 = __pyx_v_n;
  __pyx_t_3 = __pyx_t_2;
  for (__pyx_t_4 = 0; __pyx_t_4 < __pyx_t_3; __pyx_t_4+=1) {
    __pyx_v_i = __pyx_t_4;

    /* "spacy/tokenizer.pyx":518
 *             return 0
 *         for i in range(n):
 *             if self.vocab._by_orth.get(tokens[i].lex.orth) == NULL:             # <<<<<<<<<<<<<<
 *                 return 0
 *         # See #1250
 */
    __pyx_t_1 = ((((struct __pyx_vtabstruct_7preshed_4maps_PreshMap *)__pyx_v_self->vocab->_by_orth->__pyx_vtab)->get(__pyx_v_self->vocab->_by_orth, (__pyx_v_tokens[__pyx_v_i]).lex->orth) == NULL) != 0);
    if (__pyx_t_1) {

      /* "spacy/tokenizer.pyx":519
 *         for i in range(n):
 *             if self.vocab._by_orth.get(tokens[i].lex.orth) == NULL:
 *                 return 0             # <<<<<<<<<<<<<<
 *         # See #1250
 *         if has_special[0]:
 */
      __pyx_r = 0;
      goto __pyx_L0;

      /* "spacy/tokenizer.pyx":518
 *             return 0
 *         for i in range(n):
 *             if self.vocab._by_orth.get(tokens[i].lex.orth) == NULL:             # <<<<<<<<<<<<<<
 *                 return 0
 *         # See #1250
 */
    }
  }

  /* "spacy/tokenizer.pyx":521
 *                 return 0
 *         # See #1250
 *         if has_special[0]:             # <<<<<<<<<<<<<<
 *             return 0
 *         cached = <_Cached*>self.mem.alloc(1, sizeof(_Cached))
 */
  __pyx_t_1 = ((__pyx_v_has_special[0]) != 0);
  if (__pyx_t_1) {

    /* "spacy/tokenizer.pyx":522
 *         # See #1250
 *         if has_special[0]:
 *             return 0             # <<<<<<<<<<<<<<
 *         cached = <_Cached*>self.mem.alloc(1, sizeof(_Cached))
 *         cached.length = n
 */
    __pyx_r = 0;
    goto __pyx_L0;

    /* "spacy/tokenizer.pyx":521
 *                 return 0
 *         # See #1250
 *         if has_special[0]:             # <<<<<<<<<<<<<<
 *             return 0
 *         cached = <_Cached*>self.mem.alloc(1, sizeof(_Cached))
 */
  }

  /* "spacy/tokenizer.pyx":523
 *         if has_special[0]:
 *             return 0
 *         cached = <_Cached*>self.mem.alloc(1, sizeof(_Cached))             # <<<<<<<<<<<<<<
 *         cached.length = n
 *         cached.is_lex = True
 */
  __pyx_t_5 = ((struct __pyx_vtabstruct_5cymem_5cymem_Pool *)__pyx_v_self->mem->__pyx_vtab)->alloc(__pyx_v_self->mem, 1, (sizeof(struct __pyx_t_5spacy_5vocab__Cached))); if (unlikely(__pyx_t_5 == ((void *)NULL))) __PYX_ERR(0, 523, __pyx_L1_error)
  __pyx_v_cached = ((struct __pyx_t_5spacy_5vocab__Cached *)__pyx_t_5);

  /* "spacy/tokenizer.pyx":524
 *             return 0
 *         cached = <_Cached*>self.mem.alloc(1, sizeof(_Cached))
 *         cached.length = n             # <<<<<<<<<<<<<<
 *         cached.is_lex = True
 *         lexemes = <const LexemeC**>self.mem.alloc(n, sizeof(LexemeC**))
 */
  __pyx_v_cached->length = __pyx_v_n;

  /* "spacy/tokenizer.pyx":525
 *         cached = <_Cached*>self.mem.alloc(1, sizeof(_Cached))
 *         cached.length = n
 *         cached.is_lex = True             # <<<<<<<<<<<<<<
 *         lexemes = <const LexemeC**>self.mem.alloc(n, sizeof(LexemeC**))
 *         for i in range(n):
 */
  __pyx_v_cached->is_lex = 1;

  /* "spacy/tokenizer.pyx":526
 *         cached.length = n
 *         cached.is_lex = True
 *         lexemes = <const LexemeC**>self.mem.alloc(n, sizeof(LexemeC**))             # <<<<<<<<<<<<<<
 *         for i in range(n):
 *             lexemes[i] = tokens[i].lex
 */
  __pyx_t_5 = ((struct __pyx_vtabstruct_5cymem_5cymem_Pool *)__pyx_v_self->mem->__pyx_vtab)->alloc(__pyx_v_self->mem, __pyx_v_n, (sizeof(struct __pyx_t_5spacy_7structs_LexemeC **))); if (unlikely(__pyx_t_5 == ((void *)NULL))) __PYX_ERR(0, 526, __pyx_L1_error)
  __pyx_v_lexemes = ((struct __pyx_t_5spacy_7structs_LexemeC const **)__pyx_t_5);

  /* "spacy/tokenizer.pyx":527
 *         cached.is_lex = True
 *         lexemes = <const LexemeC**>self.mem.alloc(n, sizeof(LexemeC**))
 *         for i in range(n):             # <<<<<<<<<<<<<<
 *             lexemes[i] = tokens[i].lex
 *         cached.data.lexemes = <const LexemeC* const*>lexemes
 */
  __pyx_t_2 = __pyx_v_n;
  __pyx_t_3 = __pyx_t_2;
  for (__pyx_t_4 = 0; __pyx_t_4 < __pyx_t_3; __pyx_t_4+=1) {
    __pyx_v_i = __pyx_t_4;

    /* "spacy/tokenizer.pyx":528
 *         lexemes = <const LexemeC**>self.mem.alloc(n, sizeof(LexemeC**))
 *         for i in range(n):
 *             lexemes[i] = tokens[i].lex             # <<<<<<<<<<<<<<
 *         cached.data.lexemes = <const LexemeC* const*>lexemes
 *         self._cache.set(key, cached)
 */
    __pyx_t_6 = (__pyx_v_tokens[__pyx_v_i]).lex;
    (__pyx_v_lexemes[__pyx_v_i]) = __pyx_t_6;
  }

  /* "spacy/tokenizer.pyx":529
 *         for i in range(n):
 *             lexemes[i] = tokens[i].lex
 *         cached.data.lexemes = <const LexemeC* const*>lexemes             # <<<<<<<<<<<<<<
 *         self._cache.set(key, cached)
 * 
 */
  __pyx_v_cached->data.lexemes = ((struct __pyx_t_5spacy_7structs_LexemeC const *const *)__pyx_v_lexemes);

  /* "spacy/tokenizer.pyx":530
 *             lexemes[i] = tokens[i].lex
 *         cached.data.lexemes = <const LexemeC* const*>lexemes
 *         self._cache.set(key, cached)             # <<<<<<<<<<<<<<
 * 
 *     def find_infix(self, str string):
 */
  ((struct __pyx_vtabstruct_7preshed_4maps_PreshMap *)__pyx_v_self->_cache->__pyx_vtab)->set(__pyx_v_self->_cache, __pyx_v_key, __pyx_v_cached); if (unlikely(PyErr_Occurred())) __PYX_ERR(0, 530, __pyx_L1_error)

  /* "spacy/tokenizer.pyx":511
 *             tokens.push_back(lexeme, False)
 * 
 *     cdef int _save_cached(self, const TokenC* tokens, hash_t key,             # <<<<<<<<<<<<<<
 *                           int* has_special, int n) except -1:
 *         cdef int i
 */

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_AddTraceback("spacy.tokenizer.Tokenizer._save_cached", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "spacy/tokenizer.pyx":532
 *         self._cache.set(key, cached)
 * 
 *     def find_infix(self, str string):             # <<<<<<<<<<<<<<
 *         """Find internal split points of the string, such as hyphens.
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_5spacy_9tokenizer_9Tokenizer_16find_infix(PyObject *__pyx_v_self, PyObject *__pyx_v_string); /*proto*/
static char __pyx_doc_5spacy_9tokenizer_9Tokenizer_15find_infix[] = "Tokenizer.find_infix(self, str string)\nFind internal split points of the string, such as hyphens.\n\n        string (str): The string to segment.\n        RETURNS (list): A list of `re.MatchObject` objects that have `.start()`\n            and `.end()` methods, denoting the placement of internal segment\n            separators, e.g. hyphens.\n\n        DOCS: https://spacy.io/api/tokenizer#find_infix\n        ";
static PyMethodDef __pyx_mdef_5spacy_9tokenizer_9Tokenizer_16find_infix = {"find_infix", (PyCFunction)__pyx_pw_5spacy_9tokenizer_9Tokenizer_16find_infix, METH_O, __pyx_doc_5spacy_9tokenizer_9Tokenizer_15find_infix};
static PyObject *__pyx_pw_5spacy_9tokenizer_9Tokenizer_16find_infix(PyObject *__pyx_v_self, PyObject *__pyx_v_string) {
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("find_infix (wrapper)", 0);
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_string), (&PyString_Type), 1, "string", 1))) __PYX_ERR(0, 532, __pyx_L1_error)
  __pyx_r = __pyx_pf_5spacy_9tokenizer_9Tokenizer_15find_infix(((struct __pyx_obj_5spacy_9tokenizer_Tokenizer *)__pyx_v_self), ((PyObject*)__pyx_v_string));

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5spacy_9tokenizer_9Tokenizer_15find_infix(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *__pyx_v_self, PyObject *__pyx_v_string) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_t_2;
  int __pyx_t_3;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("find_infix", 0);

  /* "spacy/tokenizer.pyx":542
 *         DOCS: https://spacy.io/api/tokenizer#find_infix
 *         """
 *         if self.infix_finditer is None:             # <<<<<<<<<<<<<<
 *             return 0
 *         return list(self.infix_finditer(string))
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_infix_finditer); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 542, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = (__pyx_t_1 == Py_None);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_3 = (__pyx_t_2 != 0);
  if (__pyx_t_3) {

    /* "spacy/tokenizer.pyx":543
 *         """
 *         if self.infix_finditer is None:
 *             return 0             # <<<<<<<<<<<<<<
 *         return list(self.infix_finditer(string))
 * 
 */
    __Pyx_XDECREF(__pyx_r);
    __Pyx_INCREF(__pyx_int_0);
    __pyx_r = __pyx_int_0;
    goto __pyx_L0;

    /* "spacy/tokenizer.pyx":542
 *         DOCS: https://spacy.io/api/tokenizer#find_infix
 *         """
 *         if self.infix_finditer is None:             # <<<<<<<<<<<<<<
 *             return 0
 *         return list(self.infix_finditer(string))
 */
  }

  /* "spacy/tokenizer.pyx":544
 *         if self.infix_finditer is None:
 *             return 0
 *         return list(self.infix_finditer(string))             # <<<<<<<<<<<<<<
 * 
 *     def find_prefix(self, str string):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_4 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_infix_finditer); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 544, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_5 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_4))) {
    __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_4);
    if (likely(__pyx_t_5)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_4);
      __Pyx_INCREF(__pyx_t_5);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_4, function);
    }
  }
  __pyx_t_1 = (__pyx_t_5) ? __Pyx_PyObject_Call2Args(__pyx_t_4, __pyx_t_5, __pyx_v_string) : __Pyx_PyObject_CallOneArg(__pyx_t_4, __pyx_v_string);
  __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
  if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 544, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_4 = PySequence_List(__pyx_t_1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 544, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_r = __pyx_t_4;
  __pyx_t_4 = 0;
  goto __pyx_L0;

  /* "spacy/tokenizer.pyx":532
 *         self._cache.set(key, cached)
 * 
 *     def find_infix(self, str string):             # <<<<<<<<<<<<<<
 *         """Find internal split points of the string, such as hyphens.
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("spacy.tokenizer.Tokenizer.find_infix", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "spacy/tokenizer.pyx":546
 *         return list(self.infix_finditer(string))
 * 
 *     def find_prefix(self, str string):             # <<<<<<<<<<<<<<
 *         """Find the length of a prefix that should be segmented from the
 *         string, or None if no prefix rules match.
 */

/* Python wrapper */
static PyObject *__pyx_pw_5spacy_9tokenizer_9Tokenizer_18find_prefix(PyObject *__pyx_v_self, PyObject *__pyx_v_string); /*proto*/
static char __pyx_doc_5spacy_9tokenizer_9Tokenizer_17find_prefix[] = "Tokenizer.find_prefix(self, str string)\nFind the length of a prefix that should be segmented from the\n        string, or None if no prefix rules match.\n\n        string (str): The string to segment.\n        RETURNS (int): The length of the prefix if present, otherwise `None`.\n\n        DOCS: https://spacy.io/api/tokenizer#find_prefix\n        ";
static PyMethodDef __pyx_mdef_5spacy_9tokenizer_9Tokenizer_18find_prefix = {"find_prefix", (PyCFunction)__pyx_pw_5spacy_9tokenizer_9Tokenizer_18find_prefix, METH_O, __pyx_doc_5spacy_9tokenizer_9Tokenizer_17find_prefix};
static PyObject *__pyx_pw_5spacy_9tokenizer_9Tokenizer_18find_prefix(PyObject *__pyx_v_self, PyObject *__pyx_v_string) {
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("find_prefix (wrapper)", 0);
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_string), (&PyString_Type), 1, "string", 1))) __PYX_ERR(0, 546, __pyx_L1_error)
  __pyx_r = __pyx_pf_5spacy_9tokenizer_9Tokenizer_17find_prefix(((struct __pyx_obj_5spacy_9tokenizer_Tokenizer *)__pyx_v_self), ((PyObject*)__pyx_v_string));

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5spacy_9tokenizer_9Tokenizer_17find_prefix(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *__pyx_v_self, PyObject *__pyx_v_string) {
  PyObject *__pyx_v_match = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_t_2;
  int __pyx_t_3;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("find_prefix", 0);

  /* "spacy/tokenizer.pyx":555
 *         DOCS: https://spacy.io/api/tokenizer#find_prefix
 *         """
 *         if self.prefix_search is None:             # <<<<<<<<<<<<<<
 *             return 0
 *         match = self.prefix_search(string)
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_prefix_search); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 555, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = (__pyx_t_1 == Py_None);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_3 = (__pyx_t_2 != 0);
  if (__pyx_t_3) {

    /* "spacy/tokenizer.pyx":556
 *         """
 *         if self.prefix_search is None:
 *             return 0             # <<<<<<<<<<<<<<
 *         match = self.prefix_search(string)
 *         return (match.end() - match.start()) if match is not None else 0
 */
    __Pyx_XDECREF(__pyx_r);
    __Pyx_INCREF(__pyx_int_0);
    __pyx_r = __pyx_int_0;
    goto __pyx_L0;

    /* "spacy/tokenizer.pyx":555
 *         DOCS: https://spacy.io/api/tokenizer#find_prefix
 *         """
 *         if self.prefix_search is None:             # <<<<<<<<<<<<<<
 *             return 0
 *         match = self.prefix_search(string)
 */
  }

  /* "spacy/tokenizer.pyx":557
 *         if self.prefix_search is None:
 *             return 0
 *         match = self.prefix_search(string)             # <<<<<<<<<<<<<<
 *         return (match.end() - match.start()) if match is not None else 0
 * 
 */
  __pyx_t_4 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_prefix_search); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 557, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_5 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_4))) {
    __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_4);
    if (likely(__pyx_t_5)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_4);
      __Pyx_INCREF(__pyx_t_5);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_4, function);
    }
  }
  __pyx_t_1 = (__pyx_t_5) ? __Pyx_PyObject_Call2Args(__pyx_t_4, __pyx_t_5, __pyx_v_string) : __Pyx_PyObject_CallOneArg(__pyx_t_4, __pyx_v_string);
  __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
  if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 557, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_v_match = __pyx_t_1;
  __pyx_t_1 = 0;

  /* "spacy/tokenizer.pyx":558
 *             return 0
 *         match = self.prefix_search(string)
 *         return (match.end() - match.start()) if match is not None else 0             # <<<<<<<<<<<<<<
 * 
 *     def find_suffix(self, str string):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_3 = (__pyx_v_match != Py_None);
  if ((__pyx_t_3 != 0)) {
    __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_v_match, __pyx_n_s_end); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 558, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_6 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_5))) {
      __pyx_t_6 = PyMethod_GET_SELF(__pyx_t_5);
      if (likely(__pyx_t_6)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
        __Pyx_INCREF(__pyx_t_6);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_5, function);
      }
    }
    __pyx_t_4 = (__pyx_t_6) ? __Pyx_PyObject_CallOneArg(__pyx_t_5, __pyx_t_6) : __Pyx_PyObject_CallNoArg(__pyx_t_5);
    __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
    if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 558, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_v_match, __pyx_n_s_start); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 558, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_t_7 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_6))) {
      __pyx_t_7 = PyMethod_GET_SELF(__pyx_t_6);
      if (likely(__pyx_t_7)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_6);
        __Pyx_INCREF(__pyx_t_7);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_6, function);
      }
    }
    __pyx_t_5 = (__pyx_t_7) ? __Pyx_PyObject_CallOneArg(__pyx_t_6, __pyx_t_7) : __Pyx_PyObject_CallNoArg(__pyx_t_6);
    __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
    if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 558, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __pyx_t_6 = PyNumber_Subtract(__pyx_t_4, __pyx_t_5); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 558, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_1 = __pyx_t_6;
    __pyx_t_6 = 0;
  } else {
    __Pyx_INCREF(__pyx_int_0);
    __pyx_t_1 = __pyx_int_0;
  }
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "spacy/tokenizer.pyx":546
 *         return list(self.infix_finditer(string))
 * 
 *     def find_prefix(self, str string):             # <<<<<<<<<<<<<<
 *         """Find the length of a prefix that should be segmented from the
 *         string, or None if no prefix rules match.
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_AddTraceback("spacy.tokenizer.Tokenizer.find_prefix", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_match);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "spacy/tokenizer.pyx":560
 *         return (match.end() - match.start()) if match is not None else 0
 * 
 *     def find_suffix(self, str string):             # <<<<<<<<<<<<<<
 *         """Find the length of a suffix that should be segmented from the
 *         string, or None if no suffix rules match.
 */

/* Python wrapper */
static PyObject *__pyx_pw_5spacy_9tokenizer_9Tokenizer_20find_suffix(PyObject *__pyx_v_self, PyObject *__pyx_v_string); /*proto*/
static char __pyx_doc_5spacy_9tokenizer_9Tokenizer_19find_suffix[] = "Tokenizer.find_suffix(self, str string)\nFind the length of a suffix that should be segmented from the\n        string, or None if no suffix rules match.\n\n        string (str): The string to segment.\n        Returns (int): The length of the suffix if present, otherwise `None`.\n\n        DOCS: https://spacy.io/api/tokenizer#find_suffix\n        ";
static PyMethodDef __pyx_mdef_5spacy_9tokenizer_9Tokenizer_20find_suffix = {"find_suffix", (PyCFunction)__pyx_pw_5spacy_9tokenizer_9Tokenizer_20find_suffix, METH_O, __pyx_doc_5spacy_9tokenizer_9Tokenizer_19find_suffix};
static PyObject *__pyx_pw_5spacy_9tokenizer_9Tokenizer_20find_suffix(PyObject *__pyx_v_self, PyObject *__pyx_v_string) {
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("find_suffix (wrapper)", 0);
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_string), (&PyString_Type), 1, "string", 1))) __PYX_ERR(0, 560, __pyx_L1_error)
  __pyx_r = __pyx_pf_5spacy_9tokenizer_9Tokenizer_19find_suffix(((struct __pyx_obj_5spacy_9tokenizer_Tokenizer *)__pyx_v_self), ((PyObject*)__pyx_v_string));

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5spacy_9tokenizer_9Tokenizer_19find_suffix(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *__pyx_v_self, PyObject *__pyx_v_string) {
  PyObject *__pyx_v_match = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_t_2;
  int __pyx_t_3;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("find_suffix", 0);

  /* "spacy/tokenizer.pyx":569
 *         DOCS: https://spacy.io/api/tokenizer#find_suffix
 *         """
 *         if self.suffix_search is None:             # <<<<<<<<<<<<<<
 *             return 0
 *         match = self.suffix_search(string)
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_suffix_search); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 569, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = (__pyx_t_1 == Py_None);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_3 = (__pyx_t_2 != 0);
  if (__pyx_t_3) {

    /* "spacy/tokenizer.pyx":570
 *         """
 *         if self.suffix_search is None:
 *             return 0             # <<<<<<<<<<<<<<
 *         match = self.suffix_search(string)
 *         return (match.end() - match.start()) if match is not None else 0
 */
    __Pyx_XDECREF(__pyx_r);
    __Pyx_INCREF(__pyx_int_0);
    __pyx_r = __pyx_int_0;
    goto __pyx_L0;

    /* "spacy/tokenizer.pyx":569
 *         DOCS: https://spacy.io/api/tokenizer#find_suffix
 *         """
 *         if self.suffix_search is None:             # <<<<<<<<<<<<<<
 *             return 0
 *         match = self.suffix_search(string)
 */
  }

  /* "spacy/tokenizer.pyx":571
 *         if self.suffix_search is None:
 *             return 0
 *         match = self.suffix_search(string)             # <<<<<<<<<<<<<<
 *         return (match.end() - match.start()) if match is not None else 0
 * 
 */
  __pyx_t_4 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_suffix_search); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 571, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_5 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_4))) {
    __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_4);
    if (likely(__pyx_t_5)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_4);
      __Pyx_INCREF(__pyx_t_5);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_4, function);
    }
  }
  __pyx_t_1 = (__pyx_t_5) ? __Pyx_PyObject_Call2Args(__pyx_t_4, __pyx_t_5, __pyx_v_string) : __Pyx_PyObject_CallOneArg(__pyx_t_4, __pyx_v_string);
  __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
  if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 571, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_v_match = __pyx_t_1;
  __pyx_t_1 = 0;

  /* "spacy/tokenizer.pyx":572
 *             return 0
 *         match = self.suffix_search(string)
 *         return (match.end() - match.start()) if match is not None else 0             # <<<<<<<<<<<<<<
 * 
 *     def _load_special_cases(self, special_cases):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_3 = (__pyx_v_match != Py_None);
  if ((__pyx_t_3 != 0)) {
    __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_v_match, __pyx_n_s_end); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 572, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_6 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_5))) {
      __pyx_t_6 = PyMethod_GET_SELF(__pyx_t_5);
      if (likely(__pyx_t_6)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
        __Pyx_INCREF(__pyx_t_6);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_5, function);
      }
    }
    __pyx_t_4 = (__pyx_t_6) ? __Pyx_PyObject_CallOneArg(__pyx_t_5, __pyx_t_6) : __Pyx_PyObject_CallNoArg(__pyx_t_5);
    __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
    if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 572, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_v_match, __pyx_n_s_start); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 572, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_t_7 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_6))) {
      __pyx_t_7 = PyMethod_GET_SELF(__pyx_t_6);
      if (likely(__pyx_t_7)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_6);
        __Pyx_INCREF(__pyx_t_7);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_6, function);
      }
    }
    __pyx_t_5 = (__pyx_t_7) ? __Pyx_PyObject_CallOneArg(__pyx_t_6, __pyx_t_7) : __Pyx_PyObject_CallNoArg(__pyx_t_6);
    __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
    if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 572, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __pyx_t_6 = PyNumber_Subtract(__pyx_t_4, __pyx_t_5); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 572, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_1 = __pyx_t_6;
    __pyx_t_6 = 0;
  } else {
    __Pyx_INCREF(__pyx_int_0);
    __pyx_t_1 = __pyx_int_0;
  }
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "spacy/tokenizer.pyx":560
 *         return (match.end() - match.start()) if match is not None else 0
 * 
 *     def find_suffix(self, str string):             # <<<<<<<<<<<<<<
 *         """Find the length of a suffix that should be segmented from the
 *         string, or None if no suffix rules match.
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_AddTraceback("spacy.tokenizer.Tokenizer.find_suffix", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_match);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "spacy/tokenizer.pyx":574
 *         return (match.end() - match.start()) if match is not None else 0
 * 
 *     def _load_special_cases(self, special_cases):             # <<<<<<<<<<<<<<
 *         """Add special-case tokenization rules."""
 *         if special_cases is not None:
 */

/* Python wrapper */
static PyObject *__pyx_pw_5spacy_9tokenizer_9Tokenizer_22_load_special_cases(PyObject *__pyx_v_self, PyObject *__pyx_v_special_cases); /*proto*/
static char __pyx_doc_5spacy_9tokenizer_9Tokenizer_21_load_special_cases[] = "Tokenizer._load_special_cases(self, special_cases)\nAdd special-case tokenization rules.";
static PyMethodDef __pyx_mdef_5spacy_9tokenizer_9Tokenizer_22_load_special_cases = {"_load_special_cases", (PyCFunction)__pyx_pw_5spacy_9tokenizer_9Tokenizer_22_load_special_cases, METH_O, __pyx_doc_5spacy_9tokenizer_9Tokenizer_21_load_special_cases};
static PyObject *__pyx_pw_5spacy_9tokenizer_9Tokenizer_22_load_special_cases(PyObject *__pyx_v_self, PyObject *__pyx_v_special_cases) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("_load_special_cases (wrapper)", 0);
  __pyx_r = __pyx_pf_5spacy_9tokenizer_9Tokenizer_21_load_special_cases(((struct __pyx_obj_5spacy_9tokenizer_Tokenizer *)__pyx_v_self), ((PyObject *)__pyx_v_special_cases));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5spacy_9tokenizer_9Tokenizer_21_load_special_cases(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *__pyx_v_self, PyObject *__pyx_v_special_cases) {
  PyObject *__pyx_v_chunk = NULL;
  PyObject *__pyx_v_substrings = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  int __pyx_t_2;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  int __pyx_t_7;
  Py_ssize_t __pyx_t_8;
  PyObject *__pyx_t_9 = NULL;
  PyObject *(*__pyx_t_10)(PyObject *);
  int __pyx_t_11;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("_load_special_cases", 0);

  /* "spacy/tokenizer.pyx":576
 *     def _load_special_cases(self, special_cases):
 *         """Add special-case tokenization rules."""
 *         if special_cases is not None:             # <<<<<<<<<<<<<<
 *             for chunk, substrings in sorted(special_cases.items()):
 *                 self.add_special_case(chunk, substrings)
 */
  __pyx_t_1 = (__pyx_v_special_cases != Py_None);
  __pyx_t_2 = (__pyx_t_1 != 0);
  if (__pyx_t_2) {

    /* "spacy/tokenizer.pyx":577
 *         """Add special-case tokenization rules."""
 *         if special_cases is not None:
 *             for chunk, substrings in sorted(special_cases.items()):             # <<<<<<<<<<<<<<
 *                 self.add_special_case(chunk, substrings)
 * 
 */
    __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_v_special_cases, __pyx_n_s_items); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 577, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_6 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_5))) {
      __pyx_t_6 = PyMethod_GET_SELF(__pyx_t_5);
      if (likely(__pyx_t_6)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
        __Pyx_INCREF(__pyx_t_6);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_5, function);
      }
    }
    __pyx_t_4 = (__pyx_t_6) ? __Pyx_PyObject_CallOneArg(__pyx_t_5, __pyx_t_6) : __Pyx_PyObject_CallNoArg(__pyx_t_5);
    __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
    if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 577, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_5 = PySequence_List(__pyx_t_4); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 577, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __pyx_t_3 = ((PyObject*)__pyx_t_5);
    __pyx_t_5 = 0;
    __pyx_t_7 = PyList_Sort(__pyx_t_3); if (unlikely(__pyx_t_7 == ((int)-1))) __PYX_ERR(0, 577, __pyx_L1_error)
    if (unlikely(__pyx_t_3 == Py_None)) {
      PyErr_SetString(PyExc_TypeError, "'NoneType' object is not iterable");
      __PYX_ERR(0, 577, __pyx_L1_error)
    }
    __pyx_t_5 = __pyx_t_3; __Pyx_INCREF(__pyx_t_5); __pyx_t_8 = 0;
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    for (;;) {
      if (__pyx_t_8 >= PyList_GET_SIZE(__pyx_t_5)) break;
      #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
      __pyx_t_3 = PyList_GET_ITEM(__pyx_t_5, __pyx_t_8); __Pyx_INCREF(__pyx_t_3); __pyx_t_8++; if (unlikely(0 < 0)) __PYX_ERR(0, 577, __pyx_L1_error)
      #else
      __pyx_t_3 = PySequence_ITEM(__pyx_t_5, __pyx_t_8); __pyx_t_8++; if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 577, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      #endif
      if ((likely(PyTuple_CheckExact(__pyx_t_3))) || (PyList_CheckExact(__pyx_t_3))) {
        PyObject* sequence = __pyx_t_3;
        Py_ssize_t size = __Pyx_PySequence_SIZE(sequence);
        if (unlikely(size != 2)) {
          if (size > 2) __Pyx_RaiseTooManyValuesError(2);
          else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
          __PYX_ERR(0, 577, __pyx_L1_error)
        }
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        if (likely(PyTuple_CheckExact(sequence))) {
          __pyx_t_4 = PyTuple_GET_ITEM(sequence, 0); 
          __pyx_t_6 = PyTuple_GET_ITEM(sequence, 1); 
        } else {
          __pyx_t_4 = PyList_GET_ITEM(sequence, 0); 
          __pyx_t_6 = PyList_GET_ITEM(sequence, 1); 
        }
        __Pyx_INCREF(__pyx_t_4);
        __Pyx_INCREF(__pyx_t_6);
        #else
        __pyx_t_4 = PySequence_ITEM(sequence, 0); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 577, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_4);
        __pyx_t_6 = PySequence_ITEM(sequence, 1); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 577, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_6);
        #endif
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      } else {
        Py_ssize_t index = -1;
        __pyx_t_9 = PyObject_GetIter(__pyx_t_3); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 577, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_9);
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
        __pyx_t_10 = Py_TYPE(__pyx_t_9)->tp_iternext;
        index = 0; __pyx_t_4 = __pyx_t_10(__pyx_t_9); if (unlikely(!__pyx_t_4)) goto __pyx_L6_unpacking_failed;
        __Pyx_GOTREF(__pyx_t_4);
        index = 1; __pyx_t_6 = __pyx_t_10(__pyx_t_9); if (unlikely(!__pyx_t_6)) goto __pyx_L6_unpacking_failed;
        __Pyx_GOTREF(__pyx_t_6);
        if (__Pyx_IternextUnpackEndCheck(__pyx_t_10(__pyx_t_9), 2) < 0) __PYX_ERR(0, 577, __pyx_L1_error)
        __pyx_t_10 = NULL;
        __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
        goto __pyx_L7_unpacking_done;
        __pyx_L6_unpacking_failed:;
        __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
        __pyx_t_10 = NULL;
        if (__Pyx_IterFinish() == 0) __Pyx_RaiseNeedMoreValuesError(index);
        __PYX_ERR(0, 577, __pyx_L1_error)
        __pyx_L7_unpacking_done:;
      }
      __Pyx_XDECREF_SET(__pyx_v_chunk, __pyx_t_4);
      __pyx_t_4 = 0;
      __Pyx_XDECREF_SET(__pyx_v_substrings, __pyx_t_6);
      __pyx_t_6 = 0;

      /* "spacy/tokenizer.pyx":578
 *         if special_cases is not None:
 *             for chunk, substrings in sorted(special_cases.items()):
 *                 self.add_special_case(chunk, substrings)             # <<<<<<<<<<<<<<
 * 
 *     def _validate_special_case(self, chunk, substrings):
 */
      __pyx_t_6 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_add_special_case); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 578, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __pyx_t_4 = NULL;
      __pyx_t_11 = 0;
      if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_6))) {
        __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_6);
        if (likely(__pyx_t_4)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_6);
          __Pyx_INCREF(__pyx_t_4);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_6, function);
          __pyx_t_11 = 1;
        }
      }
      #if CYTHON_FAST_PYCALL
      if (PyFunction_Check(__pyx_t_6)) {
        PyObject *__pyx_temp[3] = {__pyx_t_4, __pyx_v_chunk, __pyx_v_substrings};
        __pyx_t_3 = __Pyx_PyFunction_FastCall(__pyx_t_6, __pyx_temp+1-__pyx_t_11, 2+__pyx_t_11); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 578, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
        __Pyx_GOTREF(__pyx_t_3);
      } else
      #endif
      #if CYTHON_FAST_PYCCALL
      if (__Pyx_PyFastCFunction_Check(__pyx_t_6)) {
        PyObject *__pyx_temp[3] = {__pyx_t_4, __pyx_v_chunk, __pyx_v_substrings};
        __pyx_t_3 = __Pyx_PyCFunction_FastCall(__pyx_t_6, __pyx_temp+1-__pyx_t_11, 2+__pyx_t_11); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 578, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
        __Pyx_GOTREF(__pyx_t_3);
      } else
      #endif
      {
        __pyx_t_9 = PyTuple_New(2+__pyx_t_11); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 578, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_9);
        if (__pyx_t_4) {
          __Pyx_GIVEREF(__pyx_t_4); PyTuple_SET_ITEM(__pyx_t_9, 0, __pyx_t_4); __pyx_t_4 = NULL;
        }
        __Pyx_INCREF(__pyx_v_chunk);
        __Pyx_GIVEREF(__pyx_v_chunk);
        PyTuple_SET_ITEM(__pyx_t_9, 0+__pyx_t_11, __pyx_v_chunk);
        __Pyx_INCREF(__pyx_v_substrings);
        __Pyx_GIVEREF(__pyx_v_substrings);
        PyTuple_SET_ITEM(__pyx_t_9, 1+__pyx_t_11, __pyx_v_substrings);
        __pyx_t_3 = __Pyx_PyObject_Call(__pyx_t_6, __pyx_t_9, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 578, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_3);
        __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
      }
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

      /* "spacy/tokenizer.pyx":577
 *         """Add special-case tokenization rules."""
 *         if special_cases is not None:
 *             for chunk, substrings in sorted(special_cases.items()):             # <<<<<<<<<<<<<<
 *                 self.add_special_case(chunk, substrings)
 * 
 */
    }
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;

    /* "spacy/tokenizer.pyx":576
 *     def _load_special_cases(self, special_cases):
 *         """Add special-case tokenization rules."""
 *         if special_cases is not None:             # <<<<<<<<<<<<<<
 *             for chunk, substrings in sorted(special_cases.items()):
 *                 self.add_special_case(chunk, substrings)
 */
  }

  /* "spacy/tokenizer.pyx":574
 *         return (match.end() - match.start()) if match is not None else 0
 * 
 *     def _load_special_cases(self, special_cases):             # <<<<<<<<<<<<<<
 *         """Add special-case tokenization rules."""
 *         if special_cases is not None:
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_9);
  __Pyx_AddTraceback("spacy.tokenizer.Tokenizer._load_special_cases", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_chunk);
  __Pyx_XDECREF(__pyx_v_substrings);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "spacy/tokenizer.pyx":580
 *                 self.add_special_case(chunk, substrings)
 * 
 *     def _validate_special_case(self, chunk, substrings):             # <<<<<<<<<<<<<<
 *         """Check whether the `ORTH` fields match the string. Check that
 *         additional features beyond `ORTH` and `NORM` are not set by the
 */

/* Python wrapper */
static PyObject *__pyx_pw_5spacy_9tokenizer_9Tokenizer_24_validate_special_case(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static char __pyx_doc_5spacy_9tokenizer_9Tokenizer_23_validate_special_case[] = "Tokenizer._validate_special_case(self, chunk, substrings)\nCheck whether the `ORTH` fields match the string. Check that\n        additional features beyond `ORTH` and `NORM` are not set by the\n        exception.\n\n        chunk (str): The string to specially tokenize.\n        substrings (iterable): A sequence of dicts, where each dict describes\n            a token and its attributes.\n        ";
static PyMethodDef __pyx_mdef_5spacy_9tokenizer_9Tokenizer_24_validate_special_case = {"_validate_special_case", (PyCFunction)(void*)(PyCFunctionWithKeywords)__pyx_pw_5spacy_9tokenizer_9Tokenizer_24_validate_special_case, METH_VARARGS|METH_KEYWORDS, __pyx_doc_5spacy_9tokenizer_9Tokenizer_23_validate_special_case};
static PyObject *__pyx_pw_5spacy_9tokenizer_9Tokenizer_24_validate_special_case(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_chunk = 0;
  PyObject *__pyx_v_substrings = 0;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("_validate_special_case (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_chunk,&__pyx_n_s_substrings,0};
    PyObject* values[2] = {0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_chunk)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_substrings)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("_validate_special_case", 1, 2, 2, 1); __PYX_ERR(0, 580, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "_validate_special_case") < 0)) __PYX_ERR(0, 580, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 2) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
    }
    __pyx_v_chunk = values[0];
    __pyx_v_substrings = values[1];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("_validate_special_case", 1, 2, 2, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 580, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("spacy.tokenizer.Tokenizer._validate_special_case", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5spacy_9tokenizer_9Tokenizer_23_validate_special_case(((struct __pyx_obj_5spacy_9tokenizer_Tokenizer *)__pyx_v_self), __pyx_v_chunk, __pyx_v_substrings);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5spacy_9tokenizer_9Tokenizer_23_validate_special_case(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *__pyx_v_self, PyObject *__pyx_v_chunk, PyObject *__pyx_v_substrings) {
  PyObject *__pyx_v_attrs = NULL;
  PyObject *__pyx_v_orth = NULL;
  PyObject *__pyx_v_substring = NULL;
  PyObject *__pyx_v_attr = NULL;
  PyObject *__pyx_v_spec = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  Py_ssize_t __pyx_t_3;
  PyObject *(*__pyx_t_4)(PyObject *);
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  PyObject *__pyx_t_8 = NULL;
  int __pyx_t_9;
  Py_ssize_t __pyx_t_10;
  int __pyx_t_11;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("_validate_special_case", 0);

  /* "spacy/tokenizer.pyx":589
 *             a token and its attributes.
 *         """
 *         attrs = [intify_attrs(spec, _do_deprecated=True) for spec in substrings]             # <<<<<<<<<<<<<<
 *         orth = "".join([spec[ORTH] for spec in attrs])
 *         if chunk != orth:
 */
  __pyx_t_1 = PyList_New(0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 589, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (likely(PyList_CheckExact(__pyx_v_substrings)) || PyTuple_CheckExact(__pyx_v_substrings)) {
    __pyx_t_2 = __pyx_v_substrings; __Pyx_INCREF(__pyx_t_2); __pyx_t_3 = 0;
    __pyx_t_4 = NULL;
  } else {
    __pyx_t_3 = -1; __pyx_t_2 = PyObject_GetIter(__pyx_v_substrings); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 589, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_4 = Py_TYPE(__pyx_t_2)->tp_iternext; if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 589, __pyx_L1_error)
  }
  for (;;) {
    if (likely(!__pyx_t_4)) {
      if (likely(PyList_CheckExact(__pyx_t_2))) {
        if (__pyx_t_3 >= PyList_GET_SIZE(__pyx_t_2)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_5 = PyList_GET_ITEM(__pyx_t_2, __pyx_t_3); __Pyx_INCREF(__pyx_t_5); __pyx_t_3++; if (unlikely(0 < 0)) __PYX_ERR(0, 589, __pyx_L1_error)
        #else
        __pyx_t_5 = PySequence_ITEM(__pyx_t_2, __pyx_t_3); __pyx_t_3++; if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 589, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_5);
        #endif
      } else {
        if (__pyx_t_3 >= PyTuple_GET_SIZE(__pyx_t_2)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_5 = PyTuple_GET_ITEM(__pyx_t_2, __pyx_t_3); __Pyx_INCREF(__pyx_t_5); __pyx_t_3++; if (unlikely(0 < 0)) __PYX_ERR(0, 589, __pyx_L1_error)
        #else
        __pyx_t_5 = PySequence_ITEM(__pyx_t_2, __pyx_t_3); __pyx_t_3++; if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 589, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_5);
        #endif
      }
    } else {
      __pyx_t_5 = __pyx_t_4(__pyx_t_2);
      if (unlikely(!__pyx_t_5)) {
        PyObject* exc_type = PyErr_Occurred();
        if (exc_type) {
          if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
          else __PYX_ERR(0, 589, __pyx_L1_error)
        }
        break;
      }
      __Pyx_GOTREF(__pyx_t_5);
    }
    __Pyx_XDECREF_SET(__pyx_v_spec, __pyx_t_5);
    __pyx_t_5 = 0;
    __Pyx_GetModuleGlobalName(__pyx_t_5, __pyx_n_s_intify_attrs); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 589, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_6 = PyTuple_New(1); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 589, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_INCREF(__pyx_v_spec);
    __Pyx_GIVEREF(__pyx_v_spec);
    PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_v_spec);
    __pyx_t_7 = __Pyx_PyDict_NewPresized(1); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 589, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    if (PyDict_SetItem(__pyx_t_7, __pyx_n_s_do_deprecated, Py_True) < 0) __PYX_ERR(0, 589, __pyx_L1_error)
    __pyx_t_8 = __Pyx_PyObject_Call(__pyx_t_5, __pyx_t_6, __pyx_t_7); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 589, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    if (unlikely(__Pyx_ListComp_Append(__pyx_t_1, (PyObject*)__pyx_t_8))) __PYX_ERR(0, 589, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  }
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_attrs = ((PyObject*)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "spacy/tokenizer.pyx":590
 *         """
 *         attrs = [intify_attrs(spec, _do_deprecated=True) for spec in substrings]
 *         orth = "".join([spec[ORTH] for spec in attrs])             # <<<<<<<<<<<<<<
 *         if chunk != orth:
 *             raise ValueError(Errors.E997.format(chunk=chunk, orth=orth, token_attrs=substrings))
 */
  __pyx_t_1 = PyList_New(0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 590, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __pyx_v_attrs; __Pyx_INCREF(__pyx_t_2); __pyx_t_3 = 0;
  for (;;) {
    if (__pyx_t_3 >= PyList_GET_SIZE(__pyx_t_2)) break;
    #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
    __pyx_t_8 = PyList_GET_ITEM(__pyx_t_2, __pyx_t_3); __Pyx_INCREF(__pyx_t_8); __pyx_t_3++; if (unlikely(0 < 0)) __PYX_ERR(0, 590, __pyx_L1_error)
    #else
    __pyx_t_8 = PySequence_ITEM(__pyx_t_2, __pyx_t_3); __pyx_t_3++; if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 590, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    #endif
    __Pyx_XDECREF_SET(__pyx_v_spec, __pyx_t_8);
    __pyx_t_8 = 0;
    __Pyx_GetModuleGlobalName(__pyx_t_8, __pyx_n_s_ORTH); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 590, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __pyx_t_7 = __Pyx_PyObject_GetItem(__pyx_v_spec, __pyx_t_8); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 590, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    if (unlikely(__Pyx_ListComp_Append(__pyx_t_1, (PyObject*)__pyx_t_7))) __PYX_ERR(0, 590, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  }
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = __Pyx_PyString_Join(__pyx_kp_s__3, __pyx_t_1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 590, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_orth = ((PyObject*)__pyx_t_2);
  __pyx_t_2 = 0;

  /* "spacy/tokenizer.pyx":591
 *         attrs = [intify_attrs(spec, _do_deprecated=True) for spec in substrings]
 *         orth = "".join([spec[ORTH] for spec in attrs])
 *         if chunk != orth:             # <<<<<<<<<<<<<<
 *             raise ValueError(Errors.E997.format(chunk=chunk, orth=orth, token_attrs=substrings))
 *         for substring in attrs:
 */
  __pyx_t_9 = (__Pyx_PyUnicode_Equals(__pyx_v_chunk, __pyx_v_orth, Py_NE)); if (unlikely(__pyx_t_9 < 0)) __PYX_ERR(0, 591, __pyx_L1_error)
  if (unlikely(__pyx_t_9)) {

    /* "spacy/tokenizer.pyx":592
 *         orth = "".join([spec[ORTH] for spec in attrs])
 *         if chunk != orth:
 *             raise ValueError(Errors.E997.format(chunk=chunk, orth=orth, token_attrs=substrings))             # <<<<<<<<<<<<<<
 *         for substring in attrs:
 *             for attr in substring:
 */
    __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_n_s_Errors); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 592, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_E997); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 592, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_format); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 592, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_1 = __Pyx_PyDict_NewPresized(3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 592, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    if (PyDict_SetItem(__pyx_t_1, __pyx_n_s_chunk, __pyx_v_chunk) < 0) __PYX_ERR(0, 592, __pyx_L1_error)
    if (PyDict_SetItem(__pyx_t_1, __pyx_n_s_orth, __pyx_v_orth) < 0) __PYX_ERR(0, 592, __pyx_L1_error)
    if (PyDict_SetItem(__pyx_t_1, __pyx_n_s_token_attrs, __pyx_v_substrings) < 0) __PYX_ERR(0, 592, __pyx_L1_error)
    __pyx_t_7 = __Pyx_PyObject_Call(__pyx_t_2, __pyx_empty_tuple, __pyx_t_1); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 592, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_builtin_ValueError, __pyx_t_7); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 592, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __Pyx_Raise(__pyx_t_1, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __PYX_ERR(0, 592, __pyx_L1_error)

    /* "spacy/tokenizer.pyx":591
 *         attrs = [intify_attrs(spec, _do_deprecated=True) for spec in substrings]
 *         orth = "".join([spec[ORTH] for spec in attrs])
 *         if chunk != orth:             # <<<<<<<<<<<<<<
 *             raise ValueError(Errors.E997.format(chunk=chunk, orth=orth, token_attrs=substrings))
 *         for substring in attrs:
 */
  }

  /* "spacy/tokenizer.pyx":593
 *         if chunk != orth:
 *             raise ValueError(Errors.E997.format(chunk=chunk, orth=orth, token_attrs=substrings))
 *         for substring in attrs:             # <<<<<<<<<<<<<<
 *             for attr in substring:
 *                 if attr not in (ORTH, NORM):
 */
  __pyx_t_1 = __pyx_v_attrs; __Pyx_INCREF(__pyx_t_1); __pyx_t_3 = 0;
  for (;;) {
    if (__pyx_t_3 >= PyList_GET_SIZE(__pyx_t_1)) break;
    #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
    __pyx_t_7 = PyList_GET_ITEM(__pyx_t_1, __pyx_t_3); __Pyx_INCREF(__pyx_t_7); __pyx_t_3++; if (unlikely(0 < 0)) __PYX_ERR(0, 593, __pyx_L1_error)
    #else
    __pyx_t_7 = PySequence_ITEM(__pyx_t_1, __pyx_t_3); __pyx_t_3++; if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 593, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    #endif
    __Pyx_XDECREF_SET(__pyx_v_substring, __pyx_t_7);
    __pyx_t_7 = 0;

    /* "spacy/tokenizer.pyx":594
 *             raise ValueError(Errors.E997.format(chunk=chunk, orth=orth, token_attrs=substrings))
 *         for substring in attrs:
 *             for attr in substring:             # <<<<<<<<<<<<<<
 *                 if attr not in (ORTH, NORM):
 *                     raise ValueError(Errors.E1005.format(attr=self.vocab.strings[attr], chunk=chunk))
 */
    if (likely(PyList_CheckExact(__pyx_v_substring)) || PyTuple_CheckExact(__pyx_v_substring)) {
      __pyx_t_7 = __pyx_v_substring; __Pyx_INCREF(__pyx_t_7); __pyx_t_10 = 0;
      __pyx_t_4 = NULL;
    } else {
      __pyx_t_10 = -1; __pyx_t_7 = PyObject_GetIter(__pyx_v_substring); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 594, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_7);
      __pyx_t_4 = Py_TYPE(__pyx_t_7)->tp_iternext; if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 594, __pyx_L1_error)
    }
    for (;;) {
      if (likely(!__pyx_t_4)) {
        if (likely(PyList_CheckExact(__pyx_t_7))) {
          if (__pyx_t_10 >= PyList_GET_SIZE(__pyx_t_7)) break;
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          __pyx_t_2 = PyList_GET_ITEM(__pyx_t_7, __pyx_t_10); __Pyx_INCREF(__pyx_t_2); __pyx_t_10++; if (unlikely(0 < 0)) __PYX_ERR(0, 594, __pyx_L1_error)
          #else
          __pyx_t_2 = PySequence_ITEM(__pyx_t_7, __pyx_t_10); __pyx_t_10++; if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 594, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_2);
          #endif
        } else {
          if (__pyx_t_10 >= PyTuple_GET_SIZE(__pyx_t_7)) break;
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          __pyx_t_2 = PyTuple_GET_ITEM(__pyx_t_7, __pyx_t_10); __Pyx_INCREF(__pyx_t_2); __pyx_t_10++; if (unlikely(0 < 0)) __PYX_ERR(0, 594, __pyx_L1_error)
          #else
          __pyx_t_2 = PySequence_ITEM(__pyx_t_7, __pyx_t_10); __pyx_t_10++; if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 594, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_2);
          #endif
        }
      } else {
        __pyx_t_2 = __pyx_t_4(__pyx_t_7);
        if (unlikely(!__pyx_t_2)) {
          PyObject* exc_type = PyErr_Occurred();
          if (exc_type) {
            if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
            else __PYX_ERR(0, 594, __pyx_L1_error)
          }
          break;
        }
        __Pyx_GOTREF(__pyx_t_2);
      }
      __Pyx_XDECREF_SET(__pyx_v_attr, __pyx_t_2);
      __pyx_t_2 = 0;

      /* "spacy/tokenizer.pyx":595
 *         for substring in attrs:
 *             for attr in substring:
 *                 if attr not in (ORTH, NORM):             # <<<<<<<<<<<<<<
 *                     raise ValueError(Errors.E1005.format(attr=self.vocab.strings[attr], chunk=chunk))
 * 
 */
      __Pyx_INCREF(__pyx_v_attr);
      __pyx_t_2 = __pyx_v_attr;
      __Pyx_GetModuleGlobalName(__pyx_t_8, __pyx_n_s_ORTH); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 595, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __pyx_t_6 = PyObject_RichCompare(__pyx_t_2, __pyx_t_8, Py_NE); __Pyx_XGOTREF(__pyx_t_6); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 595, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __pyx_t_11 = __Pyx_PyObject_IsTrue(__pyx_t_6); if (unlikely(__pyx_t_11 < 0)) __PYX_ERR(0, 595, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      if (__pyx_t_11) {
      } else {
        __pyx_t_9 = __pyx_t_11;
        goto __pyx_L13_bool_binop_done;
      }
      __Pyx_GetModuleGlobalName(__pyx_t_6, __pyx_n_s_NORM); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 595, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __pyx_t_8 = PyObject_RichCompare(__pyx_t_2, __pyx_t_6, Py_NE); __Pyx_XGOTREF(__pyx_t_8); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 595, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      __pyx_t_11 = __Pyx_PyObject_IsTrue(__pyx_t_8); if (unlikely(__pyx_t_11 < 0)) __PYX_ERR(0, 595, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __pyx_t_9 = __pyx_t_11;
      __pyx_L13_bool_binop_done:;
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_t_11 = (__pyx_t_9 != 0);
      if (unlikely(__pyx_t_11)) {

        /* "spacy/tokenizer.pyx":596
 *             for attr in substring:
 *                 if attr not in (ORTH, NORM):
 *                     raise ValueError(Errors.E1005.format(attr=self.vocab.strings[attr], chunk=chunk))             # <<<<<<<<<<<<<<
 * 
 *     def add_special_case(self, str string, substrings):
 */
        __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_n_s_Errors); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 596, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
        __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_E1005); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 596, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_8);
        __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
        __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_8, __pyx_n_s_format); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 596, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
        __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
        __pyx_t_8 = __Pyx_PyDict_NewPresized(2); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 596, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_8);
        __pyx_t_6 = __Pyx_PyObject_GetItem(((PyObject *)__pyx_v_self->vocab->strings), __pyx_v_attr); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 596, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_6);
        if (PyDict_SetItem(__pyx_t_8, __pyx_n_s_attr, __pyx_t_6) < 0) __PYX_ERR(0, 596, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
        if (PyDict_SetItem(__pyx_t_8, __pyx_n_s_chunk, __pyx_v_chunk) < 0) __PYX_ERR(0, 596, __pyx_L1_error)
        __pyx_t_6 = __Pyx_PyObject_Call(__pyx_t_2, __pyx_empty_tuple, __pyx_t_8); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 596, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_6);
        __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
        __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
        __pyx_t_8 = __Pyx_PyObject_CallOneArg(__pyx_builtin_ValueError, __pyx_t_6); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 596, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_8);
        __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
        __Pyx_Raise(__pyx_t_8, 0, 0, 0);
        __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
        __PYX_ERR(0, 596, __pyx_L1_error)

        /* "spacy/tokenizer.pyx":595
 *         for substring in attrs:
 *             for attr in substring:
 *                 if attr not in (ORTH, NORM):             # <<<<<<<<<<<<<<
 *                     raise ValueError(Errors.E1005.format(attr=self.vocab.strings[attr], chunk=chunk))
 * 
 */
      }

      /* "spacy/tokenizer.pyx":594
 *             raise ValueError(Errors.E997.format(chunk=chunk, orth=orth, token_attrs=substrings))
 *         for substring in attrs:
 *             for attr in substring:             # <<<<<<<<<<<<<<
 *                 if attr not in (ORTH, NORM):
 *                     raise ValueError(Errors.E1005.format(attr=self.vocab.strings[attr], chunk=chunk))
 */
    }
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;

    /* "spacy/tokenizer.pyx":593
 *         if chunk != orth:
 *             raise ValueError(Errors.E997.format(chunk=chunk, orth=orth, token_attrs=substrings))
 *         for substring in attrs:             # <<<<<<<<<<<<<<
 *             for attr in substring:
 *                 if attr not in (ORTH, NORM):
 */
  }
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "spacy/tokenizer.pyx":580
 *                 self.add_special_case(chunk, substrings)
 * 
 *     def _validate_special_case(self, chunk, substrings):             # <<<<<<<<<<<<<<
 *         """Check whether the `ORTH` fields match the string. Check that
 *         additional features beyond `ORTH` and `NORM` are not set by the
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_AddTraceback("spacy.tokenizer.Tokenizer._validate_special_case", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_attrs);
  __Pyx_XDECREF(__pyx_v_orth);
  __Pyx_XDECREF(__pyx_v_substring);
  __Pyx_XDECREF(__pyx_v_attr);
  __Pyx_XDECREF(__pyx_v_spec);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "spacy/tokenizer.pyx":598
 *                     raise ValueError(Errors.E1005.format(attr=self.vocab.strings[attr], chunk=chunk))
 * 
 *     def add_special_case(self, str string, substrings):             # <<<<<<<<<<<<<<
 *         """Add a special-case tokenization rule.
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_5spacy_9tokenizer_9Tokenizer_26add_special_case(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static char __pyx_doc_5spacy_9tokenizer_9Tokenizer_25add_special_case[] = "Tokenizer.add_special_case(self, str string, substrings)\nAdd a special-case tokenization rule.\n\n        string (str): The string to specially tokenize.\n        substrings (iterable): A sequence of dicts, where each dict describes\n            a token and its attributes. The `ORTH` fields of the attributes\n            must exactly match the string when they are concatenated.\n\n        DOCS: https://spacy.io/api/tokenizer#add_special_case\n        ";
static PyMethodDef __pyx_mdef_5spacy_9tokenizer_9Tokenizer_26add_special_case = {"add_special_case", (PyCFunction)(void*)(PyCFunctionWithKeywords)__pyx_pw_5spacy_9tokenizer_9Tokenizer_26add_special_case, METH_VARARGS|METH_KEYWORDS, __pyx_doc_5spacy_9tokenizer_9Tokenizer_25add_special_case};
static PyObject *__pyx_pw_5spacy_9tokenizer_9Tokenizer_26add_special_case(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_string = 0;
  PyObject *__pyx_v_substrings = 0;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("add_special_case (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_string,&__pyx_n_s_substrings,0};
    PyObject* values[2] = {0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_string)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_substrings)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("add_special_case", 1, 2, 2, 1); __PYX_ERR(0, 598, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "add_special_case") < 0)) __PYX_ERR(0, 598, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 2) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
    }
    __pyx_v_string = ((PyObject*)values[0]);
    __pyx_v_substrings = values[1];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("add_special_case", 1, 2, 2, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 598, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("spacy.tokenizer.Tokenizer.add_special_case", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_string), (&PyString_Type), 1, "string", 1))) __PYX_ERR(0, 598, __pyx_L1_error)
  __pyx_r = __pyx_pf_5spacy_9tokenizer_9Tokenizer_25add_special_case(((struct __pyx_obj_5spacy_9tokenizer_Tokenizer *)__pyx_v_self), __pyx_v_string, __pyx_v_substrings);

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5spacy_9tokenizer_9Tokenizer_25add_special_case(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *__pyx_v_self, PyObject *__pyx_v_string, PyObject *__pyx_v_substrings) {
  struct __pyx_t_5spacy_5vocab__Cached *__pyx_v_cached;
  __pyx_t_5spacy_8typedefs_hash_t __pyx_v_key;
  struct __pyx_t_5spacy_5vocab__Cached *__pyx_v_stale_special;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  void *__pyx_t_6;
  Py_ssize_t __pyx_t_7;
  struct __pyx_t_5spacy_7structs_TokenC const *__pyx_t_8;
  __pyx_t_5spacy_8typedefs_hash_t __pyx_t_9;
  int __pyx_t_10;
  int __pyx_t_11;
  int __pyx_t_12;
  PyObject *__pyx_t_13 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("add_special_case", 0);
  __Pyx_INCREF(__pyx_v_substrings);

  /* "spacy/tokenizer.pyx":608
 *         DOCS: https://spacy.io/api/tokenizer#add_special_case
 *         """
 *         self._validate_special_case(string, substrings)             # <<<<<<<<<<<<<<
 *         substrings = list(substrings)
 *         cached = <_Cached*>self.mem.alloc(1, sizeof(_Cached))
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_validate_special_case); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 608, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = NULL;
  __pyx_t_4 = 0;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
      __pyx_t_4 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_2)) {
    PyObject *__pyx_temp[3] = {__pyx_t_3, __pyx_v_string, __pyx_v_substrings};
    __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_2, __pyx_temp+1-__pyx_t_4, 2+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 608, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_2)) {
    PyObject *__pyx_temp[3] = {__pyx_t_3, __pyx_v_string, __pyx_v_substrings};
    __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_2, __pyx_temp+1-__pyx_t_4, 2+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 608, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  {
    __pyx_t_5 = PyTuple_New(2+__pyx_t_4); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 608, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    if (__pyx_t_3) {
      __Pyx_GIVEREF(__pyx_t_3); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_3); __pyx_t_3 = NULL;
    }
    __Pyx_INCREF(__pyx_v_string);
    __Pyx_GIVEREF(__pyx_v_string);
    PyTuple_SET_ITEM(__pyx_t_5, 0+__pyx_t_4, __pyx_v_string);
    __Pyx_INCREF(__pyx_v_substrings);
    __Pyx_GIVEREF(__pyx_v_substrings);
    PyTuple_SET_ITEM(__pyx_t_5, 1+__pyx_t_4, __pyx_v_substrings);
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_2, __pyx_t_5, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 608, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  }
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "spacy/tokenizer.pyx":609
 *         """
 *         self._validate_special_case(string, substrings)
 *         substrings = list(substrings)             # <<<<<<<<<<<<<<
 *         cached = <_Cached*>self.mem.alloc(1, sizeof(_Cached))
 *         cached.length = len(substrings)
 */
  __pyx_t_1 = PySequence_List(__pyx_v_substrings); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 609, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF_SET(__pyx_v_substrings, __pyx_t_1);
  __pyx_t_1 = 0;

  /* "spacy/tokenizer.pyx":610
 *         self._validate_special_case(string, substrings)
 *         substrings = list(substrings)
 *         cached = <_Cached*>self.mem.alloc(1, sizeof(_Cached))             # <<<<<<<<<<<<<<
 *         cached.length = len(substrings)
 *         cached.is_lex = False
 */
  __pyx_t_6 = ((struct __pyx_vtabstruct_5cymem_5cymem_Pool *)__pyx_v_self->mem->__pyx_vtab)->alloc(__pyx_v_self->mem, 1, (sizeof(struct __pyx_t_5spacy_5vocab__Cached))); if (unlikely(__pyx_t_6 == ((void *)NULL))) __PYX_ERR(0, 610, __pyx_L1_error)
  __pyx_v_cached = ((struct __pyx_t_5spacy_5vocab__Cached *)__pyx_t_6);

  /* "spacy/tokenizer.pyx":611
 *         substrings = list(substrings)
 *         cached = <_Cached*>self.mem.alloc(1, sizeof(_Cached))
 *         cached.length = len(substrings)             # <<<<<<<<<<<<<<
 *         cached.is_lex = False
 *         cached.data.tokens = self.vocab.make_fused_token(substrings)
 */
  __pyx_t_7 = PyObject_Length(__pyx_v_substrings); if (unlikely(__pyx_t_7 == ((Py_ssize_t)-1))) __PYX_ERR(0, 611, __pyx_L1_error)
  __pyx_v_cached->length = __pyx_t_7;

  /* "spacy/tokenizer.pyx":612
 *         cached = <_Cached*>self.mem.alloc(1, sizeof(_Cached))
 *         cached.length = len(substrings)
 *         cached.is_lex = False             # <<<<<<<<<<<<<<
 *         cached.data.tokens = self.vocab.make_fused_token(substrings)
 *         key = hash_string(string)
 */
  __pyx_v_cached->is_lex = 0;

  /* "spacy/tokenizer.pyx":613
 *         cached.length = len(substrings)
 *         cached.is_lex = False
 *         cached.data.tokens = self.vocab.make_fused_token(substrings)             # <<<<<<<<<<<<<<
 *         key = hash_string(string)
 *         stale_special = <_Cached*>self._specials.get(key)
 */
  __pyx_t_8 = ((struct __pyx_vtabstruct_5spacy_5vocab_Vocab *)__pyx_v_self->vocab->__pyx_vtab)->make_fused_token(__pyx_v_self->vocab, __pyx_v_substrings); if (unlikely(__pyx_t_8 == ((struct __pyx_t_5spacy_7structs_TokenC const *)NULL))) __PYX_ERR(0, 613, __pyx_L1_error)
  __pyx_v_cached->data.tokens = __pyx_t_8;

  /* "spacy/tokenizer.pyx":614
 *         cached.is_lex = False
 *         cached.data.tokens = self.vocab.make_fused_token(substrings)
 *         key = hash_string(string)             # <<<<<<<<<<<<<<
 *         stale_special = <_Cached*>self._specials.get(key)
 *         self._specials.set(key, cached)
 */
  __pyx_t_9 = __pyx_f_5spacy_7strings_hash_string(__pyx_v_string, 0); if (unlikely(__pyx_t_9 == ((__pyx_t_5spacy_8typedefs_hash_t)0))) __PYX_ERR(0, 614, __pyx_L1_error)
  __pyx_v_key = __pyx_t_9;

  /* "spacy/tokenizer.pyx":615
 *         cached.data.tokens = self.vocab.make_fused_token(substrings)
 *         key = hash_string(string)
 *         stale_special = <_Cached*>self._specials.get(key)             # <<<<<<<<<<<<<<
 *         self._specials.set(key, cached)
 *         if stale_special is not NULL:
 */
  __pyx_v_stale_special = ((struct __pyx_t_5spacy_5vocab__Cached *)((struct __pyx_vtabstruct_7preshed_4maps_PreshMap *)__pyx_v_self->_specials->__pyx_vtab)->get(__pyx_v_self->_specials, __pyx_v_key));

  /* "spacy/tokenizer.pyx":616
 *         key = hash_string(string)
 *         stale_special = <_Cached*>self._specials.get(key)
 *         self._specials.set(key, cached)             # <<<<<<<<<<<<<<
 *         if stale_special is not NULL:
 *             self.mem.free(stale_special)
 */
  ((struct __pyx_vtabstruct_7preshed_4maps_PreshMap *)__pyx_v_self->_specials->__pyx_vtab)->set(__pyx_v_self->_specials, __pyx_v_key, __pyx_v_cached); if (unlikely(PyErr_Occurred())) __PYX_ERR(0, 616, __pyx_L1_error)

  /* "spacy/tokenizer.pyx":617
 *         stale_special = <_Cached*>self._specials.get(key)
 *         self._specials.set(key, cached)
 *         if stale_special is not NULL:             # <<<<<<<<<<<<<<
 *             self.mem.free(stale_special)
 *         self._rules[string] = substrings
 */
  __pyx_t_10 = ((__pyx_v_stale_special != NULL) != 0);
  if (__pyx_t_10) {

    /* "spacy/tokenizer.pyx":618
 *         self._specials.set(key, cached)
 *         if stale_special is not NULL:
 *             self.mem.free(stale_special)             # <<<<<<<<<<<<<<
 *         self._rules[string] = substrings
 *         self._flush_cache()
 */
    ((struct __pyx_vtabstruct_5cymem_5cymem_Pool *)__pyx_v_self->mem->__pyx_vtab)->free(__pyx_v_self->mem, __pyx_v_stale_special); if (unlikely(PyErr_Occurred())) __PYX_ERR(0, 618, __pyx_L1_error)

    /* "spacy/tokenizer.pyx":617
 *         stale_special = <_Cached*>self._specials.get(key)
 *         self._specials.set(key, cached)
 *         if stale_special is not NULL:             # <<<<<<<<<<<<<<
 *             self.mem.free(stale_special)
 *         self._rules[string] = substrings
 */
  }

  /* "spacy/tokenizer.pyx":619
 *         if stale_special is not NULL:
 *             self.mem.free(stale_special)
 *         self._rules[string] = substrings             # <<<<<<<<<<<<<<
 *         self._flush_cache()
 *         if not self.faster_heuristics or self.find_prefix(string) or self.find_infix(string) or self.find_suffix(string) or " " in string:
 */
  if (unlikely(PyObject_SetItem(__pyx_v_self->_rules, __pyx_v_string, __pyx_v_substrings) < 0)) __PYX_ERR(0, 619, __pyx_L1_error)

  /* "spacy/tokenizer.pyx":620
 *             self.mem.free(stale_special)
 *         self._rules[string] = substrings
 *         self._flush_cache()             # <<<<<<<<<<<<<<
 *         if not self.faster_heuristics or self.find_prefix(string) or self.find_infix(string) or self.find_suffix(string) or " " in string:
 *             self._special_matcher.add(string, None, self._tokenize_affixes(string, False))
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_flush_cache); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 620, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_5 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_5)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_5);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
    }
  }
  __pyx_t_1 = (__pyx_t_5) ? __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_5) : __Pyx_PyObject_CallNoArg(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
  if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 620, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "spacy/tokenizer.pyx":621
 *         self._rules[string] = substrings
 *         self._flush_cache()
 *         if not self.faster_heuristics or self.find_prefix(string) or self.find_infix(string) or self.find_suffix(string) or " " in string:             # <<<<<<<<<<<<<<
 *             self._special_matcher.add(string, None, self._tokenize_affixes(string, False))
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_faster_heuristics); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 621, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_11 = __Pyx_PyObject_IsTrue(__pyx_t_1); if (unlikely(__pyx_t_11 < 0)) __PYX_ERR(0, 621, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_12 = ((!__pyx_t_11) != 0);
  if (!__pyx_t_12) {
  } else {
    __pyx_t_10 = __pyx_t_12;
    goto __pyx_L5_bool_binop_done;
  }
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_find_prefix); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 621, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_5 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_5)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_5);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
    }
  }
  __pyx_t_1 = (__pyx_t_5) ? __Pyx_PyObject_Call2Args(__pyx_t_2, __pyx_t_5, __pyx_v_string) : __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_v_string);
  __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
  if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 621, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_12 = __Pyx_PyObject_IsTrue(__pyx_t_1); if (unlikely(__pyx_t_12 < 0)) __PYX_ERR(0, 621, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  if (!__pyx_t_12) {
  } else {
    __pyx_t_10 = __pyx_t_12;
    goto __pyx_L5_bool_binop_done;
  }
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_find_infix); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 621, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_5 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_5)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_5);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
    }
  }
  __pyx_t_1 = (__pyx_t_5) ? __Pyx_PyObject_Call2Args(__pyx_t_2, __pyx_t_5, __pyx_v_string) : __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_v_string);
  __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
  if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 621, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_12 = __Pyx_PyObject_IsTrue(__pyx_t_1); if (unlikely(__pyx_t_12 < 0)) __PYX_ERR(0, 621, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  if (!__pyx_t_12) {
  } else {
    __pyx_t_10 = __pyx_t_12;
    goto __pyx_L5_bool_binop_done;
  }
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_find_suffix); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 621, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_5 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_5)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_5);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
    }
  }
  __pyx_t_1 = (__pyx_t_5) ? __Pyx_PyObject_Call2Args(__pyx_t_2, __pyx_t_5, __pyx_v_string) : __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_v_string);
  __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
  if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 621, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_12 = __Pyx_PyObject_IsTrue(__pyx_t_1); if (unlikely(__pyx_t_12 < 0)) __PYX_ERR(0, 621, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  if (!__pyx_t_12) {
  } else {
    __pyx_t_10 = __pyx_t_12;
    goto __pyx_L5_bool_binop_done;
  }
  __pyx_t_12 = (__Pyx_PySequence_ContainsTF(__pyx_kp_s_, __pyx_v_string, Py_EQ)); if (unlikely(__pyx_t_12 < 0)) __PYX_ERR(0, 621, __pyx_L1_error)
  __pyx_t_11 = (__pyx_t_12 != 0);
  __pyx_t_10 = __pyx_t_11;
  __pyx_L5_bool_binop_done:;
  if (__pyx_t_10) {

    /* "spacy/tokenizer.pyx":622
 *         self._flush_cache()
 *         if not self.faster_heuristics or self.find_prefix(string) or self.find_infix(string) or self.find_suffix(string) or " " in string:
 *             self._special_matcher.add(string, None, self._tokenize_affixes(string, False))             # <<<<<<<<<<<<<<
 * 
 *     def _reload_special_cases(self):
 */
    __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self->_special_matcher), __pyx_n_s_add); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 622, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_5 = ((PyObject *)((struct __pyx_vtabstruct_5spacy_9tokenizer_Tokenizer *)__pyx_v_self->__pyx_vtab)->_tokenize_affixes(__pyx_v_self, __pyx_v_string, 0)); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 622, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_3 = NULL;
    __pyx_t_4 = 0;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
      __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
      if (likely(__pyx_t_3)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
        __Pyx_INCREF(__pyx_t_3);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_2, function);
        __pyx_t_4 = 1;
      }
    }
    #if CYTHON_FAST_PYCALL
    if (PyFunction_Check(__pyx_t_2)) {
      PyObject *__pyx_temp[4] = {__pyx_t_3, __pyx_v_string, Py_None, __pyx_t_5};
      __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_2, __pyx_temp+1-__pyx_t_4, 3+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 622, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    } else
    #endif
    #if CYTHON_FAST_PYCCALL
    if (__Pyx_PyFastCFunction_Check(__pyx_t_2)) {
      PyObject *__pyx_temp[4] = {__pyx_t_3, __pyx_v_string, Py_None, __pyx_t_5};
      __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_2, __pyx_temp+1-__pyx_t_4, 3+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 622, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    } else
    #endif
    {
      __pyx_t_13 = PyTuple_New(3+__pyx_t_4); if (unlikely(!__pyx_t_13)) __PYX_ERR(0, 622, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_13);
      if (__pyx_t_3) {
        __Pyx_GIVEREF(__pyx_t_3); PyTuple_SET_ITEM(__pyx_t_13, 0, __pyx_t_3); __pyx_t_3 = NULL;
      }
      __Pyx_INCREF(__pyx_v_string);
      __Pyx_GIVEREF(__pyx_v_string);
      PyTuple_SET_ITEM(__pyx_t_13, 0+__pyx_t_4, __pyx_v_string);
      __Pyx_INCREF(Py_None);
      __Pyx_GIVEREF(Py_None);
      PyTuple_SET_ITEM(__pyx_t_13, 1+__pyx_t_4, Py_None);
      __Pyx_GIVEREF(__pyx_t_5);
      PyTuple_SET_ITEM(__pyx_t_13, 2+__pyx_t_4, __pyx_t_5);
      __pyx_t_5 = 0;
      __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_2, __pyx_t_13, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 622, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_13); __pyx_t_13 = 0;
    }
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

    /* "spacy/tokenizer.pyx":621
 *         self._rules[string] = substrings
 *         self._flush_cache()
 *         if not self.faster_heuristics or self.find_prefix(string) or self.find_infix(string) or self.find_suffix(string) or " " in string:             # <<<<<<<<<<<<<<
 *             self._special_matcher.add(string, None, self._tokenize_affixes(string, False))
 * 
 */
  }

  /* "spacy/tokenizer.pyx":598
 *                     raise ValueError(Errors.E1005.format(attr=self.vocab.strings[attr], chunk=chunk))
 * 
 *     def add_special_case(self, str string, substrings):             # <<<<<<<<<<<<<<
 *         """Add a special-case tokenization rule.
 * 
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_13);
  __Pyx_AddTraceback("spacy.tokenizer.Tokenizer.add_special_case", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_substrings);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "spacy/tokenizer.pyx":624
 *             self._special_matcher.add(string, None, self._tokenize_affixes(string, False))
 * 
 *     def _reload_special_cases(self):             # <<<<<<<<<<<<<<
 *         self._flush_cache()
 *         self._flush_specials()
 */

/* Python wrapper */
static PyObject *__pyx_pw_5spacy_9tokenizer_9Tokenizer_28_reload_special_cases(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static char __pyx_doc_5spacy_9tokenizer_9Tokenizer_27_reload_special_cases[] = "Tokenizer._reload_special_cases(self)";
static PyMethodDef __pyx_mdef_5spacy_9tokenizer_9Tokenizer_28_reload_special_cases = {"_reload_special_cases", (PyCFunction)__pyx_pw_5spacy_9tokenizer_9Tokenizer_28_reload_special_cases, METH_NOARGS, __pyx_doc_5spacy_9tokenizer_9Tokenizer_27_reload_special_cases};
static PyObject *__pyx_pw_5spacy_9tokenizer_9Tokenizer_28_reload_special_cases(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("_reload_special_cases (wrapper)", 0);
  __pyx_r = __pyx_pf_5spacy_9tokenizer_9Tokenizer_27_reload_special_cases(((struct __pyx_obj_5spacy_9tokenizer_Tokenizer *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5spacy_9tokenizer_9Tokenizer_27_reload_special_cases(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("_reload_special_cases", 0);

  /* "spacy/tokenizer.pyx":625
 * 
 *     def _reload_special_cases(self):
 *         self._flush_cache()             # <<<<<<<<<<<<<<
 *         self._flush_specials()
 *         self._load_special_cases(self._rules)
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_flush_cache); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 625, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
    }
  }
  __pyx_t_1 = (__pyx_t_3) ? __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_3) : __Pyx_PyObject_CallNoArg(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 625, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "spacy/tokenizer.pyx":626
 *     def _reload_special_cases(self):
 *         self._flush_cache()
 *         self._flush_specials()             # <<<<<<<<<<<<<<
 *         self._load_special_cases(self._rules)
 * 
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_flush_specials); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 626, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
    }
  }
  __pyx_t_1 = (__pyx_t_3) ? __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_3) : __Pyx_PyObject_CallNoArg(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 626, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "spacy/tokenizer.pyx":627
 *         self._flush_cache()
 *         self._flush_specials()
 *         self._load_special_cases(self._rules)             # <<<<<<<<<<<<<<
 * 
 *     def explain(self, text):
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_load_special_cases); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 627, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
    }
  }
  __pyx_t_1 = (__pyx_t_3) ? __Pyx_PyObject_Call2Args(__pyx_t_2, __pyx_t_3, __pyx_v_self->_rules) : __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_v_self->_rules);
  __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 627, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "spacy/tokenizer.pyx":624
 *             self._special_matcher.add(string, None, self._tokenize_affixes(string, False))
 * 
 *     def _reload_special_cases(self):             # <<<<<<<<<<<<<<
 *         self._flush_cache()
 *         self._flush_specials()
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("spacy.tokenizer.Tokenizer._reload_special_cases", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "spacy/tokenizer.pyx":629
 *         self._load_special_cases(self._rules)
 * 
 *     def explain(self, text):             # <<<<<<<<<<<<<<
 *         """A debugging tokenizer that provides information about which
 *         tokenizer rule or pattern was matched for each token. The tokens
 */

/* Python wrapper */
static PyObject *__pyx_pw_5spacy_9tokenizer_9Tokenizer_30explain(PyObject *__pyx_v_self, PyObject *__pyx_v_text); /*proto*/
static char __pyx_doc_5spacy_9tokenizer_9Tokenizer_29explain[] = "Tokenizer.explain(self, text)\nA debugging tokenizer that provides information about which\n        tokenizer rule or pattern was matched for each token. The tokens\n        produced are identical to `nlp.tokenizer()` except for whitespace\n        tokens.\n\n        string (str): The string to tokenize.\n        RETURNS (list): A list of (pattern_string, token_string) tuples\n\n        DOCS: https://spacy.io/api/tokenizer#explain\n        ";
static PyMethodDef __pyx_mdef_5spacy_9tokenizer_9Tokenizer_30explain = {"explain", (PyCFunction)__pyx_pw_5spacy_9tokenizer_9Tokenizer_30explain, METH_O, __pyx_doc_5spacy_9tokenizer_9Tokenizer_29explain};
static PyObject *__pyx_pw_5spacy_9tokenizer_9Tokenizer_30explain(PyObject *__pyx_v_self, PyObject *__pyx_v_text) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("explain (wrapper)", 0);
  __pyx_r = __pyx_pf_5spacy_9tokenizer_9Tokenizer_29explain(((struct __pyx_obj_5spacy_9tokenizer_Tokenizer *)__pyx_v_self), ((PyObject *)__pyx_v_text));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}
static PyObject *__pyx_gb_5spacy_9tokenizer_9Tokenizer_7explain_2generator1(__pyx_CoroutineObject *__pyx_generator, CYTHON_UNUSED PyThreadState *__pyx_tstate, PyObject *__pyx_sent_value); /* proto */

/* "spacy/tokenizer.pyx":663
 *             while substring:
 *                 if substring in special_cases:
 *                     tokens.extend(("SPECIAL-" + str(i + 1), self.vocab.strings[e[ORTH]]) for i, e in enumerate(special_cases[substring]))             # <<<<<<<<<<<<<<
 *                     substring = ''
 *                     continue
 */

static PyObject *__pyx_pf_5spacy_9tokenizer_9Tokenizer_7explain_genexpr(PyObject *__pyx_self) {
  struct __pyx_obj_5spacy_9tokenizer___pyx_scope_struct_2_genexpr *__pyx_cur_scope;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("genexpr", 0);
  __pyx_cur_scope = (struct __pyx_obj_5spacy_9tokenizer___pyx_scope_struct_2_genexpr *)__pyx_tp_new_5spacy_9tokenizer___pyx_scope_struct_2_genexpr(__pyx_ptype_5spacy_9tokenizer___pyx_scope_struct_2_genexpr, __pyx_empty_tuple, NULL);
  if (unlikely(!__pyx_cur_scope)) {
    __pyx_cur_scope = ((struct __pyx_obj_5spacy_9tokenizer___pyx_scope_struct_2_genexpr *)Py_None);
    __Pyx_INCREF(Py_None);
    __PYX_ERR(0, 663, __pyx_L1_error)
  } else {
    __Pyx_GOTREF(__pyx_cur_scope);
  }
  __pyx_cur_scope->__pyx_outer_scope = (struct __pyx_obj_5spacy_9tokenizer___pyx_scope_struct_1_explain *) __pyx_self;
  __Pyx_INCREF(((PyObject *)__pyx_cur_scope->__pyx_outer_scope));
  __Pyx_GIVEREF(__pyx_cur_scope->__pyx_outer_scope);
  {
    __pyx_CoroutineObject *gen = __Pyx_Generator_New((__pyx_coroutine_body_t) __pyx_gb_5spacy_9tokenizer_9Tokenizer_7explain_2generator1, NULL, (PyObject *) __pyx_cur_scope, __pyx_n_s_genexpr, __pyx_n_s_explain_locals_genexpr, __pyx_n_s_spacy_tokenizer); if (unlikely(!gen)) __PYX_ERR(0, 663, __pyx_L1_error)
    __Pyx_DECREF(__pyx_cur_scope);
    __Pyx_RefNannyFinishContext();
    return (PyObject *) gen;
  }

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_AddTraceback("spacy.tokenizer.Tokenizer.explain.genexpr", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __Pyx_DECREF(((PyObject *)__pyx_cur_scope));
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_gb_5spacy_9tokenizer_9Tokenizer_7explain_2generator1(__pyx_CoroutineObject *__pyx_generator, CYTHON_UNUSED PyThreadState *__pyx_tstate, PyObject *__pyx_sent_value) /* generator body */
{
  struct __pyx_obj_5spacy_9tokenizer___pyx_scope_struct_2_genexpr *__pyx_cur_scope = ((struct __pyx_obj_5spacy_9tokenizer___pyx_scope_struct_2_genexpr *)__pyx_generator->closure);
  PyObject *__pyx_r = NULL;
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  Py_ssize_t __pyx_t_4;
  PyObject *(*__pyx_t_5)(PyObject *);
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("genexpr", 0);
  switch (__pyx_generator->resume_label) {
    case 0: goto __pyx_L3_first_run;
    case 1: goto __pyx_L6_resume_from_yield;
    default: /* CPython raises the right error here */
    __Pyx_RefNannyFinishContext();
    return NULL;
  }
  __pyx_L3_first_run:;
  if (unlikely(!__pyx_sent_value)) __PYX_ERR(0, 663, __pyx_L1_error)
  __Pyx_INCREF(__pyx_int_0);
  __pyx_t_1 = __pyx_int_0;
  if (unlikely(!__pyx_cur_scope->__pyx_outer_scope->__pyx_v_special_cases)) { __Pyx_RaiseClosureNameError("special_cases"); __PYX_ERR(0, 663, __pyx_L1_error) }
  if (unlikely(__pyx_cur_scope->__pyx_outer_scope->__pyx_v_special_cases == Py_None)) {
    PyErr_SetString(PyExc_TypeError, "'NoneType' object is not subscriptable");
    __PYX_ERR(0, 663, __pyx_L1_error)
  }
  if (unlikely(!__pyx_cur_scope->__pyx_outer_scope->__pyx_v_substring)) { __Pyx_RaiseClosureNameError("substring"); __PYX_ERR(0, 663, __pyx_L1_error) }
  __pyx_t_2 = __Pyx_PyDict_GetItem(__pyx_cur_scope->__pyx_outer_scope->__pyx_v_special_cases, __pyx_cur_scope->__pyx_outer_scope->__pyx_v_substring); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 663, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (likely(PyList_CheckExact(__pyx_t_2)) || PyTuple_CheckExact(__pyx_t_2)) {
    __pyx_t_3 = __pyx_t_2; __Pyx_INCREF(__pyx_t_3); __pyx_t_4 = 0;
    __pyx_t_5 = NULL;
  } else {
    __pyx_t_4 = -1; __pyx_t_3 = PyObject_GetIter(__pyx_t_2); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 663, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_5 = Py_TYPE(__pyx_t_3)->tp_iternext; if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 663, __pyx_L1_error)
  }
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  for (;;) {
    if (likely(!__pyx_t_5)) {
      if (likely(PyList_CheckExact(__pyx_t_3))) {
        if (__pyx_t_4 >= PyList_GET_SIZE(__pyx_t_3)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_2 = PyList_GET_ITEM(__pyx_t_3, __pyx_t_4); __Pyx_INCREF(__pyx_t_2); __pyx_t_4++; if (unlikely(0 < 0)) __PYX_ERR(0, 663, __pyx_L1_error)
        #else
        __pyx_t_2 = PySequence_ITEM(__pyx_t_3, __pyx_t_4); __pyx_t_4++; if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 663, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
        #endif
      } else {
        if (__pyx_t_4 >= PyTuple_GET_SIZE(__pyx_t_3)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_2 = PyTuple_GET_ITEM(__pyx_t_3, __pyx_t_4); __Pyx_INCREF(__pyx_t_2); __pyx_t_4++; if (unlikely(0 < 0)) __PYX_ERR(0, 663, __pyx_L1_error)
        #else
        __pyx_t_2 = PySequence_ITEM(__pyx_t_3, __pyx_t_4); __pyx_t_4++; if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 663, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
        #endif
      }
    } else {
      __pyx_t_2 = __pyx_t_5(__pyx_t_3);
      if (unlikely(!__pyx_t_2)) {
        PyObject* exc_type = PyErr_Occurred();
        if (exc_type) {
          if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
          else __PYX_ERR(0, 663, __pyx_L1_error)
        }
        break;
      }
      __Pyx_GOTREF(__pyx_t_2);
    }
    __Pyx_XGOTREF(__pyx_cur_scope->__pyx_v_e);
    __Pyx_XDECREF_SET(__pyx_cur_scope->__pyx_v_e, __pyx_t_2);
    __Pyx_GIVEREF(__pyx_t_2);
    __pyx_t_2 = 0;
    __Pyx_INCREF(__pyx_t_1);
    __Pyx_XGOTREF(__pyx_cur_scope->__pyx_v_i);
    __Pyx_XDECREF_SET(__pyx_cur_scope->__pyx_v_i, __pyx_t_1);
    __Pyx_GIVEREF(__pyx_t_1);
    __pyx_t_2 = __Pyx_PyInt_AddObjC(__pyx_t_1, __pyx_int_1, 1, 0, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 663, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_1);
    __pyx_t_1 = __pyx_t_2;
    __pyx_t_2 = 0;
    __pyx_t_2 = __Pyx_PyInt_AddObjC(__pyx_cur_scope->__pyx_v_i, __pyx_int_1, 1, 0, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 663, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_6 = __Pyx_PyObject_CallOneArg(((PyObject *)(&PyString_Type)), __pyx_t_2); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 663, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_2 = PyNumber_Add(__pyx_kp_s_SPECIAL, __pyx_t_6); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 663, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    if (unlikely(!__pyx_cur_scope->__pyx_outer_scope->__pyx_v_self)) { __Pyx_RaiseClosureNameError("self"); __PYX_ERR(0, 663, __pyx_L1_error) }
    __Pyx_GetModuleGlobalName(__pyx_t_6, __pyx_n_s_ORTH); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 663, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_t_7 = __Pyx_PyObject_GetItem(__pyx_cur_scope->__pyx_v_e, __pyx_t_6); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 663, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __pyx_t_6 = __Pyx_PyObject_GetItem(((PyObject *)__pyx_cur_scope->__pyx_outer_scope->__pyx_v_self->vocab->strings), __pyx_t_7); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 663, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __pyx_t_7 = PyTuple_New(2); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 663, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_GIVEREF(__pyx_t_2);
    PyTuple_SET_ITEM(__pyx_t_7, 0, __pyx_t_2);
    __Pyx_GIVEREF(__pyx_t_6);
    PyTuple_SET_ITEM(__pyx_t_7, 1, __pyx_t_6);
    __pyx_t_2 = 0;
    __pyx_t_6 = 0;
    __pyx_r = __pyx_t_7;
    __pyx_t_7 = 0;
    __Pyx_XGIVEREF(__pyx_t_1);
    __pyx_cur_scope->__pyx_t_0 = __pyx_t_1;
    __Pyx_XGIVEREF(__pyx_t_3);
    __pyx_cur_scope->__pyx_t_1 = __pyx_t_3;
    __pyx_cur_scope->__pyx_t_2 = __pyx_t_4;
    __pyx_cur_scope->__pyx_t_3 = __pyx_t_5;
    __Pyx_XGIVEREF(__pyx_r);
    __Pyx_RefNannyFinishContext();
    __Pyx_Coroutine_ResetAndClearException(__pyx_generator);
    /* return from generator, yielding value */
    __pyx_generator->resume_label = 1;
    return __pyx_r;
    __pyx_L6_resume_from_yield:;
    __pyx_t_1 = __pyx_cur_scope->__pyx_t_0;
    __pyx_cur_scope->__pyx_t_0 = 0;
    __Pyx_XGOTREF(__pyx_t_1);
    __pyx_t_3 = __pyx_cur_scope->__pyx_t_1;
    __pyx_cur_scope->__pyx_t_1 = 0;
    __Pyx_XGOTREF(__pyx_t_3);
    __pyx_t_4 = __pyx_cur_scope->__pyx_t_2;
    __pyx_t_5 = __pyx_cur_scope->__pyx_t_3;
    if (unlikely(!__pyx_sent_value)) __PYX_ERR(0, 663, __pyx_L1_error)
  }
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  CYTHON_MAYBE_UNUSED_VAR(__pyx_cur_scope);

  /* function exit code */
  PyErr_SetNone(PyExc_StopIteration);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_AddTraceback("genexpr", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_r); __pyx_r = 0;
  #if !CYTHON_USE_EXC_INFO_STACK
  __Pyx_Coroutine_ResetAndClearException(__pyx_generator);
  #endif
  __pyx_generator->resume_label = -1;
  __Pyx_Coroutine_clear((PyObject*)__pyx_generator);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}
static PyObject *__pyx_gb_5spacy_9tokenizer_9Tokenizer_7explain_5generator2(__pyx_CoroutineObject *__pyx_generator, CYTHON_UNUSED PyThreadState *__pyx_tstate, PyObject *__pyx_sent_value); /* proto */

/* "spacy/tokenizer.pyx":672
 *                         break
 *                     if substring in special_cases:
 *                         tokens.extend(("SPECIAL-" + str(i + 1), self.vocab.strings[e[ORTH]]) for i, e in enumerate(special_cases[substring]))             # <<<<<<<<<<<<<<
 *                         substring = ''
 *                         break
 */

static PyObject *__pyx_pf_5spacy_9tokenizer_9Tokenizer_7explain_3genexpr(PyObject *__pyx_self) {
  struct __pyx_obj_5spacy_9tokenizer___pyx_scope_struct_3_genexpr *__pyx_cur_scope;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("genexpr", 0);
  __pyx_cur_scope = (struct __pyx_obj_5spacy_9tokenizer___pyx_scope_struct_3_genexpr *)__pyx_tp_new_5spacy_9tokenizer___pyx_scope_struct_3_genexpr(__pyx_ptype_5spacy_9tokenizer___pyx_scope_struct_3_genexpr, __pyx_empty_tuple, NULL);
  if (unlikely(!__pyx_cur_scope)) {
    __pyx_cur_scope = ((struct __pyx_obj_5spacy_9tokenizer___pyx_scope_struct_3_genexpr *)Py_None);
    __Pyx_INCREF(Py_None);
    __PYX_ERR(0, 672, __pyx_L1_error)
  } else {
    __Pyx_GOTREF(__pyx_cur_scope);
  }
  __pyx_cur_scope->__pyx_outer_scope = (struct __pyx_obj_5spacy_9tokenizer___pyx_scope_struct_1_explain *) __pyx_self;
  __Pyx_INCREF(((PyObject *)__pyx_cur_scope->__pyx_outer_scope));
  __Pyx_GIVEREF(__pyx_cur_scope->__pyx_outer_scope);
  {
    __pyx_CoroutineObject *gen = __Pyx_Generator_New((__pyx_coroutine_body_t) __pyx_gb_5spacy_9tokenizer_9Tokenizer_7explain_5generator2, NULL, (PyObject *) __pyx_cur_scope, __pyx_n_s_genexpr, __pyx_n_s_explain_locals_genexpr, __pyx_n_s_spacy_tokenizer); if (unlikely(!gen)) __PYX_ERR(0, 672, __pyx_L1_error)
    __Pyx_DECREF(__pyx_cur_scope);
    __Pyx_RefNannyFinishContext();
    return (PyObject *) gen;
  }

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_AddTraceback("spacy.tokenizer.Tokenizer.explain.genexpr", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __Pyx_DECREF(((PyObject *)__pyx_cur_scope));
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_gb_5spacy_9tokenizer_9Tokenizer_7explain_5generator2(__pyx_CoroutineObject *__pyx_generator, CYTHON_UNUSED PyThreadState *__pyx_tstate, PyObject *__pyx_sent_value) /* generator body */
{
  struct __pyx_obj_5spacy_9tokenizer___pyx_scope_struct_3_genexpr *__pyx_cur_scope = ((struct __pyx_obj_5spacy_9tokenizer___pyx_scope_struct_3_genexpr *)__pyx_generator->closure);
  PyObject *__pyx_r = NULL;
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  Py_ssize_t __pyx_t_4;
  PyObject *(*__pyx_t_5)(PyObject *);
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("genexpr", 0);
  switch (__pyx_generator->resume_label) {
    case 0: goto __pyx_L3_first_run;
    case 1: goto __pyx_L6_resume_from_yield;
    default: /* CPython raises the right error here */
    __Pyx_RefNannyFinishContext();
    return NULL;
  }
  __pyx_L3_first_run:;
  if (unlikely(!__pyx_sent_value)) __PYX_ERR(0, 672, __pyx_L1_error)
  __Pyx_INCREF(__pyx_int_0);
  __pyx_t_1 = __pyx_int_0;
  if (unlikely(!__pyx_cur_scope->__pyx_outer_scope->__pyx_v_special_cases)) { __Pyx_RaiseClosureNameError("special_cases"); __PYX_ERR(0, 672, __pyx_L1_error) }
  if (unlikely(__pyx_cur_scope->__pyx_outer_scope->__pyx_v_special_cases == Py_None)) {
    PyErr_SetString(PyExc_TypeError, "'NoneType' object is not subscriptable");
    __PYX_ERR(0, 672, __pyx_L1_error)
  }
  if (unlikely(!__pyx_cur_scope->__pyx_outer_scope->__pyx_v_substring)) { __Pyx_RaiseClosureNameError("substring"); __PYX_ERR(0, 672, __pyx_L1_error) }
  __pyx_t_2 = __Pyx_PyDict_GetItem(__pyx_cur_scope->__pyx_outer_scope->__pyx_v_special_cases, __pyx_cur_scope->__pyx_outer_scope->__pyx_v_substring); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 672, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (likely(PyList_CheckExact(__pyx_t_2)) || PyTuple_CheckExact(__pyx_t_2)) {
    __pyx_t_3 = __pyx_t_2; __Pyx_INCREF(__pyx_t_3); __pyx_t_4 = 0;
    __pyx_t_5 = NULL;
  } else {
    __pyx_t_4 = -1; __pyx_t_3 = PyObject_GetIter(__pyx_t_2); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 672, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_5 = Py_TYPE(__pyx_t_3)->tp_iternext; if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 672, __pyx_L1_error)
  }
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  for (;;) {
    if (likely(!__pyx_t_5)) {
      if (likely(PyList_CheckExact(__pyx_t_3))) {
        if (__pyx_t_4 >= PyList_GET_SIZE(__pyx_t_3)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_2 = PyList_GET_ITEM(__pyx_t_3, __pyx_t_4); __Pyx_INCREF(__pyx_t_2); __pyx_t_4++; if (unlikely(0 < 0)) __PYX_ERR(0, 672, __pyx_L1_error)
        #else
        __pyx_t_2 = PySequence_ITEM(__pyx_t_3, __pyx_t_4); __pyx_t_4++; if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 672, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
        #endif
      } else {
        if (__pyx_t_4 >= PyTuple_GET_SIZE(__pyx_t_3)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_2 = PyTuple_GET_ITEM(__pyx_t_3, __pyx_t_4); __Pyx_INCREF(__pyx_t_2); __pyx_t_4++; if (unlikely(0 < 0)) __PYX_ERR(0, 672, __pyx_L1_error)
        #else
        __pyx_t_2 = PySequence_ITEM(__pyx_t_3, __pyx_t_4); __pyx_t_4++; if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 672, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
        #endif
      }
    } else {
      __pyx_t_2 = __pyx_t_5(__pyx_t_3);
      if (unlikely(!__pyx_t_2)) {
        PyObject* exc_type = PyErr_Occurred();
        if (exc_type) {
          if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
          else __PYX_ERR(0, 672, __pyx_L1_error)
        }
        break;
      }
      __Pyx_GOTREF(__pyx_t_2);
    }
    __Pyx_XGOTREF(__pyx_cur_scope->__pyx_v_e);
    __Pyx_XDECREF_SET(__pyx_cur_scope->__pyx_v_e, __pyx_t_2);
    __Pyx_GIVEREF(__pyx_t_2);
    __pyx_t_2 = 0;
    __Pyx_INCREF(__pyx_t_1);
    __Pyx_XGOTREF(__pyx_cur_scope->__pyx_v_i);
    __Pyx_XDECREF_SET(__pyx_cur_scope->__pyx_v_i, __pyx_t_1);
    __Pyx_GIVEREF(__pyx_t_1);
    __pyx_t_2 = __Pyx_PyInt_AddObjC(__pyx_t_1, __pyx_int_1, 1, 0, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 672, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_1);
    __pyx_t_1 = __pyx_t_2;
    __pyx_t_2 = 0;
    __pyx_t_2 = __Pyx_PyInt_AddObjC(__pyx_cur_scope->__pyx_v_i, __pyx_int_1, 1, 0, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 672, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_6 = __Pyx_PyObject_CallOneArg(((PyObject *)(&PyString_Type)), __pyx_t_2); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 672, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_2 = PyNumber_Add(__pyx_kp_s_SPECIAL, __pyx_t_6); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 672, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    if (unlikely(!__pyx_cur_scope->__pyx_outer_scope->__pyx_v_self)) { __Pyx_RaiseClosureNameError("self"); __PYX_ERR(0, 672, __pyx_L1_error) }
    __Pyx_GetModuleGlobalName(__pyx_t_6, __pyx_n_s_ORTH); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 672, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_t_7 = __Pyx_PyObject_GetItem(__pyx_cur_scope->__pyx_v_e, __pyx_t_6); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 672, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __pyx_t_6 = __Pyx_PyObject_GetItem(((PyObject *)__pyx_cur_scope->__pyx_outer_scope->__pyx_v_self->vocab->strings), __pyx_t_7); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 672, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __pyx_t_7 = PyTuple_New(2); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 672, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_GIVEREF(__pyx_t_2);
    PyTuple_SET_ITEM(__pyx_t_7, 0, __pyx_t_2);
    __Pyx_GIVEREF(__pyx_t_6);
    PyTuple_SET_ITEM(__pyx_t_7, 1, __pyx_t_6);
    __pyx_t_2 = 0;
    __pyx_t_6 = 0;
    __pyx_r = __pyx_t_7;
    __pyx_t_7 = 0;
    __Pyx_XGIVEREF(__pyx_t_1);
    __pyx_cur_scope->__pyx_t_0 = __pyx_t_1;
    __Pyx_XGIVEREF(__pyx_t_3);
    __pyx_cur_scope->__pyx_t_1 = __pyx_t_3;
    __pyx_cur_scope->__pyx_t_2 = __pyx_t_4;
    __pyx_cur_scope->__pyx_t_3 = __pyx_t_5;
    __Pyx_XGIVEREF(__pyx_r);
    __Pyx_RefNannyFinishContext();
    __Pyx_Coroutine_ResetAndClearException(__pyx_generator);
    /* return from generator, yielding value */
    __pyx_generator->resume_label = 1;
    return __pyx_r;
    __pyx_L6_resume_from_yield:;
    __pyx_t_1 = __pyx_cur_scope->__pyx_t_0;
    __pyx_cur_scope->__pyx_t_0 = 0;
    __Pyx_XGOTREF(__pyx_t_1);
    __pyx_t_3 = __pyx_cur_scope->__pyx_t_1;
    __pyx_cur_scope->__pyx_t_1 = 0;
    __Pyx_XGOTREF(__pyx_t_3);
    __pyx_t_4 = __pyx_cur_scope->__pyx_t_2;
    __pyx_t_5 = __pyx_cur_scope->__pyx_t_3;
    if (unlikely(!__pyx_sent_value)) __PYX_ERR(0, 672, __pyx_L1_error)
  }
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  CYTHON_MAYBE_UNUSED_VAR(__pyx_cur_scope);

  /* function exit code */
  PyErr_SetNone(PyExc_StopIteration);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_AddTraceback("genexpr", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_r); __pyx_r = 0;
  #if !CYTHON_USE_EXC_INFO_STACK
  __Pyx_Coroutine_ResetAndClearException(__pyx_generator);
  #endif
  __pyx_generator->resume_label = -1;
  __Pyx_Coroutine_clear((PyObject*)__pyx_generator);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}
static PyObject *__pyx_gb_5spacy_9tokenizer_9Tokenizer_7explain_8generator3(__pyx_CoroutineObject *__pyx_generator, CYTHON_UNUSED PyThreadState *__pyx_tstate, PyObject *__pyx_sent_value); /* proto */

/* "spacy/tokenizer.pyx":700
 *                     substring = ''
 *                 elif substring in special_cases:
 *                     tokens.extend((f"SPECIAL-{i + 1}", self.vocab.strings[e[ORTH]]) for i, e in enumerate(special_cases[substring]))             # <<<<<<<<<<<<<<
 *                     substring = ''
 *                 elif list(infix_finditer(substring)):
 */

static PyObject *__pyx_pf_5spacy_9tokenizer_9Tokenizer_7explain_6genexpr(PyObject *__pyx_self) {
  struct __pyx_obj_5spacy_9tokenizer___pyx_scope_struct_4_genexpr *__pyx_cur_scope;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("genexpr", 0);
  __pyx_cur_scope = (struct __pyx_obj_5spacy_9tokenizer___pyx_scope_struct_4_genexpr *)__pyx_tp_new_5spacy_9tokenizer___pyx_scope_struct_4_genexpr(__pyx_ptype_5spacy_9tokenizer___pyx_scope_struct_4_genexpr, __pyx_empty_tuple, NULL);
  if (unlikely(!__pyx_cur_scope)) {
    __pyx_cur_scope = ((struct __pyx_obj_5spacy_9tokenizer___pyx_scope_struct_4_genexpr *)Py_None);
    __Pyx_INCREF(Py_None);
    __PYX_ERR(0, 700, __pyx_L1_error)
  } else {
    __Pyx_GOTREF(__pyx_cur_scope);
  }
  __pyx_cur_scope->__pyx_outer_scope = (struct __pyx_obj_5spacy_9tokenizer___pyx_scope_struct_1_explain *) __pyx_self;
  __Pyx_INCREF(((PyObject *)__pyx_cur_scope->__pyx_outer_scope));
  __Pyx_GIVEREF(__pyx_cur_scope->__pyx_outer_scope);
  {
    __pyx_CoroutineObject *gen = __Pyx_Generator_New((__pyx_coroutine_body_t) __pyx_gb_5spacy_9tokenizer_9Tokenizer_7explain_8generator3, NULL, (PyObject *) __pyx_cur_scope, __pyx_n_s_genexpr, __pyx_n_s_explain_locals_genexpr, __pyx_n_s_spacy_tokenizer); if (unlikely(!gen)) __PYX_ERR(0, 700, __pyx_L1_error)
    __Pyx_DECREF(__pyx_cur_scope);
    __Pyx_RefNannyFinishContext();
    return (PyObject *) gen;
  }

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_AddTraceback("spacy.tokenizer.Tokenizer.explain.genexpr", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __Pyx_DECREF(((PyObject *)__pyx_cur_scope));
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_gb_5spacy_9tokenizer_9Tokenizer_7explain_8generator3(__pyx_CoroutineObject *__pyx_generator, CYTHON_UNUSED PyThreadState *__pyx_tstate, PyObject *__pyx_sent_value) /* generator body */
{
  struct __pyx_obj_5spacy_9tokenizer___pyx_scope_struct_4_genexpr *__pyx_cur_scope = ((struct __pyx_obj_5spacy_9tokenizer___pyx_scope_struct_4_genexpr *)__pyx_generator->closure);
  PyObject *__pyx_r = NULL;
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  Py_ssize_t __pyx_t_4;
  PyObject *(*__pyx_t_5)(PyObject *);
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("genexpr", 0);
  switch (__pyx_generator->resume_label) {
    case 0: goto __pyx_L3_first_run;
    case 1: goto __pyx_L6_resume_from_yield;
    default: /* CPython raises the right error here */
    __Pyx_RefNannyFinishContext();
    return NULL;
  }
  __pyx_L3_first_run:;
  if (unlikely(!__pyx_sent_value)) __PYX_ERR(0, 700, __pyx_L1_error)
  __Pyx_INCREF(__pyx_int_0);
  __pyx_t_1 = __pyx_int_0;
  if (unlikely(!__pyx_cur_scope->__pyx_outer_scope->__pyx_v_special_cases)) { __Pyx_RaiseClosureNameError("special_cases"); __PYX_ERR(0, 700, __pyx_L1_error) }
  if (unlikely(__pyx_cur_scope->__pyx_outer_scope->__pyx_v_special_cases == Py_None)) {
    PyErr_SetString(PyExc_TypeError, "'NoneType' object is not subscriptable");
    __PYX_ERR(0, 700, __pyx_L1_error)
  }
  if (unlikely(!__pyx_cur_scope->__pyx_outer_scope->__pyx_v_substring)) { __Pyx_RaiseClosureNameError("substring"); __PYX_ERR(0, 700, __pyx_L1_error) }
  __pyx_t_2 = __Pyx_PyDict_GetItem(__pyx_cur_scope->__pyx_outer_scope->__pyx_v_special_cases, __pyx_cur_scope->__pyx_outer_scope->__pyx_v_substring); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 700, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (likely(PyList_CheckExact(__pyx_t_2)) || PyTuple_CheckExact(__pyx_t_2)) {
    __pyx_t_3 = __pyx_t_2; __Pyx_INCREF(__pyx_t_3); __pyx_t_4 = 0;
    __pyx_t_5 = NULL;
  } else {
    __pyx_t_4 = -1; __pyx_t_3 = PyObject_GetIter(__pyx_t_2); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 700, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_5 = Py_TYPE(__pyx_t_3)->tp_iternext; if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 700, __pyx_L1_error)
  }
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  for (;;) {
    if (likely(!__pyx_t_5)) {
      if (likely(PyList_CheckExact(__pyx_t_3))) {
        if (__pyx_t_4 >= PyList_GET_SIZE(__pyx_t_3)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_2 = PyList_GET_ITEM(__pyx_t_3, __pyx_t_4); __Pyx_INCREF(__pyx_t_2); __pyx_t_4++; if (unlikely(0 < 0)) __PYX_ERR(0, 700, __pyx_L1_error)
        #else
        __pyx_t_2 = PySequence_ITEM(__pyx_t_3, __pyx_t_4); __pyx_t_4++; if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 700, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
        #endif
      } else {
        if (__pyx_t_4 >= PyTuple_GET_SIZE(__pyx_t_3)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_2 = PyTuple_GET_ITEM(__pyx_t_3, __pyx_t_4); __Pyx_INCREF(__pyx_t_2); __pyx_t_4++; if (unlikely(0 < 0)) __PYX_ERR(0, 700, __pyx_L1_error)
        #else
        __pyx_t_2 = PySequence_ITEM(__pyx_t_3, __pyx_t_4); __pyx_t_4++; if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 700, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
        #endif
      }
    } else {
      __pyx_t_2 = __pyx_t_5(__pyx_t_3);
      if (unlikely(!__pyx_t_2)) {
        PyObject* exc_type = PyErr_Occurred();
        if (exc_type) {
          if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
          else __PYX_ERR(0, 700, __pyx_L1_error)
        }
        break;
      }
      __Pyx_GOTREF(__pyx_t_2);
    }
    __Pyx_XGOTREF(__pyx_cur_scope->__pyx_v_e);
    __Pyx_XDECREF_SET(__pyx_cur_scope->__pyx_v_e, __pyx_t_2);
    __Pyx_GIVEREF(__pyx_t_2);
    __pyx_t_2 = 0;
    __Pyx_INCREF(__pyx_t_1);
    __Pyx_XGOTREF(__pyx_cur_scope->__pyx_v_i);
    __Pyx_XDECREF_SET(__pyx_cur_scope->__pyx_v_i, __pyx_t_1);
    __Pyx_GIVEREF(__pyx_t_1);
    __pyx_t_2 = __Pyx_PyInt_AddObjC(__pyx_t_1, __pyx_int_1, 1, 0, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 700, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_1);
    __pyx_t_1 = __pyx_t_2;
    __pyx_t_2 = 0;
    __pyx_t_2 = __Pyx_PyInt_AddObjC(__pyx_cur_scope->__pyx_v_i, __pyx_int_1, 1, 0, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 700, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_6 = __Pyx_PyObject_FormatSimple(__pyx_t_2, __pyx_empty_unicode); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 700, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_2 = __Pyx_PyUnicode_Concat(__pyx_kp_u_SPECIAL, __pyx_t_6); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 700, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    if (unlikely(!__pyx_cur_scope->__pyx_outer_scope->__pyx_v_self)) { __Pyx_RaiseClosureNameError("self"); __PYX_ERR(0, 700, __pyx_L1_error) }
    __Pyx_GetModuleGlobalName(__pyx_t_6, __pyx_n_s_ORTH); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 700, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_t_7 = __Pyx_PyObject_GetItem(__pyx_cur_scope->__pyx_v_e, __pyx_t_6); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 700, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __pyx_t_6 = __Pyx_PyObject_GetItem(((PyObject *)__pyx_cur_scope->__pyx_outer_scope->__pyx_v_self->vocab->strings), __pyx_t_7); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 700, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __pyx_t_7 = PyTuple_New(2); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 700, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_GIVEREF(__pyx_t_2);
    PyTuple_SET_ITEM(__pyx_t_7, 0, __pyx_t_2);
    __Pyx_GIVEREF(__pyx_t_6);
    PyTuple_SET_ITEM(__pyx_t_7, 1, __pyx_t_6);
    __pyx_t_2 = 0;
    __pyx_t_6 = 0;
    __pyx_r = __pyx_t_7;
    __pyx_t_7 = 0;
    __Pyx_XGIVEREF(__pyx_t_1);
    __pyx_cur_scope->__pyx_t_0 = __pyx_t_1;
    __Pyx_XGIVEREF(__pyx_t_3);
    __pyx_cur_scope->__pyx_t_1 = __pyx_t_3;
    __pyx_cur_scope->__pyx_t_2 = __pyx_t_4;
    __pyx_cur_scope->__pyx_t_3 = __pyx_t_5;
    __Pyx_XGIVEREF(__pyx_r);
    __Pyx_RefNannyFinishContext();
    __Pyx_Coroutine_ResetAndClearException(__pyx_generator);
    /* return from generator, yielding value */
    __pyx_generator->resume_label = 1;
    return __pyx_r;
    __pyx_L6_resume_from_yield:;
    __pyx_t_1 = __pyx_cur_scope->__pyx_t_0;
    __pyx_cur_scope->__pyx_t_0 = 0;
    __Pyx_XGOTREF(__pyx_t_1);
    __pyx_t_3 = __pyx_cur_scope->__pyx_t_1;
    __pyx_cur_scope->__pyx_t_1 = 0;
    __Pyx_XGOTREF(__pyx_t_3);
    __pyx_t_4 = __pyx_cur_scope->__pyx_t_2;
    __pyx_t_5 = __pyx_cur_scope->__pyx_t_3;
    if (unlikely(!__pyx_sent_value)) __PYX_ERR(0, 700, __pyx_L1_error)
  }
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  CYTHON_MAYBE_UNUSED_VAR(__pyx_cur_scope);

  /* function exit code */
  PyErr_SetNone(PyExc_StopIteration);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_AddTraceback("genexpr", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_r); __pyx_r = 0;
  #if !CYTHON_USE_EXC_INFO_STACK
  __Pyx_Coroutine_ResetAndClearException(__pyx_generator);
  #endif
  __pyx_generator->resume_label = -1;
  __Pyx_Coroutine_clear((PyObject*)__pyx_generator);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "spacy/tokenizer.pyx":629
 *         self._load_special_cases(self._rules)
 * 
 *     def explain(self, text):             # <<<<<<<<<<<<<<
 *         """A debugging tokenizer that provides information about which
 *         tokenizer rule or pattern was matched for each token. The tokens
 */

static PyObject *__pyx_pf_5spacy_9tokenizer_9Tokenizer_29explain(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *__pyx_v_self, PyObject *__pyx_v_text) {
  struct __pyx_obj_5spacy_9tokenizer___pyx_scope_struct_1_explain *__pyx_cur_scope;
  PyObject *__pyx_v_prefix_search = NULL;
  PyObject *__pyx_v_suffix_search = NULL;
  PyObject *__pyx_v_infix_finditer = NULL;
  PyObject *__pyx_v_token_match = NULL;
  PyObject *__pyx_v_url_match = NULL;
  PyObject *__pyx_v_orth = NULL;
  PyObject *__pyx_v_special_tokens = NULL;
  PyObject *__pyx_v_tokens = NULL;
  PyObject *__pyx_v_suffixes = NULL;
  PyObject *__pyx_v_split = NULL;
  PyObject *__pyx_v_infixes = NULL;
  PyObject *__pyx_v_offset = NULL;
  PyObject *__pyx_v_match = NULL;
  PyObject *__pyx_v_words = NULL;
  PyObject *__pyx_v_spaces = NULL;
  PyObject *__pyx_v_t_words = NULL;
  PyObject *__pyx_v_t_spaces = NULL;
  PyObject *__pyx_v_word = NULL;
  PyObject *__pyx_v_space = NULL;
  struct __pyx_obj_5spacy_6tokens_3doc_Doc *__pyx_v_doc = NULL;
  PyObject *__pyx_v_matches = NULL;
  PyObject *__pyx_v_spans = NULL;
  PyObject *__pyx_v_i = NULL;
  PyObject *__pyx_v_final_tokens = NULL;
  PyObject *__pyx_v_spans_by_start = NULL;
  PyObject *__pyx_v_span = NULL;
  PyObject *__pyx_v_exc = NULL;
  PyObject *__pyx_v_j = NULL;
  PyObject *__pyx_v_special_token = NULL;
  PyObject *__pyx_gb_5spacy_9tokenizer_9Tokenizer_7explain_2generator1 = 0;
  PyObject *__pyx_gb_5spacy_9tokenizer_9Tokenizer_7explain_5generator2 = 0;
  PyObject *__pyx_gb_5spacy_9tokenizer_9Tokenizer_7explain_8generator3 = 0;
  PyObject *__pyx_v_t = NULL;
  PyObject *__pyx_v_m_id = NULL;
  PyObject *__pyx_v_s = NULL;
  PyObject *__pyx_v_e = NULL;
  PyObject *__pyx_8genexpr3__pyx_v_s = NULL;
  PyObject *__pyx_v_d = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_t_2;
  int __pyx_t_3;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  Py_ssize_t __pyx_t_6;
  PyObject *(*__pyx_t_7)(PyObject *);
  PyObject *__pyx_t_8 = NULL;
  PyObject *__pyx_t_9 = NULL;
  PyObject *(*__pyx_t_10)(PyObject *);
  Py_ssize_t __pyx_t_11;
  PyObject *(*__pyx_t_12)(PyObject *);
  PyObject *__pyx_t_13 = NULL;
  PyObject *__pyx_t_14 = NULL;
  int __pyx_t_15;
  int __pyx_t_16;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("explain", 0);
  __pyx_cur_scope = (struct __pyx_obj_5spacy_9tokenizer___pyx_scope_struct_1_explain *)__pyx_tp_new_5spacy_9tokenizer___pyx_scope_struct_1_explain(__pyx_ptype_5spacy_9tokenizer___pyx_scope_struct_1_explain, __pyx_empty_tuple, NULL);
  if (unlikely(!__pyx_cur_scope)) {
    __pyx_cur_scope = ((struct __pyx_obj_5spacy_9tokenizer___pyx_scope_struct_1_explain *)Py_None);
    __Pyx_INCREF(Py_None);
    __PYX_ERR(0, 629, __pyx_L1_error)
  } else {
    __Pyx_GOTREF(__pyx_cur_scope);
  }
  __pyx_cur_scope->__pyx_v_self = __pyx_v_self;
  __Pyx_INCREF((PyObject *)__pyx_cur_scope->__pyx_v_self);
  __Pyx_GIVEREF((PyObject *)__pyx_cur_scope->__pyx_v_self);

  /* "spacy/tokenizer.pyx":640
 *         DOCS: https://spacy.io/api/tokenizer#explain
 *         """
 *         prefix_search = self.prefix_search             # <<<<<<<<<<<<<<
 *         if prefix_search is None:
 *             prefix_search = re.compile("a^").search
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_cur_scope->__pyx_v_self), __pyx_n_s_prefix_search); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 640, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_v_prefix_search = __pyx_t_1;
  __pyx_t_1 = 0;

  /* "spacy/tokenizer.pyx":641
 *         """
 *         prefix_search = self.prefix_search
 *         if prefix_search is None:             # <<<<<<<<<<<<<<
 *             prefix_search = re.compile("a^").search
 *         suffix_search = self.suffix_search
 */
  __pyx_t_2 = (__pyx_v_prefix_search == Py_None);
  __pyx_t_3 = (__pyx_t_2 != 0);
  if (__pyx_t_3) {

    /* "spacy/tokenizer.pyx":642
 *         prefix_search = self.prefix_search
 *         if prefix_search is None:
 *             prefix_search = re.compile("a^").search             # <<<<<<<<<<<<<<
 *         suffix_search = self.suffix_search
 *         if suffix_search is None:
 */
    __Pyx_GetModuleGlobalName(__pyx_t_4, __pyx_n_s_re); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 642, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_4, __pyx_n_s_compile); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 642, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __pyx_t_4 = NULL;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_5))) {
      __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_5);
      if (likely(__pyx_t_4)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
        __Pyx_INCREF(__pyx_t_4);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_5, function);
      }
    }
    __pyx_t_1 = (__pyx_t_4) ? __Pyx_PyObject_Call2Args(__pyx_t_5, __pyx_t_4, __pyx_kp_s_a) : __Pyx_PyObject_CallOneArg(__pyx_t_5, __pyx_kp_s_a);
    __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
    if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 642, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_search); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 642, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_DECREF_SET(__pyx_v_prefix_search, __pyx_t_5);
    __pyx_t_5 = 0;

    /* "spacy/tokenizer.pyx":641
 *         """
 *         prefix_search = self.prefix_search
 *         if prefix_search is None:             # <<<<<<<<<<<<<<
 *             prefix_search = re.compile("a^").search
 *         suffix_search = self.suffix_search
 */
  }

  /* "spacy/tokenizer.pyx":643
 *         if prefix_search is None:
 *             prefix_search = re.compile("a^").search
 *         suffix_search = self.suffix_search             # <<<<<<<<<<<<<<
 *         if suffix_search is None:
 *             suffix_search = re.compile("a^").search
 */
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_cur_scope->__pyx_v_self), __pyx_n_s_suffix_search); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 643, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_v_suffix_search = __pyx_t_5;
  __pyx_t_5 = 0;

  /* "spacy/tokenizer.pyx":644
 *             prefix_search = re.compile("a^").search
 *         suffix_search = self.suffix_search
 *         if suffix_search is None:             # <<<<<<<<<<<<<<
 *             suffix_search = re.compile("a^").search
 *         infix_finditer = self.infix_finditer
 */
  __pyx_t_3 = (__pyx_v_suffix_search == Py_None);
  __pyx_t_2 = (__pyx_t_3 != 0);
  if (__pyx_t_2) {

    /* "spacy/tokenizer.pyx":645
 *         suffix_search = self.suffix_search
 *         if suffix_search is None:
 *             suffix_search = re.compile("a^").search             # <<<<<<<<<<<<<<
 *         infix_finditer = self.infix_finditer
 *         if infix_finditer is None:
 */
    __Pyx_GetModuleGlobalName(__pyx_t_1, __pyx_n_s_re); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 645, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_compile); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 645, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_1 = NULL;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_4))) {
      __pyx_t_1 = PyMethod_GET_SELF(__pyx_t_4);
      if (likely(__pyx_t_1)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_4);
        __Pyx_INCREF(__pyx_t_1);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_4, function);
      }
    }
    __pyx_t_5 = (__pyx_t_1) ? __Pyx_PyObject_Call2Args(__pyx_t_4, __pyx_t_1, __pyx_kp_s_a) : __Pyx_PyObject_CallOneArg(__pyx_t_4, __pyx_kp_s_a);
    __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
    if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 645, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_t_5, __pyx_n_s_search); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 645, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_DECREF_SET(__pyx_v_suffix_search, __pyx_t_4);
    __pyx_t_4 = 0;

    /* "spacy/tokenizer.pyx":644
 *             prefix_search = re.compile("a^").search
 *         suffix_search = self.suffix_search
 *         if suffix_search is None:             # <<<<<<<<<<<<<<
 *             suffix_search = re.compile("a^").search
 *         infix_finditer = self.infix_finditer
 */
  }

  /* "spacy/tokenizer.pyx":646
 *         if suffix_search is None:
 *             suffix_search = re.compile("a^").search
 *         infix_finditer = self.infix_finditer             # <<<<<<<<<<<<<<
 *         if infix_finditer is None:
 *             infix_finditer = re.compile("a^").finditer
 */
  __pyx_t_4 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_cur_scope->__pyx_v_self), __pyx_n_s_infix_finditer); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 646, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_v_infix_finditer = __pyx_t_4;
  __pyx_t_4 = 0;

  /* "spacy/tokenizer.pyx":647
 *             suffix_search = re.compile("a^").search
 *         infix_finditer = self.infix_finditer
 *         if infix_finditer is None:             # <<<<<<<<<<<<<<
 *             infix_finditer = re.compile("a^").finditer
 *         token_match = self.token_match
 */
  __pyx_t_2 = (__pyx_v_infix_finditer == Py_None);
  __pyx_t_3 = (__pyx_t_2 != 0);
  if (__pyx_t_3) {

    /* "spacy/tokenizer.pyx":648
 *         infix_finditer = self.infix_finditer
 *         if infix_finditer is None:
 *             infix_finditer = re.compile("a^").finditer             # <<<<<<<<<<<<<<
 *         token_match = self.token_match
 *         if token_match is None:
 */
    __Pyx_GetModuleGlobalName(__pyx_t_5, __pyx_n_s_re); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 648, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_5, __pyx_n_s_compile); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 648, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_5 = NULL;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_1))) {
      __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_1);
      if (likely(__pyx_t_5)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_1);
        __Pyx_INCREF(__pyx_t_5);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_1, function);
      }
    }
    __pyx_t_4 = (__pyx_t_5) ? __Pyx_PyObject_Call2Args(__pyx_t_1, __pyx_t_5, __pyx_kp_s_a) : __Pyx_PyObject_CallOneArg(__pyx_t_1, __pyx_kp_s_a);
    __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
    if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 648, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_4, __pyx_n_s_finditer); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 648, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_DECREF_SET(__pyx_v_infix_finditer, __pyx_t_1);
    __pyx_t_1 = 0;

    /* "spacy/tokenizer.pyx":647
 *             suffix_search = re.compile("a^").search
 *         infix_finditer = self.infix_finditer
 *         if infix_finditer is None:             # <<<<<<<<<<<<<<
 *             infix_finditer = re.compile("a^").finditer
 *         token_match = self.token_match
 */
  }

  /* "spacy/tokenizer.pyx":649
 *         if infix_finditer is None:
 *             infix_finditer = re.compile("a^").finditer
 *         token_match = self.token_match             # <<<<<<<<<<<<<<
 *         if token_match is None:
 *             token_match = re.compile("a^").match
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_cur_scope->__pyx_v_self), __pyx_n_s_token_match); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 649, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_v_token_match = __pyx_t_1;
  __pyx_t_1 = 0;

  /* "spacy/tokenizer.pyx":650
 *             infix_finditer = re.compile("a^").finditer
 *         token_match = self.token_match
 *         if token_match is None:             # <<<<<<<<<<<<<<
 *             token_match = re.compile("a^").match
 *         url_match = self.url_match
 */
  __pyx_t_3 = (__pyx_v_token_match == Py_None);
  __pyx_t_2 = (__pyx_t_3 != 0);
  if (__pyx_t_2) {

    /* "spacy/tokenizer.pyx":651
 *         token_match = self.token_match
 *         if token_match is None:
 *             token_match = re.compile("a^").match             # <<<<<<<<<<<<<<
 *         url_match = self.url_match
 *         if url_match is None:
 */
    __Pyx_GetModuleGlobalName(__pyx_t_4, __pyx_n_s_re); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 651, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_4, __pyx_n_s_compile); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 651, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __pyx_t_4 = NULL;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_5))) {
      __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_5);
      if (likely(__pyx_t_4)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
        __Pyx_INCREF(__pyx_t_4);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_5, function);
      }
    }
    __pyx_t_1 = (__pyx_t_4) ? __Pyx_PyObject_Call2Args(__pyx_t_5, __pyx_t_4, __pyx_kp_s_a) : __Pyx_PyObject_CallOneArg(__pyx_t_5, __pyx_kp_s_a);
    __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
    if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 651, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_match); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 651, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_DECREF_SET(__pyx_v_token_match, __pyx_t_5);
    __pyx_t_5 = 0;

    /* "spacy/tokenizer.pyx":650
 *             infix_finditer = re.compile("a^").finditer
 *         token_match = self.token_match
 *         if token_match is None:             # <<<<<<<<<<<<<<
 *             token_match = re.compile("a^").match
 *         url_match = self.url_match
 */
  }

  /* "spacy/tokenizer.pyx":652
 *         if token_match is None:
 *             token_match = re.compile("a^").match
 *         url_match = self.url_match             # <<<<<<<<<<<<<<
 *         if url_match is None:
 *             url_match = re.compile("a^").match
 */
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_cur_scope->__pyx_v_self), __pyx_n_s_url_match); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 652, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_v_url_match = __pyx_t_5;
  __pyx_t_5 = 0;

  /* "spacy/tokenizer.pyx":653
 *             token_match = re.compile("a^").match
 *         url_match = self.url_match
 *         if url_match is None:             # <<<<<<<<<<<<<<
 *             url_match = re.compile("a^").match
 *         special_cases = {}
 */
  __pyx_t_2 = (__pyx_v_url_match == Py_None);
  __pyx_t_3 = (__pyx_t_2 != 0);
  if (__pyx_t_3) {

    /* "spacy/tokenizer.pyx":654
 *         url_match = self.url_match
 *         if url_match is None:
 *             url_match = re.compile("a^").match             # <<<<<<<<<<<<<<
 *         special_cases = {}
 *         for orth, special_tokens in self.rules.items():
 */
    __Pyx_GetModuleGlobalName(__pyx_t_1, __pyx_n_s_re); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 654, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_compile); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 654, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_1 = NULL;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_4))) {
      __pyx_t_1 = PyMethod_GET_SELF(__pyx_t_4);
      if (likely(__pyx_t_1)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_4);
        __Pyx_INCREF(__pyx_t_1);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_4, function);
      }
    }
    __pyx_t_5 = (__pyx_t_1) ? __Pyx_PyObject_Call2Args(__pyx_t_4, __pyx_t_1, __pyx_kp_s_a) : __Pyx_PyObject_CallOneArg(__pyx_t_4, __pyx_kp_s_a);
    __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
    if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 654, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_t_5, __pyx_n_s_match); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 654, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_DECREF_SET(__pyx_v_url_match, __pyx_t_4);
    __pyx_t_4 = 0;

    /* "spacy/tokenizer.pyx":653
 *             token_match = re.compile("a^").match
 *         url_match = self.url_match
 *         if url_match is None:             # <<<<<<<<<<<<<<
 *             url_match = re.compile("a^").match
 *         special_cases = {}
 */
  }

  /* "spacy/tokenizer.pyx":655
 *         if url_match is None:
 *             url_match = re.compile("a^").match
 *         special_cases = {}             # <<<<<<<<<<<<<<
 *         for orth, special_tokens in self.rules.items():
 *             special_cases[orth] = [intify_attrs(special_token, strings_map=self.vocab.strings, _do_deprecated=True) for special_token in special_tokens]
 */
  __pyx_t_4 = __Pyx_PyDict_NewPresized(0); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 655, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_GIVEREF(__pyx_t_4);
  __pyx_cur_scope->__pyx_v_special_cases = ((PyObject*)__pyx_t_4);
  __pyx_t_4 = 0;

  /* "spacy/tokenizer.pyx":656
 *             url_match = re.compile("a^").match
 *         special_cases = {}
 *         for orth, special_tokens in self.rules.items():             # <<<<<<<<<<<<<<
 *             special_cases[orth] = [intify_attrs(special_token, strings_map=self.vocab.strings, _do_deprecated=True) for special_token in special_tokens]
 *         tokens = []
 */
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_cur_scope->__pyx_v_self), __pyx_n_s_rules); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 656, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_5, __pyx_n_s_items); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 656, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_t_5 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_1))) {
    __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_1);
    if (likely(__pyx_t_5)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_1);
      __Pyx_INCREF(__pyx_t_5);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_1, function);
    }
  }
  __pyx_t_4 = (__pyx_t_5) ? __Pyx_PyObject_CallOneArg(__pyx_t_1, __pyx_t_5) : __Pyx_PyObject_CallNoArg(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
  if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 656, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  if (likely(PyList_CheckExact(__pyx_t_4)) || PyTuple_CheckExact(__pyx_t_4)) {
    __pyx_t_1 = __pyx_t_4; __Pyx_INCREF(__pyx_t_1); __pyx_t_6 = 0;
    __pyx_t_7 = NULL;
  } else {
    __pyx_t_6 = -1; __pyx_t_1 = PyObject_GetIter(__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 656, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_7 = Py_TYPE(__pyx_t_1)->tp_iternext; if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 656, __pyx_L1_error)
  }
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  for (;;) {
    if (likely(!__pyx_t_7)) {
      if (likely(PyList_CheckExact(__pyx_t_1))) {
        if (__pyx_t_6 >= PyList_GET_SIZE(__pyx_t_1)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_4 = PyList_GET_ITEM(__pyx_t_1, __pyx_t_6); __Pyx_INCREF(__pyx_t_4); __pyx_t_6++; if (unlikely(0 < 0)) __PYX_ERR(0, 656, __pyx_L1_error)
        #else
        __pyx_t_4 = PySequence_ITEM(__pyx_t_1, __pyx_t_6); __pyx_t_6++; if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 656, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_4);
        #endif
      } else {
        if (__pyx_t_6 >= PyTuple_GET_SIZE(__pyx_t_1)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_4 = PyTuple_GET_ITEM(__pyx_t_1, __pyx_t_6); __Pyx_INCREF(__pyx_t_4); __pyx_t_6++; if (unlikely(0 < 0)) __PYX_ERR(0, 656, __pyx_L1_error)
        #else
        __pyx_t_4 = PySequence_ITEM(__pyx_t_1, __pyx_t_6); __pyx_t_6++; if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 656, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_4);
        #endif
      }
    } else {
      __pyx_t_4 = __pyx_t_7(__pyx_t_1);
      if (unlikely(!__pyx_t_4)) {
        PyObject* exc_type = PyErr_Occurred();
        if (exc_type) {
          if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
          else __PYX_ERR(0, 656, __pyx_L1_error)
        }
        break;
      }
      __Pyx_GOTREF(__pyx_t_4);
    }
    if ((likely(PyTuple_CheckExact(__pyx_t_4))) || (PyList_CheckExact(__pyx_t_4))) {
      PyObject* sequence = __pyx_t_4;
      Py_ssize_t size = __Pyx_PySequence_SIZE(sequence);
      if (unlikely(size != 2)) {
        if (size > 2) __Pyx_RaiseTooManyValuesError(2);
        else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
        __PYX_ERR(0, 656, __pyx_L1_error)
      }
      #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
      if (likely(PyTuple_CheckExact(sequence))) {
        __pyx_t_5 = PyTuple_GET_ITEM(sequence, 0); 
        __pyx_t_8 = PyTuple_GET_ITEM(sequence, 1); 
      } else {
        __pyx_t_5 = PyList_GET_ITEM(sequence, 0); 
        __pyx_t_8 = PyList_GET_ITEM(sequence, 1); 
      }
      __Pyx_INCREF(__pyx_t_5);
      __Pyx_INCREF(__pyx_t_8);
      #else
      __pyx_t_5 = PySequence_ITEM(sequence, 0); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 656, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_5);
      __pyx_t_8 = PySequence_ITEM(sequence, 1); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 656, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      #endif
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    } else {
      Py_ssize_t index = -1;
      __pyx_t_9 = PyObject_GetIter(__pyx_t_4); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 656, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_9);
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __pyx_t_10 = Py_TYPE(__pyx_t_9)->tp_iternext;
      index = 0; __pyx_t_5 = __pyx_t_10(__pyx_t_9); if (unlikely(!__pyx_t_5)) goto __pyx_L10_unpacking_failed;
      __Pyx_GOTREF(__pyx_t_5);
      index = 1; __pyx_t_8 = __pyx_t_10(__pyx_t_9); if (unlikely(!__pyx_t_8)) goto __pyx_L10_unpacking_failed;
      __Pyx_GOTREF(__pyx_t_8);
      if (__Pyx_IternextUnpackEndCheck(__pyx_t_10(__pyx_t_9), 2) < 0) __PYX_ERR(0, 656, __pyx_L1_error)
      __pyx_t_10 = NULL;
      __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
      goto __pyx_L11_unpacking_done;
      __pyx_L10_unpacking_failed:;
      __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
      __pyx_t_10 = NULL;
      if (__Pyx_IterFinish() == 0) __Pyx_RaiseNeedMoreValuesError(index);
      __PYX_ERR(0, 656, __pyx_L1_error)
      __pyx_L11_unpacking_done:;
    }
    __Pyx_XDECREF_SET(__pyx_v_orth, __pyx_t_5);
    __pyx_t_5 = 0;
    __Pyx_XDECREF_SET(__pyx_v_special_tokens, __pyx_t_8);
    __pyx_t_8 = 0;

    /* "spacy/tokenizer.pyx":657
 *         special_cases = {}
 *         for orth, special_tokens in self.rules.items():
 *             special_cases[orth] = [intify_attrs(special_token, strings_map=self.vocab.strings, _do_deprecated=True) for special_token in special_tokens]             # <<<<<<<<<<<<<<
 *         tokens = []
 *         for substring in text.split():
 */
    __pyx_t_4 = PyList_New(0); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 657, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    if (likely(PyList_CheckExact(__pyx_v_special_tokens)) || PyTuple_CheckExact(__pyx_v_special_tokens)) {
      __pyx_t_8 = __pyx_v_special_tokens; __Pyx_INCREF(__pyx_t_8); __pyx_t_11 = 0;
      __pyx_t_12 = NULL;
    } else {
      __pyx_t_11 = -1; __pyx_t_8 = PyObject_GetIter(__pyx_v_special_tokens); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 657, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __pyx_t_12 = Py_TYPE(__pyx_t_8)->tp_iternext; if (unlikely(!__pyx_t_12)) __PYX_ERR(0, 657, __pyx_L1_error)
    }
    for (;;) {
      if (likely(!__pyx_t_12)) {
        if (likely(PyList_CheckExact(__pyx_t_8))) {
          if (__pyx_t_11 >= PyList_GET_SIZE(__pyx_t_8)) break;
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          __pyx_t_5 = PyList_GET_ITEM(__pyx_t_8, __pyx_t_11); __Pyx_INCREF(__pyx_t_5); __pyx_t_11++; if (unlikely(0 < 0)) __PYX_ERR(0, 657, __pyx_L1_error)
          #else
          __pyx_t_5 = PySequence_ITEM(__pyx_t_8, __pyx_t_11); __pyx_t_11++; if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 657, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_5);
          #endif
        } else {
          if (__pyx_t_11 >= PyTuple_GET_SIZE(__pyx_t_8)) break;
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          __pyx_t_5 = PyTuple_GET_ITEM(__pyx_t_8, __pyx_t_11); __Pyx_INCREF(__pyx_t_5); __pyx_t_11++; if (unlikely(0 < 0)) __PYX_ERR(0, 657, __pyx_L1_error)
          #else
          __pyx_t_5 = PySequence_ITEM(__pyx_t_8, __pyx_t_11); __pyx_t_11++; if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 657, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_5);
          #endif
        }
      } else {
        __pyx_t_5 = __pyx_t_12(__pyx_t_8);
        if (unlikely(!__pyx_t_5)) {
          PyObject* exc_type = PyErr_Occurred();
          if (exc_type) {
            if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
            else __PYX_ERR(0, 657, __pyx_L1_error)
          }
          break;
        }
        __Pyx_GOTREF(__pyx_t_5);
      }
      __Pyx_XDECREF_SET(__pyx_v_special_token, __pyx_t_5);
      __pyx_t_5 = 0;
      __Pyx_GetModuleGlobalName(__pyx_t_5, __pyx_n_s_intify_attrs); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 657, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_5);
      __pyx_t_9 = PyTuple_New(1); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 657, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_9);
      __Pyx_INCREF(__pyx_v_special_token);
      __Pyx_GIVEREF(__pyx_v_special_token);
      PyTuple_SET_ITEM(__pyx_t_9, 0, __pyx_v_special_token);
      __pyx_t_13 = __Pyx_PyDict_NewPresized(2); if (unlikely(!__pyx_t_13)) __PYX_ERR(0, 657, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_13);
      if (PyDict_SetItem(__pyx_t_13, __pyx_n_s_strings_map, ((PyObject *)__pyx_cur_scope->__pyx_v_self->vocab->strings)) < 0) __PYX_ERR(0, 657, __pyx_L1_error)
      if (PyDict_SetItem(__pyx_t_13, __pyx_n_s_do_deprecated, Py_True) < 0) __PYX_ERR(0, 657, __pyx_L1_error)
      __pyx_t_14 = __Pyx_PyObject_Call(__pyx_t_5, __pyx_t_9, __pyx_t_13); if (unlikely(!__pyx_t_14)) __PYX_ERR(0, 657, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_14);
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
      __Pyx_DECREF(__pyx_t_13); __pyx_t_13 = 0;
      if (unlikely(__Pyx_ListComp_Append(__pyx_t_4, (PyObject*)__pyx_t_14))) __PYX_ERR(0, 657, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_14); __pyx_t_14 = 0;
    }
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    if (unlikely(PyDict_SetItem(__pyx_cur_scope->__pyx_v_special_cases, __pyx_v_orth, __pyx_t_4) < 0)) __PYX_ERR(0, 657, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;

    /* "spacy/tokenizer.pyx":656
 *             url_match = re.compile("a^").match
 *         special_cases = {}
 *         for orth, special_tokens in self.rules.items():             # <<<<<<<<<<<<<<
 *             special_cases[orth] = [intify_attrs(special_token, strings_map=self.vocab.strings, _do_deprecated=True) for special_token in special_tokens]
 *         tokens = []
 */
  }
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "spacy/tokenizer.pyx":658
 *         for orth, special_tokens in self.rules.items():
 *             special_cases[orth] = [intify_attrs(special_token, strings_map=self.vocab.strings, _do_deprecated=True) for special_token in special_tokens]
 *         tokens = []             # <<<<<<<<<<<<<<
 *         for substring in text.split():
 *             suffixes = []
 */
  __pyx_t_1 = PyList_New(0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 658, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_v_tokens = ((PyObject*)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "spacy/tokenizer.pyx":659
 *             special_cases[orth] = [intify_attrs(special_token, strings_map=self.vocab.strings, _do_deprecated=True) for special_token in special_tokens]
 *         tokens = []
 *         for substring in text.split():             # <<<<<<<<<<<<<<
 *             suffixes = []
 *             while substring:
 */
  __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_v_text, __pyx_n_s_split); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 659, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_8 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_4))) {
    __pyx_t_8 = PyMethod_GET_SELF(__pyx_t_4);
    if (likely(__pyx_t_8)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_4);
      __Pyx_INCREF(__pyx_t_8);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_4, function);
    }
  }
  __pyx_t_1 = (__pyx_t_8) ? __Pyx_PyObject_CallOneArg(__pyx_t_4, __pyx_t_8) : __Pyx_PyObject_CallNoArg(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_8); __pyx_t_8 = 0;
  if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 659, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  if (likely(PyList_CheckExact(__pyx_t_1)) || PyTuple_CheckExact(__pyx_t_1)) {
    __pyx_t_4 = __pyx_t_1; __Pyx_INCREF(__pyx_t_4); __pyx_t_6 = 0;
    __pyx_t_7 = NULL;
  } else {
    __pyx_t_6 = -1; __pyx_t_4 = PyObject_GetIter(__pyx_t_1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 659, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_7 = Py_TYPE(__pyx_t_4)->tp_iternext; if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 659, __pyx_L1_error)
  }
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  for (;;) {
    if (likely(!__pyx_t_7)) {
      if (likely(PyList_CheckExact(__pyx_t_4))) {
        if (__pyx_t_6 >= PyList_GET_SIZE(__pyx_t_4)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_1 = PyList_GET_ITEM(__pyx_t_4, __pyx_t_6); __Pyx_INCREF(__pyx_t_1); __pyx_t_6++; if (unlikely(0 < 0)) __PYX_ERR(0, 659, __pyx_L1_error)
        #else
        __pyx_t_1 = PySequence_ITEM(__pyx_t_4, __pyx_t_6); __pyx_t_6++; if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 659, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        #endif
      } else {
        if (__pyx_t_6 >= PyTuple_GET_SIZE(__pyx_t_4)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_1 = PyTuple_GET_ITEM(__pyx_t_4, __pyx_t_6); __Pyx_INCREF(__pyx_t_1); __pyx_t_6++; if (unlikely(0 < 0)) __PYX_ERR(0, 659, __pyx_L1_error)
        #else
        __pyx_t_1 = PySequence_ITEM(__pyx_t_4, __pyx_t_6); __pyx_t_6++; if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 659, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        #endif
      }
    } else {
      __pyx_t_1 = __pyx_t_7(__pyx_t_4);
      if (unlikely(!__pyx_t_1)) {
        PyObject* exc_type = PyErr_Occurred();
        if (exc_type) {
          if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
          else __PYX_ERR(0, 659, __pyx_L1_error)
        }
        break;
      }
      __Pyx_GOTREF(__pyx_t_1);
    }
    __Pyx_XGOTREF(__pyx_cur_scope->__pyx_v_substring);
    __Pyx_XDECREF_SET(__pyx_cur_scope->__pyx_v_substring, __pyx_t_1);
    __Pyx_GIVEREF(__pyx_t_1);
    __pyx_t_1 = 0;

    /* "spacy/tokenizer.pyx":660
 *         tokens = []
 *         for substring in text.split():
 *             suffixes = []             # <<<<<<<<<<<<<<
 *             while substring:
 *                 if substring in special_cases:
 */
    __pyx_t_1 = PyList_New(0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 660, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_XDECREF_SET(__pyx_v_suffixes, ((PyObject*)__pyx_t_1));
    __pyx_t_1 = 0;

    /* "spacy/tokenizer.pyx":661
 *         for substring in text.split():
 *             suffixes = []
 *             while substring:             # <<<<<<<<<<<<<<
 *                 if substring in special_cases:
 *                     tokens.extend(("SPECIAL-" + str(i + 1), self.vocab.strings[e[ORTH]]) for i, e in enumerate(special_cases[substring]))
 */
    while (1) {
      __pyx_t_3 = __Pyx_PyObject_IsTrue(__pyx_cur_scope->__pyx_v_substring); if (unlikely(__pyx_t_3 < 0)) __PYX_ERR(0, 661, __pyx_L1_error)
      if (!__pyx_t_3) break;

      /* "spacy/tokenizer.pyx":662
 *             suffixes = []
 *             while substring:
 *                 if substring in special_cases:             # <<<<<<<<<<<<<<
 *                     tokens.extend(("SPECIAL-" + str(i + 1), self.vocab.strings[e[ORTH]]) for i, e in enumerate(special_cases[substring]))
 *                     substring = ''
 */
      __pyx_t_3 = (__Pyx_PyDict_ContainsTF(__pyx_cur_scope->__pyx_v_substring, __pyx_cur_scope->__pyx_v_special_cases, Py_EQ)); if (unlikely(__pyx_t_3 < 0)) __PYX_ERR(0, 662, __pyx_L1_error)
      __pyx_t_2 = (__pyx_t_3 != 0);
      if (__pyx_t_2) {

        /* "spacy/tokenizer.pyx":663
 *             while substring:
 *                 if substring in special_cases:
 *                     tokens.extend(("SPECIAL-" + str(i + 1), self.vocab.strings[e[ORTH]]) for i, e in enumerate(special_cases[substring]))             # <<<<<<<<<<<<<<
 *                     substring = ''
 *                     continue
 */
        __pyx_t_1 = __pyx_pf_5spacy_9tokenizer_9Tokenizer_7explain_genexpr(((PyObject*)__pyx_cur_scope)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 663, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        __pyx_t_15 = __Pyx_PyList_Extend(__pyx_v_tokens, __pyx_t_1); if (unlikely(__pyx_t_15 == ((int)-1))) __PYX_ERR(0, 663, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

        /* "spacy/tokenizer.pyx":664
 *                 if substring in special_cases:
 *                     tokens.extend(("SPECIAL-" + str(i + 1), self.vocab.strings[e[ORTH]]) for i, e in enumerate(special_cases[substring]))
 *                     substring = ''             # <<<<<<<<<<<<<<
 *                     continue
 *                 while prefix_search(substring) or suffix_search(substring):
 */
        __Pyx_INCREF(__pyx_kp_s__3);
        __Pyx_GOTREF(__pyx_cur_scope->__pyx_v_substring);
        __Pyx_DECREF_SET(__pyx_cur_scope->__pyx_v_substring, __pyx_kp_s__3);
        __Pyx_GIVEREF(__pyx_kp_s__3);

        /* "spacy/tokenizer.pyx":665
 *                     tokens.extend(("SPECIAL-" + str(i + 1), self.vocab.strings[e[ORTH]]) for i, e in enumerate(special_cases[substring]))
 *                     substring = ''
 *                     continue             # <<<<<<<<<<<<<<
 *                 while prefix_search(substring) or suffix_search(substring):
 *                     if token_match(substring):
 */
        goto __pyx_L16_continue;

        /* "spacy/tokenizer.pyx":662
 *             suffixes = []
 *             while substring:
 *                 if substring in special_cases:             # <<<<<<<<<<<<<<
 *                     tokens.extend(("SPECIAL-" + str(i + 1), self.vocab.strings[e[ORTH]]) for i, e in enumerate(special_cases[substring]))
 *                     substring = ''
 */
      }

      /* "spacy/tokenizer.pyx":666
 *                     substring = ''
 *                     continue
 *                 while prefix_search(substring) or suffix_search(substring):             # <<<<<<<<<<<<<<
 *                     if token_match(substring):
 *                         tokens.append(("TOKEN_MATCH", substring))
 */
      while (1) {
        __Pyx_INCREF(__pyx_v_prefix_search);
        __pyx_t_8 = __pyx_v_prefix_search; __pyx_t_14 = NULL;
        if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_8))) {
          __pyx_t_14 = PyMethod_GET_SELF(__pyx_t_8);
          if (likely(__pyx_t_14)) {
            PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_8);
            __Pyx_INCREF(__pyx_t_14);
            __Pyx_INCREF(function);
            __Pyx_DECREF_SET(__pyx_t_8, function);
          }
        }
        __pyx_t_1 = (__pyx_t_14) ? __Pyx_PyObject_Call2Args(__pyx_t_8, __pyx_t_14, __pyx_cur_scope->__pyx_v_substring) : __Pyx_PyObject_CallOneArg(__pyx_t_8, __pyx_cur_scope->__pyx_v_substring);
        __Pyx_XDECREF(__pyx_t_14); __pyx_t_14 = 0;
        if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 666, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
        __pyx_t_3 = __Pyx_PyObject_IsTrue(__pyx_t_1); if (unlikely(__pyx_t_3 < 0)) __PYX_ERR(0, 666, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
        if (!__pyx_t_3) {
        } else {
          __pyx_t_2 = __pyx_t_3;
          goto __pyx_L21_bool_binop_done;
        }
        __Pyx_INCREF(__pyx_v_suffix_search);
        __pyx_t_8 = __pyx_v_suffix_search; __pyx_t_14 = NULL;
        if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_8))) {
          __pyx_t_14 = PyMethod_GET_SELF(__pyx_t_8);
          if (likely(__pyx_t_14)) {
            PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_8);
            __Pyx_INCREF(__pyx_t_14);
            __Pyx_INCREF(function);
            __Pyx_DECREF_SET(__pyx_t_8, function);
          }
        }
        __pyx_t_1 = (__pyx_t_14) ? __Pyx_PyObject_Call2Args(__pyx_t_8, __pyx_t_14, __pyx_cur_scope->__pyx_v_substring) : __Pyx_PyObject_CallOneArg(__pyx_t_8, __pyx_cur_scope->__pyx_v_substring);
        __Pyx_XDECREF(__pyx_t_14); __pyx_t_14 = 0;
        if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 666, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
        __pyx_t_3 = __Pyx_PyObject_IsTrue(__pyx_t_1); if (unlikely(__pyx_t_3 < 0)) __PYX_ERR(0, 666, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
        __pyx_t_2 = __pyx_t_3;
        __pyx_L21_bool_binop_done:;
        if (!__pyx_t_2) break;

        /* "spacy/tokenizer.pyx":667
 *                     continue
 *                 while prefix_search(substring) or suffix_search(substring):
 *                     if token_match(substring):             # <<<<<<<<<<<<<<
 *                         tokens.append(("TOKEN_MATCH", substring))
 *                         substring = ''
 */
        __Pyx_INCREF(__pyx_v_token_match);
        __pyx_t_8 = __pyx_v_token_match; __pyx_t_14 = NULL;
        if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_8))) {
          __pyx_t_14 = PyMethod_GET_SELF(__pyx_t_8);
          if (likely(__pyx_t_14)) {
            PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_8);
            __Pyx_INCREF(__pyx_t_14);
            __Pyx_INCREF(function);
            __Pyx_DECREF_SET(__pyx_t_8, function);
          }
        }
        __pyx_t_1 = (__pyx_t_14) ? __Pyx_PyObject_Call2Args(__pyx_t_8, __pyx_t_14, __pyx_cur_scope->__pyx_v_substring) : __Pyx_PyObject_CallOneArg(__pyx_t_8, __pyx_cur_scope->__pyx_v_substring);
        __Pyx_XDECREF(__pyx_t_14); __pyx_t_14 = 0;
        if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 667, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
        __pyx_t_2 = __Pyx_PyObject_IsTrue(__pyx_t_1); if (unlikely(__pyx_t_2 < 0)) __PYX_ERR(0, 667, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
        if (__pyx_t_2) {

          /* "spacy/tokenizer.pyx":668
 *                 while prefix_search(substring) or suffix_search(substring):
 *                     if token_match(substring):
 *                         tokens.append(("TOKEN_MATCH", substring))             # <<<<<<<<<<<<<<
 *                         substring = ''
 *                         break
 */
          __pyx_t_1 = PyTuple_New(2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 668, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_1);
          __Pyx_INCREF(__pyx_n_s_TOKEN_MATCH);
          __Pyx_GIVEREF(__pyx_n_s_TOKEN_MATCH);
          PyTuple_SET_ITEM(__pyx_t_1, 0, __pyx_n_s_TOKEN_MATCH);
          __Pyx_INCREF(__pyx_cur_scope->__pyx_v_substring);
          __Pyx_GIVEREF(__pyx_cur_scope->__pyx_v_substring);
          PyTuple_SET_ITEM(__pyx_t_1, 1, __pyx_cur_scope->__pyx_v_substring);
          __pyx_t_15 = __Pyx_PyList_Append(__pyx_v_tokens, __pyx_t_1); if (unlikely(__pyx_t_15 == ((int)-1))) __PYX_ERR(0, 668, __pyx_L1_error)
          __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

          /* "spacy/tokenizer.pyx":669
 *                     if token_match(substring):
 *                         tokens.append(("TOKEN_MATCH", substring))
 *                         substring = ''             # <<<<<<<<<<<<<<
 *                         break
 *                     if substring in special_cases:
 */
          __Pyx_INCREF(__pyx_kp_s__3);
          __Pyx_GOTREF(__pyx_cur_scope->__pyx_v_substring);
          __Pyx_DECREF_SET(__pyx_cur_scope->__pyx_v_substring, __pyx_kp_s__3);
          __Pyx_GIVEREF(__pyx_kp_s__3);

          /* "spacy/tokenizer.pyx":670
 *                         tokens.append(("TOKEN_MATCH", substring))
 *                         substring = ''
 *                         break             # <<<<<<<<<<<<<<
 *                     if substring in special_cases:
 *                         tokens.extend(("SPECIAL-" + str(i + 1), self.vocab.strings[e[ORTH]]) for i, e in enumerate(special_cases[substring]))
 */
          goto __pyx_L20_break;

          /* "spacy/tokenizer.pyx":667
 *                     continue
 *                 while prefix_search(substring) or suffix_search(substring):
 *                     if token_match(substring):             # <<<<<<<<<<<<<<
 *                         tokens.append(("TOKEN_MATCH", substring))
 *                         substring = ''
 */
        }

        /* "spacy/tokenizer.pyx":671
 *                         substring = ''
 *                         break
 *                     if substring in special_cases:             # <<<<<<<<<<<<<<
 *                         tokens.extend(("SPECIAL-" + str(i + 1), self.vocab.strings[e[ORTH]]) for i, e in enumerate(special_cases[substring]))
 *                         substring = ''
 */
        __pyx_t_2 = (__Pyx_PyDict_ContainsTF(__pyx_cur_scope->__pyx_v_substring, __pyx_cur_scope->__pyx_v_special_cases, Py_EQ)); if (unlikely(__pyx_t_2 < 0)) __PYX_ERR(0, 671, __pyx_L1_error)
        __pyx_t_3 = (__pyx_t_2 != 0);
        if (__pyx_t_3) {

          /* "spacy/tokenizer.pyx":672
 *                         break
 *                     if substring in special_cases:
 *                         tokens.extend(("SPECIAL-" + str(i + 1), self.vocab.strings[e[ORTH]]) for i, e in enumerate(special_cases[substring]))             # <<<<<<<<<<<<<<
 *                         substring = ''
 *                         break
 */
          __pyx_t_1 = __pyx_pf_5spacy_9tokenizer_9Tokenizer_7explain_3genexpr(((PyObject*)__pyx_cur_scope)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 672, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_1);
          __pyx_t_15 = __Pyx_PyList_Extend(__pyx_v_tokens, __pyx_t_1); if (unlikely(__pyx_t_15 == ((int)-1))) __PYX_ERR(0, 672, __pyx_L1_error)
          __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

          /* "spacy/tokenizer.pyx":673
 *                     if substring in special_cases:
 *                         tokens.extend(("SPECIAL-" + str(i + 1), self.vocab.strings[e[ORTH]]) for i, e in enumerate(special_cases[substring]))
 *                         substring = ''             # <<<<<<<<<<<<<<
 *                         break
 *                     if prefix_search(substring):
 */
          __Pyx_INCREF(__pyx_kp_s__3);
          __Pyx_GOTREF(__pyx_cur_scope->__pyx_v_substring);
          __Pyx_DECREF_SET(__pyx_cur_scope->__pyx_v_substring, __pyx_kp_s__3);
          __Pyx_GIVEREF(__pyx_kp_s__3);

          /* "spacy/tokenizer.pyx":674
 *                         tokens.extend(("SPECIAL-" + str(i + 1), self.vocab.strings[e[ORTH]]) for i, e in enumerate(special_cases[substring]))
 *                         substring = ''
 *                         break             # <<<<<<<<<<<<<<
 *                     if prefix_search(substring):
 *                         split = prefix_search(substring).end()
 */
          goto __pyx_L20_break;

          /* "spacy/tokenizer.pyx":671
 *                         substring = ''
 *                         break
 *                     if substring in special_cases:             # <<<<<<<<<<<<<<
 *                         tokens.extend(("SPECIAL-" + str(i + 1), self.vocab.strings[e[ORTH]]) for i, e in enumerate(special_cases[substring]))
 *                         substring = ''
 */
        }

        /* "spacy/tokenizer.pyx":675
 *                         substring = ''
 *                         break
 *                     if prefix_search(substring):             # <<<<<<<<<<<<<<
 *                         split = prefix_search(substring).end()
 *                         # break if pattern matches the empty string
 */
        __Pyx_INCREF(__pyx_v_prefix_search);
        __pyx_t_8 = __pyx_v_prefix_search; __pyx_t_14 = NULL;
        if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_8))) {
          __pyx_t_14 = PyMethod_GET_SELF(__pyx_t_8);
          if (likely(__pyx_t_14)) {
            PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_8);
            __Pyx_INCREF(__pyx_t_14);
            __Pyx_INCREF(function);
            __Pyx_DECREF_SET(__pyx_t_8, function);
          }
        }
        __pyx_t_1 = (__pyx_t_14) ? __Pyx_PyObject_Call2Args(__pyx_t_8, __pyx_t_14, __pyx_cur_scope->__pyx_v_substring) : __Pyx_PyObject_CallOneArg(__pyx_t_8, __pyx_cur_scope->__pyx_v_substring);
        __Pyx_XDECREF(__pyx_t_14); __pyx_t_14 = 0;
        if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 675, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
        __pyx_t_3 = __Pyx_PyObject_IsTrue(__pyx_t_1); if (unlikely(__pyx_t_3 < 0)) __PYX_ERR(0, 675, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
        if (__pyx_t_3) {

          /* "spacy/tokenizer.pyx":676
 *                         break
 *                     if prefix_search(substring):
 *                         split = prefix_search(substring).end()             # <<<<<<<<<<<<<<
 *                         # break if pattern matches the empty string
 *                         if split == 0:
 */
          __Pyx_INCREF(__pyx_v_prefix_search);
          __pyx_t_14 = __pyx_v_prefix_search; __pyx_t_13 = NULL;
          if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_14))) {
            __pyx_t_13 = PyMethod_GET_SELF(__pyx_t_14);
            if (likely(__pyx_t_13)) {
              PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_14);
              __Pyx_INCREF(__pyx_t_13);
              __Pyx_INCREF(function);
              __Pyx_DECREF_SET(__pyx_t_14, function);
            }
          }
          __pyx_t_8 = (__pyx_t_13) ? __Pyx_PyObject_Call2Args(__pyx_t_14, __pyx_t_13, __pyx_cur_scope->__pyx_v_substring) : __Pyx_PyObject_CallOneArg(__pyx_t_14, __pyx_cur_scope->__pyx_v_substring);
          __Pyx_XDECREF(__pyx_t_13); __pyx_t_13 = 0;
          if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 676, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_8);
          __Pyx_DECREF(__pyx_t_14); __pyx_t_14 = 0;
          __pyx_t_14 = __Pyx_PyObject_GetAttrStr(__pyx_t_8, __pyx_n_s_end); if (unlikely(!__pyx_t_14)) __PYX_ERR(0, 676, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_14);
          __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
          __pyx_t_8 = NULL;
          if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_14))) {
            __pyx_t_8 = PyMethod_GET_SELF(__pyx_t_14);
            if (likely(__pyx_t_8)) {
              PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_14);
              __Pyx_INCREF(__pyx_t_8);
              __Pyx_INCREF(function);
              __Pyx_DECREF_SET(__pyx_t_14, function);
            }
          }
          __pyx_t_1 = (__pyx_t_8) ? __Pyx_PyObject_CallOneArg(__pyx_t_14, __pyx_t_8) : __Pyx_PyObject_CallNoArg(__pyx_t_14);
          __Pyx_XDECREF(__pyx_t_8); __pyx_t_8 = 0;
          if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 676, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_1);
          __Pyx_DECREF(__pyx_t_14); __pyx_t_14 = 0;
          __Pyx_XDECREF_SET(__pyx_v_split, __pyx_t_1);
          __pyx_t_1 = 0;

          /* "spacy/tokenizer.pyx":678
 *                         split = prefix_search(substring).end()
 *                         # break if pattern matches the empty string
 *                         if split == 0:             # <<<<<<<<<<<<<<
 *                             break
 *                         tokens.append(("PREFIX", substring[:split]))
 */
          __pyx_t_1 = __Pyx_PyInt_EqObjC(__pyx_v_split, __pyx_int_0, 0, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 678, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_1);
          __pyx_t_3 = __Pyx_PyObject_IsTrue(__pyx_t_1); if (unlikely(__pyx_t_3 < 0)) __PYX_ERR(0, 678, __pyx_L1_error)
          __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
          if (__pyx_t_3) {

            /* "spacy/tokenizer.pyx":679
 *                         # break if pattern matches the empty string
 *                         if split == 0:
 *                             break             # <<<<<<<<<<<<<<
 *                         tokens.append(("PREFIX", substring[:split]))
 *                         substring = substring[split:]
 */
            goto __pyx_L20_break;

            /* "spacy/tokenizer.pyx":678
 *                         split = prefix_search(substring).end()
 *                         # break if pattern matches the empty string
 *                         if split == 0:             # <<<<<<<<<<<<<<
 *                             break
 *                         tokens.append(("PREFIX", substring[:split]))
 */
          }

          /* "spacy/tokenizer.pyx":680
 *                         if split == 0:
 *                             break
 *                         tokens.append(("PREFIX", substring[:split]))             # <<<<<<<<<<<<<<
 *                         substring = substring[split:]
 *                         if substring in special_cases:
 */
          __pyx_t_1 = __Pyx_PyObject_GetSlice(__pyx_cur_scope->__pyx_v_substring, 0, 0, NULL, &__pyx_v_split, NULL, 0, 0, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 680, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_1);
          __pyx_t_14 = PyTuple_New(2); if (unlikely(!__pyx_t_14)) __PYX_ERR(0, 680, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_14);
          __Pyx_INCREF(__pyx_n_s_PREFIX);
          __Pyx_GIVEREF(__pyx_n_s_PREFIX);
          PyTuple_SET_ITEM(__pyx_t_14, 0, __pyx_n_s_PREFIX);
          __Pyx_GIVEREF(__pyx_t_1);
          PyTuple_SET_ITEM(__pyx_t_14, 1, __pyx_t_1);
          __pyx_t_1 = 0;
          __pyx_t_15 = __Pyx_PyList_Append(__pyx_v_tokens, __pyx_t_14); if (unlikely(__pyx_t_15 == ((int)-1))) __PYX_ERR(0, 680, __pyx_L1_error)
          __Pyx_DECREF(__pyx_t_14); __pyx_t_14 = 0;

          /* "spacy/tokenizer.pyx":681
 *                             break
 *                         tokens.append(("PREFIX", substring[:split]))
 *                         substring = substring[split:]             # <<<<<<<<<<<<<<
 *                         if substring in special_cases:
 *                             continue
 */
          __pyx_t_14 = __Pyx_PyObject_GetSlice(__pyx_cur_scope->__pyx_v_substring, 0, 0, &__pyx_v_split, NULL, NULL, 0, 0, 1); if (unlikely(!__pyx_t_14)) __PYX_ERR(0, 681, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_14);
          __Pyx_GOTREF(__pyx_cur_scope->__pyx_v_substring);
          __Pyx_DECREF_SET(__pyx_cur_scope->__pyx_v_substring, __pyx_t_14);
          __Pyx_GIVEREF(__pyx_t_14);
          __pyx_t_14 = 0;

          /* "spacy/tokenizer.pyx":682
 *                         tokens.append(("PREFIX", substring[:split]))
 *                         substring = substring[split:]
 *                         if substring in special_cases:             # <<<<<<<<<<<<<<
 *                             continue
 *                     if suffix_search(substring):
 */
          __pyx_t_3 = (__Pyx_PyDict_ContainsTF(__pyx_cur_scope->__pyx_v_substring, __pyx_cur_scope->__pyx_v_special_cases, Py_EQ)); if (unlikely(__pyx_t_3 < 0)) __PYX_ERR(0, 682, __pyx_L1_error)
          __pyx_t_2 = (__pyx_t_3 != 0);
          if (__pyx_t_2) {

            /* "spacy/tokenizer.pyx":683
 *                         substring = substring[split:]
 *                         if substring in special_cases:
 *                             continue             # <<<<<<<<<<<<<<
 *                     if suffix_search(substring):
 *                         split = suffix_search(substring).start()
 */
            goto __pyx_L19_continue;

            /* "spacy/tokenizer.pyx":682
 *                         tokens.append(("PREFIX", substring[:split]))
 *                         substring = substring[split:]
 *                         if substring in special_cases:             # <<<<<<<<<<<<<<
 *                             continue
 *                     if suffix_search(substring):
 */
          }

          /* "spacy/tokenizer.pyx":675
 *                         substring = ''
 *                         break
 *                     if prefix_search(substring):             # <<<<<<<<<<<<<<
 *                         split = prefix_search(substring).end()
 *                         # break if pattern matches the empty string
 */
        }

        /* "spacy/tokenizer.pyx":684
 *                         if substring in special_cases:
 *                             continue
 *                     if suffix_search(substring):             # <<<<<<<<<<<<<<
 *                         split = suffix_search(substring).start()
 *                         # break if pattern matches the empty string
 */
        __Pyx_INCREF(__pyx_v_suffix_search);
        __pyx_t_1 = __pyx_v_suffix_search; __pyx_t_8 = NULL;
        if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_1))) {
          __pyx_t_8 = PyMethod_GET_SELF(__pyx_t_1);
          if (likely(__pyx_t_8)) {
            PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_1);
            __Pyx_INCREF(__pyx_t_8);
            __Pyx_INCREF(function);
            __Pyx_DECREF_SET(__pyx_t_1, function);
          }
        }
        __pyx_t_14 = (__pyx_t_8) ? __Pyx_PyObject_Call2Args(__pyx_t_1, __pyx_t_8, __pyx_cur_scope->__pyx_v_substring) : __Pyx_PyObject_CallOneArg(__pyx_t_1, __pyx_cur_scope->__pyx_v_substring);
        __Pyx_XDECREF(__pyx_t_8); __pyx_t_8 = 0;
        if (unlikely(!__pyx_t_14)) __PYX_ERR(0, 684, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_14);
        __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
        __pyx_t_2 = __Pyx_PyObject_IsTrue(__pyx_t_14); if (unlikely(__pyx_t_2 < 0)) __PYX_ERR(0, 684, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_14); __pyx_t_14 = 0;
        if (__pyx_t_2) {

          /* "spacy/tokenizer.pyx":685
 *                             continue
 *                     if suffix_search(substring):
 *                         split = suffix_search(substring).start()             # <<<<<<<<<<<<<<
 *                         # break if pattern matches the empty string
 *                         if split == len(substring):
 */
          __Pyx_INCREF(__pyx_v_suffix_search);
          __pyx_t_8 = __pyx_v_suffix_search; __pyx_t_13 = NULL;
          if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_8))) {
            __pyx_t_13 = PyMethod_GET_SELF(__pyx_t_8);
            if (likely(__pyx_t_13)) {
              PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_8);
              __Pyx_INCREF(__pyx_t_13);
              __Pyx_INCREF(function);
              __Pyx_DECREF_SET(__pyx_t_8, function);
            }
          }
          __pyx_t_1 = (__pyx_t_13) ? __Pyx_PyObject_Call2Args(__pyx_t_8, __pyx_t_13, __pyx_cur_scope->__pyx_v_substring) : __Pyx_PyObject_CallOneArg(__pyx_t_8, __pyx_cur_scope->__pyx_v_substring);
          __Pyx_XDECREF(__pyx_t_13); __pyx_t_13 = 0;
          if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 685, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_1);
          __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
          __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_start); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 685, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_8);
          __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
          __pyx_t_1 = NULL;
          if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_8))) {
            __pyx_t_1 = PyMethod_GET_SELF(__pyx_t_8);
            if (likely(__pyx_t_1)) {
              PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_8);
              __Pyx_INCREF(__pyx_t_1);
              __Pyx_INCREF(function);
              __Pyx_DECREF_SET(__pyx_t_8, function);
            }
          }
          __pyx_t_14 = (__pyx_t_1) ? __Pyx_PyObject_CallOneArg(__pyx_t_8, __pyx_t_1) : __Pyx_PyObject_CallNoArg(__pyx_t_8);
          __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
          if (unlikely(!__pyx_t_14)) __PYX_ERR(0, 685, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_14);
          __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
          __Pyx_XDECREF_SET(__pyx_v_split, __pyx_t_14);
          __pyx_t_14 = 0;

          /* "spacy/tokenizer.pyx":687
 *                         split = suffix_search(substring).start()
 *                         # break if pattern matches the empty string
 *                         if split == len(substring):             # <<<<<<<<<<<<<<
 *                             break
 *                         suffixes.append(("SUFFIX", substring[split:]))
 */
          __pyx_t_14 = __pyx_cur_scope->__pyx_v_substring;
          __Pyx_INCREF(__pyx_t_14);
          __pyx_t_11 = PyObject_Length(__pyx_t_14); if (unlikely(__pyx_t_11 == ((Py_ssize_t)-1))) __PYX_ERR(0, 687, __pyx_L1_error)
          __Pyx_DECREF(__pyx_t_14); __pyx_t_14 = 0;
          __pyx_t_14 = PyInt_FromSsize_t(__pyx_t_11); if (unlikely(!__pyx_t_14)) __PYX_ERR(0, 687, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_14);
          __pyx_t_8 = PyObject_RichCompare(__pyx_v_split, __pyx_t_14, Py_EQ); __Pyx_XGOTREF(__pyx_t_8); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 687, __pyx_L1_error)
          __Pyx_DECREF(__pyx_t_14); __pyx_t_14 = 0;
          __pyx_t_2 = __Pyx_PyObject_IsTrue(__pyx_t_8); if (unlikely(__pyx_t_2 < 0)) __PYX_ERR(0, 687, __pyx_L1_error)
          __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
          if (__pyx_t_2) {

            /* "spacy/tokenizer.pyx":688
 *                         # break if pattern matches the empty string
 *                         if split == len(substring):
 *                             break             # <<<<<<<<<<<<<<
 *                         suffixes.append(("SUFFIX", substring[split:]))
 *                         substring = substring[:split]
 */
            goto __pyx_L20_break;

            /* "spacy/tokenizer.pyx":687
 *                         split = suffix_search(substring).start()
 *                         # break if pattern matches the empty string
 *                         if split == len(substring):             # <<<<<<<<<<<<<<
 *                             break
 *                         suffixes.append(("SUFFIX", substring[split:]))
 */
          }

          /* "spacy/tokenizer.pyx":689
 *                         if split == len(substring):
 *                             break
 *                         suffixes.append(("SUFFIX", substring[split:]))             # <<<<<<<<<<<<<<
 *                         substring = substring[:split]
 *                 if len(substring) == 0:
 */
          __pyx_t_8 = __Pyx_PyObject_GetSlice(__pyx_cur_scope->__pyx_v_substring, 0, 0, &__pyx_v_split, NULL, NULL, 0, 0, 1); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 689, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_8);
          __pyx_t_14 = PyTuple_New(2); if (unlikely(!__pyx_t_14)) __PYX_ERR(0, 689, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_14);
          __Pyx_INCREF(__pyx_n_s_SUFFIX);
          __Pyx_GIVEREF(__pyx_n_s_SUFFIX);
          PyTuple_SET_ITEM(__pyx_t_14, 0, __pyx_n_s_SUFFIX);
          __Pyx_GIVEREF(__pyx_t_8);
          PyTuple_SET_ITEM(__pyx_t_14, 1, __pyx_t_8);
          __pyx_t_8 = 0;
          __pyx_t_15 = __Pyx_PyList_Append(__pyx_v_suffixes, __pyx_t_14); if (unlikely(__pyx_t_15 == ((int)-1))) __PYX_ERR(0, 689, __pyx_L1_error)
          __Pyx_DECREF(__pyx_t_14); __pyx_t_14 = 0;

          /* "spacy/tokenizer.pyx":690
 *                             break
 *                         suffixes.append(("SUFFIX", substring[split:]))
 *                         substring = substring[:split]             # <<<<<<<<<<<<<<
 *                 if len(substring) == 0:
 *                     continue
 */
          __pyx_t_14 = __Pyx_PyObject_GetSlice(__pyx_cur_scope->__pyx_v_substring, 0, 0, NULL, &__pyx_v_split, NULL, 0, 0, 1); if (unlikely(!__pyx_t_14)) __PYX_ERR(0, 690, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_14);
          __Pyx_GOTREF(__pyx_cur_scope->__pyx_v_substring);
          __Pyx_DECREF_SET(__pyx_cur_scope->__pyx_v_substring, __pyx_t_14);
          __Pyx_GIVEREF(__pyx_t_14);
          __pyx_t_14 = 0;

          /* "spacy/tokenizer.pyx":684
 *                         if substring in special_cases:
 *                             continue
 *                     if suffix_search(substring):             # <<<<<<<<<<<<<<
 *                         split = suffix_search(substring).start()
 *                         # break if pattern matches the empty string
 */
        }
        __pyx_L19_continue:;
      }
      __pyx_L20_break:;

      /* "spacy/tokenizer.pyx":691
 *                         suffixes.append(("SUFFIX", substring[split:]))
 *                         substring = substring[:split]
 *                 if len(substring) == 0:             # <<<<<<<<<<<<<<
 *                     continue
 *                 if token_match(substring):
 */
      __pyx_t_14 = __pyx_cur_scope->__pyx_v_substring;
      __Pyx_INCREF(__pyx_t_14);
      __pyx_t_11 = PyObject_Length(__pyx_t_14); if (unlikely(__pyx_t_11 == ((Py_ssize_t)-1))) __PYX_ERR(0, 691, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_14); __pyx_t_14 = 0;
      __pyx_t_2 = ((__pyx_t_11 == 0) != 0);
      if (__pyx_t_2) {

        /* "spacy/tokenizer.pyx":692
 *                         substring = substring[:split]
 *                 if len(substring) == 0:
 *                     continue             # <<<<<<<<<<<<<<
 *                 if token_match(substring):
 *                     tokens.append(("TOKEN_MATCH", substring))
 */
        goto __pyx_L16_continue;

        /* "spacy/tokenizer.pyx":691
 *                         suffixes.append(("SUFFIX", substring[split:]))
 *                         substring = substring[:split]
 *                 if len(substring) == 0:             # <<<<<<<<<<<<<<
 *                     continue
 *                 if token_match(substring):
 */
      }

      /* "spacy/tokenizer.pyx":693
 *                 if len(substring) == 0:
 *                     continue
 *                 if token_match(substring):             # <<<<<<<<<<<<<<
 *                     tokens.append(("TOKEN_MATCH", substring))
 *                     substring = ''
 */
      __Pyx_INCREF(__pyx_v_token_match);
      __pyx_t_8 = __pyx_v_token_match; __pyx_t_1 = NULL;
      if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_8))) {
        __pyx_t_1 = PyMethod_GET_SELF(__pyx_t_8);
        if (likely(__pyx_t_1)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_8);
          __Pyx_INCREF(__pyx_t_1);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_8, function);
        }
      }
      __pyx_t_14 = (__pyx_t_1) ? __Pyx_PyObject_Call2Args(__pyx_t_8, __pyx_t_1, __pyx_cur_scope->__pyx_v_substring) : __Pyx_PyObject_CallOneArg(__pyx_t_8, __pyx_cur_scope->__pyx_v_substring);
      __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
      if (unlikely(!__pyx_t_14)) __PYX_ERR(0, 693, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_14);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __pyx_t_2 = __Pyx_PyObject_IsTrue(__pyx_t_14); if (unlikely(__pyx_t_2 < 0)) __PYX_ERR(0, 693, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_14); __pyx_t_14 = 0;
      if (__pyx_t_2) {

        /* "spacy/tokenizer.pyx":694
 *                     continue
 *                 if token_match(substring):
 *                     tokens.append(("TOKEN_MATCH", substring))             # <<<<<<<<<<<<<<
 *                     substring = ''
 *                 elif url_match(substring):
 */
        __pyx_t_14 = PyTuple_New(2); if (unlikely(!__pyx_t_14)) __PYX_ERR(0, 694, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_14);
        __Pyx_INCREF(__pyx_n_s_TOKEN_MATCH);
        __Pyx_GIVEREF(__pyx_n_s_TOKEN_MATCH);
        PyTuple_SET_ITEM(__pyx_t_14, 0, __pyx_n_s_TOKEN_MATCH);
        __Pyx_INCREF(__pyx_cur_scope->__pyx_v_substring);
        __Pyx_GIVEREF(__pyx_cur_scope->__pyx_v_substring);
        PyTuple_SET_ITEM(__pyx_t_14, 1, __pyx_cur_scope->__pyx_v_substring);
        __pyx_t_15 = __Pyx_PyList_Append(__pyx_v_tokens, __pyx_t_14); if (unlikely(__pyx_t_15 == ((int)-1))) __PYX_ERR(0, 694, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_14); __pyx_t_14 = 0;

        /* "spacy/tokenizer.pyx":695
 *                 if token_match(substring):
 *                     tokens.append(("TOKEN_MATCH", substring))
 *                     substring = ''             # <<<<<<<<<<<<<<
 *                 elif url_match(substring):
 *                     tokens.append(("URL_MATCH", substring))
 */
        __Pyx_INCREF(__pyx_kp_s__3);
        __Pyx_GOTREF(__pyx_cur_scope->__pyx_v_substring);
        __Pyx_DECREF_SET(__pyx_cur_scope->__pyx_v_substring, __pyx_kp_s__3);
        __Pyx_GIVEREF(__pyx_kp_s__3);

        /* "spacy/tokenizer.pyx":693
 *                 if len(substring) == 0:
 *                     continue
 *                 if token_match(substring):             # <<<<<<<<<<<<<<
 *                     tokens.append(("TOKEN_MATCH", substring))
 *                     substring = ''
 */
        goto __pyx_L31;
      }

      /* "spacy/tokenizer.pyx":696
 *                     tokens.append(("TOKEN_MATCH", substring))
 *                     substring = ''
 *                 elif url_match(substring):             # <<<<<<<<<<<<<<
 *                     tokens.append(("URL_MATCH", substring))
 *                     substring = ''
 */
      __Pyx_INCREF(__pyx_v_url_match);
      __pyx_t_8 = __pyx_v_url_match; __pyx_t_1 = NULL;
      if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_8))) {
        __pyx_t_1 = PyMethod_GET_SELF(__pyx_t_8);
        if (likely(__pyx_t_1)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_8);
          __Pyx_INCREF(__pyx_t_1);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_8, function);
        }
      }
      __pyx_t_14 = (__pyx_t_1) ? __Pyx_PyObject_Call2Args(__pyx_t_8, __pyx_t_1, __pyx_cur_scope->__pyx_v_substring) : __Pyx_PyObject_CallOneArg(__pyx_t_8, __pyx_cur_scope->__pyx_v_substring);
      __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
      if (unlikely(!__pyx_t_14)) __PYX_ERR(0, 696, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_14);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __pyx_t_2 = __Pyx_PyObject_IsTrue(__pyx_t_14); if (unlikely(__pyx_t_2 < 0)) __PYX_ERR(0, 696, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_14); __pyx_t_14 = 0;
      if (__pyx_t_2) {

        /* "spacy/tokenizer.pyx":697
 *                     substring = ''
 *                 elif url_match(substring):
 *                     tokens.append(("URL_MATCH", substring))             # <<<<<<<<<<<<<<
 *                     substring = ''
 *                 elif substring in special_cases:
 */
        __pyx_t_14 = PyTuple_New(2); if (unlikely(!__pyx_t_14)) __PYX_ERR(0, 697, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_14);
        __Pyx_INCREF(__pyx_n_s_URL_MATCH);
        __Pyx_GIVEREF(__pyx_n_s_URL_MATCH);
        PyTuple_SET_ITEM(__pyx_t_14, 0, __pyx_n_s_URL_MATCH);
        __Pyx_INCREF(__pyx_cur_scope->__pyx_v_substring);
        __Pyx_GIVEREF(__pyx_cur_scope->__pyx_v_substring);
        PyTuple_SET_ITEM(__pyx_t_14, 1, __pyx_cur_scope->__pyx_v_substring);
        __pyx_t_15 = __Pyx_PyList_Append(__pyx_v_tokens, __pyx_t_14); if (unlikely(__pyx_t_15 == ((int)-1))) __PYX_ERR(0, 697, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_14); __pyx_t_14 = 0;

        /* "spacy/tokenizer.pyx":698
 *                 elif url_match(substring):
 *                     tokens.append(("URL_MATCH", substring))
 *                     substring = ''             # <<<<<<<<<<<<<<
 *                 elif substring in special_cases:
 *                     tokens.extend((f"SPECIAL-{i + 1}", self.vocab.strings[e[ORTH]]) for i, e in enumerate(special_cases[substring]))
 */
        __Pyx_INCREF(__pyx_kp_s__3);
        __Pyx_GOTREF(__pyx_cur_scope->__pyx_v_substring);
        __Pyx_DECREF_SET(__pyx_cur_scope->__pyx_v_substring, __pyx_kp_s__3);
        __Pyx_GIVEREF(__pyx_kp_s__3);

        /* "spacy/tokenizer.pyx":696
 *                     tokens.append(("TOKEN_MATCH", substring))
 *                     substring = ''
 *                 elif url_match(substring):             # <<<<<<<<<<<<<<
 *                     tokens.append(("URL_MATCH", substring))
 *                     substring = ''
 */
        goto __pyx_L31;
      }

      /* "spacy/tokenizer.pyx":699
 *                     tokens.append(("URL_MATCH", substring))
 *                     substring = ''
 *                 elif substring in special_cases:             # <<<<<<<<<<<<<<
 *                     tokens.extend((f"SPECIAL-{i + 1}", self.vocab.strings[e[ORTH]]) for i, e in enumerate(special_cases[substring]))
 *                     substring = ''
 */
      __pyx_t_2 = (__Pyx_PyDict_ContainsTF(__pyx_cur_scope->__pyx_v_substring, __pyx_cur_scope->__pyx_v_special_cases, Py_EQ)); if (unlikely(__pyx_t_2 < 0)) __PYX_ERR(0, 699, __pyx_L1_error)
      __pyx_t_3 = (__pyx_t_2 != 0);
      if (__pyx_t_3) {

        /* "spacy/tokenizer.pyx":700
 *                     substring = ''
 *                 elif substring in special_cases:
 *                     tokens.extend((f"SPECIAL-{i + 1}", self.vocab.strings[e[ORTH]]) for i, e in enumerate(special_cases[substring]))             # <<<<<<<<<<<<<<
 *                     substring = ''
 *                 elif list(infix_finditer(substring)):
 */
        __pyx_t_14 = __pyx_pf_5spacy_9tokenizer_9Tokenizer_7explain_6genexpr(((PyObject*)__pyx_cur_scope)); if (unlikely(!__pyx_t_14)) __PYX_ERR(0, 700, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_14);
        __pyx_t_15 = __Pyx_PyList_Extend(__pyx_v_tokens, __pyx_t_14); if (unlikely(__pyx_t_15 == ((int)-1))) __PYX_ERR(0, 700, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_14); __pyx_t_14 = 0;

        /* "spacy/tokenizer.pyx":701
 *                 elif substring in special_cases:
 *                     tokens.extend((f"SPECIAL-{i + 1}", self.vocab.strings[e[ORTH]]) for i, e in enumerate(special_cases[substring]))
 *                     substring = ''             # <<<<<<<<<<<<<<
 *                 elif list(infix_finditer(substring)):
 *                     infixes = infix_finditer(substring)
 */
        __Pyx_INCREF(__pyx_kp_s__3);
        __Pyx_GOTREF(__pyx_cur_scope->__pyx_v_substring);
        __Pyx_DECREF_SET(__pyx_cur_scope->__pyx_v_substring, __pyx_kp_s__3);
        __Pyx_GIVEREF(__pyx_kp_s__3);

        /* "spacy/tokenizer.pyx":699
 *                     tokens.append(("URL_MATCH", substring))
 *                     substring = ''
 *                 elif substring in special_cases:             # <<<<<<<<<<<<<<
 *                     tokens.extend((f"SPECIAL-{i + 1}", self.vocab.strings[e[ORTH]]) for i, e in enumerate(special_cases[substring]))
 *                     substring = ''
 */
        goto __pyx_L31;
      }

      /* "spacy/tokenizer.pyx":702
 *                     tokens.extend((f"SPECIAL-{i + 1}", self.vocab.strings[e[ORTH]]) for i, e in enumerate(special_cases[substring]))
 *                     substring = ''
 *                 elif list(infix_finditer(substring)):             # <<<<<<<<<<<<<<
 *                     infixes = infix_finditer(substring)
 *                     offset = 0
 */
      __Pyx_INCREF(__pyx_v_infix_finditer);
      __pyx_t_8 = __pyx_v_infix_finditer; __pyx_t_1 = NULL;
      if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_8))) {
        __pyx_t_1 = PyMethod_GET_SELF(__pyx_t_8);
        if (likely(__pyx_t_1)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_8);
          __Pyx_INCREF(__pyx_t_1);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_8, function);
        }
      }
      __pyx_t_14 = (__pyx_t_1) ? __Pyx_PyObject_Call2Args(__pyx_t_8, __pyx_t_1, __pyx_cur_scope->__pyx_v_substring) : __Pyx_PyObject_CallOneArg(__pyx_t_8, __pyx_cur_scope->__pyx_v_substring);
      __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
      if (unlikely(!__pyx_t_14)) __PYX_ERR(0, 702, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_14);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __pyx_t_8 = PySequence_List(__pyx_t_14); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 702, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_DECREF(__pyx_t_14); __pyx_t_14 = 0;
      __pyx_t_3 = (PyList_GET_SIZE(__pyx_t_8) != 0);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      if (__pyx_t_3) {

        /* "spacy/tokenizer.pyx":703
 *                     substring = ''
 *                 elif list(infix_finditer(substring)):
 *                     infixes = infix_finditer(substring)             # <<<<<<<<<<<<<<
 *                     offset = 0
 *                     for match in infixes:
 */
        __Pyx_INCREF(__pyx_v_infix_finditer);
        __pyx_t_14 = __pyx_v_infix_finditer; __pyx_t_1 = NULL;
        if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_14))) {
          __pyx_t_1 = PyMethod_GET_SELF(__pyx_t_14);
          if (likely(__pyx_t_1)) {
            PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_14);
            __Pyx_INCREF(__pyx_t_1);
            __Pyx_INCREF(function);
            __Pyx_DECREF_SET(__pyx_t_14, function);
          }
        }
        __pyx_t_8 = (__pyx_t_1) ? __Pyx_PyObject_Call2Args(__pyx_t_14, __pyx_t_1, __pyx_cur_scope->__pyx_v_substring) : __Pyx_PyObject_CallOneArg(__pyx_t_14, __pyx_cur_scope->__pyx_v_substring);
        __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
        if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 703, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_8);
        __Pyx_DECREF(__pyx_t_14); __pyx_t_14 = 0;
        __Pyx_XDECREF_SET(__pyx_v_infixes, __pyx_t_8);
        __pyx_t_8 = 0;

        /* "spacy/tokenizer.pyx":704
 *                 elif list(infix_finditer(substring)):
 *                     infixes = infix_finditer(substring)
 *                     offset = 0             # <<<<<<<<<<<<<<
 *                     for match in infixes:
 *                         if offset == 0 and match.start() == 0:
 */
        __Pyx_INCREF(__pyx_int_0);
        __Pyx_XDECREF_SET(__pyx_v_offset, __pyx_int_0);

        /* "spacy/tokenizer.pyx":705
 *                     infixes = infix_finditer(substring)
 *                     offset = 0
 *                     for match in infixes:             # <<<<<<<<<<<<<<
 *                         if offset == 0 and match.start() == 0:
 *                             continue
 */
        if (likely(PyList_CheckExact(__pyx_v_infixes)) || PyTuple_CheckExact(__pyx_v_infixes)) {
          __pyx_t_8 = __pyx_v_infixes; __Pyx_INCREF(__pyx_t_8); __pyx_t_11 = 0;
          __pyx_t_12 = NULL;
        } else {
          __pyx_t_11 = -1; __pyx_t_8 = PyObject_GetIter(__pyx_v_infixes); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 705, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_8);
          __pyx_t_12 = Py_TYPE(__pyx_t_8)->tp_iternext; if (unlikely(!__pyx_t_12)) __PYX_ERR(0, 705, __pyx_L1_error)
        }
        for (;;) {
          if (likely(!__pyx_t_12)) {
            if (likely(PyList_CheckExact(__pyx_t_8))) {
              if (__pyx_t_11 >= PyList_GET_SIZE(__pyx_t_8)) break;
              #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
              __pyx_t_14 = PyList_GET_ITEM(__pyx_t_8, __pyx_t_11); __Pyx_INCREF(__pyx_t_14); __pyx_t_11++; if (unlikely(0 < 0)) __PYX_ERR(0, 705, __pyx_L1_error)
              #else
              __pyx_t_14 = PySequence_ITEM(__pyx_t_8, __pyx_t_11); __pyx_t_11++; if (unlikely(!__pyx_t_14)) __PYX_ERR(0, 705, __pyx_L1_error)
              __Pyx_GOTREF(__pyx_t_14);
              #endif
            } else {
              if (__pyx_t_11 >= PyTuple_GET_SIZE(__pyx_t_8)) break;
              #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
              __pyx_t_14 = PyTuple_GET_ITEM(__pyx_t_8, __pyx_t_11); __Pyx_INCREF(__pyx_t_14); __pyx_t_11++; if (unlikely(0 < 0)) __PYX_ERR(0, 705, __pyx_L1_error)
              #else
              __pyx_t_14 = PySequence_ITEM(__pyx_t_8, __pyx_t_11); __pyx_t_11++; if (unlikely(!__pyx_t_14)) __PYX_ERR(0, 705, __pyx_L1_error)
              __Pyx_GOTREF(__pyx_t_14);
              #endif
            }
          } else {
            __pyx_t_14 = __pyx_t_12(__pyx_t_8);
            if (unlikely(!__pyx_t_14)) {
              PyObject* exc_type = PyErr_Occurred();
              if (exc_type) {
                if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
                else __PYX_ERR(0, 705, __pyx_L1_error)
              }
              break;
            }
            __Pyx_GOTREF(__pyx_t_14);
          }
          __Pyx_XDECREF_SET(__pyx_v_match, __pyx_t_14);
          __pyx_t_14 = 0;

          /* "spacy/tokenizer.pyx":706
 *                     offset = 0
 *                     for match in infixes:
 *                         if offset == 0 and match.start() == 0:             # <<<<<<<<<<<<<<
 *                             continue
 *                         if substring[offset : match.start()]:
 */
          __pyx_t_14 = __Pyx_PyInt_EqObjC(__pyx_v_offset, __pyx_int_0, 0, 0); if (unlikely(!__pyx_t_14)) __PYX_ERR(0, 706, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_14);
          __pyx_t_2 = __Pyx_PyObject_IsTrue(__pyx_t_14); if (unlikely(__pyx_t_2 < 0)) __PYX_ERR(0, 706, __pyx_L1_error)
          __Pyx_DECREF(__pyx_t_14); __pyx_t_14 = 0;
          if (__pyx_t_2) {
          } else {
            __pyx_t_3 = __pyx_t_2;
            goto __pyx_L35_bool_binop_done;
          }
          __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_match, __pyx_n_s_start); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 706, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_1);
          __pyx_t_13 = NULL;
          if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_1))) {
            __pyx_t_13 = PyMethod_GET_SELF(__pyx_t_1);
            if (likely(__pyx_t_13)) {
              PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_1);
              __Pyx_INCREF(__pyx_t_13);
              __Pyx_INCREF(function);
              __Pyx_DECREF_SET(__pyx_t_1, function);
            }
          }
          __pyx_t_14 = (__pyx_t_13) ? __Pyx_PyObject_CallOneArg(__pyx_t_1, __pyx_t_13) : __Pyx_PyObject_CallNoArg(__pyx_t_1);
          __Pyx_XDECREF(__pyx_t_13); __pyx_t_13 = 0;
          if (unlikely(!__pyx_t_14)) __PYX_ERR(0, 706, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_14);
          __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
          __pyx_t_1 = __Pyx_PyInt_EqObjC(__pyx_t_14, __pyx_int_0, 0, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 706, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_1);
          __Pyx_DECREF(__pyx_t_14); __pyx_t_14 = 0;
          __pyx_t_2 = __Pyx_PyObject_IsTrue(__pyx_t_1); if (unlikely(__pyx_t_2 < 0)) __PYX_ERR(0, 706, __pyx_L1_error)
          __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
          __pyx_t_3 = __pyx_t_2;
          __pyx_L35_bool_binop_done:;
          if (__pyx_t_3) {

            /* "spacy/tokenizer.pyx":707
 *                     for match in infixes:
 *                         if offset == 0 and match.start() == 0:
 *                             continue             # <<<<<<<<<<<<<<
 *                         if substring[offset : match.start()]:
 *                             tokens.append(("TOKEN", substring[offset : match.start()]))
 */
            goto __pyx_L32_continue;

            /* "spacy/tokenizer.pyx":706
 *                     offset = 0
 *                     for match in infixes:
 *                         if offset == 0 and match.start() == 0:             # <<<<<<<<<<<<<<
 *                             continue
 *                         if substring[offset : match.start()]:
 */
          }

          /* "spacy/tokenizer.pyx":708
 *                         if offset == 0 and match.start() == 0:
 *                             continue
 *                         if substring[offset : match.start()]:             # <<<<<<<<<<<<<<
 *                             tokens.append(("TOKEN", substring[offset : match.start()]))
 *                         if substring[match.start() : match.end()]:
 */
          __pyx_t_14 = __Pyx_PyObject_GetAttrStr(__pyx_v_match, __pyx_n_s_start); if (unlikely(!__pyx_t_14)) __PYX_ERR(0, 708, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_14);
          __pyx_t_13 = NULL;
          if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_14))) {
            __pyx_t_13 = PyMethod_GET_SELF(__pyx_t_14);
            if (likely(__pyx_t_13)) {
              PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_14);
              __Pyx_INCREF(__pyx_t_13);
              __Pyx_INCREF(function);
              __Pyx_DECREF_SET(__pyx_t_14, function);
            }
          }
          __pyx_t_1 = (__pyx_t_13) ? __Pyx_PyObject_CallOneArg(__pyx_t_14, __pyx_t_13) : __Pyx_PyObject_CallNoArg(__pyx_t_14);
          __Pyx_XDECREF(__pyx_t_13); __pyx_t_13 = 0;
          if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 708, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_1);
          __Pyx_DECREF(__pyx_t_14); __pyx_t_14 = 0;
          __pyx_t_14 = __Pyx_PyObject_GetSlice(__pyx_cur_scope->__pyx_v_substring, 0, 0, &__pyx_v_offset, &__pyx_t_1, NULL, 0, 0, 1); if (unlikely(!__pyx_t_14)) __PYX_ERR(0, 708, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_14);
          __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
          __pyx_t_3 = __Pyx_PyObject_IsTrue(__pyx_t_14); if (unlikely(__pyx_t_3 < 0)) __PYX_ERR(0, 708, __pyx_L1_error)
          __Pyx_DECREF(__pyx_t_14); __pyx_t_14 = 0;
          if (__pyx_t_3) {

            /* "spacy/tokenizer.pyx":709
 *                             continue
 *                         if substring[offset : match.start()]:
 *                             tokens.append(("TOKEN", substring[offset : match.start()]))             # <<<<<<<<<<<<<<
 *                         if substring[match.start() : match.end()]:
 *                             tokens.append(("INFIX", substring[match.start() : match.end()]))
 */
            __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_match, __pyx_n_s_start); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 709, __pyx_L1_error)
            __Pyx_GOTREF(__pyx_t_1);
            __pyx_t_13 = NULL;
            if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_1))) {
              __pyx_t_13 = PyMethod_GET_SELF(__pyx_t_1);
              if (likely(__pyx_t_13)) {
                PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_1);
                __Pyx_INCREF(__pyx_t_13);
                __Pyx_INCREF(function);
                __Pyx_DECREF_SET(__pyx_t_1, function);
              }
            }
            __pyx_t_14 = (__pyx_t_13) ? __Pyx_PyObject_CallOneArg(__pyx_t_1, __pyx_t_13) : __Pyx_PyObject_CallNoArg(__pyx_t_1);
            __Pyx_XDECREF(__pyx_t_13); __pyx_t_13 = 0;
            if (unlikely(!__pyx_t_14)) __PYX_ERR(0, 709, __pyx_L1_error)
            __Pyx_GOTREF(__pyx_t_14);
            __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
            __pyx_t_1 = __Pyx_PyObject_GetSlice(__pyx_cur_scope->__pyx_v_substring, 0, 0, &__pyx_v_offset, &__pyx_t_14, NULL, 0, 0, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 709, __pyx_L1_error)
            __Pyx_GOTREF(__pyx_t_1);
            __Pyx_DECREF(__pyx_t_14); __pyx_t_14 = 0;
            __pyx_t_14 = PyTuple_New(2); if (unlikely(!__pyx_t_14)) __PYX_ERR(0, 709, __pyx_L1_error)
            __Pyx_GOTREF(__pyx_t_14);
            __Pyx_INCREF(__pyx_n_s_TOKEN);
            __Pyx_GIVEREF(__pyx_n_s_TOKEN);
            PyTuple_SET_ITEM(__pyx_t_14, 0, __pyx_n_s_TOKEN);
            __Pyx_GIVEREF(__pyx_t_1);
            PyTuple_SET_ITEM(__pyx_t_14, 1, __pyx_t_1);
            __pyx_t_1 = 0;
            __pyx_t_15 = __Pyx_PyList_Append(__pyx_v_tokens, __pyx_t_14); if (unlikely(__pyx_t_15 == ((int)-1))) __PYX_ERR(0, 709, __pyx_L1_error)
            __Pyx_DECREF(__pyx_t_14); __pyx_t_14 = 0;

            /* "spacy/tokenizer.pyx":708
 *                         if offset == 0 and match.start() == 0:
 *                             continue
 *                         if substring[offset : match.start()]:             # <<<<<<<<<<<<<<
 *                             tokens.append(("TOKEN", substring[offset : match.start()]))
 *                         if substring[match.start() : match.end()]:
 */
          }

          /* "spacy/tokenizer.pyx":710
 *                         if substring[offset : match.start()]:
 *                             tokens.append(("TOKEN", substring[offset : match.start()]))
 *                         if substring[match.start() : match.end()]:             # <<<<<<<<<<<<<<
 *                             tokens.append(("INFIX", substring[match.start() : match.end()]))
 *                         offset = match.end()
 */
          __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_match, __pyx_n_s_start); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 710, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_1);
          __pyx_t_13 = NULL;
          if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_1))) {
            __pyx_t_13 = PyMethod_GET_SELF(__pyx_t_1);
            if (likely(__pyx_t_13)) {
              PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_1);
              __Pyx_INCREF(__pyx_t_13);
              __Pyx_INCREF(function);
              __Pyx_DECREF_SET(__pyx_t_1, function);
            }
          }
          __pyx_t_14 = (__pyx_t_13) ? __Pyx_PyObject_CallOneArg(__pyx_t_1, __pyx_t_13) : __Pyx_PyObject_CallNoArg(__pyx_t_1);
          __Pyx_XDECREF(__pyx_t_13); __pyx_t_13 = 0;
          if (unlikely(!__pyx_t_14)) __PYX_ERR(0, 710, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_14);
          __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
          __pyx_t_13 = __Pyx_PyObject_GetAttrStr(__pyx_v_match, __pyx_n_s_end); if (unlikely(!__pyx_t_13)) __PYX_ERR(0, 710, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_13);
          __pyx_t_9 = NULL;
          if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_13))) {
            __pyx_t_9 = PyMethod_GET_SELF(__pyx_t_13);
            if (likely(__pyx_t_9)) {
              PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_13);
              __Pyx_INCREF(__pyx_t_9);
              __Pyx_INCREF(function);
              __Pyx_DECREF_SET(__pyx_t_13, function);
            }
          }
          __pyx_t_1 = (__pyx_t_9) ? __Pyx_PyObject_CallOneArg(__pyx_t_13, __pyx_t_9) : __Pyx_PyObject_CallNoArg(__pyx_t_13);
          __Pyx_XDECREF(__pyx_t_9); __pyx_t_9 = 0;
          if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 710, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_1);
          __Pyx_DECREF(__pyx_t_13); __pyx_t_13 = 0;
          __pyx_t_13 = __Pyx_PyObject_GetSlice(__pyx_cur_scope->__pyx_v_substring, 0, 0, &__pyx_t_14, &__pyx_t_1, NULL, 0, 0, 1); if (unlikely(!__pyx_t_13)) __PYX_ERR(0, 710, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_13);
          __Pyx_DECREF(__pyx_t_14); __pyx_t_14 = 0;
          __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
          __pyx_t_3 = __Pyx_PyObject_IsTrue(__pyx_t_13); if (unlikely(__pyx_t_3 < 0)) __PYX_ERR(0, 710, __pyx_L1_error)
          __Pyx_DECREF(__pyx_t_13); __pyx_t_13 = 0;
          if (__pyx_t_3) {

            /* "spacy/tokenizer.pyx":711
 *                             tokens.append(("TOKEN", substring[offset : match.start()]))
 *                         if substring[match.start() : match.end()]:
 *                             tokens.append(("INFIX", substring[match.start() : match.end()]))             # <<<<<<<<<<<<<<
 *                         offset = match.end()
 *                     if substring[offset:]:
 */
            __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_match, __pyx_n_s_start); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 711, __pyx_L1_error)
            __Pyx_GOTREF(__pyx_t_1);
            __pyx_t_14 = NULL;
            if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_1))) {
              __pyx_t_14 = PyMethod_GET_SELF(__pyx_t_1);
              if (likely(__pyx_t_14)) {
                PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_1);
                __Pyx_INCREF(__pyx_t_14);
                __Pyx_INCREF(function);
                __Pyx_DECREF_SET(__pyx_t_1, function);
              }
            }
            __pyx_t_13 = (__pyx_t_14) ? __Pyx_PyObject_CallOneArg(__pyx_t_1, __pyx_t_14) : __Pyx_PyObject_CallNoArg(__pyx_t_1);
            __Pyx_XDECREF(__pyx_t_14); __pyx_t_14 = 0;
            if (unlikely(!__pyx_t_13)) __PYX_ERR(0, 711, __pyx_L1_error)
            __Pyx_GOTREF(__pyx_t_13);
            __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
            __pyx_t_14 = __Pyx_PyObject_GetAttrStr(__pyx_v_match, __pyx_n_s_end); if (unlikely(!__pyx_t_14)) __PYX_ERR(0, 711, __pyx_L1_error)
            __Pyx_GOTREF(__pyx_t_14);
            __pyx_t_9 = NULL;
            if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_14))) {
              __pyx_t_9 = PyMethod_GET_SELF(__pyx_t_14);
              if (likely(__pyx_t_9)) {
                PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_14);
                __Pyx_INCREF(__pyx_t_9);
                __Pyx_INCREF(function);
                __Pyx_DECREF_SET(__pyx_t_14, function);
              }
            }
            __pyx_t_1 = (__pyx_t_9) ? __Pyx_PyObject_CallOneArg(__pyx_t_14, __pyx_t_9) : __Pyx_PyObject_CallNoArg(__pyx_t_14);
            __Pyx_XDECREF(__pyx_t_9); __pyx_t_9 = 0;
            if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 711, __pyx_L1_error)
            __Pyx_GOTREF(__pyx_t_1);
            __Pyx_DECREF(__pyx_t_14); __pyx_t_14 = 0;
            __pyx_t_14 = __Pyx_PyObject_GetSlice(__pyx_cur_scope->__pyx_v_substring, 0, 0, &__pyx_t_13, &__pyx_t_1, NULL, 0, 0, 1); if (unlikely(!__pyx_t_14)) __PYX_ERR(0, 711, __pyx_L1_error)
            __Pyx_GOTREF(__pyx_t_14);
            __Pyx_DECREF(__pyx_t_13); __pyx_t_13 = 0;
            __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
            __pyx_t_1 = PyTuple_New(2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 711, __pyx_L1_error)
            __Pyx_GOTREF(__pyx_t_1);
            __Pyx_INCREF(__pyx_n_s_INFIX);
            __Pyx_GIVEREF(__pyx_n_s_INFIX);
            PyTuple_SET_ITEM(__pyx_t_1, 0, __pyx_n_s_INFIX);
            __Pyx_GIVEREF(__pyx_t_14);
            PyTuple_SET_ITEM(__pyx_t_1, 1, __pyx_t_14);
            __pyx_t_14 = 0;
            __pyx_t_15 = __Pyx_PyList_Append(__pyx_v_tokens, __pyx_t_1); if (unlikely(__pyx_t_15 == ((int)-1))) __PYX_ERR(0, 711, __pyx_L1_error)
            __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

            /* "spacy/tokenizer.pyx":710
 *                         if substring[offset : match.start()]:
 *                             tokens.append(("TOKEN", substring[offset : match.start()]))
 *                         if substring[match.start() : match.end()]:             # <<<<<<<<<<<<<<
 *                             tokens.append(("INFIX", substring[match.start() : match.end()]))
 *                         offset = match.end()
 */
          }

          /* "spacy/tokenizer.pyx":712
 *                         if substring[match.start() : match.end()]:
 *                             tokens.append(("INFIX", substring[match.start() : match.end()]))
 *                         offset = match.end()             # <<<<<<<<<<<<<<
 *                     if substring[offset:]:
 *                         tokens.append(("TOKEN", substring[offset:]))
 */
          __pyx_t_14 = __Pyx_PyObject_GetAttrStr(__pyx_v_match, __pyx_n_s_end); if (unlikely(!__pyx_t_14)) __PYX_ERR(0, 712, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_14);
          __pyx_t_13 = NULL;
          if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_14))) {
            __pyx_t_13 = PyMethod_GET_SELF(__pyx_t_14);
            if (likely(__pyx_t_13)) {
              PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_14);
              __Pyx_INCREF(__pyx_t_13);
              __Pyx_INCREF(function);
              __Pyx_DECREF_SET(__pyx_t_14, function);
            }
          }
          __pyx_t_1 = (__pyx_t_13) ? __Pyx_PyObject_CallOneArg(__pyx_t_14, __pyx_t_13) : __Pyx_PyObject_CallNoArg(__pyx_t_14);
          __Pyx_XDECREF(__pyx_t_13); __pyx_t_13 = 0;
          if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 712, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_1);
          __Pyx_DECREF(__pyx_t_14); __pyx_t_14 = 0;
          __Pyx_DECREF_SET(__pyx_v_offset, __pyx_t_1);
          __pyx_t_1 = 0;

          /* "spacy/tokenizer.pyx":705
 *                     infixes = infix_finditer(substring)
 *                     offset = 0
 *                     for match in infixes:             # <<<<<<<<<<<<<<
 *                         if offset == 0 and match.start() == 0:
 *                             continue
 */
          __pyx_L32_continue:;
        }
        __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;

        /* "spacy/tokenizer.pyx":713
 *                             tokens.append(("INFIX", substring[match.start() : match.end()]))
 *                         offset = match.end()
 *                     if substring[offset:]:             # <<<<<<<<<<<<<<
 *                         tokens.append(("TOKEN", substring[offset:]))
 *                     substring = ''
 */
        __pyx_t_8 = __Pyx_PyObject_GetSlice(__pyx_cur_scope->__pyx_v_substring, 0, 0, &__pyx_v_offset, NULL, NULL, 0, 0, 1); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 713, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_8);
        __pyx_t_3 = __Pyx_PyObject_IsTrue(__pyx_t_8); if (unlikely(__pyx_t_3 < 0)) __PYX_ERR(0, 713, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
        if (__pyx_t_3) {

          /* "spacy/tokenizer.pyx":714
 *                         offset = match.end()
 *                     if substring[offset:]:
 *                         tokens.append(("TOKEN", substring[offset:]))             # <<<<<<<<<<<<<<
 *                     substring = ''
 *                 elif substring:
 */
          __pyx_t_8 = __Pyx_PyObject_GetSlice(__pyx_cur_scope->__pyx_v_substring, 0, 0, &__pyx_v_offset, NULL, NULL, 0, 0, 1); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 714, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_8);
          __pyx_t_1 = PyTuple_New(2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 714, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_1);
          __Pyx_INCREF(__pyx_n_s_TOKEN);
          __Pyx_GIVEREF(__pyx_n_s_TOKEN);
          PyTuple_SET_ITEM(__pyx_t_1, 0, __pyx_n_s_TOKEN);
          __Pyx_GIVEREF(__pyx_t_8);
          PyTuple_SET_ITEM(__pyx_t_1, 1, __pyx_t_8);
          __pyx_t_8 = 0;
          __pyx_t_15 = __Pyx_PyList_Append(__pyx_v_tokens, __pyx_t_1); if (unlikely(__pyx_t_15 == ((int)-1))) __PYX_ERR(0, 714, __pyx_L1_error)
          __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

          /* "spacy/tokenizer.pyx":713
 *                             tokens.append(("INFIX", substring[match.start() : match.end()]))
 *                         offset = match.end()
 *                     if substring[offset:]:             # <<<<<<<<<<<<<<
 *                         tokens.append(("TOKEN", substring[offset:]))
 *                     substring = ''
 */
        }

        /* "spacy/tokenizer.pyx":715
 *                     if substring[offset:]:
 *                         tokens.append(("TOKEN", substring[offset:]))
 *                     substring = ''             # <<<<<<<<<<<<<<
 *                 elif substring:
 *                     tokens.append(("TOKEN", substring))
 */
        __Pyx_INCREF(__pyx_kp_s__3);
        __Pyx_GOTREF(__pyx_cur_scope->__pyx_v_substring);
        __Pyx_DECREF_SET(__pyx_cur_scope->__pyx_v_substring, __pyx_kp_s__3);
        __Pyx_GIVEREF(__pyx_kp_s__3);

        /* "spacy/tokenizer.pyx":702
 *                     tokens.extend((f"SPECIAL-{i + 1}", self.vocab.strings[e[ORTH]]) for i, e in enumerate(special_cases[substring]))
 *                     substring = ''
 *                 elif list(infix_finditer(substring)):             # <<<<<<<<<<<<<<
 *                     infixes = infix_finditer(substring)
 *                     offset = 0
 */
        goto __pyx_L31;
      }

      /* "spacy/tokenizer.pyx":716
 *                         tokens.append(("TOKEN", substring[offset:]))
 *                     substring = ''
 *                 elif substring:             # <<<<<<<<<<<<<<
 *                     tokens.append(("TOKEN", substring))
 *                     substring = ''
 */
      __pyx_t_3 = __Pyx_PyObject_IsTrue(__pyx_cur_scope->__pyx_v_substring); if (unlikely(__pyx_t_3 < 0)) __PYX_ERR(0, 716, __pyx_L1_error)
      if (__pyx_t_3) {

        /* "spacy/tokenizer.pyx":717
 *                     substring = ''
 *                 elif substring:
 *                     tokens.append(("TOKEN", substring))             # <<<<<<<<<<<<<<
 *                     substring = ''
 *             tokens.extend(reversed(suffixes))
 */
        __pyx_t_1 = PyTuple_New(2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 717, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_INCREF(__pyx_n_s_TOKEN);
        __Pyx_GIVEREF(__pyx_n_s_TOKEN);
        PyTuple_SET_ITEM(__pyx_t_1, 0, __pyx_n_s_TOKEN);
        __Pyx_INCREF(__pyx_cur_scope->__pyx_v_substring);
        __Pyx_GIVEREF(__pyx_cur_scope->__pyx_v_substring);
        PyTuple_SET_ITEM(__pyx_t_1, 1, __pyx_cur_scope->__pyx_v_substring);
        __pyx_t_15 = __Pyx_PyList_Append(__pyx_v_tokens, __pyx_t_1); if (unlikely(__pyx_t_15 == ((int)-1))) __PYX_ERR(0, 717, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

        /* "spacy/tokenizer.pyx":718
 *                 elif substring:
 *                     tokens.append(("TOKEN", substring))
 *                     substring = ''             # <<<<<<<<<<<<<<
 *             tokens.extend(reversed(suffixes))
 *         # Find matches for special cases handled by special matcher
 */
        __Pyx_INCREF(__pyx_kp_s__3);
        __Pyx_GOTREF(__pyx_cur_scope->__pyx_v_substring);
        __Pyx_DECREF_SET(__pyx_cur_scope->__pyx_v_substring, __pyx_kp_s__3);
        __Pyx_GIVEREF(__pyx_kp_s__3);

        /* "spacy/tokenizer.pyx":716
 *                         tokens.append(("TOKEN", substring[offset:]))
 *                     substring = ''
 *                 elif substring:             # <<<<<<<<<<<<<<
 *                     tokens.append(("TOKEN", substring))
 *                     substring = ''
 */
      }
      __pyx_L31:;
      __pyx_L16_continue:;
    }

    /* "spacy/tokenizer.pyx":719
 *                     tokens.append(("TOKEN", substring))
 *                     substring = ''
 *             tokens.extend(reversed(suffixes))             # <<<<<<<<<<<<<<
 *         # Find matches for special cases handled by special matcher
 *         words, spaces = get_words_and_spaces([t[1] for t in tokens], text)
 */
    __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_builtin_reversed, __pyx_v_suffixes); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 719, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_15 = __Pyx_PyList_Extend(__pyx_v_tokens, __pyx_t_1); if (unlikely(__pyx_t_15 == ((int)-1))) __PYX_ERR(0, 719, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

    /* "spacy/tokenizer.pyx":659
 *             special_cases[orth] = [intify_attrs(special_token, strings_map=self.vocab.strings, _do_deprecated=True) for special_token in special_tokens]
 *         tokens = []
 *         for substring in text.split():             # <<<<<<<<<<<<<<
 *             suffixes = []
 *             while substring:
 */
  }
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;

  /* "spacy/tokenizer.pyx":721
 *             tokens.extend(reversed(suffixes))
 *         # Find matches for special cases handled by special matcher
 *         words, spaces = get_words_and_spaces([t[1] for t in tokens], text)             # <<<<<<<<<<<<<<
 *         t_words = []
 *         t_spaces = []
 */
  __Pyx_GetModuleGlobalName(__pyx_t_1, __pyx_n_s_get_words_and_spaces); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 721, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_8 = PyList_New(0); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 721, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __pyx_t_14 = __pyx_v_tokens; __Pyx_INCREF(__pyx_t_14); __pyx_t_6 = 0;
  for (;;) {
    if (__pyx_t_6 >= PyList_GET_SIZE(__pyx_t_14)) break;
    #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
    __pyx_t_13 = PyList_GET_ITEM(__pyx_t_14, __pyx_t_6); __Pyx_INCREF(__pyx_t_13); __pyx_t_6++; if (unlikely(0 < 0)) __PYX_ERR(0, 721, __pyx_L1_error)
    #else
    __pyx_t_13 = PySequence_ITEM(__pyx_t_14, __pyx_t_6); __pyx_t_6++; if (unlikely(!__pyx_t_13)) __PYX_ERR(0, 721, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_13);
    #endif
    __Pyx_XDECREF_SET(__pyx_v_t, __pyx_t_13);
    __pyx_t_13 = 0;
    __pyx_t_13 = __Pyx_GetItemInt(__pyx_v_t, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_13)) __PYX_ERR(0, 721, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_13);
    if (unlikely(__Pyx_ListComp_Append(__pyx_t_8, (PyObject*)__pyx_t_13))) __PYX_ERR(0, 721, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_13); __pyx_t_13 = 0;
  }
  __Pyx_DECREF(__pyx_t_14); __pyx_t_14 = 0;
  __pyx_t_14 = NULL;
  __pyx_t_16 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_1))) {
    __pyx_t_14 = PyMethod_GET_SELF(__pyx_t_1);
    if (likely(__pyx_t_14)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_1);
      __Pyx_INCREF(__pyx_t_14);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_1, function);
      __pyx_t_16 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_1)) {
    PyObject *__pyx_temp[3] = {__pyx_t_14, __pyx_t_8, __pyx_v_text};
    __pyx_t_4 = __Pyx_PyFunction_FastCall(__pyx_t_1, __pyx_temp+1-__pyx_t_16, 2+__pyx_t_16); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 721, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_14); __pyx_t_14 = 0;
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_1)) {
    PyObject *__pyx_temp[3] = {__pyx_t_14, __pyx_t_8, __pyx_v_text};
    __pyx_t_4 = __Pyx_PyCFunction_FastCall(__pyx_t_1, __pyx_temp+1-__pyx_t_16, 2+__pyx_t_16); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 721, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_14); __pyx_t_14 = 0;
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  } else
  #endif
  {
    __pyx_t_13 = PyTuple_New(2+__pyx_t_16); if (unlikely(!__pyx_t_13)) __PYX_ERR(0, 721, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_13);
    if (__pyx_t_14) {
      __Pyx_GIVEREF(__pyx_t_14); PyTuple_SET_ITEM(__pyx_t_13, 0, __pyx_t_14); __pyx_t_14 = NULL;
    }
    __Pyx_GIVEREF(__pyx_t_8);
    PyTuple_SET_ITEM(__pyx_t_13, 0+__pyx_t_16, __pyx_t_8);
    __Pyx_INCREF(__pyx_v_text);
    __Pyx_GIVEREF(__pyx_v_text);
    PyTuple_SET_ITEM(__pyx_t_13, 1+__pyx_t_16, __pyx_v_text);
    __pyx_t_8 = 0;
    __pyx_t_4 = __Pyx_PyObject_Call(__pyx_t_1, __pyx_t_13, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 721, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_DECREF(__pyx_t_13); __pyx_t_13 = 0;
  }
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  if ((likely(PyTuple_CheckExact(__pyx_t_4))) || (PyList_CheckExact(__pyx_t_4))) {
    PyObject* sequence = __pyx_t_4;
    Py_ssize_t size = __Pyx_PySequence_SIZE(sequence);
    if (unlikely(size != 2)) {
      if (size > 2) __Pyx_RaiseTooManyValuesError(2);
      else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
      __PYX_ERR(0, 721, __pyx_L1_error)
    }
    #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
    if (likely(PyTuple_CheckExact(sequence))) {
      __pyx_t_1 = PyTuple_GET_ITEM(sequence, 0); 
      __pyx_t_13 = PyTuple_GET_ITEM(sequence, 1); 
    } else {
      __pyx_t_1 = PyList_GET_ITEM(sequence, 0); 
      __pyx_t_13 = PyList_GET_ITEM(sequence, 1); 
    }
    __Pyx_INCREF(__pyx_t_1);
    __Pyx_INCREF(__pyx_t_13);
    #else
    __pyx_t_1 = PySequence_ITEM(sequence, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 721, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_13 = PySequence_ITEM(sequence, 1); if (unlikely(!__pyx_t_13)) __PYX_ERR(0, 721, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_13);
    #endif
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  } else {
    Py_ssize_t index = -1;
    __pyx_t_8 = PyObject_GetIter(__pyx_t_4); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 721, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __pyx_t_10 = Py_TYPE(__pyx_t_8)->tp_iternext;
    index = 0; __pyx_t_1 = __pyx_t_10(__pyx_t_8); if (unlikely(!__pyx_t_1)) goto __pyx_L42_unpacking_failed;
    __Pyx_GOTREF(__pyx_t_1);
    index = 1; __pyx_t_13 = __pyx_t_10(__pyx_t_8); if (unlikely(!__pyx_t_13)) goto __pyx_L42_unpacking_failed;
    __Pyx_GOTREF(__pyx_t_13);
    if (__Pyx_IternextUnpackEndCheck(__pyx_t_10(__pyx_t_8), 2) < 0) __PYX_ERR(0, 721, __pyx_L1_error)
    __pyx_t_10 = NULL;
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    goto __pyx_L43_unpacking_done;
    __pyx_L42_unpacking_failed:;
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    __pyx_t_10 = NULL;
    if (__Pyx_IterFinish() == 0) __Pyx_RaiseNeedMoreValuesError(index);
    __PYX_ERR(0, 721, __pyx_L1_error)
    __pyx_L43_unpacking_done:;
  }
  __pyx_v_words = __pyx_t_1;
  __pyx_t_1 = 0;
  __pyx_v_spaces = __pyx_t_13;
  __pyx_t_13 = 0;

  /* "spacy/tokenizer.pyx":722
 *         # Find matches for special cases handled by special matcher
 *         words, spaces = get_words_and_spaces([t[1] for t in tokens], text)
 *         t_words = []             # <<<<<<<<<<<<<<
 *         t_spaces = []
 *         for word, space in zip(words, spaces):
 */
  __pyx_t_4 = PyList_New(0); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 722, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_v_t_words = ((PyObject*)__pyx_t_4);
  __pyx_t_4 = 0;

  /* "spacy/tokenizer.pyx":723
 *         words, spaces = get_words_and_spaces([t[1] for t in tokens], text)
 *         t_words = []
 *         t_spaces = []             # <<<<<<<<<<<<<<
 *         for word, space in zip(words, spaces):
 *             if not word.isspace():
 */
  __pyx_t_4 = PyList_New(0); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 723, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_v_t_spaces = ((PyObject*)__pyx_t_4);
  __pyx_t_4 = 0;

  /* "spacy/tokenizer.pyx":724
 *         t_words = []
 *         t_spaces = []
 *         for word, space in zip(words, spaces):             # <<<<<<<<<<<<<<
 *             if not word.isspace():
 *                 t_words.append(word)
 */
  __pyx_t_4 = PyTuple_New(2); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 724, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_INCREF(__pyx_v_words);
  __Pyx_GIVEREF(__pyx_v_words);
  PyTuple_SET_ITEM(__pyx_t_4, 0, __pyx_v_words);
  __Pyx_INCREF(__pyx_v_spaces);
  __Pyx_GIVEREF(__pyx_v_spaces);
  PyTuple_SET_ITEM(__pyx_t_4, 1, __pyx_v_spaces);
  __pyx_t_13 = __Pyx_PyObject_Call(__pyx_builtin_zip, __pyx_t_4, NULL); if (unlikely(!__pyx_t_13)) __PYX_ERR(0, 724, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_13);
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  if (likely(PyList_CheckExact(__pyx_t_13)) || PyTuple_CheckExact(__pyx_t_13)) {
    __pyx_t_4 = __pyx_t_13; __Pyx_INCREF(__pyx_t_4); __pyx_t_6 = 0;
    __pyx_t_7 = NULL;
  } else {
    __pyx_t_6 = -1; __pyx_t_4 = PyObject_GetIter(__pyx_t_13); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 724, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_7 = Py_TYPE(__pyx_t_4)->tp_iternext; if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 724, __pyx_L1_error)
  }
  __Pyx_DECREF(__pyx_t_13); __pyx_t_13 = 0;
  for (;;) {
    if (likely(!__pyx_t_7)) {
      if (likely(PyList_CheckExact(__pyx_t_4))) {
        if (__pyx_t_6 >= PyList_GET_SIZE(__pyx_t_4)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_13 = PyList_GET_ITEM(__pyx_t_4, __pyx_t_6); __Pyx_INCREF(__pyx_t_13); __pyx_t_6++; if (unlikely(0 < 0)) __PYX_ERR(0, 724, __pyx_L1_error)
        #else
        __pyx_t_13 = PySequence_ITEM(__pyx_t_4, __pyx_t_6); __pyx_t_6++; if (unlikely(!__pyx_t_13)) __PYX_ERR(0, 724, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_13);
        #endif
      } else {
        if (__pyx_t_6 >= PyTuple_GET_SIZE(__pyx_t_4)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_13 = PyTuple_GET_ITEM(__pyx_t_4, __pyx_t_6); __Pyx_INCREF(__pyx_t_13); __pyx_t_6++; if (unlikely(0 < 0)) __PYX_ERR(0, 724, __pyx_L1_error)
        #else
        __pyx_t_13 = PySequence_ITEM(__pyx_t_4, __pyx_t_6); __pyx_t_6++; if (unlikely(!__pyx_t_13)) __PYX_ERR(0, 724, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_13);
        #endif
      }
    } else {
      __pyx_t_13 = __pyx_t_7(__pyx_t_4);
      if (unlikely(!__pyx_t_13)) {
        PyObject* exc_type = PyErr_Occurred();
        if (exc_type) {
          if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
          else __PYX_ERR(0, 724, __pyx_L1_error)
        }
        break;
      }
      __Pyx_GOTREF(__pyx_t_13);
    }
    if ((likely(PyTuple_CheckExact(__pyx_t_13))) || (PyList_CheckExact(__pyx_t_13))) {
      PyObject* sequence = __pyx_t_13;
      Py_ssize_t size = __Pyx_PySequence_SIZE(sequence);
      if (unlikely(size != 2)) {
        if (size > 2) __Pyx_RaiseTooManyValuesError(2);
        else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
        __PYX_ERR(0, 724, __pyx_L1_error)
      }
      #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
      if (likely(PyTuple_CheckExact(sequence))) {
        __pyx_t_1 = PyTuple_GET_ITEM(sequence, 0); 
        __pyx_t_8 = PyTuple_GET_ITEM(sequence, 1); 
      } else {
        __pyx_t_1 = PyList_GET_ITEM(sequence, 0); 
        __pyx_t_8 = PyList_GET_ITEM(sequence, 1); 
      }
      __Pyx_INCREF(__pyx_t_1);
      __Pyx_INCREF(__pyx_t_8);
      #else
      __pyx_t_1 = PySequence_ITEM(sequence, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 724, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __pyx_t_8 = PySequence_ITEM(sequence, 1); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 724, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      #endif
      __Pyx_DECREF(__pyx_t_13); __pyx_t_13 = 0;
    } else {
      Py_ssize_t index = -1;
      __pyx_t_14 = PyObject_GetIter(__pyx_t_13); if (unlikely(!__pyx_t_14)) __PYX_ERR(0, 724, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_14);
      __Pyx_DECREF(__pyx_t_13); __pyx_t_13 = 0;
      __pyx_t_10 = Py_TYPE(__pyx_t_14)->tp_iternext;
      index = 0; __pyx_t_1 = __pyx_t_10(__pyx_t_14); if (unlikely(!__pyx_t_1)) goto __pyx_L46_unpacking_failed;
      __Pyx_GOTREF(__pyx_t_1);
      index = 1; __pyx_t_8 = __pyx_t_10(__pyx_t_14); if (unlikely(!__pyx_t_8)) goto __pyx_L46_unpacking_failed;
      __Pyx_GOTREF(__pyx_t_8);
      if (__Pyx_IternextUnpackEndCheck(__pyx_t_10(__pyx_t_14), 2) < 0) __PYX_ERR(0, 724, __pyx_L1_error)
      __pyx_t_10 = NULL;
      __Pyx_DECREF(__pyx_t_14); __pyx_t_14 = 0;
      goto __pyx_L47_unpacking_done;
      __pyx_L46_unpacking_failed:;
      __Pyx_DECREF(__pyx_t_14); __pyx_t_14 = 0;
      __pyx_t_10 = NULL;
      if (__Pyx_IterFinish() == 0) __Pyx_RaiseNeedMoreValuesError(index);
      __PYX_ERR(0, 724, __pyx_L1_error)
      __pyx_L47_unpacking_done:;
    }
    __Pyx_XDECREF_SET(__pyx_v_word, __pyx_t_1);
    __pyx_t_1 = 0;
    __Pyx_XDECREF_SET(__pyx_v_space, __pyx_t_8);
    __pyx_t_8 = 0;

    /* "spacy/tokenizer.pyx":725
 *         t_spaces = []
 *         for word, space in zip(words, spaces):
 *             if not word.isspace():             # <<<<<<<<<<<<<<
 *                 t_words.append(word)
 *                 t_spaces.append(space)
 */
    __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_v_word, __pyx_n_s_isspace); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 725, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __pyx_t_1 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_8))) {
      __pyx_t_1 = PyMethod_GET_SELF(__pyx_t_8);
      if (likely(__pyx_t_1)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_8);
        __Pyx_INCREF(__pyx_t_1);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_8, function);
      }
    }
    __pyx_t_13 = (__pyx_t_1) ? __Pyx_PyObject_CallOneArg(__pyx_t_8, __pyx_t_1) : __Pyx_PyObject_CallNoArg(__pyx_t_8);
    __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
    if (unlikely(!__pyx_t_13)) __PYX_ERR(0, 725, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_13);
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    __pyx_t_3 = __Pyx_PyObject_IsTrue(__pyx_t_13); if (unlikely(__pyx_t_3 < 0)) __PYX_ERR(0, 725, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_13); __pyx_t_13 = 0;
    __pyx_t_2 = ((!__pyx_t_3) != 0);
    if (__pyx_t_2) {

      /* "spacy/tokenizer.pyx":726
 *         for word, space in zip(words, spaces):
 *             if not word.isspace():
 *                 t_words.append(word)             # <<<<<<<<<<<<<<
 *                 t_spaces.append(space)
 *         doc = Doc(self.vocab, words=t_words, spaces=t_spaces)
 */
      __pyx_t_15 = __Pyx_PyList_Append(__pyx_v_t_words, __pyx_v_word); if (unlikely(__pyx_t_15 == ((int)-1))) __PYX_ERR(0, 726, __pyx_L1_error)

      /* "spacy/tokenizer.pyx":727
 *             if not word.isspace():
 *                 t_words.append(word)
 *                 t_spaces.append(space)             # <<<<<<<<<<<<<<
 *         doc = Doc(self.vocab, words=t_words, spaces=t_spaces)
 *         matches = self._special_matcher(doc)
 */
      __pyx_t_15 = __Pyx_PyList_Append(__pyx_v_t_spaces, __pyx_v_space); if (unlikely(__pyx_t_15 == ((int)-1))) __PYX_ERR(0, 727, __pyx_L1_error)

      /* "spacy/tokenizer.pyx":725
 *         t_spaces = []
 *         for word, space in zip(words, spaces):
 *             if not word.isspace():             # <<<<<<<<<<<<<<
 *                 t_words.append(word)
 *                 t_spaces.append(space)
 */
    }

    /* "spacy/tokenizer.pyx":724
 *         t_words = []
 *         t_spaces = []
 *         for word, space in zip(words, spaces):             # <<<<<<<<<<<<<<
 *             if not word.isspace():
 *                 t_words.append(word)
 */
  }
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;

  /* "spacy/tokenizer.pyx":728
 *                 t_words.append(word)
 *                 t_spaces.append(space)
 *         doc = Doc(self.vocab, words=t_words, spaces=t_spaces)             # <<<<<<<<<<<<<<
 *         matches = self._special_matcher(doc)
 *         spans = [Span(doc, s, e, label=m_id) for m_id, s, e in matches]
 */
  __pyx_t_4 = PyTuple_New(1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 728, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_INCREF(((PyObject *)__pyx_cur_scope->__pyx_v_self->vocab));
  __Pyx_GIVEREF(((PyObject *)__pyx_cur_scope->__pyx_v_self->vocab));
  PyTuple_SET_ITEM(__pyx_t_4, 0, ((PyObject *)__pyx_cur_scope->__pyx_v_self->vocab));
  __pyx_t_13 = __Pyx_PyDict_NewPresized(2); if (unlikely(!__pyx_t_13)) __PYX_ERR(0, 728, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_13);
  if (PyDict_SetItem(__pyx_t_13, __pyx_n_s_words, __pyx_v_t_words) < 0) __PYX_ERR(0, 728, __pyx_L1_error)
  if (PyDict_SetItem(__pyx_t_13, __pyx_n_s_spaces, __pyx_v_t_spaces) < 0) __PYX_ERR(0, 728, __pyx_L1_error)
  __pyx_t_8 = __Pyx_PyObject_Call(((PyObject *)__pyx_ptype_5spacy_6tokens_3doc_Doc), __pyx_t_4, __pyx_t_13); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 728, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __Pyx_DECREF(__pyx_t_13); __pyx_t_13 = 0;
  __pyx_v_doc = ((struct __pyx_obj_5spacy_6tokens_3doc_Doc *)__pyx_t_8);
  __pyx_t_8 = 0;

  /* "spacy/tokenizer.pyx":729
 *                 t_spaces.append(space)
 *         doc = Doc(self.vocab, words=t_words, spaces=t_spaces)
 *         matches = self._special_matcher(doc)             # <<<<<<<<<<<<<<
 *         spans = [Span(doc, s, e, label=m_id) for m_id, s, e in matches]
 *         spans = util.filter_spans(spans)
 */
  __Pyx_INCREF(((PyObject *)__pyx_cur_scope->__pyx_v_self->_special_matcher));
  __pyx_t_13 = ((PyObject *)__pyx_cur_scope->__pyx_v_self->_special_matcher); __pyx_t_4 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_13))) {
    __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_13);
    if (likely(__pyx_t_4)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_13);
      __Pyx_INCREF(__pyx_t_4);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_13, function);
    }
  }
  __pyx_t_8 = (__pyx_t_4) ? __Pyx_PyObject_Call2Args(__pyx_t_13, __pyx_t_4, ((PyObject *)__pyx_v_doc)) : __Pyx_PyObject_CallOneArg(__pyx_t_13, ((PyObject *)__pyx_v_doc));
  __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
  if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 729, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __Pyx_DECREF(__pyx_t_13); __pyx_t_13 = 0;
  __pyx_v_matches = __pyx_t_8;
  __pyx_t_8 = 0;

  /* "spacy/tokenizer.pyx":730
 *         doc = Doc(self.vocab, words=t_words, spaces=t_spaces)
 *         matches = self._special_matcher(doc)
 *         spans = [Span(doc, s, e, label=m_id) for m_id, s, e in matches]             # <<<<<<<<<<<<<<
 *         spans = util.filter_spans(spans)
 *         # Replace matched tokens with their exceptions
 */
  __pyx_t_8 = PyList_New(0); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 730, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  if (likely(PyList_CheckExact(__pyx_v_matches)) || PyTuple_CheckExact(__pyx_v_matches)) {
    __pyx_t_13 = __pyx_v_matches; __Pyx_INCREF(__pyx_t_13); __pyx_t_6 = 0;
    __pyx_t_7 = NULL;
  } else {
    __pyx_t_6 = -1; __pyx_t_13 = PyObject_GetIter(__pyx_v_matches); if (unlikely(!__pyx_t_13)) __PYX_ERR(0, 730, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_13);
    __pyx_t_7 = Py_TYPE(__pyx_t_13)->tp_iternext; if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 730, __pyx_L1_error)
  }
  for (;;) {
    if (likely(!__pyx_t_7)) {
      if (likely(PyList_CheckExact(__pyx_t_13))) {
        if (__pyx_t_6 >= PyList_GET_SIZE(__pyx_t_13)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_4 = PyList_GET_ITEM(__pyx_t_13, __pyx_t_6); __Pyx_INCREF(__pyx_t_4); __pyx_t_6++; if (unlikely(0 < 0)) __PYX_ERR(0, 730, __pyx_L1_error)
        #else
        __pyx_t_4 = PySequence_ITEM(__pyx_t_13, __pyx_t_6); __pyx_t_6++; if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 730, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_4);
        #endif
      } else {
        if (__pyx_t_6 >= PyTuple_GET_SIZE(__pyx_t_13)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_4 = PyTuple_GET_ITEM(__pyx_t_13, __pyx_t_6); __Pyx_INCREF(__pyx_t_4); __pyx_t_6++; if (unlikely(0 < 0)) __PYX_ERR(0, 730, __pyx_L1_error)
        #else
        __pyx_t_4 = PySequence_ITEM(__pyx_t_13, __pyx_t_6); __pyx_t_6++; if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 730, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_4);
        #endif
      }
    } else {
      __pyx_t_4 = __pyx_t_7(__pyx_t_13);
      if (unlikely(!__pyx_t_4)) {
        PyObject* exc_type = PyErr_Occurred();
        if (exc_type) {
          if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
          else __PYX_ERR(0, 730, __pyx_L1_error)
        }
        break;
      }
      __Pyx_GOTREF(__pyx_t_4);
    }
    if ((likely(PyTuple_CheckExact(__pyx_t_4))) || (PyList_CheckExact(__pyx_t_4))) {
      PyObject* sequence = __pyx_t_4;
      Py_ssize_t size = __Pyx_PySequence_SIZE(sequence);
      if (unlikely(size != 3)) {
        if (size > 3) __Pyx_RaiseTooManyValuesError(3);
        else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
        __PYX_ERR(0, 730, __pyx_L1_error)
      }
      #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
      if (likely(PyTuple_CheckExact(sequence))) {
        __pyx_t_1 = PyTuple_GET_ITEM(sequence, 0); 
        __pyx_t_14 = PyTuple_GET_ITEM(sequence, 1); 
        __pyx_t_9 = PyTuple_GET_ITEM(sequence, 2); 
      } else {
        __pyx_t_1 = PyList_GET_ITEM(sequence, 0); 
        __pyx_t_14 = PyList_GET_ITEM(sequence, 1); 
        __pyx_t_9 = PyList_GET_ITEM(sequence, 2); 
      }
      __Pyx_INCREF(__pyx_t_1);
      __Pyx_INCREF(__pyx_t_14);
      __Pyx_INCREF(__pyx_t_9);
      #else
      __pyx_t_1 = PySequence_ITEM(sequence, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 730, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __pyx_t_14 = PySequence_ITEM(sequence, 1); if (unlikely(!__pyx_t_14)) __PYX_ERR(0, 730, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_14);
      __pyx_t_9 = PySequence_ITEM(sequence, 2); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 730, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_9);
      #endif
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    } else {
      Py_ssize_t index = -1;
      __pyx_t_5 = PyObject_GetIter(__pyx_t_4); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 730, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_5);
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __pyx_t_10 = Py_TYPE(__pyx_t_5)->tp_iternext;
      index = 0; __pyx_t_1 = __pyx_t_10(__pyx_t_5); if (unlikely(!__pyx_t_1)) goto __pyx_L51_unpacking_failed;
      __Pyx_GOTREF(__pyx_t_1);
      index = 1; __pyx_t_14 = __pyx_t_10(__pyx_t_5); if (unlikely(!__pyx_t_14)) goto __pyx_L51_unpacking_failed;
      __Pyx_GOTREF(__pyx_t_14);
      index = 2; __pyx_t_9 = __pyx_t_10(__pyx_t_5); if (unlikely(!__pyx_t_9)) goto __pyx_L51_unpacking_failed;
      __Pyx_GOTREF(__pyx_t_9);
      if (__Pyx_IternextUnpackEndCheck(__pyx_t_10(__pyx_t_5), 3) < 0) __PYX_ERR(0, 730, __pyx_L1_error)
      __pyx_t_10 = NULL;
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      goto __pyx_L52_unpacking_done;
      __pyx_L51_unpacking_failed:;
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      __pyx_t_10 = NULL;
      if (__Pyx_IterFinish() == 0) __Pyx_RaiseNeedMoreValuesError(index);
      __PYX_ERR(0, 730, __pyx_L1_error)
      __pyx_L52_unpacking_done:;
    }
    __Pyx_XDECREF_SET(__pyx_v_m_id, __pyx_t_1);
    __pyx_t_1 = 0;
    __Pyx_XDECREF_SET(__pyx_v_s, __pyx_t_14);
    __pyx_t_14 = 0;
    __Pyx_XDECREF_SET(__pyx_v_e, __pyx_t_9);
    __pyx_t_9 = 0;
    __Pyx_GetModuleGlobalName(__pyx_t_4, __pyx_n_s_Span); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 730, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_9 = PyTuple_New(3); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 730, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_9);
    __Pyx_INCREF(((PyObject *)__pyx_v_doc));
    __Pyx_GIVEREF(((PyObject *)__pyx_v_doc));
    PyTuple_SET_ITEM(__pyx_t_9, 0, ((PyObject *)__pyx_v_doc));
    __Pyx_INCREF(__pyx_v_s);
    __Pyx_GIVEREF(__pyx_v_s);
    PyTuple_SET_ITEM(__pyx_t_9, 1, __pyx_v_s);
    __Pyx_INCREF(__pyx_v_e);
    __Pyx_GIVEREF(__pyx_v_e);
    PyTuple_SET_ITEM(__pyx_t_9, 2, __pyx_v_e);
    __pyx_t_14 = __Pyx_PyDict_NewPresized(1); if (unlikely(!__pyx_t_14)) __PYX_ERR(0, 730, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_14);
    if (PyDict_SetItem(__pyx_t_14, __pyx_n_s_label, __pyx_v_m_id) < 0) __PYX_ERR(0, 730, __pyx_L1_error)
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_4, __pyx_t_9, __pyx_t_14); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 730, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
    __Pyx_DECREF(__pyx_t_14); __pyx_t_14 = 0;
    if (unlikely(__Pyx_ListComp_Append(__pyx_t_8, (PyObject*)__pyx_t_1))) __PYX_ERR(0, 730, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  }
  __Pyx_DECREF(__pyx_t_13); __pyx_t_13 = 0;
  __pyx_v_spans = __pyx_t_8;
  __pyx_t_8 = 0;

  /* "spacy/tokenizer.pyx":731
 *         matches = self._special_matcher(doc)
 *         spans = [Span(doc, s, e, label=m_id) for m_id, s, e in matches]
 *         spans = util.filter_spans(spans)             # <<<<<<<<<<<<<<
 *         # Replace matched tokens with their exceptions
 *         i = 0
 */
  __Pyx_GetModuleGlobalName(__pyx_t_13, __pyx_n_s_util); if (unlikely(!__pyx_t_13)) __PYX_ERR(0, 731, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_13);
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_13, __pyx_n_s_filter_spans); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 731, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_13); __pyx_t_13 = 0;
  __pyx_t_13 = NULL;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_1))) {
    __pyx_t_13 = PyMethod_GET_SELF(__pyx_t_1);
    if (likely(__pyx_t_13)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_1);
      __Pyx_INCREF(__pyx_t_13);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_1, function);
    }
  }
  __pyx_t_8 = (__pyx_t_13) ? __Pyx_PyObject_Call2Args(__pyx_t_1, __pyx_t_13, __pyx_v_spans) : __Pyx_PyObject_CallOneArg(__pyx_t_1, __pyx_v_spans);
  __Pyx_XDECREF(__pyx_t_13); __pyx_t_13 = 0;
  if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 731, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __Pyx_DECREF_SET(__pyx_v_spans, __pyx_t_8);
  __pyx_t_8 = 0;

  /* "spacy/tokenizer.pyx":733
 *         spans = util.filter_spans(spans)
 *         # Replace matched tokens with their exceptions
 *         i = 0             # <<<<<<<<<<<<<<
 *         final_tokens = []
 *         spans_by_start = {s.start: s for s in spans}
 */
  __Pyx_INCREF(__pyx_int_0);
  __pyx_v_i = __pyx_int_0;

  /* "spacy/tokenizer.pyx":734
 *         # Replace matched tokens with their exceptions
 *         i = 0
 *         final_tokens = []             # <<<<<<<<<<<<<<
 *         spans_by_start = {s.start: s for s in spans}
 *         while i < len(tokens):
 */
  __pyx_t_8 = PyList_New(0); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 734, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __pyx_v_final_tokens = ((PyObject*)__pyx_t_8);
  __pyx_t_8 = 0;

  /* "spacy/tokenizer.pyx":735
 *         i = 0
 *         final_tokens = []
 *         spans_by_start = {s.start: s for s in spans}             # <<<<<<<<<<<<<<
 *         while i < len(tokens):
 *             if i in spans_by_start:
 */
  { /* enter inner scope */
    __pyx_t_8 = PyDict_New(); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 735, __pyx_L55_error)
    __Pyx_GOTREF(__pyx_t_8);
    if (likely(PyList_CheckExact(__pyx_v_spans)) || PyTuple_CheckExact(__pyx_v_spans)) {
      __pyx_t_1 = __pyx_v_spans; __Pyx_INCREF(__pyx_t_1); __pyx_t_6 = 0;
      __pyx_t_7 = NULL;
    } else {
      __pyx_t_6 = -1; __pyx_t_1 = PyObject_GetIter(__pyx_v_spans); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 735, __pyx_L55_error)
      __Pyx_GOTREF(__pyx_t_1);
      __pyx_t_7 = Py_TYPE(__pyx_t_1)->tp_iternext; if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 735, __pyx_L55_error)
    }
    for (;;) {
      if (likely(!__pyx_t_7)) {
        if (likely(PyList_CheckExact(__pyx_t_1))) {
          if (__pyx_t_6 >= PyList_GET_SIZE(__pyx_t_1)) break;
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          __pyx_t_13 = PyList_GET_ITEM(__pyx_t_1, __pyx_t_6); __Pyx_INCREF(__pyx_t_13); __pyx_t_6++; if (unlikely(0 < 0)) __PYX_ERR(0, 735, __pyx_L55_error)
          #else
          __pyx_t_13 = PySequence_ITEM(__pyx_t_1, __pyx_t_6); __pyx_t_6++; if (unlikely(!__pyx_t_13)) __PYX_ERR(0, 735, __pyx_L55_error)
          __Pyx_GOTREF(__pyx_t_13);
          #endif
        } else {
          if (__pyx_t_6 >= PyTuple_GET_SIZE(__pyx_t_1)) break;
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          __pyx_t_13 = PyTuple_GET_ITEM(__pyx_t_1, __pyx_t_6); __Pyx_INCREF(__pyx_t_13); __pyx_t_6++; if (unlikely(0 < 0)) __PYX_ERR(0, 735, __pyx_L55_error)
          #else
          __pyx_t_13 = PySequence_ITEM(__pyx_t_1, __pyx_t_6); __pyx_t_6++; if (unlikely(!__pyx_t_13)) __PYX_ERR(0, 735, __pyx_L55_error)
          __Pyx_GOTREF(__pyx_t_13);
          #endif
        }
      } else {
        __pyx_t_13 = __pyx_t_7(__pyx_t_1);
        if (unlikely(!__pyx_t_13)) {
          PyObject* exc_type = PyErr_Occurred();
          if (exc_type) {
            if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
            else __PYX_ERR(0, 735, __pyx_L55_error)
          }
          break;
        }
        __Pyx_GOTREF(__pyx_t_13);
      }
      __Pyx_XDECREF_SET(__pyx_8genexpr3__pyx_v_s, __pyx_t_13);
      __pyx_t_13 = 0;
      __pyx_t_13 = __Pyx_PyObject_GetAttrStr(__pyx_8genexpr3__pyx_v_s, __pyx_n_s_start); if (unlikely(!__pyx_t_13)) __PYX_ERR(0, 735, __pyx_L55_error)
      __Pyx_GOTREF(__pyx_t_13);
      if (unlikely(PyDict_SetItem(__pyx_t_8, (PyObject*)__pyx_t_13, (PyObject*)__pyx_8genexpr3__pyx_v_s))) __PYX_ERR(0, 735, __pyx_L55_error)
      __Pyx_DECREF(__pyx_t_13); __pyx_t_13 = 0;
    }
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_XDECREF(__pyx_8genexpr3__pyx_v_s); __pyx_8genexpr3__pyx_v_s = 0;
    goto __pyx_L58_exit_scope;
    __pyx_L55_error:;
    __Pyx_XDECREF(__pyx_8genexpr3__pyx_v_s); __pyx_8genexpr3__pyx_v_s = 0;
    goto __pyx_L1_error;
    __pyx_L58_exit_scope:;
  } /* exit inner scope */
  __pyx_v_spans_by_start = ((PyObject*)__pyx_t_8);
  __pyx_t_8 = 0;

  /* "spacy/tokenizer.pyx":736
 *         final_tokens = []
 *         spans_by_start = {s.start: s for s in spans}
 *         while i < len(tokens):             # <<<<<<<<<<<<<<
 *             if i in spans_by_start:
 *                 span = spans_by_start[i]
 */
  while (1) {
    __pyx_t_6 = PyList_GET_SIZE(__pyx_v_tokens); if (unlikely(__pyx_t_6 == ((Py_ssize_t)-1))) __PYX_ERR(0, 736, __pyx_L1_error)
    __pyx_t_8 = PyInt_FromSsize_t(__pyx_t_6); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 736, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __pyx_t_1 = PyObject_RichCompare(__pyx_v_i, __pyx_t_8, Py_LT); __Pyx_XGOTREF(__pyx_t_1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 736, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    __pyx_t_2 = __Pyx_PyObject_IsTrue(__pyx_t_1); if (unlikely(__pyx_t_2 < 0)) __PYX_ERR(0, 736, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    if (!__pyx_t_2) break;

    /* "spacy/tokenizer.pyx":737
 *         spans_by_start = {s.start: s for s in spans}
 *         while i < len(tokens):
 *             if i in spans_by_start:             # <<<<<<<<<<<<<<
 *                 span = spans_by_start[i]
 *                 exc = [d[ORTH] for d in special_cases[span.label_]]
 */
    __pyx_t_2 = (__Pyx_PyDict_ContainsTF(__pyx_v_i, __pyx_v_spans_by_start, Py_EQ)); if (unlikely(__pyx_t_2 < 0)) __PYX_ERR(0, 737, __pyx_L1_error)
    __pyx_t_3 = (__pyx_t_2 != 0);
    if (__pyx_t_3) {

      /* "spacy/tokenizer.pyx":738
 *         while i < len(tokens):
 *             if i in spans_by_start:
 *                 span = spans_by_start[i]             # <<<<<<<<<<<<<<
 *                 exc = [d[ORTH] for d in special_cases[span.label_]]
 *                 # The phrase matcher can overmatch for tokens separated by
 */
      __pyx_t_1 = __Pyx_PyDict_GetItem(__pyx_v_spans_by_start, __pyx_v_i); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 738, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_XDECREF_SET(__pyx_v_span, __pyx_t_1);
      __pyx_t_1 = 0;

      /* "spacy/tokenizer.pyx":739
 *             if i in spans_by_start:
 *                 span = spans_by_start[i]
 *                 exc = [d[ORTH] for d in special_cases[span.label_]]             # <<<<<<<<<<<<<<
 *                 # The phrase matcher can overmatch for tokens separated by
 *                 # spaces in the text but not in the underlying rule, so skip
 */
      __pyx_t_1 = PyList_New(0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 739, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_v_span, __pyx_n_s_label_2); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 739, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __pyx_t_13 = __Pyx_PyDict_GetItem(__pyx_cur_scope->__pyx_v_special_cases, __pyx_t_8); if (unlikely(!__pyx_t_13)) __PYX_ERR(0, 739, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_13);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      if (likely(PyList_CheckExact(__pyx_t_13)) || PyTuple_CheckExact(__pyx_t_13)) {
        __pyx_t_8 = __pyx_t_13; __Pyx_INCREF(__pyx_t_8); __pyx_t_6 = 0;
        __pyx_t_7 = NULL;
      } else {
        __pyx_t_6 = -1; __pyx_t_8 = PyObject_GetIter(__pyx_t_13); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 739, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_8);
        __pyx_t_7 = Py_TYPE(__pyx_t_8)->tp_iternext; if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 739, __pyx_L1_error)
      }
      __Pyx_DECREF(__pyx_t_13); __pyx_t_13 = 0;
      for (;;) {
        if (likely(!__pyx_t_7)) {
          if (likely(PyList_CheckExact(__pyx_t_8))) {
            if (__pyx_t_6 >= PyList_GET_SIZE(__pyx_t_8)) break;
            #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
            __pyx_t_13 = PyList_GET_ITEM(__pyx_t_8, __pyx_t_6); __Pyx_INCREF(__pyx_t_13); __pyx_t_6++; if (unlikely(0 < 0)) __PYX_ERR(0, 739, __pyx_L1_error)
            #else
            __pyx_t_13 = PySequence_ITEM(__pyx_t_8, __pyx_t_6); __pyx_t_6++; if (unlikely(!__pyx_t_13)) __PYX_ERR(0, 739, __pyx_L1_error)
            __Pyx_GOTREF(__pyx_t_13);
            #endif
          } else {
            if (__pyx_t_6 >= PyTuple_GET_SIZE(__pyx_t_8)) break;
            #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
            __pyx_t_13 = PyTuple_GET_ITEM(__pyx_t_8, __pyx_t_6); __Pyx_INCREF(__pyx_t_13); __pyx_t_6++; if (unlikely(0 < 0)) __PYX_ERR(0, 739, __pyx_L1_error)
            #else
            __pyx_t_13 = PySequence_ITEM(__pyx_t_8, __pyx_t_6); __pyx_t_6++; if (unlikely(!__pyx_t_13)) __PYX_ERR(0, 739, __pyx_L1_error)
            __Pyx_GOTREF(__pyx_t_13);
            #endif
          }
        } else {
          __pyx_t_13 = __pyx_t_7(__pyx_t_8);
          if (unlikely(!__pyx_t_13)) {
            PyObject* exc_type = PyErr_Occurred();
            if (exc_type) {
              if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
              else __PYX_ERR(0, 739, __pyx_L1_error)
            }
            break;
          }
          __Pyx_GOTREF(__pyx_t_13);
        }
        __Pyx_XDECREF_SET(__pyx_v_d, __pyx_t_13);
        __pyx_t_13 = 0;
        __Pyx_GetModuleGlobalName(__pyx_t_13, __pyx_n_s_ORTH); if (unlikely(!__pyx_t_13)) __PYX_ERR(0, 739, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_13);
        __pyx_t_14 = __Pyx_PyObject_GetItem(__pyx_v_d, __pyx_t_13); if (unlikely(!__pyx_t_14)) __PYX_ERR(0, 739, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_14);
        __Pyx_DECREF(__pyx_t_13); __pyx_t_13 = 0;
        if (unlikely(__Pyx_ListComp_Append(__pyx_t_1, (PyObject*)__pyx_t_14))) __PYX_ERR(0, 739, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_14); __pyx_t_14 = 0;
      }
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __Pyx_XDECREF_SET(__pyx_v_exc, ((PyObject*)__pyx_t_1));
      __pyx_t_1 = 0;

      /* "spacy/tokenizer.pyx":743
 *                 # spaces in the text but not in the underlying rule, so skip
 *                 # cases where the texts aren't identical
 *                 if span.text != "".join([self.vocab.strings[orth] for orth in exc]):             # <<<<<<<<<<<<<<
 *                     final_tokens.append(tokens[i])
 *                     i += 1
 */
      __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_span, __pyx_n_s_text); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 743, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __pyx_t_8 = PyList_New(0); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 743, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __pyx_t_14 = __pyx_v_exc; __Pyx_INCREF(__pyx_t_14); __pyx_t_6 = 0;
      for (;;) {
        if (__pyx_t_6 >= PyList_GET_SIZE(__pyx_t_14)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_13 = PyList_GET_ITEM(__pyx_t_14, __pyx_t_6); __Pyx_INCREF(__pyx_t_13); __pyx_t_6++; if (unlikely(0 < 0)) __PYX_ERR(0, 743, __pyx_L1_error)
        #else
        __pyx_t_13 = PySequence_ITEM(__pyx_t_14, __pyx_t_6); __pyx_t_6++; if (unlikely(!__pyx_t_13)) __PYX_ERR(0, 743, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_13);
        #endif
        __Pyx_XDECREF_SET(__pyx_v_orth, __pyx_t_13);
        __pyx_t_13 = 0;
        __pyx_t_13 = __Pyx_PyObject_GetItem(((PyObject *)__pyx_cur_scope->__pyx_v_self->vocab->strings), __pyx_v_orth); if (unlikely(!__pyx_t_13)) __PYX_ERR(0, 743, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_13);
        if (unlikely(__Pyx_ListComp_Append(__pyx_t_8, (PyObject*)__pyx_t_13))) __PYX_ERR(0, 743, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_13); __pyx_t_13 = 0;
      }
      __Pyx_DECREF(__pyx_t_14); __pyx_t_14 = 0;
      __pyx_t_14 = __Pyx_PyString_Join(__pyx_kp_s__3, __pyx_t_8); if (unlikely(!__pyx_t_14)) __PYX_ERR(0, 743, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_14);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __pyx_t_3 = (__Pyx_PyUnicode_Equals(__pyx_t_1, __pyx_t_14, Py_NE)); if (unlikely(__pyx_t_3 < 0)) __PYX_ERR(0, 743, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __Pyx_DECREF(__pyx_t_14); __pyx_t_14 = 0;
      if (__pyx_t_3) {

        /* "spacy/tokenizer.pyx":744
 *                 # cases where the texts aren't identical
 *                 if span.text != "".join([self.vocab.strings[orth] for orth in exc]):
 *                     final_tokens.append(tokens[i])             # <<<<<<<<<<<<<<
 *                     i += 1
 *                 else:
 */
        __pyx_t_14 = __Pyx_PyObject_GetItem(__pyx_v_tokens, __pyx_v_i); if (unlikely(!__pyx_t_14)) __PYX_ERR(0, 744, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_14);
        __pyx_t_15 = __Pyx_PyList_Append(__pyx_v_final_tokens, __pyx_t_14); if (unlikely(__pyx_t_15 == ((int)-1))) __PYX_ERR(0, 744, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_14); __pyx_t_14 = 0;

        /* "spacy/tokenizer.pyx":745
 *                 if span.text != "".join([self.vocab.strings[orth] for orth in exc]):
 *                     final_tokens.append(tokens[i])
 *                     i += 1             # <<<<<<<<<<<<<<
 *                 else:
 *                     for j, orth in enumerate(exc):
 */
        __pyx_t_14 = __Pyx_PyInt_AddObjC(__pyx_v_i, __pyx_int_1, 1, 1, 0); if (unlikely(!__pyx_t_14)) __PYX_ERR(0, 745, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_14);
        __Pyx_DECREF_SET(__pyx_v_i, __pyx_t_14);
        __pyx_t_14 = 0;

        /* "spacy/tokenizer.pyx":743
 *                 # spaces in the text but not in the underlying rule, so skip
 *                 # cases where the texts aren't identical
 *                 if span.text != "".join([self.vocab.strings[orth] for orth in exc]):             # <<<<<<<<<<<<<<
 *                     final_tokens.append(tokens[i])
 *                     i += 1
 */
        goto __pyx_L64;
      }

      /* "spacy/tokenizer.pyx":747
 *                     i += 1
 *                 else:
 *                     for j, orth in enumerate(exc):             # <<<<<<<<<<<<<<
 *                         final_tokens.append((f"SPECIAL-{j + 1}", self.vocab.strings[orth]))
 *                     i += len(span)
 */
      /*else*/ {
        __Pyx_INCREF(__pyx_int_0);
        __pyx_t_14 = __pyx_int_0;
        __pyx_t_1 = __pyx_v_exc; __Pyx_INCREF(__pyx_t_1); __pyx_t_6 = 0;
        for (;;) {
          if (__pyx_t_6 >= PyList_GET_SIZE(__pyx_t_1)) break;
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          __pyx_t_8 = PyList_GET_ITEM(__pyx_t_1, __pyx_t_6); __Pyx_INCREF(__pyx_t_8); __pyx_t_6++; if (unlikely(0 < 0)) __PYX_ERR(0, 747, __pyx_L1_error)
          #else
          __pyx_t_8 = PySequence_ITEM(__pyx_t_1, __pyx_t_6); __pyx_t_6++; if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 747, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_8);
          #endif
          __Pyx_XDECREF_SET(__pyx_v_orth, __pyx_t_8);
          __pyx_t_8 = 0;
          __Pyx_INCREF(__pyx_t_14);
          __Pyx_XDECREF_SET(__pyx_v_j, __pyx_t_14);
          __pyx_t_8 = __Pyx_PyInt_AddObjC(__pyx_t_14, __pyx_int_1, 1, 0, 0); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 747, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_8);
          __Pyx_DECREF(__pyx_t_14);
          __pyx_t_14 = __pyx_t_8;
          __pyx_t_8 = 0;

          /* "spacy/tokenizer.pyx":748
 *                 else:
 *                     for j, orth in enumerate(exc):
 *                         final_tokens.append((f"SPECIAL-{j + 1}", self.vocab.strings[orth]))             # <<<<<<<<<<<<<<
 *                     i += len(span)
 *             else:
 */
          __pyx_t_8 = __Pyx_PyInt_AddObjC(__pyx_v_j, __pyx_int_1, 1, 0, 0); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 748, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_8);
          __pyx_t_13 = __Pyx_PyObject_FormatSimple(__pyx_t_8, __pyx_empty_unicode); if (unlikely(!__pyx_t_13)) __PYX_ERR(0, 748, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_13);
          __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
          __pyx_t_8 = __Pyx_PyUnicode_Concat(__pyx_kp_u_SPECIAL, __pyx_t_13); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 748, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_8);
          __Pyx_DECREF(__pyx_t_13); __pyx_t_13 = 0;
          __pyx_t_13 = __Pyx_PyObject_GetItem(((PyObject *)__pyx_cur_scope->__pyx_v_self->vocab->strings), __pyx_v_orth); if (unlikely(!__pyx_t_13)) __PYX_ERR(0, 748, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_13);
          __pyx_t_9 = PyTuple_New(2); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 748, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_9);
          __Pyx_GIVEREF(__pyx_t_8);
          PyTuple_SET_ITEM(__pyx_t_9, 0, __pyx_t_8);
          __Pyx_GIVEREF(__pyx_t_13);
          PyTuple_SET_ITEM(__pyx_t_9, 1, __pyx_t_13);
          __pyx_t_8 = 0;
          __pyx_t_13 = 0;
          __pyx_t_15 = __Pyx_PyList_Append(__pyx_v_final_tokens, __pyx_t_9); if (unlikely(__pyx_t_15 == ((int)-1))) __PYX_ERR(0, 748, __pyx_L1_error)
          __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;

          /* "spacy/tokenizer.pyx":747
 *                     i += 1
 *                 else:
 *                     for j, orth in enumerate(exc):             # <<<<<<<<<<<<<<
 *                         final_tokens.append((f"SPECIAL-{j + 1}", self.vocab.strings[orth]))
 *                     i += len(span)
 */
        }
        __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
        __Pyx_DECREF(__pyx_t_14); __pyx_t_14 = 0;

        /* "spacy/tokenizer.pyx":749
 *                     for j, orth in enumerate(exc):
 *                         final_tokens.append((f"SPECIAL-{j + 1}", self.vocab.strings[orth]))
 *                     i += len(span)             # <<<<<<<<<<<<<<
 *             else:
 *                 final_tokens.append(tokens[i])
 */
        __pyx_t_6 = PyObject_Length(__pyx_v_span); if (unlikely(__pyx_t_6 == ((Py_ssize_t)-1))) __PYX_ERR(0, 749, __pyx_L1_error)
        __pyx_t_14 = PyInt_FromSsize_t(__pyx_t_6); if (unlikely(!__pyx_t_14)) __PYX_ERR(0, 749, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_14);
        __pyx_t_1 = PyNumber_InPlaceAdd(__pyx_v_i, __pyx_t_14); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 749, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_DECREF(__pyx_t_14); __pyx_t_14 = 0;
        __Pyx_DECREF_SET(__pyx_v_i, __pyx_t_1);
        __pyx_t_1 = 0;
      }
      __pyx_L64:;

      /* "spacy/tokenizer.pyx":737
 *         spans_by_start = {s.start: s for s in spans}
 *         while i < len(tokens):
 *             if i in spans_by_start:             # <<<<<<<<<<<<<<
 *                 span = spans_by_start[i]
 *                 exc = [d[ORTH] for d in special_cases[span.label_]]
 */
      goto __pyx_L61;
    }

    /* "spacy/tokenizer.pyx":751
 *                     i += len(span)
 *             else:
 *                 final_tokens.append(tokens[i])             # <<<<<<<<<<<<<<
 *                 i += 1
 *         return final_tokens
 */
    /*else*/ {
      __pyx_t_1 = __Pyx_PyObject_GetItem(__pyx_v_tokens, __pyx_v_i); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 751, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __pyx_t_15 = __Pyx_PyList_Append(__pyx_v_final_tokens, __pyx_t_1); if (unlikely(__pyx_t_15 == ((int)-1))) __PYX_ERR(0, 751, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

      /* "spacy/tokenizer.pyx":752
 *             else:
 *                 final_tokens.append(tokens[i])
 *                 i += 1             # <<<<<<<<<<<<<<
 *         return final_tokens
 * 
 */
      __pyx_t_1 = __Pyx_PyInt_AddObjC(__pyx_v_i, __pyx_int_1, 1, 1, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 752, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF_SET(__pyx_v_i, __pyx_t_1);
      __pyx_t_1 = 0;
    }
    __pyx_L61:;
  }

  /* "spacy/tokenizer.pyx":753
 *                 final_tokens.append(tokens[i])
 *                 i += 1
 *         return final_tokens             # <<<<<<<<<<<<<<
 * 
 *     def score(self, examples, **kwargs):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v_final_tokens);
  __pyx_r = __pyx_v_final_tokens;
  goto __pyx_L0;

  /* "spacy/tokenizer.pyx":629
 *         self._load_special_cases(self._rules)
 * 
 *     def explain(self, text):             # <<<<<<<<<<<<<<
 *         """A debugging tokenizer that provides information about which
 *         tokenizer rule or pattern was matched for each token. The tokens
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_XDECREF(__pyx_t_9);
  __Pyx_XDECREF(__pyx_t_13);
  __Pyx_XDECREF(__pyx_t_14);
  __Pyx_AddTraceback("spacy.tokenizer.Tokenizer.explain", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_prefix_search);
  __Pyx_XDECREF(__pyx_v_suffix_search);
  __Pyx_XDECREF(__pyx_v_infix_finditer);
  __Pyx_XDECREF(__pyx_v_token_match);
  __Pyx_XDECREF(__pyx_v_url_match);
  __Pyx_XDECREF(__pyx_v_orth);
  __Pyx_XDECREF(__pyx_v_special_tokens);
  __Pyx_XDECREF(__pyx_v_tokens);
  __Pyx_XDECREF(__pyx_v_suffixes);
  __Pyx_XDECREF(__pyx_v_split);
  __Pyx_XDECREF(__pyx_v_infixes);
  __Pyx_XDECREF(__pyx_v_offset);
  __Pyx_XDECREF(__pyx_v_match);
  __Pyx_XDECREF(__pyx_v_words);
  __Pyx_XDECREF(__pyx_v_spaces);
  __Pyx_XDECREF(__pyx_v_t_words);
  __Pyx_XDECREF(__pyx_v_t_spaces);
  __Pyx_XDECREF(__pyx_v_word);
  __Pyx_XDECREF(__pyx_v_space);
  __Pyx_XDECREF((PyObject *)__pyx_v_doc);
  __Pyx_XDECREF(__pyx_v_matches);
  __Pyx_XDECREF(__pyx_v_spans);
  __Pyx_XDECREF(__pyx_v_i);
  __Pyx_XDECREF(__pyx_v_final_tokens);
  __Pyx_XDECREF(__pyx_v_spans_by_start);
  __Pyx_XDECREF(__pyx_v_span);
  __Pyx_XDECREF(__pyx_v_exc);
  __Pyx_XDECREF(__pyx_v_j);
  __Pyx_XDECREF(__pyx_v_special_token);
  __Pyx_XDECREF(__pyx_gb_5spacy_9tokenizer_9Tokenizer_7explain_2generator1);
  __Pyx_XDECREF(__pyx_gb_5spacy_9tokenizer_9Tokenizer_7explain_5generator2);
  __Pyx_XDECREF(__pyx_gb_5spacy_9tokenizer_9Tokenizer_7explain_8generator3);
  __Pyx_XDECREF(__pyx_v_t);
  __Pyx_XDECREF(__pyx_v_m_id);
  __Pyx_XDECREF(__pyx_v_s);
  __Pyx_XDECREF(__pyx_v_e);
  __Pyx_XDECREF(__pyx_8genexpr3__pyx_v_s);
  __Pyx_XDECREF(__pyx_v_d);
  __Pyx_DECREF(((PyObject *)__pyx_cur_scope));
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "spacy/tokenizer.pyx":755
 *         return final_tokens
 * 
 *     def score(self, examples, **kwargs):             # <<<<<<<<<<<<<<
 *         validate_examples(examples, "Tokenizer.score")
 *         return Scorer.score_tokenization(examples)
 */

/* Python wrapper */
static PyObject *__pyx_pw_5spacy_9tokenizer_9Tokenizer_32score(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static char __pyx_doc_5spacy_9tokenizer_9Tokenizer_31score[] = "Tokenizer.score(self, examples, **kwargs)";
static PyMethodDef __pyx_mdef_5spacy_9tokenizer_9Tokenizer_32score = {"score", (PyCFunction)(void*)(PyCFunctionWithKeywords)__pyx_pw_5spacy_9tokenizer_9Tokenizer_32score, METH_VARARGS|METH_KEYWORDS, __pyx_doc_5spacy_9tokenizer_9Tokenizer_31score};
static PyObject *__pyx_pw_5spacy_9tokenizer_9Tokenizer_32score(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_examples = 0;
  CYTHON_UNUSED PyObject *__pyx_v_kwargs = 0;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("score (wrapper)", 0);
  __pyx_v_kwargs = PyDict_New(); if (unlikely(!__pyx_v_kwargs)) return NULL;
  __Pyx_GOTREF(__pyx_v_kwargs);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_examples,0};
    PyObject* values[1] = {0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_examples)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, __pyx_v_kwargs, values, pos_args, "score") < 0)) __PYX_ERR(0, 755, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 1) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
    }
    __pyx_v_examples = values[0];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("score", 1, 1, 1, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 755, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_DECREF(__pyx_v_kwargs); __pyx_v_kwargs = 0;
  __Pyx_AddTraceback("spacy.tokenizer.Tokenizer.score", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5spacy_9tokenizer_9Tokenizer_31score(((struct __pyx_obj_5spacy_9tokenizer_Tokenizer *)__pyx_v_self), __pyx_v_examples, __pyx_v_kwargs);

  /* function exit code */
  __Pyx_XDECREF(__pyx_v_kwargs);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5spacy_9tokenizer_9Tokenizer_31score(CYTHON_UNUSED struct __pyx_obj_5spacy_9tokenizer_Tokenizer *__pyx_v_self, PyObject *__pyx_v_examples, CYTHON_UNUSED PyObject *__pyx_v_kwargs) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("score", 0);

  /* "spacy/tokenizer.pyx":756
 * 
 *     def score(self, examples, **kwargs):
 *         validate_examples(examples, "Tokenizer.score")             # <<<<<<<<<<<<<<
 *         return Scorer.score_tokenization(examples)
 * 
 */
  __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_n_s_validate_examples); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 756, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = NULL;
  __pyx_t_4 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
      __pyx_t_4 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_2)) {
    PyObject *__pyx_temp[3] = {__pyx_t_3, __pyx_v_examples, __pyx_kp_s_Tokenizer_score};
    __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_2, __pyx_temp+1-__pyx_t_4, 2+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 756, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_2)) {
    PyObject *__pyx_temp[3] = {__pyx_t_3, __pyx_v_examples, __pyx_kp_s_Tokenizer_score};
    __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_2, __pyx_temp+1-__pyx_t_4, 2+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 756, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  {
    __pyx_t_5 = PyTuple_New(2+__pyx_t_4); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 756, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    if (__pyx_t_3) {
      __Pyx_GIVEREF(__pyx_t_3); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_3); __pyx_t_3 = NULL;
    }
    __Pyx_INCREF(__pyx_v_examples);
    __Pyx_GIVEREF(__pyx_v_examples);
    PyTuple_SET_ITEM(__pyx_t_5, 0+__pyx_t_4, __pyx_v_examples);
    __Pyx_INCREF(__pyx_kp_s_Tokenizer_score);
    __Pyx_GIVEREF(__pyx_kp_s_Tokenizer_score);
    PyTuple_SET_ITEM(__pyx_t_5, 1+__pyx_t_4, __pyx_kp_s_Tokenizer_score);
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_2, __pyx_t_5, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 756, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  }
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "spacy/tokenizer.pyx":757
 *     def score(self, examples, **kwargs):
 *         validate_examples(examples, "Tokenizer.score")
 *         return Scorer.score_tokenization(examples)             # <<<<<<<<<<<<<<
 * 
 *     def to_disk(self, path, **kwargs):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_n_s_Scorer); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 757, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_score_tokenization); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 757, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = NULL;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_5))) {
    __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_5);
    if (likely(__pyx_t_2)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
      __Pyx_INCREF(__pyx_t_2);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_5, function);
    }
  }
  __pyx_t_1 = (__pyx_t_2) ? __Pyx_PyObject_Call2Args(__pyx_t_5, __pyx_t_2, __pyx_v_examples) : __Pyx_PyObject_CallOneArg(__pyx_t_5, __pyx_v_examples);
  __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 757, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "spacy/tokenizer.pyx":755
 *         return final_tokens
 * 
 *     def score(self, examples, **kwargs):             # <<<<<<<<<<<<<<
 *         validate_examples(examples, "Tokenizer.score")
 *         return Scorer.score_tokenization(examples)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("spacy.tokenizer.Tokenizer.score", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "spacy/tokenizer.pyx":759
 *         return Scorer.score_tokenization(examples)
 * 
 *     def to_disk(self, path, **kwargs):             # <<<<<<<<<<<<<<
 *         """Save the current state to a directory.
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_5spacy_9tokenizer_9Tokenizer_34to_disk(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static char __pyx_doc_5spacy_9tokenizer_9Tokenizer_33to_disk[] = "Tokenizer.to_disk(self, path, **kwargs)\nSave the current state to a directory.\n\n        path (str / Path): A path to a directory, which will be created if\n            it doesn't exist.\n        exclude (list): String names of serialization fields to exclude.\n\n        DOCS: https://spacy.io/api/tokenizer#to_disk\n        ";
static PyMethodDef __pyx_mdef_5spacy_9tokenizer_9Tokenizer_34to_disk = {"to_disk", (PyCFunction)(void*)(PyCFunctionWithKeywords)__pyx_pw_5spacy_9tokenizer_9Tokenizer_34to_disk, METH_VARARGS|METH_KEYWORDS, __pyx_doc_5spacy_9tokenizer_9Tokenizer_33to_disk};
static PyObject *__pyx_pw_5spacy_9tokenizer_9Tokenizer_34to_disk(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_path = 0;
  PyObject *__pyx_v_kwargs = 0;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("to_disk (wrapper)", 0);
  __pyx_v_kwargs = PyDict_New(); if (unlikely(!__pyx_v_kwargs)) return NULL;
  __Pyx_GOTREF(__pyx_v_kwargs);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_path,0};
    PyObject* values[1] = {0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_path)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, __pyx_v_kwargs, values, pos_args, "to_disk") < 0)) __PYX_ERR(0, 759, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 1) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
    }
    __pyx_v_path = values[0];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("to_disk", 1, 1, 1, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 759, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_DECREF(__pyx_v_kwargs); __pyx_v_kwargs = 0;
  __Pyx_AddTraceback("spacy.tokenizer.Tokenizer.to_disk", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5spacy_9tokenizer_9Tokenizer_33to_disk(((struct __pyx_obj_5spacy_9tokenizer_Tokenizer *)__pyx_v_self), __pyx_v_path, __pyx_v_kwargs);

  /* function exit code */
  __Pyx_XDECREF(__pyx_v_kwargs);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5spacy_9tokenizer_9Tokenizer_33to_disk(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *__pyx_v_self, PyObject *__pyx_v_path, PyObject *__pyx_v_kwargs) {
  PyObject *__pyx_v_file_ = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  PyObject *__pyx_t_8 = NULL;
  PyObject *__pyx_t_9 = NULL;
  PyObject *__pyx_t_10 = NULL;
  int __pyx_t_11;
  int __pyx_t_12;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("to_disk", 0);
  __Pyx_INCREF(__pyx_v_path);

  /* "spacy/tokenizer.pyx":768
 *         DOCS: https://spacy.io/api/tokenizer#to_disk
 *         """
 *         path = util.ensure_path(path)             # <<<<<<<<<<<<<<
 *         with path.open("wb") as file_:
 *             file_.write(self.to_bytes(**kwargs))
 */
  __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_n_s_util); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 768, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_ensure_path); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 768, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = NULL;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
    __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_3);
    if (likely(__pyx_t_2)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
      __Pyx_INCREF(__pyx_t_2);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_3, function);
    }
  }
  __pyx_t_1 = (__pyx_t_2) ? __Pyx_PyObject_Call2Args(__pyx_t_3, __pyx_t_2, __pyx_v_path) : __Pyx_PyObject_CallOneArg(__pyx_t_3, __pyx_v_path);
  __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 768, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF_SET(__pyx_v_path, __pyx_t_1);
  __pyx_t_1 = 0;

  /* "spacy/tokenizer.pyx":769
 *         """
 *         path = util.ensure_path(path)
 *         with path.open("wb") as file_:             # <<<<<<<<<<<<<<
 *             file_.write(self.to_bytes(**kwargs))
 * 
 */
  /*with:*/ {
    __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_path, __pyx_n_s_open); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 769, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_2 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_3))) {
      __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_3);
      if (likely(__pyx_t_2)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
        __Pyx_INCREF(__pyx_t_2);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_3, function);
      }
    }
    __pyx_t_1 = (__pyx_t_2) ? __Pyx_PyObject_Call2Args(__pyx_t_3, __pyx_t_2, __pyx_n_s_wb) : __Pyx_PyObject_CallOneArg(__pyx_t_3, __pyx_n_s_wb);
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 769, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_t_4 = __Pyx_PyObject_LookupSpecial(__pyx_t_1, __pyx_n_s_exit); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 769, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_2 = __Pyx_PyObject_LookupSpecial(__pyx_t_1, __pyx_n_s_enter); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 769, __pyx_L3_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_5 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
      __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_2);
      if (likely(__pyx_t_5)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
        __Pyx_INCREF(__pyx_t_5);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_2, function);
      }
    }
    __pyx_t_3 = (__pyx_t_5) ? __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_5) : __Pyx_PyObject_CallNoArg(__pyx_t_2);
    __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
    if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 769, __pyx_L3_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_2 = __pyx_t_3;
    __pyx_t_3 = 0;
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    /*try:*/ {
      {
        __Pyx_PyThreadState_declare
        __Pyx_PyThreadState_assign
        __Pyx_ExceptionSave(&__pyx_t_6, &__pyx_t_7, &__pyx_t_8);
        __Pyx_XGOTREF(__pyx_t_6);
        __Pyx_XGOTREF(__pyx_t_7);
        __Pyx_XGOTREF(__pyx_t_8);
        /*try:*/ {
          __pyx_v_file_ = __pyx_t_2;
          __pyx_t_2 = 0;

          /* "spacy/tokenizer.pyx":770
 *         path = util.ensure_path(path)
 *         with path.open("wb") as file_:
 *             file_.write(self.to_bytes(**kwargs))             # <<<<<<<<<<<<<<
 * 
 *     def from_disk(self, path, *, exclude=tuple()):
 */
          __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_file_, __pyx_n_s_write); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 770, __pyx_L7_error)
          __Pyx_GOTREF(__pyx_t_1);
          __pyx_t_3 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_to_bytes); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 770, __pyx_L7_error)
          __Pyx_GOTREF(__pyx_t_3);
          __pyx_t_5 = PyDict_Copy(__pyx_v_kwargs); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 770, __pyx_L7_error)
          __Pyx_GOTREF(__pyx_t_5);
          __pyx_t_9 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_empty_tuple, __pyx_t_5); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 770, __pyx_L7_error)
          __Pyx_GOTREF(__pyx_t_9);
          __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
          __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
          __pyx_t_5 = NULL;
          if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_1))) {
            __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_1);
            if (likely(__pyx_t_5)) {
              PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_1);
              __Pyx_INCREF(__pyx_t_5);
              __Pyx_INCREF(function);
              __Pyx_DECREF_SET(__pyx_t_1, function);
            }
          }
          __pyx_t_2 = (__pyx_t_5) ? __Pyx_PyObject_Call2Args(__pyx_t_1, __pyx_t_5, __pyx_t_9) : __Pyx_PyObject_CallOneArg(__pyx_t_1, __pyx_t_9);
          __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
          __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
          if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 770, __pyx_L7_error)
          __Pyx_GOTREF(__pyx_t_2);
          __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
          __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

          /* "spacy/tokenizer.pyx":769
 *         """
 *         path = util.ensure_path(path)
 *         with path.open("wb") as file_:             # <<<<<<<<<<<<<<
 *             file_.write(self.to_bytes(**kwargs))
 * 
 */
        }
        __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
        __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
        __Pyx_XDECREF(__pyx_t_8); __pyx_t_8 = 0;
        goto __pyx_L12_try_end;
        __pyx_L7_error:;
        __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
        __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
        __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
        __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
        __Pyx_XDECREF(__pyx_t_9); __pyx_t_9 = 0;
        /*except:*/ {
          __Pyx_AddTraceback("spacy.tokenizer.Tokenizer.to_disk", __pyx_clineno, __pyx_lineno, __pyx_filename);
          if (__Pyx_GetException(&__pyx_t_2, &__pyx_t_1, &__pyx_t_9) < 0) __PYX_ERR(0, 769, __pyx_L9_except_error)
          __Pyx_GOTREF(__pyx_t_2);
          __Pyx_GOTREF(__pyx_t_1);
          __Pyx_GOTREF(__pyx_t_9);
          __pyx_t_5 = PyTuple_Pack(3, __pyx_t_2, __pyx_t_1, __pyx_t_9); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 769, __pyx_L9_except_error)
          __Pyx_GOTREF(__pyx_t_5);
          __pyx_t_10 = __Pyx_PyObject_Call(__pyx_t_4, __pyx_t_5, NULL);
          __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
          __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
          if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 769, __pyx_L9_except_error)
          __Pyx_GOTREF(__pyx_t_10);
          __pyx_t_11 = __Pyx_PyObject_IsTrue(__pyx_t_10);
          __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
          if (__pyx_t_11 < 0) __PYX_ERR(0, 769, __pyx_L9_except_error)
          __pyx_t_12 = ((!(__pyx_t_11 != 0)) != 0);
          if (__pyx_t_12) {
            __Pyx_GIVEREF(__pyx_t_2);
            __Pyx_GIVEREF(__pyx_t_1);
            __Pyx_XGIVEREF(__pyx_t_9);
            __Pyx_ErrRestoreWithState(__pyx_t_2, __pyx_t_1, __pyx_t_9);
            __pyx_t_2 = 0; __pyx_t_1 = 0; __pyx_t_9 = 0; 
            __PYX_ERR(0, 769, __pyx_L9_except_error)
          }
          __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
          __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
          __Pyx_XDECREF(__pyx_t_9); __pyx_t_9 = 0;
          goto __pyx_L8_exception_handled;
        }
        __pyx_L9_except_error:;
        __Pyx_XGIVEREF(__pyx_t_6);
        __Pyx_XGIVEREF(__pyx_t_7);
        __Pyx_XGIVEREF(__pyx_t_8);
        __Pyx_ExceptionReset(__pyx_t_6, __pyx_t_7, __pyx_t_8);
        goto __pyx_L1_error;
        __pyx_L8_exception_handled:;
        __Pyx_XGIVEREF(__pyx_t_6);
        __Pyx_XGIVEREF(__pyx_t_7);
        __Pyx_XGIVEREF(__pyx_t_8);
        __Pyx_ExceptionReset(__pyx_t_6, __pyx_t_7, __pyx_t_8);
        __pyx_L12_try_end:;
      }
    }
    /*finally:*/ {
      /*normal exit:*/{
        if (__pyx_t_4) {
          __pyx_t_8 = __Pyx_PyObject_Call(__pyx_t_4, __pyx_tuple__4, NULL);
          __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
          if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 769, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_8);
          __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
        }
        goto __pyx_L6;
      }
      __pyx_L6:;
    }
    goto __pyx_L16;
    __pyx_L3_error:;
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    goto __pyx_L1_error;
    __pyx_L16:;
  }

  /* "spacy/tokenizer.pyx":759
 *         return Scorer.score_tokenization(examples)
 * 
 *     def to_disk(self, path, **kwargs):             # <<<<<<<<<<<<<<
 *         """Save the current state to a directory.
 * 
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_9);
  __Pyx_AddTraceback("spacy.tokenizer.Tokenizer.to_disk", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_file_);
  __Pyx_XDECREF(__pyx_v_path);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "spacy/tokenizer.pyx":772
 *             file_.write(self.to_bytes(**kwargs))
 * 
 *     def from_disk(self, path, *, exclude=tuple()):             # <<<<<<<<<<<<<<
 *         """Loads state from a directory. Modifies the object in place and
 *         returns it.
 */

/* Python wrapper */
static PyObject *__pyx_pw_5spacy_9tokenizer_9Tokenizer_36from_disk(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static char __pyx_doc_5spacy_9tokenizer_9Tokenizer_35from_disk[] = "Tokenizer.from_disk(self, path, *, exclude=tuple())\nLoads state from a directory. Modifies the object in place and\n        returns it.\n\n        path (str / Path): A path to a directory.\n        exclude (list): String names of serialization fields to exclude.\n        RETURNS (Tokenizer): The modified `Tokenizer` object.\n\n        DOCS: https://spacy.io/api/tokenizer#from_disk\n        ";
static PyMethodDef __pyx_mdef_5spacy_9tokenizer_9Tokenizer_36from_disk = {"from_disk", (PyCFunction)(void*)(PyCFunctionWithKeywords)__pyx_pw_5spacy_9tokenizer_9Tokenizer_36from_disk, METH_VARARGS|METH_KEYWORDS, __pyx_doc_5spacy_9tokenizer_9Tokenizer_35from_disk};
static PyObject *__pyx_pw_5spacy_9tokenizer_9Tokenizer_36from_disk(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_path = 0;
  PyObject *__pyx_v_exclude = 0;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("from_disk (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_path,&__pyx_n_s_exclude,0};
    PyObject* values[2] = {0,0};
    values[1] = __pyx_k__5;
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_path)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
      }
      if (kw_args == 1) {
        const Py_ssize_t index = 1;
        PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, *__pyx_pyargnames[index]);
        if (value) { values[index] = value; kw_args--; }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "from_disk") < 0)) __PYX_ERR(0, 772, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 1) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
    }
    __pyx_v_path = values[0];
    __pyx_v_exclude = values[1];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("from_disk", 1, 1, 1, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 772, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("spacy.tokenizer.Tokenizer.from_disk", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5spacy_9tokenizer_9Tokenizer_35from_disk(((struct __pyx_obj_5spacy_9tokenizer_Tokenizer *)__pyx_v_self), __pyx_v_path, __pyx_v_exclude);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5spacy_9tokenizer_9Tokenizer_35from_disk(struct __pyx_obj_5spacy_9tokenizer_Tokenizer *__pyx_v_self, PyObject *__pyx_v_path, PyObject *__pyx_v_exclude) {
  PyObject *__pyx_v_file_ = NULL;
  PyObject *__pyx_v_bytes_data = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  PyObject *__pyx_t_8 = NULL;
  PyObject *__pyx_t_9 = NULL;
  int __pyx_t_10;
  int __pyx_t_11;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("from_disk", 0);
  __Pyx_INCREF(__pyx_v_path);

  /* "spacy/tokenizer.pyx":782
 *         DOCS: https://spacy.io/api/tokenizer#from_disk
 *         """
 *         path = util.ensure_path(path)             # <<<<<<<<<<<<<<
 *         with path.open("rb") as file_:
 *             bytes_data = file_.read()
 */
  __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_n_s_util); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 782, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_ensure_path); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 782, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = NULL;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check